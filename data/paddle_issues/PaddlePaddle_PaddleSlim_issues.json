[
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 67,
        "title": "[DocumentTranslation]search space",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/docs/search_space.md",
        "state": "closed",
        "user": "ceci3",
        "closed_by": "ceci3",
        "created_at": "2020-02-04T02:38:44+00:00",
        "updated_at": "2020-02-10T14:33:40+00:00",
        "closed_at": "2020-02-10T14:33:40+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 61,
        "title": "[DocumentTranslation]tutorials-prune",
        "body": "",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-02-03T03:17:28+00:00",
        "updated_at": "2020-02-10T13:30:24+00:00",
        "closed_at": "2020-02-10T13:30:24+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 66,
        "title": "[DocumentTranslation]tutorials-sanas",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/docs/tutorials/nas_demo.md",
        "state": "closed",
        "user": "ceci3",
        "closed_by": "ceci3",
        "created_at": "2020-02-04T02:37:33+00:00",
        "updated_at": "2020-02-10T14:33:34+00:00",
        "closed_at": "2020-02-10T14:33:34+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 60,
        "title": "[DocumentTranslation]API-sanas",
        "body": "https://paddlepaddle.github.io/PaddleSlim/api/nas_api/",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "ceci3",
        "created_at": "2020-02-03T03:16:21+00:00",
        "updated_at": "2020-02-10T14:33:27+00:00",
        "closed_at": "2020-02-10T14:33:27+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 57,
        "title": "[DocumentTranslation]API-prune",
        "body": "https://paddlepaddle.github.io/PaddleSlim/api/prune_api/",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-02-03T03:10:46+00:00",
        "updated_at": "2020-02-10T02:54:57+00:00",
        "closed_at": "2020-02-10T02:54:57+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 58,
        "title": "[DocumentTranslation]API-distillation",
        "body": "https://paddlepaddle.github.io/PaddleSlim/api/single_distiller_api/",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-02-03T03:14:02+00:00",
        "updated_at": "2020-02-11T03:17:37+00:00",
        "closed_at": "2020-02-11T03:17:37+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 62,
        "title": "[DocumentTranslation]tutorials-distillation",
        "body": "",
        "state": "closed",
        "user": "baiyfbupt",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-02-03T07:42:54+00:00",
        "updated_at": "2020-02-10T07:59:58+00:00",
        "closed_at": "2020-02-10T07:59:58+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 26,
        "title": "在aistudio上运行sa_nas_mobilenetv2出现错误",
        "body": "运行时输出如下：\r\naistudio@jupyter-7623-23204:~/work/PaddleSlim/demo/nas$ python sa_nas_mobilenetv2.py --class_dim 10 --lr 0.01\r\nNamespace(batch_size=256, class_dim=10, data='cifar10', is_server=True, lr=0.01, search_steps=100, use_gpu=True)\r\n2020-01-06 16:57:17,903-INFO: range table: ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [7, 5, 8, 6, 2, 5, 8, 6, 2, 5, 8, 6, 2, 5, 10, 6, 2, 5, 10, 6, 2, 5, 12, 6, 2])\r\n2020-01-06 16:57:17,903-INFO: ControllerServer - listen on: [172.25.33.199:8989]\r\n2020-01-06 16:57:17,904-INFO: Controller Server run...\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py\", line 45, in convert_to_list\r\n    value_list = list(value)\r\nTypeError: 'numpy.int64' object is not iterable\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"sa_nas_mobilenetv2.py\", line 318, in <module>\r\n    search_mobilenetv2(config, args, image_size, is_server=args.is_server)\r\n  File \"sa_nas_mobilenetv2.py\", line 92, in search_mobilenetv2\r\n    train_program, startup_program, image_shape, archs, args)\r\n  File \"sa_nas_mobilenetv2.py\", line 49, in build_program\r\n    output = archs(data)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.1-py3.7.egg/paddleslim/nas/search_space/mobilenetv2.py\", line 186, in net_arch\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.1-py3.7.egg/paddleslim/nas/search_space/mobilenetv2.py\", line 311, in _invresi_blocks\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.1-py3.7.egg/paddleslim/nas/search_space/mobilenetv2.py\", line 271, in _inverted_residual_unit\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.1-py3.7.egg/paddleslim/nas/search_space/base_layer.py\", line 52, in conv_bn_layer\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 2721, in conv2d\r\n    filter_size = utils.convert_to_list(filter_size, 2, 'filter_size')\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py\", line 49, in convert_to_list\r\n    value))\r\nValueError: The filter_size's type must be list or tuple. Received: 3\r\n\r\n请问怎么处理下？谢谢\r\n另外， block_sa_nas_mobilenetv2.py 运行也是这个错误",
        "state": "closed",
        "user": "chunyisong",
        "closed_by": "chunyisong",
        "created_at": "2020-01-06T09:00:40+00:00",
        "updated_at": "2020-01-10T00:09:16+00:00",
        "closed_at": "2020-01-10T00:09:16+00:00",
        "comments_count": [
            "ceci3",
            "chunyisong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 59,
        "title": "[DocumentTranslation]API-quantization",
        "body": "https://paddlepaddle.github.io/PaddleSlim/api/quantization_api/",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-02-03T03:14:41+00:00",
        "updated_at": "2020-02-10T12:49:51+00:00",
        "closed_at": "2020-02-10T12:49:51+00:00",
        "comments_count": [
            "slf12"
        ],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 68,
        "title": "[DocumentTranslation] tutorials-quantization",
        "body": "https://paddlepaddle.github.io/PaddleSlim/tutorials/quant_post_demo/\r\nhttps://paddlepaddle.github.io/PaddleSlim/tutorials/quant_aware_demo/\r\nhttps://paddlepaddle.github.io/PaddleSlim/tutorials/quant_embedding_demo/",
        "state": "closed",
        "user": "slf12",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-02-04T02:53:38+00:00",
        "updated_at": "2020-02-10T08:02:21+00:00",
        "closed_at": "2020-02-10T08:02:21+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 71,
        "title": "[DocumentTranslation]API-analysis",
        "body": "https://paddlepaddle.github.io/PaddleSlim/api/analysis_api/",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-02-04T04:01:39+00:00",
        "updated_at": "2020-02-10T02:54:50+00:00",
        "closed_at": "2020-02-10T02:54:50+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 73,
        "title": "[DocumentTranslation]home page",
        "body": "https://paddlepaddle.github.io/PaddleSlim/",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-02-04T04:08:04+00:00",
        "updated_at": "2020-02-11T08:06:16+00:00",
        "closed_at": "2020-02-11T08:06:16+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 72,
        "title": "[DocumentTranslation]API-table_latency",
        "body": "https://paddlepaddle.github.io/PaddleSlim/table_latency/",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "ceci3",
        "created_at": "2020-02-04T04:04:02+00:00",
        "updated_at": "2020-03-03T09:29:33+00:00",
        "closed_at": "2020-03-03T09:29:33+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 74,
        "title": "[DocumentTranslation]model zoo",
        "body": "https://paddlepaddle.github.io/PaddleSlim/model_zoo/",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "baiyfbupt",
        "created_at": "2020-02-04T04:08:32+00:00",
        "updated_at": "2020-02-13T09:41:20+00:00",
        "closed_at": "2020-02-13T09:41:20+00:00",
        "comments_count": [],
        "labels": [
            "documentation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 95,
        "title": "安装时错误",
        "body": "使用从clone代码安装会报错：\r\n```\r\nfrom paddle.fluid.contrib.slim.quantization import PostTrainingQuantization\r\nImportError: cannot import name 'PostTrainingQuantization'\r\n\r\n```\r\n使用pip安装不会报错，但运行代码会报上述错误",
        "state": "closed",
        "user": "zhizunbao-y",
        "closed_by": "zhizunbao-y",
        "created_at": "2020-02-09T05:02:14+00:00",
        "updated_at": "2020-02-21T03:36:12+00:00",
        "closed_at": "2020-02-12T14:52:21+00:00",
        "comments_count": [
            "slf12",
            "zhizunbao-y",
            "slf12",
            "wanghaoshuang",
            "CheungBH",
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 107,
        "title": "如何理解敏感度裁切中的greedy_prune和普通的prune区别？",
        "body": "1.如提问\r\n2.下列代码中 ，#标出的部分有何意义？为什么要乘2？\r\n```\r\ndef flops_sensitivity(program,\r\n                      place,\r\n                      param_names,\r\n                      eval_func,\r\n                      sensitivities_file=None,\r\n                      pruned_flops_rate=0.1):\r\n\r\n    assert (1.0 / len(param_names) > pruned_flops_rate)\r\n\r\n    scope = fluid.global_scope()\r\n    graph = GraphWrapper(program)\r\n    sensitivities = load_sensitivities(sensitivities_file)\r\n\r\n    for name in param_names:\r\n        if name not in sensitivities:\r\n            sensitivities[name] = {}\r\n    base_flops = flops(program)\r\n    target_pruned_flops = base_flops * pruned_flops_rate\r\n\r\n    pruner = Pruner()\r\n    baseline = None\r\n    for name in sensitivities:\r\n\r\n        pruned_program, _, _ = pruner.prune(\r\n            program=graph.program,\r\n            scope=None,\r\n            params=[name],\r\n            ratios=[0.5],\r\n            place=None,\r\n            lazy=False,\r\n            only_graph=True)\r\n       ################################################\r\n        param_flops = (base_flops - flops(pruned_program)) * 2\r\n        channel_size = graph.var(name).shape()[0]\r\n        pruned_ratio = target_pruned_flops / float(param_flops)\r\n       ################################################\r\n        pruned_ratio = round(pruned_ratio, 3)\r\n        pruned_size = round(pruned_ratio * channel_size)\r\n        pruned_ratio = 1 if pruned_size >= channel_size else pruned_ratio\r\n\r\n        if len(sensitivities[name].keys()) > 0:\r\n            _logger.debug(\r\n                '{} exist; pruned ratio: {}; excepted ratio: {}'.format(\r\n                    name, sensitivities[name].keys(), pruned_ratio))\r\n            continue\r\n        if baseline is None:\r\n            baseline = eval_func(graph.program)\r\n        param_backup = {}\r\n        pruner = Pruner()\r\n        _logger.info(\"sensitive - param: {}; ratios: {}\".format(name,\r\n                                                                pruned_ratio))\r\n        loss = 1\r\n        if pruned_ratio < 1:\r\n            pruned_program = pruner.prune(\r\n                program=graph.program,\r\n                scope=scope,\r\n                params=[name],\r\n                ratios=[pruned_ratio],\r\n                place=place,\r\n                lazy=True,\r\n                only_graph=False,\r\n                param_backup=param_backup)\r\n            pruned_metric = eval_func(pruned_program)\r\n            loss = (baseline - pruned_metric) / baseline\r\n        _logger.info(\"pruned param: {}; {}; loss={}\".format(name, pruned_ratio,\r\n                                                            loss))\r\n        sensitivities[name][pruned_ratio] = loss\r\n        _save_sensitivities(sensitivities, sensitivities_file)\r\n\r\n        # restore pruned parameters\r\n        for param_name in param_backup.keys():\r\n            param_t = scope.find_var(param_name).get_tensor()\r\n            param_t.set(param_backup[param_name], place)\r\n    return sensitivities\r\n\r\n```\r\n3.下列代码中min_loss和max_loss初始值均为0，会导致while循环不执行\r\n```\r\ndef get_ratios_by_sensitive(self, sensitivities, pruned_flops,\r\n                                eval_program):\r\n        \"\"\"\r\n        Search a group of ratios for pruning target flops.\r\n        Args:\r\n          sensitivities(dict): The sensitivities used to generate a group of pruning ratios. The key of dict\r\n                               is name of parameters to be pruned. The value of dict is a list of tuple with\r\n                               format `(pruned_ratio, accuracy_loss)`.\r\n          pruned_flops(float): The percent of FLOPS to be pruned.\r\n          eval_program(Program): The program whose FLOPS is considered.\r\n        Returns:\r\n          dict: A group of ratios. The key of dict is name of parameters while the value is the ratio to be pruned.\r\n        \"\"\"\r\n\r\n        min_loss = 0.\r\n        max_loss = 0.\r\n        # step 2: Find a group of ratios by binary searching.\r\n        base_flops = flops(eval_program)\r\n        ratios = None\r\n        max_times = 20\r\n        while min_loss < max_loss and max_times > 0:\r\n            loss = (max_loss + min_loss) / 2\r\n            _logger.info(\r\n                '-----------Try pruned ratios while acc loss={}-----------'.\r\n                format(loss))\r\n            ratios = self.get_ratios_by_loss(sensitivities, loss)\r\n            _logger.info('Pruned ratios={}'.format(\r\n                [round(ratio, 3) for ratio in ratios.values()]))\r\n            pruned_program = self._pruner.prune(\r\n                eval_program,\r\n                None,  # scope\r\n                ratios.keys(),\r\n                ratios.values(),\r\n                None,  # place\r\n                only_graph=True)\r\n            pruned_ratio = 1 - (float(flops(pruned_program)) / base_flops)\r\n            _logger.info('Pruned flops: {:.4f}'.format(pruned_ratio))\r\n\r\n            # Check whether current ratios is enough\r\n            if abs(pruned_ratio - pruned_flops) < 0.015:\r\n                break\r\n            if pruned_ratio > pruned_flops:\r\n                max_loss = loss\r\n            else:\r\n                min_loss = loss\r\n            max_times -= 1\r\n        return ratios\r\n```",
        "state": "closed",
        "user": "zhizunbao-y",
        "closed_by": "zhizunbao-y",
        "created_at": "2020-02-12T15:10:05+00:00",
        "updated_at": "2020-02-13T04:49:37+00:00",
        "closed_at": "2020-02-13T04:49:37+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "zhizunbao-y"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 117,
        "title": "加载通道裁剪后的模型，再进行蒸馏报错",
        "body": "```python\r\n    student_program = fluid.Program()\r\n    s_startup = fluid.Program()\r\n    with fluid.program_guard(student_program, s_startup):\r\n        with fluid.unique_name.guard():\r\n            # model definition\r\n           ...\r\n    place = fluid.CUDAPlace(0) if args.use_gpu else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n    load_model(exe, student_program, args.pretrained_model)  #prune.io\r\n    val_program = student_program.clone(for_test=True)\r\n\r\n    teacher_model = models.__dict__[args.teacher_model]()\r\n    teacher_program = fluid.Program()\r\n    t_startup = fluid.Program()\r\n    with fluid.program_guard(teacher_program, t_startup):\r\n        with fluid.unique_name.guard():\r\n            # teacher model definition\r\n           ...\r\n\r\n    exe.run(t_startup)\r\n    if args.teacher_pretrained_model:\r\n        def if_exist(var):\r\n            return os.path.exists(\r\n                os.path.join(args.teacher_pretrained_model, var.name))\r\n        fluid.io.load_vars(\r\n            exe,\r\n            args.teacher_pretrained_model,\r\n            main_program=teacher_program,\r\n            predicate=if_exist)\r\n\r\n    data_name_map = {'images': 'images'}\r\n    merge(teacher_program, student_program, data_name_map, place)\r\n    with fluid.program_guard(student_program, s_startup):\r\n        dist_loss = soft_label_loss(\"teacher_fc_0.tmp_0\", \"fc_0.tmp_0\", student_program)\r\n        loss = avg_cost + dist_loss\r\n        lr, opt = create_optimizer(args)\r\n        opt.minimize(loss)\r\n    exe.run(s_startup)\r\n```\r\n会报以下错误：\r\n```\r\nError: Param and Velocity of MomentumOp should have the same dimension.\r\n  [Hint: Expected param_dim == ctx->GetInputDim(\"Velocity\"), but received param_dim:256 != ctx->GetInputDim(\"Velocity\"):128.] at (/paddle/paddle/fluid/operators/optimizers/momentum_op.h:79)\r\n  [operator < momentum > error]\r\n```\r\n怀疑是exe.run(s_startup)这句代码覆盖了load_model ，但是optimizer又需要初始化，请问如何解决？",
        "state": "closed",
        "user": "zhizunbao-y",
        "closed_by": "zhizunbao-y",
        "created_at": "2020-02-17T17:48:46+00:00",
        "updated_at": "2020-03-04T08:05:08+00:00",
        "closed_at": "2020-03-04T08:05:08+00:00",
        "comments_count": [
            "wanghaoshuang",
            "zhizunbao-y",
            "baiyfbupt",
            "zhizunbao-y",
            "baiyfbupt",
            "zhizunbao-y",
            "zhizunbao-y",
            "wanghaoshuang",
            "zhizunbao-y",
            "baiyfbupt",
            "zhizunbao-y",
            "baiyfbupt",
            "zhizunbao-y",
            "zhizunbao-y",
            "baiyfbupt",
            "zhizunbao-y",
            "baiyfbupt",
            "zhizunbao-y",
            "baiyfbupt",
            "zhizunbao-y",
            "zhizunbao-y"
        ],
        "labels": [
            "distillation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 108,
        "title": "analysis中的model_size计算",
        "body": "该计算中对于模型中bn层，除了scale和offset外，将mean和variance也统计为了参数量，后两者没有经过优化算法优化过，不是学习到的 ，是否应该算作参数量？",
        "state": "closed",
        "user": "zhizunbao-y",
        "closed_by": "zhizunbao-y",
        "created_at": "2020-02-12T15:51:44+00:00",
        "updated_at": "2020-02-18T06:02:22+00:00",
        "closed_at": "2020-02-18T06:02:22+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 174,
        "title": "等大佬们先试水用起来",
        "body": "等大佬们先试水用起来",
        "state": "closed",
        "user": "JensenHJS",
        "closed_by": "JensenHJS",
        "created_at": "2020-03-10T10:42:33+00:00",
        "updated_at": "2020-03-10T10:42:37+00:00",
        "closed_at": "2020-03-10T10:42:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 151,
        "title": "name '_logger' is not defined",
        "body": "使用在线量化训练模型，报错：\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 734, in <module>\r\n    main()\r\n  File \"train.py\", line 730, in main\r\n    train(args)\r\n  File \"train.py\", line 339, in train\r\n    test_prog, place, quant_config, scope=None, for_test=True)\r\n  File \"/home/vis/duyuting/anaconda3/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/quant/quanter.py\", line 132, in quant_aware\r\nNameError: name '_logger' is not defined\r\n环境是paddle1.6 paddleslim是上一个issue给的release版本 我去quanter.py去看了一下确实对_logger没有定义？是有bug？",
        "state": "closed",
        "user": "Cristhine",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-02-25T03:13:00+00:00",
        "updated_at": "2024-02-06T02:57:31+00:00",
        "closed_at": "2024-02-06T02:57:31+00:00",
        "comments_count": [
            "slf12",
            "Cristhine",
            "slf12",
            "Cristhine",
            "slf12",
            "Cristhine",
            "slf12",
            "Cristhine",
            "slf12",
            "Cristhine",
            "slf12",
            "Cristhine",
            "slf12",
            "Cristhine",
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 133,
        "title": "是否支出训练自己的数据集",
        "body": "paddleslim是否支持训练自己的数据集，yolov3_mobilenet_v1_voc_prune下载的一堆权重文件怎么使用？是否有教程或者视频等",
        "state": "closed",
        "user": "jaffe-fly",
        "closed_by": "jaffe-fly",
        "created_at": "2020-02-21T02:50:59+00:00",
        "updated_at": "2020-02-21T11:04:48+00:00",
        "closed_at": "2020-02-21T11:04:48+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "jaffe-fly",
            "wanghaoshuang",
            "wanghaoshuang",
            "jaffe-fly",
            "wanghaoshuang",
            "jaffe-fly"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 118,
        "title": "安装问题",
        "body": "安装不成功，使用pip安装成功后，出现以下问题：\r\n![image](https://user-images.githubusercontent.com/30516196/74702482-20848c00-5245-11ea-8502-e1f27151ad08.png)\r\n使用源码安装，出现以下问题：\r\n![image](https://user-images.githubusercontent.com/30516196/74702526-3d20c400-5245-11ea-9bb5-07bd22648647.png)\r\n另外，给的demo中，尝试运行了多个，结果都无法正常运行，主要是：\r\nsensitive：无法运行，merge_sensitive()报错；\r\nauto_prune：无法运行，报错信息如下\r\n![image](https://user-images.githubusercontent.com/30516196/74734600-d70a6000-5289-11ea-9c11-6007250a124a.png)\r\nsensitive_prune：无法正常运行完。报错信息如下\r\n![image](https://user-images.githubusercontent.com/30516196/74734733-1d5fbf00-528a-11ea-9c69-0e7a73b52a69.png)\r\n几乎给的demo都无法正常运行\r\n",
        "state": "closed",
        "user": "yeliang2258",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-02-18T03:53:20+00:00",
        "updated_at": "2024-02-06T02:57:30+00:00",
        "closed_at": "2024-02-06T02:57:30+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "Cristhine",
            "wanghaoshuang",
            "yeliang2258",
            "Cristhine",
            "wanghaoshuang",
            "Cristhine"
        ],
        "labels": [
            "install"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 175,
        "title": "剪枝例子报错",
        "body": "![image](https://user-images.githubusercontent.com/50724968/76413196-f6e7fc00-63cf-11ea-8abe-a0eba7982a88.png)\r\n",
        "state": "closed",
        "user": "AIpioneer",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-03-11T11:41:47+00:00",
        "updated_at": "2020-03-12T01:48:52+00:00",
        "closed_at": "2020-03-12T01:48:52+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 177,
        "title": "quant_post量化yolov3报错 KeyError: 'stage.3.7.0.conv.weights'",
        "body": "CPU 8\r\nRAM 32GB\r\nGPU v100\r\n显存 16GB\r\n磁盘 100GB\r\n环境配置\r\nPython版本 python3.7\r\n框架版本  PaddlePaddle 1.7.0\r\n@slf12 \r\naistudio@jupyter-115786-193843:~/post_training_quantization_withdata$ sh run_post_training_quanzation.sh \r\n-------------------args----------------------\r\nalgo: KL\r\nbatch_nums: 20\r\nbatch_size: 3000\r\nis_full_quantize: False\r\nmodel_dir: ../work/PaddleDetection_1/yolov3_dark_freeze/mj_yolov3_darknet\r\nmodel_filename: None\r\nparams_filename: None\r\nsave_model_path: yolov3_int8_model\r\nuse_gpu: True\r\n---------------------------------------------\r\nW0314 12:14:31.721148   637 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW0314 12:14:31.725704   637 device_context.cc:245] device: 0, cuDNN Version: 7.3.\r\n2020-03-14 12:14:34,203-INFO: all run batch: 0\r\n2020-03-14 12:14:34,203-INFO: all run batch: 0\r\n2020-03-14 12:14:34,203-INFO: calculate scale factor ...\r\n2020-03-14 12:14:34,203-INFO: calculate scale factor ...\r\nTraceback (most recent call last):\r\n  File \"post_training_quantization.py\", line 66, in <module>\r\n    batch_nums=10)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/quant/quanter.py\", line 306, in quant_post\r\n    post_training_quantization.quantize()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 231, in quantize\r\n    self._calculate_scale_factor()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 353, in _calculate_scale_factor\r\n    data = self._sampling_data[var_name]\r\nKeyError: 'stage.3.7.0.conv.weights'",
        "state": "closed",
        "user": "aixier",
        "closed_by": "aixier",
        "created_at": "2020-03-14T04:16:55+00:00",
        "updated_at": "2020-03-15T10:49:30+00:00",
        "closed_at": "2020-03-15T10:49:30+00:00",
        "comments_count": [
            "slf12",
            "aixier",
            "slf12",
            "aixier"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 185,
        "title": "How to make pruning support for SGD operator",
        "body": "Please register SGD in this script: https://github.com/PaddlePaddle/PaddleSlim/blob/release/1.0.1/paddleslim/prune/prune_walker.py#L526\r\n\r\nAdd lines as below:\r\n\r\n```\r\n@PRUNE_WORKER.register\r\nclass sgd(PruneWorker):\r\n    def __init__(self, op, pruned_params, visited={}):\r\n        super(sgd, self).__init__(op, pruned_params, visited)\r\n\r\n    def _prune(self, var, pruned_axis, pruned_idx):\r\n        pass\r\n```\r\n\r\nWe will fix this issue by skipping default operators in the next version. ",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2020-03-24T07:03:56+00:00",
        "updated_at": "2024-02-06T03:20:39+00:00",
        "closed_at": "2024-02-06T03:20:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 178,
        "title": "yolov3训练后量化 出错",
        "body": "CPU8\r\nRAM32GB\r\nGPUv100\r\n显存16GB\r\n磁盘100GB\r\n环境配置\r\nPython版本python3.7\r\n框架版本 PaddlePaddle 1.7.0\r\n运行代码：\r\n```\r\ninput_size=(3, 512, 512)\r\nsys.path[0] = os.path.join(\r\n    os.path.dirname(\"__file__\"), os.path.pardir, os.path.pardir)\r\n\r\n\r\n        \r\n\r\ndef quantize():\r\n    val_reader = mjreader.custom_reader(images_lists, data_dir, input_size,mode)\r\n    place = fluid.CUDAPlace(0) \r\n    exe = fluid.Executor(place)\r\n    quant_post(\r\n        executor=exe,\r\n        model_dir='../work/PaddleDetection/yolov3_dark_freeze/mj_yolov3_darknet',\r\n        quantize_model_path='./yolov3_darknet_quant/',\r\n        sample_generator=val_reader,\r\n        model_filename='__model__',\r\n        params_filename='__params__',\r\n        batch_size=16,\r\n        batch_nums=20) \r\n```\r\n\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: Input(ImgSize) dim[0] and Input(X) dim[0] should be same.\r\n  [Hint: Expected dim_imgsize[0] == dim_x[0], but received dim_imgsize[0]:4800 != dim_x[0]:16.] at (/paddle/paddle/fluid/operators/detection/yolo_box_op.cc:50)\r\n  [operator < yolo_box > error]",
        "state": "closed",
        "user": "aixier",
        "closed_by": "aixier",
        "created_at": "2020-03-15T06:12:25+00:00",
        "updated_at": "2020-05-29T06:16:44+00:00",
        "closed_at": "2020-03-15T10:49:19+00:00",
        "comments_count": [
            "AIpioneer",
            "JensenHJS"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 186,
        "title": "yolov3剪枝训练时，优化器报错",
        "body": "训练部分主要代码如下：\r\n```\r\ndef train():\r\n\r\n    logger.info(\"start train YOLOv3, train params:%s\", str(train_parameters))\r\n\r\n    logger.info(\"create place, use gpu:\" + str(train_parameters['use_gpu']))\r\n\r\n    logger.info(\"build network and program\")\r\n\r\n    place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n\r\n    scope = fluid.Scope()\r\n    train_program = fluid.Program()\r\n    start_program = fluid.Program()\r\n    test_program = fluid.Program()\r\n    \r\n    feeder, reader, loss = build_program_with_feeder(train_program, start_program, place)\r\n\r\n    pred = build_program_with_feeder(test_program, start_program, istrain=False)\r\n    \r\n    test_program = test_program.clone(for_test=True)\r\n    \r\n    train_fetch_list = [loss.name]\r\n    \r\n    exe.run(start_program, scope=scope)\r\n    \r\n    load_pretrained_params(exe, train_program)\r\n    \r\n    if train_parameters['print_params']:\r\n        param_delimit_str = '-' * 20 + \"All parameters in current graph\" + '-' * 20\r\n        print(param_delimit_str)\r\n        for block in train_program.blocks:\r\n            for param in block.all_parameters():\r\n                print(\"parameter name: {}\\tshape: {}\".format(param.name,\r\n                                                             param.shape))\r\n        print('-' * len(param_delimit_str))\r\n    \r\n    pruned_params = train_parameters['pruned_params'].strip().split(\",\")\r\n    logger.info(\"pruned params: {}\".format(pruned_params))\r\n    pruned_ratios = [float(n) for n in train_parameters['pruned_ratios'].strip().split(\",\")]\r\n    logger.info(\"pruned ratios: {}\".format(pruned_ratios))\r\n    \r\n    logger.info(\"build executor and init params\")\r\n    \r\n    pruner = Pruner()\r\n    train_program = pruner.prune(\r\n        train_program,\r\n        scope,\r\n        params=pruned_params,\r\n        ratios=pruned_ratios,\r\n        place=place,\r\n        only_graph=False)[0]\r\n    \r\n    base_flops = flops(test_program)\r\n    test_program = pruner.prune(\r\n        test_program,\r\n        scope,\r\n        params=pruned_params,\r\n        ratios=pruned_ratios,\r\n        place=place,\r\n        only_graph=True)[0]\r\n    pruned_flops = flops(test_program)\r\n\r\n    stop_strategy = train_parameters['early_stop']\r\n    rise_limit = stop_strategy['rise_limit']\r\n\r\n    min_loss = stop_strategy['min_loss']\r\n    # stop_train = False\r\n    rise_count = 0\r\n    total_batch_count = 0\r\n    current_best_f1 = 0.0\r\n    train_temp_loss = 0\r\n    current_best_pass = 0\r\n    current_best_box_pass = 0\r\n    current_best_recall = 0\r\n    current_best_precision = 0\r\n    current_best_box_recall = 0\r\n    current_best_box_precision = 0\r\n    current_best_box_f1 = 0\r\n    for pass_id in range(train_parameters[\"num_epochs\"]):\r\n        logger.info(\"current pass: {}, start read image\".format(pass_id))\r\n        batch_id = 0\r\n        total_loss = 0.0\r\n        for batch_id, data in enumerate(reader()):\r\n            t1 = time.time()\r\n            loss = exe.run(train_program, feed=feeder.feed(data), fetch_list=train_fetch_list)\r\n            period = time.time() - t1\r\n            loss = np.mean(np.array(loss))\r\n            total_loss += loss\r\n            batch_id += 1\r\n            total_batch_count += 1\r\n            \r\n            if batch_id % 200 == 0:\r\n                logger.info(\"pass {}, trainbatch {}, loss {} time {}\".format(pass_id,\r\n                                                                             batch_id, loss, \"%2.2f sec\" % period))\r\n        pass_mean_loss = total_loss / batch_id\r\n        logger.info(\"pass {0} train result, current pass mean loss: {1}\".format(pass_id, pass_mean_loss))\r\n\r\n    logger.info(\"end training\")`\r\n```\r\n\r\n#########################################################\r\n#####################报错信息如下：\r\n\r\n```\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2594, in _prepend_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 5472, in autoincreased_step_counter\r\n    attrs={'step': float(step)})\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/learning_rate_scheduler.py\", line 48, in _decay_step_counter\r\n    counter_name='@LR_DECAY_COUNTER@', begin=begin, step=1)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/learning_rate_scheduler.py\", line 387, in piecewise_decay\r\n    global_step = _decay_step_counter()\r\n  File \"train.py\", line 265, in optimizer_momentum_setting\r\n    learning_rate=fluid.layers.piecewise_decay(boundaries=boundaries, values=values),\r\n  File \"train.py\", line 371, in get_loss\r\n    optimizer = optimizer_momentum_setting()\r\n  File \"train.py\", line 306, in build_program_with_feeder\r\n    loss = get_loss(model, outputs, gt_box, gt_label, main_prog)\r\n  File \"train.py\", line 403, in train\r\n    feeder, reader, loss = build_program_with_feeder(train_program, start_program, place)\r\n  File \"train.py\", line 544, in <module>\r\n    train()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The Tensor in the increment Op's Input Variable X(@LR_DECAY_COUNTER@) is not initialized.\r\n  [Hint: Expected t->IsInitialized() == true, but received t->IsInitialized():0 != true:1.] at (/paddle/paddle/fluid/framework/operator.cc:1264)\r\n  [operator < increment > error]\r\n```",
        "state": "closed",
        "user": "sucuicong",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-03-24T08:23:53+00:00",
        "updated_at": "2020-03-24T08:43:44+00:00",
        "closed_at": "2020-03-24T08:43:44+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 197,
        "title": "How to reuse the result of pruning",
        "body": null,
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2020-03-30T07:39:53+00:00",
        "updated_at": "2024-02-06T03:53:56+00:00",
        "closed_at": "2024-02-06T03:53:56+00:00",
        "comments_count": [],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 187,
        "title": "PaddleSlim支持transformer模型吗？今后会支持吗",
        "body": "谢谢！",
        "state": "closed",
        "user": "AIpioneer",
        "closed_by": "XGZhang11",
        "created_at": "2020-03-24T08:24:36+00:00",
        "updated_at": "2024-02-06T04:08:25+00:00",
        "closed_at": "2024-02-06T04:08:25+00:00",
        "comments_count": [
            "wanghaoshuang",
            "syyxtl",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 195,
        "title": "蒸馏时将teacher的变量加入student的program，那保存训练断点时模型参数会否变大？",
        "body": "如题。模型是transformer模型",
        "state": "closed",
        "user": "AIpioneer",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-03-27T12:32:16+00:00",
        "updated_at": "2024-02-06T02:57:32+00:00",
        "closed_at": "2024-02-06T02:57:32+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 199,
        "title": "是否能支持设置某些层不量化？",
        "body": "实测发现某些层量化后对精度的影响明显大于其他层，是否可以设置将这些层不量化只量化其他层？",
        "state": "closed",
        "user": "HaoLiuHust",
        "closed_by": "XGZhang11",
        "created_at": "2020-03-30T14:23:27+00:00",
        "updated_at": "2024-02-06T03:54:06+00:00",
        "closed_at": "2024-02-06T03:54:06+00:00",
        "comments_count": [
            "slf12",
            "HaoLiuHust",
            "HaoLiuHust",
            "slf12",
            "HaoLiuHust",
            "HaoLiuHust",
            "HaoLiuHust"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 202,
        "title": "transformer distilling出错",
        "body": "我试了transformer的distill,train了两个batch之后提示如下错误：\r\nError: Tensor holds no memory. Call Tensor::mutable_data first.\r\n  [Hint: holder_ should not be null.] at (/paddle/paddle/fluid/framework/tensor.cc:23)\r\n  [operator < elementwise_div > error]\r\n\r\n是内存原因吗？\r\n",
        "state": "closed",
        "user": "dlkht",
        "closed_by": "XGZhang11",
        "created_at": "2020-04-01T06:33:49+00:00",
        "updated_at": "2024-02-06T03:54:18+00:00",
        "closed_at": "2024-02-06T03:54:17+00:00",
        "comments_count": [
            "wanghaoshuang",
            "dlkht",
            "dlkht",
            "baiyfbupt",
            "dlkht"
        ],
        "labels": [
            "distillation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 203,
        "title": "mobilenetv2 deeplabv3+ pruning问题",
        "body": "在最新的paddleslim库和paddleseg库上进行mobilenetv2 deeplabv3+的pruning，配置裁剪参数后报以下错误，请问是什么原因。\r\n![image](https://user-images.githubusercontent.com/7035538/78204782-1a80fc80-74cd-11ea-8d02-cd7084c188c8.png)\r\n\r\nParameter[decoder/separable_conv1/pointwise/BatchNorm/beta] loaded sucessfully!\r\nParameter[decoder/separable_conv1/pointwise/BatchNorm/moving_mean] loaded sucessfully!\r\nParameter[decoder/separable_conv1/pointwise/BatchNorm/moving_variance] loaded sucessfully!\r\nParameter[decoder/separable_conv2/depthwise/weights] loaded sucessfully!\r\nParameter[decoder/separable_conv2/depthwise/BatchNorm/gamma] loaded sucessfully!\r\nParameter[decoder/separable_conv2/depthwise/BatchNorm/beta] loaded sucessfully!\r\nParameter[decoder/separable_conv2/depthwise/BatchNorm/moving_mean] loaded sucessfully!\r\nParameter[decoder/separable_conv2/depthwise/BatchNorm/moving_variance] loaded sucessfully!\r\nParameter[decoder/separable_conv2/pointwise/weights] loaded sucessfully!\r\nParameter[decoder/separable_conv2/pointwise/BatchNorm/gamma] loaded sucessfully!\r\nParameter[decoder/separable_conv2/pointwise/BatchNorm/beta] loaded sucessfully!\r\nParameter[decoder/separable_conv2/pointwise/BatchNorm/moving_mean] loaded sucessfully!\r\nParameter[decoder/separable_conv2/pointwise/BatchNorm/moving_variance] loaded sucessfully!\r\nParameter[logit/weights] loaded sucessfully!\r\nParameter[logit/biases] loaded sucessfully!\r\n332/332 pretrained parameters loaded successfully!\r\nTraceback (most recent call last):\r\n  File \"./slim/prune/train_prune.py\", line 504, in <module>\r\n    main(args)\r\n  File \"./slim/prune/train_prune.py\", line 491, in main\r\n    train(cfg)\r\n  File \"./slim/prune/train_prune.py\", line 347, in train\r\n    only_graph=False)[0]\r\n  File \"/home/hpc/ccx/paddle1.7/PaddleSlim/paddleslim/prune/pruner.py\", line 82, in prune\r\n    param_t = np.array(scope.find_var(param).get_tensor())\r\nAttributeError: 'NoneType' object has no attribute 'get_tensor'\r\n\r\n@wanghaoshuang ",
        "state": "closed",
        "user": "A1exy",
        "closed_by": "A1exy",
        "created_at": "2020-04-02T02:33:36+00:00",
        "updated_at": "2020-06-05T01:54:45+00:00",
        "closed_at": "2020-04-08T07:11:27+00:00",
        "comments_count": [
            "wanghaoshuang",
            "A1exy",
            "A1exy",
            "A1exy",
            "wanghaoshuang",
            "A1exy",
            "wanghaoshuang",
            "A1exy",
            "JensenHJS"
        ],
        "labels": [
            "pruning"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 204,
        "title": "用quant_post量化了一个yolov3_darknet的的模型，推理加载出错",
        "body": "环境：\r\npaddle1.7\r\n出错信息：\r\nPaddleCheckError: OP(LoadCombine) fail to open file ..\\yolov3_darknet_quant_924\\__params__, please check whether the mod\r\nel file is complete or damaged. at [D:\\1.6.1\\paddle\\paddle/fluid/operators/load_combine_op.h:46]\r\n\r\n量化代码\r\n`def quantize():\r\n    val_reader = mjreader.custom_reader(images_lists, data_dir, input_size,mode)\r\n    place = fluid.CUDAPlace(0) \r\n    exe = fluid.Executor(place)\r\n    quant_post(\r\n        executor=exe,\r\n        model_dir='../work/PaddleDetection/yolov3_freeze/yolov3_darknet',\r\n        quantize_model_path='./yolov3_darknet_quant_924/',\r\n        sample_generator=val_reader,\r\n        model_filename='__model__',\r\n        params_filename='__params__',\r\n        batch_size=16,\r\n        batch_nums=20)       \r\ndef main():\r\n    quantize()`\r\n用quant_post量化了一个yolov3_darknet的的模型，得到的模型如何进行加载推理",
        "state": "closed",
        "user": "aixier",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-04-02T03:50:36+00:00",
        "updated_at": "2024-02-06T02:57:33+00:00",
        "closed_at": "2024-02-06T02:57:33+00:00",
        "comments_count": [
            "aixier",
            "itminner",
            "A1exy",
            "A1exy",
            "slf12",
            "A1exy",
            "slf12",
            "A1exy"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 211,
        "title": "模型量化后运行预测速度会提高吗？",
        "body": "如题",
        "state": "closed",
        "user": "dlkht",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-04-07T02:24:01+00:00",
        "updated_at": "2024-02-06T02:57:34+00:00",
        "closed_at": "2024-02-06T02:57:34+00:00",
        "comments_count": [
            "slf12",
            "JensenHJS"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 214,
        "title": "模型量化后，不支持fluid.ParallelExecutor吗？",
        "body": "执行\r\nquant_program = quant.quant_aware(train_prog, exe.place, for_test=False)\r\nval_program = fluid.default_main_program().clone(for_test=True)\r\n再训练quant_program，发觉不能用fluid.ParallelExecutor，提示\r\nAttributeError: 'CompiledProgram' object has no attribute '_enable_dgc'",
        "state": "closed",
        "user": "dlkht",
        "closed_by": "XGZhang11",
        "created_at": "2020-04-08T02:20:11+00:00",
        "updated_at": "2024-02-06T03:54:30+00:00",
        "closed_at": "2024-02-06T03:54:30+00:00",
        "comments_count": [
            "slf12",
            "dlkht",
            "slf12",
            "dlkht",
            "slf12",
            "dlkht",
            "slf12",
            "dlkht"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 217,
        "title": "我在用slim剪枝时优化器报错怎么解决",
        "body": "pruned_program, _, _ = pruner.prune(train_program, fluid.global_scope(),\r\n        params=ratios.keys(),ratios=ratios.values(), place=place)\r\n\r\n报错为：Error: Param and Velocity of MomentumOp should have the same dimension.\r\n  [Hint: Expected param_dim == ctx->GetInputDim(\"Velocity\"), but received param_dim:12544, 4096 != ctx->GetInputDim(\"Velocity\"):24832, 4096.] at (/paddle/paddle/fluid/operators/optimizers/momentum_op.h:79)\r\n  [operator < momentum > error]\r\n应该是说参数数量不匹？但我剪枝的话参数数量肯定会减少吧",
        "state": "closed",
        "user": "JLei67",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-04-10T06:21:49+00:00",
        "updated_at": "2020-04-15T09:30:57+00:00",
        "closed_at": "2020-04-15T09:30:57+00:00",
        "comments_count": [
            "JLei67",
            "wanghaoshuang",
            "JLei67",
            "wanghaoshuang",
            "wanghaoshuang",
            "JLei67",
            "JLei67",
            "wanghaoshuang",
            "JLei67"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 218,
        "title": "关于量化的问题",
        "body": "文档中关于量化的配置：\r\nweight_bits(int) - 参数量化bit数，默认8, 可选1-8，推荐设为8，因为量化后的数据类型是 int8 。\r\nactivation_bits(int) - 激活量化bit数，默认8，可选1-8，推荐设为8，因为量化后的数据类型是 int8 。\r\ndtype(int8) - 量化后的参数类型，默认 int8 , 目前仅支持 int8 。\r\n请问我如果把weight_bits(int) 设为7，把activation_bits(int)设为7，然后训练，模型的结果相当于7bit量化吗？",
        "state": "closed",
        "user": "hp-cuiwb",
        "closed_by": "hp-cuiwb",
        "created_at": "2020-04-13T08:00:02+00:00",
        "updated_at": "2020-04-13T10:52:33+00:00",
        "closed_at": "2020-04-13T10:52:32+00:00",
        "comments_count": [
            "slf12",
            "hp-cuiwb",
            "slf12",
            "hp-cuiwb"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 220,
        "title": "请问一下，使用PaddleSlim进行蒸馏的话，teacher模型的选择有什么要求吗，是不是跟student“长得越像”越好？",
        "body": "尊敬的开发者：\r\n你好！\r\n请问一下，使用PaddleSlim进行蒸馏的话，teacher模型的选择有什么要求吗，是不是跟student模型“长得越像”越好？\r\n期待你的回复！",
        "state": "closed",
        "user": "songyuc",
        "closed_by": "songyuc",
        "created_at": "2020-04-14T08:15:03+00:00",
        "updated_at": "2020-04-14T10:00:46+00:00",
        "closed_at": "2020-04-14T10:00:46+00:00",
        "comments_count": [
            "songyuc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 221,
        "title": "请问一下，对于COCO数据集任务的蒸馏是对模型整体进行蒸馏吗？",
        "body": "尊敬的开发者：\r\n你好！\r\n请问一下，对于COCO数据集的任务来说，模型蒸馏是对模型整体都进行蒸馏吗，还是只对主干网络部分进行蒸馏？\r\n我在飞桨的课程中看到了这样的训练结果，\r\n![图片](https://user-images.githubusercontent.com/27288110/79204572-5c1b8b00-7e6f-11ea-8612-49b111d35e18.png)\r\n\r\n期待你的回复！",
        "state": "closed",
        "user": "songyuc",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-04-14T08:45:49+00:00",
        "updated_at": "2024-02-06T02:57:35+00:00",
        "closed_at": "2024-02-06T02:57:35+00:00",
        "comments_count": [
            "baiyfbupt",
            "songyuc",
            "songyuc",
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 222,
        "title": "请问一下，如果针对COCO数据集的目标检测任务，使用强化学习策略进行NAS搜索有什么推荐的配置吗？",
        "body": "尊敬的开发者：\r\n你好！\r\n想请教一下，对于COCO数据集的目标检测任务，使用强化学习策略进行NAS搜索，有什么推荐的GPU配置吗？\r\n我想知道我们现在的GPU服务器的配置是否适合这个任务，\r\n期待你的回复！",
        "state": "closed",
        "user": "songyuc",
        "closed_by": "songyuc",
        "created_at": "2020-04-14T10:04:23+00:00",
        "updated_at": "2021-03-31T07:01:16+00:00",
        "closed_at": "2021-03-31T07:01:16+00:00",
        "comments_count": [
            "ceci3",
            "wanghaoshuang",
            "songyuc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 223,
        "title": "请问一下，硬件延时表，PaddleSlim是会自动测量吗，还是需要我们给出呀？",
        "body": "尊敬的开发者：\r\n你好！\r\n关于硬件延时表的话，PaddleSlim是会自动测量吗，还是需要我们给出呀？\r\n期待你的回复！",
        "state": "closed",
        "user": "songyuc",
        "closed_by": "songyuc",
        "created_at": "2020-04-14T10:20:36+00:00",
        "updated_at": "2020-04-15T06:28:59+00:00",
        "closed_at": "2020-04-15T06:28:58+00:00",
        "comments_count": [
            "ceci3",
            "songyuc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 225,
        "title": "slim裁剪，如何获取卷积层名字？",
        "body": "问题一：\r\n官网提供的很多教程都是 基于命令行形式的\r\n但是slim中很多API参数都需要program的概念，我要如何获取这个参数？\r\n比如使用 裁剪的时候，需要先获取卷积层的名字，应该什么方式获取？\r\n模型训练完保存是这样的\r\n![image](https://user-images.githubusercontent.com/49515380/79316896-92bcd880-7f37-11ea-9cc8-1513d5aa5c88.png)\r\n\r\n问题二：\r\nslim的API很多都是基于静态图的方法（根据参数来做的判断），在动态图上使用是否有连接教程？\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "jaffe-fly",
        "closed_by": "jaffe-fly",
        "created_at": "2020-04-15T08:41:13+00:00",
        "updated_at": "2020-04-16T02:13:31+00:00",
        "closed_at": "2020-04-16T02:13:31+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "jaffe-fly",
            "jaffe-fly"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 231,
        "title": "distilling报错",
        "body": "忧伤死了，调了半天，最后报个这个\r\nError: Tensor holds no memory. Call Tensor::mutable_data first.\r\n  [Hint: holder_ should not be null.] at (/paddle/paddle/fluid/framework/tensor.cc:23)\r\n  [operator < lookup_table_v2 > error]\r\n实在没头绪了，查issue似乎有别人也报过这个，希望官方注意下吧",
        "state": "closed",
        "user": "dflmingle",
        "closed_by": "baiyfbupt",
        "created_at": "2020-04-22T09:06:47+00:00",
        "updated_at": "2020-04-23T04:01:29+00:00",
        "closed_at": "2020-04-23T04:01:29+00:00",
        "comments_count": [
            "dflmingle"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 233,
        "title": "在使用蒸馏时，若teacher program里有包含BIGRU会报错",
        "body": "在teacher program里\r\n定义\r\n    encoder_fwd_cell =  fluid.layers.GRUCell(hidden_size=128)\r\n    encoder_fwd_output, fwd_state =  fluid.layers.rnn(\r\n        cell=encoder_fwd_cell,\r\n        inputs=emb_out,\r\n        sequence_length=None,\r\n        time_major=False,\r\n        is_reverse=False)\r\n    # 使用GRUCell构建反向RNN\r\n    encoder_bwd_cell =  fluid.layers.GRUCell(hidden_size=128)\r\n    encoder_bwd_output, bwd_state =  fluid.layers.rnn(\r\n        cell=encoder_bwd_cell,\r\n        inputs=emb_out,\r\n        sequence_length=None,\r\n        time_major=False,\r\n        is_reverse=True)\r\n    # 拼接前向与反向GRU的编码结果得到h\r\n    encoder_output =  fluid.layers.concat(\r\n        input=[encoder_fwd_output, encoder_bwd_output], axis=2)\r\n    encoder_output=fluid.layers.elementwise_mul(encoder_output,input_mask,axis=-1)\r\n这个结构的话，就会报错，去掉就可以，估计源码中未考虑到某种情况导致出错",
        "state": "closed",
        "user": "dflmingle",
        "closed_by": "XGZhang11",
        "created_at": "2020-04-23T02:59:28+00:00",
        "updated_at": "2024-02-06T03:54:41+00:00",
        "closed_at": "2024-02-06T03:54:41+00:00",
        "comments_count": [
            "baiyfbupt",
            "dflmingle",
            "baiyfbupt",
            "baiyfbupt",
            "dflmingle"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 241,
        "title": "为什么PaddleSlim模型量化时不量化卷积层的偏置？",
        "body": "另外，对于激活值得量化，为什么一般采用滑动窗口平均得办法，而不是最简单得abs_max，有什么依据吗？",
        "state": "closed",
        "user": "zhizunbao-y",
        "closed_by": "zhizunbao-y",
        "created_at": "2020-04-23T16:28:15+00:00",
        "updated_at": "2020-04-24T04:07:53+00:00",
        "closed_at": "2020-04-24T04:07:53+00:00",
        "comments_count": [
            "slf12",
            "zhizunbao-y",
            "slf12",
            "zhizunbao-y"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 242,
        "title": "训练后量化权值使用的量化方法确切是什么？",
        "body": "原文：`训练后量化的目标是求取量化比例因子，主要有两种方法：非饱和量化方法 ( No Saturation) 和饱和量化方法 (Saturation)。非饱和量化方法计算FP32类型Tensor中绝对值的最大值abs_max，将其映射为127，则量化比例因子等于abs_max/127。饱和量化方法使用KL散度计算一个合适的阈值T (0<T<mab_max)，将其映射为127，则量化比例因子等于T/127。一般而言，对于待量化op的权重Tensor，采用非饱和量化方法，对于待量化op的激活Tensor（包括输入和输出），采用饱和量化方法 。`\r\n问题：\r\n1.权值使用的量化方法算法原理里用的是abs_max，而api介绍里说的是channel_abs_max\r\n2.另外对于激活层，使用KL散度计算出的T，算法原理里写的是0<T<mab_max, 其中mab_max是指什么？\r\n3.训练后量化中，对于输入量化比例系数的计算也是使用KL散度吗？",
        "state": "closed",
        "user": "zhizunbao-y",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-04-24T01:41:08+00:00",
        "updated_at": "2024-02-06T02:57:36+00:00",
        "closed_at": "2024-02-06T02:57:36+00:00",
        "comments_count": [
            "slf12"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 245,
        "title": "官方文档的图片很多都加载不出来呀",
        "body": "[参考这个页面](https://paddlepaddle.github.io/PaddleSlim/algo/algo.html)\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/12961274/80474887-a0804e00-897a-11ea-9549-e6b8f2be69f9.png)\r\n",
        "state": "closed",
        "user": "312shan",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-04-28T10:04:14+00:00",
        "updated_at": "2024-02-06T02:57:38+00:00",
        "closed_at": "2024-02-06T02:57:37+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 298,
        "title": "How to append float32 operator to quantized graph",
        "body": "```\r\nfrom paddleslim.quant import quant_aware, convert\r\nquantized_graph = convert(infer_prog, place, config=config)\r\nquantized_program = quantized_graph.to_program()\r\nfor var in quantized_program.list_vars():\r\n    print(var.name)\r\n\r\nwith fluid.program_guard(quantized_program):\r\n    out = quantized_program.global_block().var(\"your_var_name\")\r\n    out = fluid.layers.some_op(out)\r\n\r\nfluid.io.save_inference_model(main_program=quantized_program, ...)\r\n```\r\n\r\nSome API docs:\r\n\r\n- program_guard: https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/fluid_cn/program_guard_cn.html#program-guard\r\n- Program: https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/fluid_cn/Program_cn.html#program\r\n- save-inference-model: https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/io_cn/save_inference_model_cn.html#save-inference-model\r\n- IrGraph.to_porgram: https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/framework.py#L3803",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-05-19T04:12:32+00:00",
        "updated_at": "2020-05-19T04:23:59+00:00",
        "closed_at": "2020-05-19T04:23:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 248,
        "title": "nas 对搜索到的模型的中间信息进行输出",
        "body": "我尝试使用paddleslim平台运行https://github.com/PaddlePaddle/PaddleSlim/blob/release/1.0.1/docs/zh_cn/tutorials/image_classification_nas_quick_start.ipynb   网址下的例程并尝试将网络模型和参数输出，但是遇到了问题，在代码中并没有将全连接层以外的其他网络层定义出，我理解其他网络层的架构是使用：archs = sanas.next_archs()[0] 总体描述的，但是当我编写输出语句时，输出语句中fluid.io.save_inference_model(dirname=save_path, feeded_var_names=[data.name], target_vars=[predict], executor=exe)      其中target_vars=[predict]   predict=其他网络层+最后全连接层，也就是说：\r\n          archs  = sanas.next_archs()[0]    \r\n          output = fluid.layers.fc(input=output, size=10)\r\n          predict = archs+output\r\n\r\n\r\n如果我的理解没有错误，那么输出语句应该怎么表达才能将整个网络架构的信息进行输出呢？",
        "state": "closed",
        "user": "ceci3",
        "closed_by": "XGZhang11",
        "created_at": "2020-04-29T09:35:36+00:00",
        "updated_at": "2024-02-06T03:54:50+00:00",
        "closed_at": "2024-02-06T03:54:50+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 314,
        "title": "在paddleDetection使用slim，训完之后测试没有map",
        "body": "量化训练在voc数据集上进行，使用以下命令，边训练边测试没有map值，map值为空。感觉可能是预训练权重有问题，是下面这个预训练模型吗\r\npython slim/quantization/train.py --not_quant_pattern yolo_output \\\r\n    --eval \\\r\n    -c ./configs/yolov3_mobilenet_v1_voc.yml \\\r\n    -o max_iters=30000 \\\r\n    save_dir=./output/yolov3_mobilenet_v1_voc_quantization \\\r\n    LearningRate.base_lr=0.0001 \\\r\n    LearningRate.schedulers=\"[!PiecewiseDecay {gamma: 0.1, milestones: [10000]}]\" \\\r\n    pretrain_weights=https://paddlemodels.bj.bcebos.com/object_detection/yolov3_mobilenet_v1_voc.tar",
        "state": "closed",
        "user": "JensenHJS",
        "closed_by": "JensenHJS",
        "created_at": "2020-05-28T12:48:10+00:00",
        "updated_at": "2020-05-29T06:25:26+00:00",
        "closed_at": "2020-05-29T06:25:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 305,
        "title": "报错cannot import name 'quant_aware'",
        "body": "from paddleslim.quant import quant_aware, convert\r\nImportError: cannot import name 'quant_aware'\r\n安装了paddleslim也报这个错，paddle是1.7版本slim是1.1.1。请问怎么解决\r\n",
        "state": "closed",
        "user": "JensenHJS",
        "closed_by": "JensenHJS",
        "created_at": "2020-05-22T12:09:53+00:00",
        "updated_at": "2020-05-28T12:48:30+00:00",
        "closed_at": "2020-05-28T12:48:30+00:00",
        "comments_count": [
            "thunder95",
            "thunder95",
            "slf12"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 316,
        "title": "使用手册里的步骤进行量化训练出错",
        "body": "paddle1.7.1\r\nslim1.0.1\r\n使用https://github.com/PaddlePaddle/PaddleDetection/tree/release/0.3/slim/quantization里面的命令行进行量化训练出错。命令如下\r\npython slim/quantization/train.py --not_quant_pattern yolo_output \\\r\n    --eval \\\r\n    -c ./configs/yolov3_mobilenet_v1.yml \\\r\n    -o max_iters=30000 \\\r\n    save_dir=./output/yolov3_mobilenet_v1_coco_quantization \\\r\n    LearningRate.base_lr=0.0001 \\\r\n    LearningRate.schedulers=\"[!PiecewiseDecay {gamma: 0.1, milestones: [10000]}]\" \\\r\n    pretrain_weights=https://paddlemodels.bj.bcebos.com/object_detection/yolov3_mobilenet_v1.tar\r\n\r\n发现在if FLAGS.eval: 里进入eval_results函数，返回值box_ap_stats是空的list\r\n改为voc上训练，也会出错",
        "state": "closed",
        "user": "JensenHJS",
        "closed_by": "JensenHJS",
        "created_at": "2020-05-29T06:23:06+00:00",
        "updated_at": "2020-05-29T09:34:34+00:00",
        "closed_at": "2020-05-29T09:34:34+00:00",
        "comments_count": [
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 317,
        "title": "在GPU上量化后加速的问题",
        "body": "文档里说在GPU上量化后加速,要使用paddle-tensorrt这个方式，但是paddle-tensorrt例子里面似乎只有一个moblinet的例子程序？",
        "state": "closed",
        "user": "JensenHJS",
        "closed_by": "JensenHJS",
        "created_at": "2020-05-30T09:18:15+00:00",
        "updated_at": "2020-06-04T07:50:51+00:00",
        "closed_at": "2020-06-04T07:50:51+00:00",
        "comments_count": [
            "JensenHJS",
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 318,
        "title": "paddleslim 知识蒸馏demo的问题",
        "body": "在进行到查看Variables这一步后，进行合并蒸馏loss，这时候报错\r\n: var depthwise_conv2d_11.tmp_0 not in this block\r\n查看Variables发现 student的Variables里并没有depthwise_conv2d_11.tmp_0\r\n\r\n通过观察发现 student模型中的depthwise_conv2d_24.tmp_0与teacher中的teacher_bn5c_branch2b.output.1.tmp_3的尺寸一致都是(-1, 512, 1, 1)\r\n\r\n所以把demo中的合并蒸馏loss改成了\r\n```python\r\ndata_name_map = {'image': 'image'}\r\nmain = slim.dist.merge(teacher_program, student_program, data_name_map, fluid.CPUPlace())\r\nwith fluid.program_guard(student_program, student_startup):\r\n    l2_loss = slim.dist.l2_loss('teacher_bn5c_branch2b.output.1.tmp_3', 'depthwise_conv2d_24.tmp_0', student_program)\r\n    loss = l2_loss + avg_cost\r\n    opt = fluid.optimizer.Momentum(0.01, 0.9)\r\n    opt.minimize(loss)\r\nexe.run(student_startup)\r\n```\r\n\r\n但是最后一步训练的时候又报这个错误\r\n```bash\r\nInvalidArgumentError: ShapeError: the shape of scale must equal to [32]But received: the shape of scale is [64]\r\n  [Hint: Expected scale_dim[0] == C, but received scale_dim[0]:64 != C:32.] at (/paddle/paddle/fluid/operators/batch_norm_op.cc:116)\r\n  [operator < batch_norm > error]\r\n```\r\n\r\n麻烦请看一下，执行是在aistudio平台,麻烦看一下谢谢",
        "state": "closed",
        "user": "lastrei",
        "closed_by": "lastrei",
        "created_at": "2020-06-01T05:02:20+00:00",
        "updated_at": "2023-04-07T04:08:41+00:00",
        "closed_at": "2023-04-07T04:08:41+00:00",
        "comments_count": [
            "baiyfbupt",
            "lastrei",
            "baiyfbupt",
            "lastrei",
            "baiyfbupt",
            "Sejudyblues"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 322,
        "title": "关于quant_config 的'quantize_op_types':项",
        "body": "'quantize_op_types':[]\r\n是不是要把模型中所有的op_type都要填写上？\r\n是不是模型没有的op_type不能写？",
        "state": "closed",
        "user": "dlkht",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-06-01T11:42:05+00:00",
        "updated_at": "2024-02-06T02:57:40+00:00",
        "closed_at": "2024-02-06T02:57:40+00:00",
        "comments_count": [
            "slf12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 321,
        "title": "关于量化的一些使用问题",
        "body": "1. 量化训练完成后保存的模型是否保存了量化参数？如果有，怎么提取量化参数（每层输入输出和权重）？\r\n2. 量化的type 包含mul ,bn 中的mul 也会被量化吗？\r\n3. model有多种save 方式，包括检查点中的best_model，__model__，对应的除了检查点中包含训练的tmp梯度，还有什么区别吗？\r\n4. 修改默认量化位宽为7bit，进行 量化训练，对训练后的模型convert 成量化模型（包括float和int）,int模型的权重范围还是【-128,127】，这个要怎么修改？\r\n5. 量化推断模型实际的数据流是量化后的int7数据还是float32的模型？\r\n6. 量化模型在做推断时，是怎么处理add,concat，等这些没有参数的层的？ 」\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-06-01T10:30:54+00:00",
        "updated_at": "2024-02-06T02:57:39+00:00",
        "closed_at": "2024-02-06T02:57:39+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "zyxcambridge",
            "wanghaoshuang",
            "aboutmei",
            "aboutmei",
            "qingqing01",
            "qingqing01",
            "aboutmei",
            "aboutmei",
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 328,
        "title": "裁剪分析敏感度，weights应该用正常训练的模型，而不是剪过之后的模型吧",
        "body": "如题~",
        "state": "closed",
        "user": "AIpioneer",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-06-03T08:39:48+00:00",
        "updated_at": "2024-02-06T02:57:41+00:00",
        "closed_at": "2024-02-06T02:57:41+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 333,
        "title": "保存量化模型时出现奇怪问题",
        "body": "\r\n你好！我在paddle-1.7.2或1.8.1下用paddleslim压缩模型（transformer)，在保存量化模型时，有时可以通过，但经常退出并提示：\r\nAborted at 1591265021 (unix time) try \"date -d @1591265021\" if you are using GNU date\r\n查百度发现这个问题叫普遍，其它框架下也有，到底什么原因呢？",
        "state": "closed",
        "user": "dlkht",
        "closed_by": "XGZhang11",
        "created_at": "2020-06-04T10:11:09+00:00",
        "updated_at": "2024-02-06T03:55:01+00:00",
        "closed_at": "2024-02-06T03:55:01+00:00",
        "comments_count": [
            "dlkht",
            "slf12",
            "qingqing01",
            "dlkht",
            "slf12",
            "dlkht"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 334,
        "title": "模型剪枝是否能够提高模型的速度？",
        "body": "最近试验了模型剪枝，大小减低了20%，但是发现速度几乎没有变化，是合理的吗",
        "state": "closed",
        "user": "AIpioneer",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-06-04T13:16:36+00:00",
        "updated_at": "2024-02-06T02:57:42+00:00",
        "closed_at": "2024-02-06T02:57:42+00:00",
        "comments_count": [
            "JensenHJS",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 337,
        "title": "为什么文档里的图挂掉了，你们也是吗",
        "body": "求助",
        "state": "closed",
        "user": "eucommiaulmoides",
        "closed_by": "XGZhang11",
        "created_at": "2020-06-08T02:02:02+00:00",
        "updated_at": "2024-02-06T03:55:12+00:00",
        "closed_at": "2024-02-06T03:55:12+00:00",
        "comments_count": [
            "wanghaoshuang",
            "eucommiaulmoides"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 339,
        "title": "如何分析敏感度信息",
        "body": "Related to https://github.com/PaddlePaddle/PaddleDetection/issues/900",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2020-06-08T15:09:58+00:00",
        "updated_at": "2020-07-09T05:05:31+00:00",
        "closed_at": "2020-07-09T05:05:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 341,
        "title": "从经过训练量化的模型产生预测模型（int8)出错",
        "body": "想从经过训练量化的模型产生预测模型（int8),\r\n实现程序是quant__freezy.py,我这边出错提示\r\nAborted at 1591755157 (unix time) try \"date -d @1591755157\" if you are using GNU date",
        "state": "closed",
        "user": "AIpioneer",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-06-10T02:18:41+00:00",
        "updated_at": "2024-02-06T02:57:43+00:00",
        "closed_at": "2024-02-06T02:57:43+00:00",
        "comments_count": [
            "itminner",
            "dlkht",
            "dlkht",
            "slf12",
            "juncaipeng",
            "dlkht"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 343,
        "title": " Optimize importing error information.",
        "body": "Related to https://github.com/PaddlePaddle/PaddleDetection/issues/925",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "ceci3",
        "created_at": "2020-06-11T12:01:30+00:00",
        "updated_at": "2020-06-12T03:50:39+00:00",
        "closed_at": "2020-06-12T03:50:39+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 347,
        "title": "opt在protobuf格式下生成的model和params能用protobuf库里的接口解析吗？和caffe是否相同？",
        "body": "麻烦问下opt生成的和caffe的模型有啥区别，都能用protobuf工具解析吗？",
        "state": "closed",
        "user": "ArtyZe",
        "closed_by": "ArtyZe",
        "created_at": "2020-06-12T06:35:36+00:00",
        "updated_at": "2020-07-07T01:54:47+00:00",
        "closed_at": "2020-07-07T01:54:47+00:00",
        "comments_count": [
            "juncaipeng",
            "ArtyZe",
            "juncaipeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 348,
        "title": "剪枝算法论文地址错误",
        "body": "感谢开源。Opt Slim Pruner论文地址指向了Slim Pruner。",
        "state": "closed",
        "user": "step404",
        "closed_by": "step404",
        "created_at": "2020-06-12T07:18:17+00:00",
        "updated_at": "2020-07-15T12:46:19+00:00",
        "closed_at": "2020-06-15T01:03:26+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 356,
        "title": "人脸识别这种类型的模型怎么量化",
        "body": "看demo generator是要提供label信息，像这种多维度输出的模型label是什么呢",
        "state": "closed",
        "user": "HaoLiuHust",
        "closed_by": "HaoLiuHust",
        "created_at": "2020-06-18T12:51:53+00:00",
        "updated_at": "2020-06-19T01:09:56+00:00",
        "closed_at": "2020-06-19T01:09:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 360,
        "title": "quant_post如何指定哪些层不量化",
        "body": "![image](https://user-images.githubusercontent.com/7233091/85114146-156d5700-b24b-11ea-9440-0a2bb1abd5bf.png)\r\nAPI文档中有一个字典配置量化参数，里面有not_quant_pattern来指定一些pattern可以不量化，可是在quant_post中却并不是通过字典来配置量化参数的，请问quant_post中能指定哪些层不量化么",
        "state": "closed",
        "user": "HaoLiuHust",
        "closed_by": "HaoLiuHust",
        "created_at": "2020-06-19T08:45:01+00:00",
        "updated_at": "2020-06-19T08:50:25+00:00",
        "closed_at": "2020-06-19T08:50:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 361,
        "title": "quant_post如何指定哪些层不量化",
        "body": "![image](https://user-images.githubusercontent.com/7233091/85114146-156d5700-b24b-11ea-9440-0a2bb1abd5bf.png)\r\nAPI文档中有一个字典配置量化参数，里面有not_quant_pattern来指定一些pattern可以不量化，可是在quant_post中却并不是通过字典来配置量化参数的，请问quant_post中能指定哪些层不量化么",
        "state": "closed",
        "user": "HaoLiuHust",
        "closed_by": "HaoLiuHust",
        "created_at": "2020-06-19T08:45:38+00:00",
        "updated_at": "2020-06-19T08:53:35+00:00",
        "closed_at": "2020-06-19T08:53:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 354,
        "title": "关于paddleslim量化原理的问题",
        "body": "在模型量化文档中(https://paddlepaddle.github.io/PaddleSlim/algo/algo.html)，训练后量化：\r\n对于权重Tensor的量化操作采用非饱和量化方法(No Saturation)，对于输入采用饱和量化方法(Saturation)。\r\n1、那权重和输入进行矩阵相乘后，反量化成float32的操作原理是什么？比如反量化的计算公式，反量化的尺度怎么计算的（因为权重和输入采用两种量化方式，所以反量化如何计算不太清楚）？",
        "state": "closed",
        "user": "taoja12",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-06-17T07:07:15+00:00",
        "updated_at": "2024-02-06T02:57:44+00:00",
        "closed_at": "2024-02-06T02:57:44+00:00",
        "comments_count": [
            "itminner",
            "itminner"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 359,
        "title": "训练后量化如何指定某些层不量化",
        "body": "![image](https://user-images.githubusercontent.com/7233091/85114146-156d5700-b24b-11ea-9440-0a2bb1abd5bf.png)\r\nAPI文档中有一个字典配置量化参数，里面有not_quant_pattern来指定一些pattern可以不量化，可是在quant_post中却并不是通过字典来配置量化参数的，请问quant_post中能指定哪些层不量化么",
        "state": "closed",
        "user": "HaoLiuHust",
        "closed_by": "HaoLiuHust",
        "created_at": "2020-06-19T08:38:22+00:00",
        "updated_at": "2020-06-24T05:37:04+00:00",
        "closed_at": "2020-06-24T05:37:04+00:00",
        "comments_count": [
            "juncaipeng",
            "HaoLiuHust",
            "juncaipeng",
            "HaoLiuHust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 362,
        "title": "quant_post如何指定哪些层不量化",
        "body": "![image](https://user-images.githubusercontent.com/7233091/85114146-156d5700-b24b-11ea-9440-0a2bb1abd5bf.png)\r\nAPI文档中有一个字典配置量化参数，里面有not_quant_pattern来指定一些pattern可以不量化，可是在quant_post中却并不是通过字典来配置量化参数的，请问quant_post中能指定哪些层不量化么",
        "state": "closed",
        "user": "HaoLiuHust",
        "closed_by": "HaoLiuHust",
        "created_at": "2020-06-19T08:46:25+00:00",
        "updated_at": "2020-06-19T08:51:18+00:00",
        "closed_at": "2020-06-19T08:51:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 369,
        "title": "Need a FAQ or doc to tell users how to not quant some layers in quant-aware training.",
        "body": "related to https://github.com/PaddlePaddle/PaddleSlim/issues/364#issuecomment-651183736\r\n\r\n\r\nFAQ: https://paddleslim.readthedocs.io/zh_CN/latest/FAQ/quantization_FAQ.html#id2",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "ceci3",
        "created_at": "2020-06-29T15:23:26+00:00",
        "updated_at": "2024-02-06T03:17:55+00:00",
        "closed_at": "2024-02-06T03:17:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 364,
        "title": "量化后精度下降非常大",
        "body": "量化了一个识别模型，精度下降了几十个点，如何调试问题出在哪一层？",
        "state": "closed",
        "user": "HaoLiuHust",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-06-22T02:33:18+00:00",
        "updated_at": "2024-02-06T02:57:44+00:00",
        "closed_at": "2024-02-06T02:57:44+00:00",
        "comments_count": [
            "qingqing01",
            "HaoLiuHust",
            "juncaipeng",
            "HaoLiuHust",
            "HaoLiuHust",
            "HaoLiuHust",
            "HaoLiuHust",
            "HaoLiuHust",
            "qingqing01",
            "itminner",
            "HaoLiuHust",
            "HaoLiuHust",
            "xiteng1988",
            "HaoLiuHust",
            "HaoLiuHust",
            "qingqing01",
            "HaoLiuHust",
            "HaoLiuHust",
            "HaoLiuHust",
            "HaoLiuHust",
            "HaoLiuHust",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 367,
        "title": "PaddleSlim/docs/zh_cn/quick_start/nas_tutorial.md里写的代码有问题",
        "body": "for step in range(3):\r\n    archs = sanas.next_archs()[0]\r\n    exe, train_program, eval_progarm, inputs, avg_cost, acc_top1, acc_top5 = build_program(archs)\r\n\r\n\r\ntest_program错写成了test_progarm\r\n需要更正为exe, train_program, test_program, inputs, avg_cost, acc_top1, acc_top5 = build_program(archs)",
        "state": "closed",
        "user": "skyliuhc",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-06-27T08:26:08+00:00",
        "updated_at": "2020-07-09T08:31:24+00:00",
        "closed_at": "2020-07-09T08:31:24+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 366,
        "title": "请问一下是版本不对吗",
        "body": "![image](https://user-images.githubusercontent.com/48110081/85413335-47f5b780-b59d-11ea-811a-8234f8931343.png)\r\n![image](https://user-images.githubusercontent.com/48110081/85413368-52b04c80-b59d-11ea-92e4-1bc7d88dd0f3.png)\r\n问题1：我不管用什么slim的命令都要提示这个，padddlepaddle用的1.8版本，slim1.1.1 请问一下是版本不对吗\r\n问题2：paddledetection里面内置了slim，请问还需要在pip install paddleslim吗\r\n![image](https://user-images.githubusercontent.com/48110081/85413607-999e4200-b59d-11ea-9e68-f67774420608.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "chengxurensheng666",
        "closed_by": "wanghaoshuang",
        "created_at": "2020-06-23T14:05:17+00:00",
        "updated_at": "2020-06-24T14:16:03+00:00",
        "closed_at": "2020-06-24T14:16:03+00:00",
        "comments_count": [
            "wanghaoshuang",
            "chengxurensheng666",
            "wanghaoshuang",
            "chengxurensheng666"
        ],
        "labels": [
            "pruning",
            "user"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 368,
        "title": "quant_aware训练出来的权重不是在int8范围",
        "body": "训练代码如下：  \r\n```\r\nimport os\r\n# os.environ['CUDA_VISIBLE_DEVICES']=\"1,2,3,4,5,6,7,8\"\r\nimport paddle.fluid as fluid\r\nfrom paddleslim.quant import quant_aware,convert\r\nimport numpy as np\r\n\r\nimport cv2\r\nimport models.paddle_caffe2.model_with_code.model as paddle_model\r\nimport batch_reader\r\nimport math\r\nfrom PaddleCV.metric_learning.losses import arcmarginloss\r\nimport sklearn.preprocessing as sp\r\n\r\nfrom quant_config import quant_config\r\n\r\ntrain_program=fluid.default_main_program()\r\n\r\ninputs, outputs,labels = paddle_model.x2paddle_net()\r\n\r\nplace=fluid.CUDAPlace(0)\r\n\r\nval_program = fluid.default_main_program().clone(for_test=True)\r\n# hidden=fluid.layers.fc(outputs[0],366984,bias_attr=False)\r\narc_loss=arcmarginloss.ArcMarginLoss(class_dim=366984,margin=0.4,scale=64,weight_init='./fc7_weight_init.npy')\r\nout_loss,out=arc_loss.loss(outputs[0],labels[0])\r\nloss=fluid.layers.mean(out_loss)\r\n\r\nsgd=fluid.optimizer.Momentum(learning_rate=0.0000001,\r\n                             momentum=0.9,\r\n                             regularization=fluid.regularizer.L2DecayRegularizer(0.00004))\r\n\r\nsgd.minimize(loss)\r\n\r\n\r\n\r\nexe=fluid.Executor(fluid.CUDAPlace(0))\r\nexe.run(fluid.default_startup_program())\r\n\r\ndef if_exist(var):\r\n\tb = os.path.exists(os.path.join(param_dir, var.name))\r\n\treturn b\r\n\r\nsave_dir=\"trained_models\"\r\nif not os.path.join(save_dir):\r\n\tos.makedirs(save_dir)\r\nparam_dir=\"models/paddle_caffe2/model_with_code/\"\r\nfluid.io.load_vars(exe, param_dir,\r\n                   predicate=if_exist)\r\n\r\n# fluid.io.load_persistables(exe, dirname=os.path.join(save_dir, \"best_model\"), main_program=train_program)\r\n\r\npy_reader=fluid.io.PyReader(feed_list=[inputs[0],labels[0]],capacity=10)\r\npy_reader.decorate_batch_generator(batch_reader.BatchReader,places=fluid.cuda_places())\r\n\r\nbuild_strategy=fluid.BuildStrategy()\r\nbuild_strategy.memory_optimize=False\r\nbuild_strategy.enable_inplace=False\r\nbuild_strategy.fuse_all_reduce_ops=False\r\nbuild_strategy.sync_batch_norm=False\r\nexec_strategy=fluid.ExecutionStrategy()\r\n\r\ncompile_prog = quant_aware(program=train_program,place=place,config=quant_config)\r\nval_program = quant_aware(program=val_program,place=fluid.CUDAPlace(1),config=quant_config,for_test=True)\r\n\r\ncompile_prog=compile_prog.with_data_parallel(loss_name=loss.name,build_strategy=build_strategy,exec_strategy=exec_strategy)\r\n\r\nfeeder=fluid.DataFeeder(place=fluid.CUDAPlace(1),feed_list=[inputs[0].name,labels[0].name],program=val_program)\r\n\r\ncnt=0\r\nfor data in py_reader():\r\n\tloss_val=exe.run(compile_prog,feed=data,fetch_list=[loss])\r\n\t# loss_val=exe.run(train_program,feed=data,fetch_list=[loss])\r\n\r\n\r\n\tif cnt % 100 == 0:\r\n\t\tprint(\"loss {}\".format(np.mean(loss_val)))\r\n\r\n\tif cnt % 1000 == 0:\r\n\t\t# float_program, int8_program = convert(val_program, place, quant_config, scope=None, save_int8=True)\r\n\t\tfluid.io.save_persistables(exe, dirname=os.path.join(save_dir, \"best_model\"), main_program=val_program)\r\n\r\n\t\t# fluid.io.save_inference_model(dirname=os.path.join(save_dir, \"float\"), feeded_var_names=[inputs[0].name],\r\n\t\t#                               target_vars=[outputs[0]], executor=exe,\r\n\t\t#                               main_program=float_program, model_filename=\"__model__\", params_filename=\"__params__\")\r\n\t\t#\r\n\t\t# fluid.io.save_inference_model(dirname=os.path.join(save_dir, \"int8\"), feeded_var_names=[inputs[0].name],\r\n\t\t#                               target_vars=[outputs[0]], executor=exe,\r\n\t\t#                               main_program=int8_program, model_filename=\"__model__\", params_filename=\"__params__\")\r\n\r\n\tcnt += 1\r\n```",
        "state": "closed",
        "user": "HaoLiuHust",
        "closed_by": "HaoLiuHust",
        "created_at": "2020-06-28T01:17:27+00:00",
        "updated_at": "2020-06-29T02:16:40+00:00",
        "closed_at": "2020-06-29T02:16:40+00:00",
        "comments_count": [
            "HaoLiuHust",
            "HaoLiuHust"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 379,
        "title": "Distillation about YOLOv3.",
        "body": "related to https://github.com/PaddlePaddle/PaddleDetection/issues/1043",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "qingqing01",
        "created_at": "2020-07-09T07:42:51+00:00",
        "updated_at": "2020-07-09T07:42:57+00:00",
        "closed_at": "2020-07-09T07:42:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 374,
        "title": "运行slimfacenet报错",
        "body": "运行代码：sh slim_train.sh\r\n报错如下：\r\nraceback (most recent call last):\r\n  File \"train_eval.py\", line 28, in <module>\r\n    from lfw_eval import parse_filelist, evaluation_10_fold\r\n  File \"/home/wkw/slim_dev/PaddleSlim/demo/slimfacenet/lfw_eval.py\", line 26, in <module>\r\n    from paddleslim import models\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/paddleslim/__init__.py\", line 17, in <module>\r\n    from paddleslim import prune\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/paddleslim/prune/__init__.py\", line 16, in <module>\r\n    from .pruner import *\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/paddleslim/prune/pruner.py\", line 22, in <module>\r\n    from .group_param import collect_convs\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/paddleslim/prune/group_param.py\", line 17, in <module>\r\n    from .prune_walker import conv2d as conv2d_walker\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/paddleslim/prune/prune_walker.py\", line 18, in <module>\r\n    from ..common import get_logger\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/paddleslim/common/__init__.py\", line 21, in <module>\r\n    from .server import Server\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/paddleslim/common/server.py\", line 28, in <module>\r\n    from .rl_controller.utils import add_grad, ConnectMessage\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/paddleslim/common/rl_controller/__init__.py\", line 19, in <module>\r\n    import parl\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/parl/__init__.py\", line 22, in <module>\r\n    from parl.utils.utils import _HAS_FLUID, _HAS_TORCH\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/parl/utils/__init__.py\", line 16, in <module>\r\n    from parl.utils.utils import *\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/parl/utils/utils.py\", line 91, in <module>\r\n    fluid_version = get_fluid_version()\r\n  File \"/root/anaconda3/envs/slim/lib/python3.6/site-packages/parl/utils/utils.py\", line 83, in get_fluid_version\r\n    fluid_version = int(paddle.__version__.replace('.', ''))\r\nValueError: invalid literal for int() with base 10: '200-alpha0'",
        "state": "closed",
        "user": "wkw1542673895",
        "closed_by": "XGZhang11",
        "created_at": "2020-07-02T09:23:40+00:00",
        "updated_at": "2024-02-06T03:55:20+00:00",
        "closed_at": "2024-02-06T03:55:20+00:00",
        "comments_count": [
            "ceci3",
            "wkw1542673895",
            "ceci3",
            "xiteng1988",
            "wkw1542673895"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 375,
        "title": "关于剪枝的咨询",
        "body": "你们这里有个例子https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/api_cn/prune_api.rst，我不太明白，Pruner就是用于重训，减少权重中不重要的通道权值么？但是我还没有训练，我怎么知道哪个权重重不重要呢，这里要填个ratios剪切率，这样的我要怎么填呢？sensitivity\r\n是重训后，计算每个卷积层敏感度，按说重训后不是去掉对应卷积层的一些通道的参数么，对比对应有些通道参数不重要的去掉么，这个计算每层的敏感度，作用是是什么？是说哪个敏感点，后面就裁剪多点？还有就是计算敏感度这里还有个pruned_ratios比例要填，不是应该是哪个不重要就去掉，这个我不去看权值，我怎么知道裁剪的比例呢？merge_sensitive\r\n还有这个合并的时候，value 为剪裁比例， value 为精度损失的比例是我们自己要修改什么么，还是就上面的敏感度直接使用。剪裁的网络是哪个，我感觉我理解的不太对。所以不太明白。怎么感觉跟我平常用的剪枝不太一样，所以没有理解",
        "state": "closed",
        "user": "AIpioneer",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-07-07T02:25:26+00:00",
        "updated_at": "2024-02-06T02:57:45+00:00",
        "closed_at": "2024-02-06T02:57:45+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 380,
        "title": "量化后的paddle模型转TensorRT模型的问题",
        "body": "您好，我需要将quant_post量化后的模型转换为独立的trt模型，我尝试先转为onnx模型，再从onnx模型转为trt模型，但在转onnx模型是出现如下问题：\r\n$x2paddle --framework=paddle2onnx --model=paddle_model/yolov3_quant_post_model/ --save_dir=paddle_quant_onnx_model\r\npaddle.__version__ = 1.8.2\r\nTranslating PaddlePaddle to ONNX...\r\n\r\nTotal:481, Current:481 : fetch                             bs\r\nThere's 4 ops are not supported yet\r\n=========== fake_quantize_range_abs_max ===========\r\n=========== pad2d ===========\r\n=========== fake_channel_wise_dequantize_max_abs ===========\r\n=========== elementwise_max ===========\r\n\r\n请问，该如何解决。或者，是否有其他更好的转换trt模型的办法",
        "state": "closed",
        "user": "DYJNG",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-07-10T02:01:48+00:00",
        "updated_at": "2025-02-11T06:41:23+00:00",
        "closed_at": "2025-02-11T06:41:23+00:00",
        "comments_count": [
            "ceci3",
            "cryoco",
            "DYJNG",
            "xaclincoln",
            "miraiaroha",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 382,
        "title": "demo/auto_prune/train.py 执行报错ERROR: '>' not supported between instances of 'float' and 'method'",
        "body": "\r\n```\r\n $python train.py --model \"MobileNet\"\r\n\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 256\r\nconfig_file: None\r\ndata: mnist\r\nl2_decay: 3e-05\r\nlog_period: 10\r\nlr: 0.1\r\nlr_strategy: piecewise_decay\r\nmodel: MobileNet\r\nmomentum_rate: 0.9\r\nnum_epochs: 120\r\npretrained_model: ../pretrained_model/MobileNetV1_pretained\r\nstep_epochs: [30, 60, 90]\r\ntest_period: 10\r\ntotal_images: 1281167\r\nuse_gpu: True\r\n------------------------------------------------\r\nW0710 20:56:55.537773 24805 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.2\r\nW0710 20:56:55.541970 24805 device_context.cc:245] device: 0, cuDNN Version: 7.3.\r\n/home/aistudio/external-libraries/paddle/fluid/executor.py:811: UserWarning: There are no operators in the program to be executed. If you pass Program manually, please use fluid.program_guard to ensure the current Program is being used.\r\n  warnings.warn(error_info)\r\n2020-07-10 20:56:57,122-INFO: AutoPruner - base flops: 10896832.0; pruned_flops: 0.5; max_flops: 5448416.0\r\n2020-07-10 20:56:57,122-INFO: range table: ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90])\r\n2020-07-10 20:56:57,123-INFO: ControllerServer - listen on: [172.25.135.83:57584]\r\n2020-07-10 20:56:57,123-INFO: Controller Server run...\r\n2020-07-10 20:57:08,227-INFO: AutoPruner - pruned ratios: [0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.14, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33]\r\nI0710 20:57:08.559082 24805 parallel_executor.cc:440] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\r\nI0710 20:57:08.574626 24805 build_strategy.cc:365] SeqOnlyAllReduceOps:0, num_trainers:1\r\nI0710 20:57:08.591606 24805 parallel_executor.cc:307] Inplace strategy is enabled, when build_strategy.enable_inplace = True\r\nI0710 20:57:08.609786 24805 parallel_executor.cc:322] Cross op memory reuse strategy is enabled, when build_strategy.memory_optimize = True or garbage collection strategy is disabled, which is not recommended\r\n2020-07-10 20:57:08,627-INFO: epoch[0]-batch[0] - loss: 2.4930074214935303; acc_top1: 0.1171875; acc_top5: 0.578125; time: 0.07857990264892578\r\n2020-07-10 20:57:08,869-INFO: epoch[0]-batch[10] - loss: 1.986519694328308; acc_top1: 0.33203125; acc_top5: 0.80078125; time: 0.010937929153442383\r\n2020-07-10 20:57:09,101-INFO: epoch[0]-batch[20] - loss: 1.0187472105026245; acc_top1: 0.6171875; acc_top5: 0.96484375; time: 0.010646820068359375\r\n2020-07-10 20:57:09,335-INFO: epoch[0]-batch[30] - loss: 0.6927857995033264; acc_top1: 0.78515625; acc_top5: 0.98046875; time: 0.010372400283813477\r\n2020-07-10 20:57:09,564-INFO: epoch[0]-batch[40] - loss: 0.3958178162574768; acc_top1: 0.86328125; acc_top5: 0.9921875; time: 0.010392189025878906\r\n2020-07-10 20:57:09,798-INFO: epoch[0]-batch[50] - loss: 0.38792482018470764; acc_top1: 0.87890625; acc_top5: 0.99609375; time: 0.010694742202758789\r\n2020-07-10 20:57:10,039-INFO: epoch[0]-batch[60] - loss: 0.20835408568382263; acc_top1: 0.9296875; acc_top5: 1.0; time: 0.010483741760253906\r\n2020-07-10 20:57:10,272-INFO: epoch[0]-batch[70] - loss: 0.18274663388729095; acc_top1: 0.94921875; acc_top5: 0.99609375; time: 0.010794401168823242\r\n2020-07-10 20:57:10,511-INFO: epoch[0]-batch[80] - loss: 0.2166232019662857; acc_top1: 0.9375; acc_top5: 0.99609375; time: 0.010834693908691406\r\n2020-07-10 20:57:10,742-INFO: epoch[0]-batch[90] - loss: 0.1662035882472992; acc_top1: 0.9609375; acc_top5: 1.0; time: 0.010776519775390625\r\n2020-07-10 20:57:10,981-INFO: epoch[0]-batch[100] - loss: 0.17765462398529053; acc_top1: 0.9375; acc_top5: 1.0; time: 0.01075601577758789\r\n2020-07-10 20:57:11,217-INFO: epoch[0]-batch[110] - loss: 0.17990663647651672; acc_top1: 0.9453125; acc_top5: 1.0; time: 0.010476827621459961\r\n2020-07-10 20:57:11,448-INFO: epoch[0]-batch[120] - loss: 0.16300000250339508; acc_top1: 0.94140625; acc_top5: 0.99609375; time: 0.01088714599609375\r\n2020-07-10 20:57:11,684-INFO: epoch[0]-batch[130] - loss: 0.1964532732963562; acc_top1: 0.93359375; acc_top5: 0.99609375; time: 0.010775089263916016\r\n2020-07-10 20:57:11,915-INFO: epoch[0]-batch[140] - loss: 0.2243642508983612; acc_top1: 0.91796875; acc_top5: 1.0; time: 0.010459423065185547\r\n2020-07-10 20:57:12,155-INFO: epoch[0]-batch[150] - loss: 0.12515389919281006; acc_top1: 0.95703125; acc_top5: 1.0; time: 0.010932683944702148\r\n2020-07-10 20:57:12,394-INFO: epoch[0]-batch[160] - loss: 0.16398948431015015; acc_top1: 0.9453125; acc_top5: 0.99609375; time: 0.010959625244140625\r\n2020-07-10 20:57:12,629-INFO: epoch[0]-batch[170] - loss: 0.12927889823913574; acc_top1: 0.96875; acc_top5: 1.0; time: 0.01081395149230957\r\n2020-07-10 20:57:12,868-INFO: epoch[0]-batch[180] - loss: 0.24925950169563293; acc_top1: 0.9296875; acc_top5: 0.99609375; time: 0.010622024536132812\r\n2020-07-10 20:57:13,100-INFO: epoch[0]-batch[190] - loss: 0.06702921539545059; acc_top1: 0.97265625; acc_top5: 1.0; time: 0.01078653335571289\r\n2020-07-10 20:57:13,341-INFO: epoch[0]-batch[200] - loss: 0.1213417500257492; acc_top1: 0.9609375; acc_top5: 1.0; time: 0.010640382766723633\r\n2020-07-10 20:57:13,575-INFO: epoch[0]-batch[210] - loss: 0.13785238564014435; acc_top1: 0.9609375; acc_top5: 0.98828125; time: 0.010520696640014648\r\n2020-07-10 20:57:13,805-INFO: epoch[0]-batch[220] - loss: 0.11549228429794312; acc_top1: 0.9609375; acc_top5: 0.99609375; time: 0.010681867599487305\r\n2020-07-10 20:57:14,040-INFO: epoch[0]-batch[230] - loss: 0.01106960978358984; acc_top1: 0.99609375; acc_top5: 1.0; time: 0.010622978210449219\r\n2020-07-10 20:57:14,225-INFO: Eval epoch[0] batch[0] - acc_top1: 0.95703125; acc_top5: 1.0; time: 0.038498640060424805\r\n2020-07-10 20:57:14,736-INFO: Eval epoch[0] batch[10] - acc_top1: 0.953125; acc_top5: 0.99609375; time: 0.03724551200866699\r\n2020-07-10 20:57:15,316-INFO: Eval epoch[0] batch[20] - acc_top1: 0.984375; acc_top5: 1.0; time: 0.03789806365966797\r\n2020-07-10 20:57:15,832-INFO: Eval epoch[0] batch[30] - acc_top1: 0.98046875; acc_top5: 1.0; time: 0.042928218841552734\r\n2020-07-10 20:57:16,273-INFO: Final eval epoch[0] - acc_top1: 0.9678710699081421; acc_top5: 0.998730480670929\r\n**2020-07-10 20:57:16,274-ERROR: '>' not supported between instances of 'float' and 'method'\r\n2020-07-10 20:57:16,275-INFO: server closed!**\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 228, in <module>\r\n    main()\r\n  File \"train.py\", line 224, in main\r\n    compress(args)\r\n  File \"train.py\", line 209, in compress\r\n    fluid.default_main_program(), val_program)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/prune/auto_pruner.py\", line 189, in prune\r\n    self._current_ratios = self._next_ratios()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/prune/auto_pruner.py\", line 236, in _next_ratios\r\n    tokens = self._controller_client.next_tokens()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/common/controller_client.py\", line 79, in next_tokens\r\n    socket_client.connect((self.server_ip, self.server_port))\r\nConnectionRefusedError: [Errno 111] Connection refused\r\n```\r\n\r\n环境如下：\r\npaddleslim 1.0.1\r\npaddlepaddle 1.7.2\r\npython 3.7.4",
        "state": "closed",
        "user": "greatyang",
        "closed_by": "XGZhang11",
        "created_at": "2020-07-10T13:03:51+00:00",
        "updated_at": "2024-02-06T03:56:10+00:00",
        "closed_at": "2024-02-06T03:56:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 391,
        "title": "量化训练示例按照readme 跑不通",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/develop/demo/quant/quant_aware/train.py\r\nhttps://github.com/PaddlePaddle/PaddleSlim/blob/develop/demo/quant/quant_aware/README.md",
        "state": "closed",
        "user": "ceci3",
        "closed_by": "ceci3",
        "created_at": "2020-07-17T07:22:12+00:00",
        "updated_at": "2020-07-20T08:22:04+00:00",
        "closed_at": "2020-07-20T08:22:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 381,
        "title": "关于yolo 的量化训练问题",
        "body": "1.yolov3_darknet.yml  coco 数据集加载与训练模型训练yolo_v3，map 一直非常低，4卡batch8迭代20000步,map大概0.14。请问预训练模型是否有问题，或者我这边哪里操作有问题?\r\n\r\n2.yolov4_coco 数据集量化训练\r\nCUDA_VISIBLE_DEVICES=2 python slim/quantization/train.py  --eval -c ./configs/yolov4/yolov4_cspdarknet_voc.yml  -o max_iters=1000      save_dir=./output_v4  LearningRate.base_lr=0.0001      LearningRate.schedulers=\"[!PiecewiseDecay {gamma: 0.1, milestones: [10000]}]\"      pretrain_weights=https://paddlemodels.bj.bcebos.com/object_detection/yolov4_cspdarknet.pdparams  \r\n已将bn 改为：bn\r\n报错 212-WARNING: recv endsignal from outq with errmsg[consumer[consumer-951-6] failed to map with error:[target0 not in samples]]\r\n",
        "state": "closed",
        "user": "aboutmei",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-07-10T12:05:39+00:00",
        "updated_at": "2024-02-06T02:57:46+00:00",
        "closed_at": "2024-02-06T02:57:46+00:00",
        "comments_count": [
            "heavengate",
            "heavengate"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 383,
        "title": "在paddleslim 图像分类模型知识蒸馏-快速开始 教程中 运行的问题？",
        "body": "model = slim.models.__dict__['MobileNet']()\r\nstudent_program = fluid.Program()\r\nstudent_startup = fluid.Program()\r\nwith fluid.program_guard(student_program, student_startup):\r\n    image = fluid.data(\r\n        name='image', shape=[None] + [1, 28, 28], dtype='float32')\r\n    label = fluid.data(name='label', shape=[None, 1], dtype='int64')\r\n    out = model.net(input=image, class_dim=10)\r\n    cost = fluid.layers.cross_entropy(input=out, label=label)\r\n    avg_cost = fluid.layers.mean(x=cost)\r\n    acc_top1 = fluid.layers.accuracy(input=out, label=label, k=1)\r\n    acc_top5 = fluid.layers.accuracy(input=out, label=label, k=5)\r\n\r\n当运行到这里时候 提示错误如下：\r\n---------------------------------------------------------------------------NameError                                 Traceback (most recent call last)<ipython-input-10-834c4c4f5932> in <module>\r\n----> 1 model = models.__dict__['MobileNet']()\r\n      2 student_program = fluid.Program()\r\n      3 student_startup = fluid.Program()\r\n      4 with fluid.program_guard(student_program, student_startup):\r\n      5     image = fluid.data(\r\nNameError: name 'models' is not defined\r\n\r\n说model没有定义  我看这个教程最开始也只是导入\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport paddleslim as slim\r\n这三个锕  这是什么原因呢？望解答",
        "state": "closed",
        "user": "Sejudyblues",
        "closed_by": "XGZhang11",
        "created_at": "2020-07-12T01:35:30+00:00",
        "updated_at": "2024-02-06T03:56:19+00:00",
        "closed_at": "2024-02-06T03:56:19+00:00",
        "comments_count": [
            "Sejudyblues",
            "baiyfbupt",
            "Sejudyblues"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 389,
        "title": " 支持Dataset方式的蒸馏训练",
        "body": "RT。\r\n目前的蒸馏使用的训练集和测试集reader，大部分是下载数据到本地后读取的，支持的训练集比较小；\r\n如果可以支持Dataset方式训练蒸馏的话，对使用方可以自定义hdfs或afs等路径，不用关心数据拉取等细节，和普通的分布式训练更能保持一致；\r\n",
        "state": "closed",
        "user": "chenzaiping-dev",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-07-16T07:45:53+00:00",
        "updated_at": "2024-02-06T02:57:47+00:00",
        "closed_at": "2024-02-06T02:57:47+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 394,
        "title": "AttributeError: 'Teacher' object has no attribute '_manager'",
        "body": "### 环境\r\npaddlepaddle-gpu     1.8.1.post97\r\npaddleslim           1.1.1\r\n\r\n### 命令\r\nCUDA_VISIBLE_DEVICES=0 python -u run_teacher1.py --use_cuda true --out_port 8080\r\n\r\n### 报错信息\r\n2020-07-22 22:11:36,723-WARNING: If you want to use training-aware and post-training quantization, please use Paddle >= 2.0.0 or develop version\r\npython3.6.8/lib/python3.6/site-packages/paddle/fluid/executor.py:1093: UserWarning: There are no operators in the program to be executed. If you pass Program manually, please use fluid.program_guard to ensure the current Program is being used.\r\n  warnings.warn(error_info)\r\nW0722 22:11:36.740073  1295 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 35, Driver API Version: 9.0, Runtime API Version: 9.0\r\nW0722 22:11:36.744243  1295 device_context.cc:260] device: 0, cuDNN Version: 7.0.\r\nW0722 22:11:38.036867  1295 device_context.h:155] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nProcess BaseManager-1:\r\nTraceback (most recent call last):\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/managers.py\", line 539, in _run_server\r\n    server = cls._Server(registry, address, authkey, serializer)\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/managers.py\", line 139, in __init__\r\n    self.listener = Listener(address=address, backlog=16)\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/connection.py\", line 438, in __init__\r\n    self._listener = SocketListener(address, family, backlog)\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/connection.py\", line 576, in __init__\r\n    self._socket.bind(address)\r\nOSError: [Errno 98] Address already in use\r\nTraceback (most recent call last):\r\n  File \"run_teacher1.py\", line 81, in <module>\r\n    run(args)\r\n  File \"run_teacher1.py\", line 42, in run\r\n    teacher.start()\r\n  File \"github/PaddleSlim/paddleslim/pantheon/teacher.py\", line 233, in start\r\n    self._manager = self._start_manager() if self._out_port else None\r\n  File \"github/PaddleSlim/paddleslim/pantheon/teacher.py\", line 219, in _start_manager\r\n    manager.start()\r\n  File \"/python3.6.8/lib/python3.6/multiprocessing/managers.py\", line 517, in start\r\n    self._address = reader.recv()\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\r\n    buf = self._recv_bytes()\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\r\n    buf = self._recv(4)\r\n  File \"python3.6.8/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\r\n    raise EOFError\r\nEOFError\r\nException ignored in: <bound method Teacher.__del__ of <paddleslim.pantheon.teacher.Teacher object at 0x7f094e5f9b38>>\r\nTraceback (most recent call last):\r\n  File \"github/PaddleSlim/paddleslim/pantheon/teacher.py\", line 661, in __del__\r\n    if self._manager:\r\nAttributeError: 'Teacher' object has no attribute '_manager'",
        "state": "closed",
        "user": "Dabulv",
        "closed_by": "Dabulv",
        "created_at": "2020-07-22T14:15:59+00:00",
        "updated_at": "2020-07-22T14:23:54+00:00",
        "closed_at": "2020-07-22T14:22:14+00:00",
        "comments_count": [
            "Dabulv"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 397,
        "title": "transformer 量化sample_generator如何设计",
        "body": "你好！想用quant_post对transformer模型量化，但参数sample_generator不知如何设计，\r\n能否提示下？",
        "state": "closed",
        "user": "dlkht",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-07-30T07:23:07+00:00",
        "updated_at": "2024-02-06T02:57:48+00:00",
        "closed_at": "2024-02-06T02:57:48+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 410,
        "title": "根据官方文档得到的量化模型，无法转化为“navie_buffer”格式",
        "body": "   RT，根据 [https://paddlepaddle.github.io/PaddleSlim/quick_start/quant_aware_tutorial.html](url) 的快速开始教程，训练得到的量化模型为非combine类型，在将模型转化为“navie_buffer”格式时，报如下错：\r\n    [I  8/ 6 17: 3:57.814 ...se_2.6/2.6.1/Paddle-Lite/lite/api/opt.cc:381 CheckIfModelSupported]  Erro: This model is not supported, because 2 ops are not supported on 'arm'. These unsupported ops are: 'accuracy, cross_entropy2'\r\n\r\n    求问如何解决?",
        "state": "closed",
        "user": "wuhang2016",
        "closed_by": "baiyfbupt",
        "created_at": "2020-08-06T09:36:43+00:00",
        "updated_at": "2020-08-07T05:17:33+00:00",
        "closed_at": "2020-08-07T05:17:33+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 423,
        "title": "您好，我想了解一下，PaddleSlim中的量化工具支持直接量化onnx模型么？",
        "body": "如题。。。",
        "state": "closed",
        "user": "JH95-ai",
        "closed_by": "JH95-ai",
        "created_at": "2020-08-17T10:39:00+00:00",
        "updated_at": "2020-08-18T10:04:24+00:00",
        "closed_at": "2020-08-18T10:04:24+00:00",
        "comments_count": [
            "baiyfbupt",
            "JH95-ai"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 424,
        "title": "请问paddleslim下个版本能支持动态图吗？",
        "body": "本人实在是不习惯静态图...\r\n\r\n> ",
        "state": "closed",
        "user": "FrancisJ7",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-08-18T03:28:30+00:00",
        "updated_at": "2024-02-06T02:57:49+00:00",
        "closed_at": "2024-02-06T02:57:49+00:00",
        "comments_count": [
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 428,
        "title": "Pantheon student memory leak",
        "body": "环境\r\n\r\n> python 3.6.8\r\n> paddlepaddle 1.8.3.post97\r\n> paddleslim 1.1.1\r\n\r\n程序\r\n\r\n```\r\nstudent = Student(merge_strategy=None)\r\nstudent.register_teacher(in_address=\"{}:{}\".format(in_address, t0_out_port), in_path=t0_out_path)\r\nstudent.register_teacher(in_address=\"{}:{}\".format(in_address, t1_out_port), in_path=t1_out_path)\r\nstudent.start()\r\n\r\nknowledge_desc = student.get_knowledge_desc()\r\ngenerator = student.get_knowledge_generator(batch_size)\r\n\r\nfor step, batch in tqdm.tqdm(enumerate(generator())):\r\n    time.sleep(3)\r\n```\r\n\r\n运行之后内存一直上涨，达到 200GB 之后就被系统kill掉了。",
        "state": "closed",
        "user": "Dabulv",
        "closed_by": "XGZhang11",
        "created_at": "2020-08-19T12:56:48+00:00",
        "updated_at": "2024-02-06T03:56:27+00:00",
        "closed_at": "2024-02-06T03:56:27+00:00",
        "comments_count": [],
        "labels": [
            "distillation"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 432,
        "title": "急急急！！求问在循环生成模型的程序中，怎么在生成下一个模型的时候把上一个模型删除，避免显存爆炸。类似tensorflow中的clear_session()函数，以及matlab中的clear功能的函数。",
        "body": "大佬们，请问一下AI Studio运行SA-NAS程序报错GPU out of memory，该怎么解决呢？（前天还跑了1000代，今天跑20代就停了）\r\n![GPU运行报错](https://user-images.githubusercontent.com/44279669/91248820-1dd09980-e788-11ea-81a5-d17162709131.PNG)\r\n",
        "state": "closed",
        "user": "1558513572",
        "closed_by": "1558513572",
        "created_at": "2020-08-26T02:37:33+00:00",
        "updated_at": "2020-08-29T00:13:09+00:00",
        "closed_at": "2020-08-29T00:09:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 426,
        "title": "quant_ware()量化在执行到_sync_with_cpp()时崩溃",
        "body": "/paddle/fluid/framework.py的函数_sync_with_cpp()，\r\n作用是Synchronize Python instance to its binding C++ object instance.\r\n\r\n",
        "state": "closed",
        "user": "dlkht",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-08-18T06:05:00+00:00",
        "updated_at": "2024-02-06T02:57:49+00:00",
        "closed_at": "2024-02-06T02:57:49+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 434,
        "title": "急急急！！求问在循环生成模型的程序中，怎么在生成下一个模型的时候把上一个模型删除，避免显存爆炸。类似tensorflow中的clear_session()函数，以及matlab中的clear功能的函数",
        "body": null,
        "state": "closed",
        "user": "1558513572",
        "closed_by": "XGZhang11",
        "created_at": "2020-08-29T00:13:56+00:00",
        "updated_at": "2024-02-06T03:56:46+00:00",
        "closed_at": "2024-02-06T03:56:46+00:00",
        "comments_count": [
            "ceci3",
            "1558513572"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 437,
        "title": "模型量化之后怎么加载int数据类型",
        "body": "量化训练之后有float和int两种数类型的模型文件\r\n\r\n\r\nfloat加载推理没有任何问题，但是int该怎么加载？\r\n运行命令如下：\r\n```bash\r\n python deploy/python/infer.py --model_dir=myfiles/quant_export/int --image_file=/d/hl_files/4_10_2_0003.jpg --use_gpu=True  --run_mode fluid --run_benchmark=True\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 2933, in conv2d\r\n    \"data_format\": data_format,\r\n  File \"/home/aistudio/work/PaddleDetection/ppdet/modeling/backbones/mobilenet.py\", line 84, in _conv_norm\r\n    bias_attr=False)\r\n  File \"/home/aistudio/work/PaddleDetection/ppdet/modeling/backbones/mobilenet.py\", line 159, in __call__\r\n    input, 3, int(32 * scale), 2, 1, name=self.prefix_name + \"conv1\")\r\n  File \"/home/aistudio/work/PaddleDetection/ppdet/modeling/architectures/yolo.py\", line 61, in build\r\n    body_feats = self.backbone(im)\r\n  File \"/home/aistudio/work/PaddleDetection/ppdet/modeling/architectures/yolo.py\", line 162, in test\r\n    return self.build(feed_vars, mode='test')\r\n  File \"export_model.py\", line 77, in main\r\n    test_fetches = model.test(feed_vars)\r\n  File \"export_model.py\", line 122, in <module>\r\n    main()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: input and filter data type should be consistent\r\n  [Hint: Expected input_data_type == filter_data_type, but received input_data_type:5 != filter_data_type:21.] at (/d/hl_files/Paddle/paddle/fluid/operators/conv_op.cc:173)\r\n  [operator < conv2d > error]\r\n```",
        "state": "closed",
        "user": "thunder95",
        "closed_by": "XGZhang11",
        "created_at": "2020-09-03T08:29:24+00:00",
        "updated_at": "2024-02-06T03:56:57+00:00",
        "closed_at": "2024-02-06T03:56:57+00:00",
        "comments_count": [
            "baiyfbupt",
            "thunder95",
            "baiyfbupt",
            "thunder95",
            "baiyfbupt",
            "thunder95",
            "cryoco",
            "thunder95",
            "thunder95",
            "thunder95",
            "cryoco",
            "thunder95"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 438,
        "title": "模型量化",
        "body": "在模型量化最后保存的时候，这块的输入和输出应该是什么呢，试了好多都报错\r\n![微信图片_20200903172158](https://user-images.githubusercontent.com/60954978/92097159-587ea580-ee0a-11ea-8e31-bd3c22c3bb5e.png)\r\n![微信图片_20200903172204](https://user-images.githubusercontent.com/60954978/92097167-5a486900-ee0a-11ea-84f1-9e2b0f419ab6.png)\r\n![微信图片_20200903172207](https://user-images.githubusercontent.com/60954978/92097173-5c122c80-ee0a-11ea-842d-79f7eb9a6cef.png)\r\n",
        "state": "closed",
        "user": "ZhijunLStudio",
        "closed_by": "ZhijunLStudio",
        "created_at": "2020-09-03T09:24:48+00:00",
        "updated_at": "2023-02-26T09:06:44+00:00",
        "closed_at": "2023-02-26T09:06:44+00:00",
        "comments_count": [
            "baiyfbupt",
            "itminner"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 439,
        "title": "模型部署问题",
        "body": "我在模型部署的时候，他说我这个expand_as不能用，有其他可以把c x 1 x 1扩展为c x n x n的api吗\r\n![微信图片_20200906202746](https://user-images.githubusercontent.com/60954978/92325731-76a10b80-f07f-11ea-8412-1d652e86bfaa.png)\r\n",
        "state": "closed",
        "user": "ZhijunLStudio",
        "closed_by": "ZhijunLStudio",
        "created_at": "2020-09-06T12:28:27+00:00",
        "updated_at": "2023-02-26T09:08:11+00:00",
        "closed_at": "2023-02-26T09:08:11+00:00",
        "comments_count": [
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 440,
        "title": "Slimfacenet文档中没有提供预训练模型",
        "body": "related to https://github.com/PaddlePaddle/PaddleDetection/issues/1364#issuecomment-687995392",
        "state": "closed",
        "user": "qingqing01",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-07T02:58:50+00:00",
        "updated_at": "2024-02-06T02:57:50+00:00",
        "closed_at": "2024-02-06T02:57:50+00:00",
        "comments_count": [
            "qingqing01",
            "nihuizhidao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 445,
        "title": "Slimfacenet的数据集及格式问题",
        "body": "[casia的dataloader](https://github.com/PaddlePaddle/PaddleSlim/blob/release/1.1.1/demo/slimfacenet/dataloader/casia.py)中的数据集是否可以提供下？\r\n\r\n是否是将原始数据集CASIA-WebFace做112X96的resize即可？\r\n\r\n还有就是对于提供的预训练模型，inference的每张图片格式是什么样的呢？\r\n是否按照如下操作？\r\n\r\n```\r\nimg = imgreader.imread('./test.jpg')\r\nimg = (img - 127.5) / 128.0\r\nimg = img.transpose(2, 0, 1)\r\n```\r\n",
        "state": "closed",
        "user": "nihuizhidao",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-08T10:58:17+00:00",
        "updated_at": "2024-02-06T02:57:51+00:00",
        "closed_at": "2024-02-06T02:57:51+00:00",
        "comments_count": [
            "nihuizhidao",
            "xiteng1988"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 444,
        "title": "Slimface的train_eval.py的importer有问题",
        "body": "python==3.6.10\r\npaddlepaddle-gpu==1.8.2.post107\r\npaddleslim==1.1.1\r\n\r\n[slimfacenet的train_eval.py](https://github.com/PaddlePaddle/PaddleSlim/blob/develop/demo/slimfacenet/train_eval.py)第30行的quant_post_static导入出错：\r\n\r\n> from paddleslim.quant import quant_post_static\r\n> W0908 17:05:49.643043  5333 init.cc:134] Compiled with WITH_GPU, but no GPU found in runtime.\r\n> 2020-09-08 17:05:49,662-WARNING: If you want to use DDPG in RLNAS, please pip install parl first. Now states: No module named 'parl'\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n> ImportError: cannot import name 'quant_post_static'\r\n\r\npaddlepaddle的gpu调用是正常的。\r\n\r\n请问这个是什么原因呢？\r\n",
        "state": "closed",
        "user": "nihuizhidao",
        "closed_by": "nihuizhidao",
        "created_at": "2020-09-08T09:08:12+00:00",
        "updated_at": "2020-09-08T12:44:06+00:00",
        "closed_at": "2020-09-08T12:44:05+00:00",
        "comments_count": [
            "nihuizhidao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 448,
        "title": "有动态图量化教程吗",
        "body": null,
        "state": "closed",
        "user": "WenmuZhou",
        "closed_by": "WenmuZhou",
        "created_at": "2020-09-10T03:05:33+00:00",
        "updated_at": "2023-09-06T11:01:54+00:00",
        "closed_at": "2023-09-06T11:01:54+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 452,
        "title": "模型量化文件数变少问题",
        "body": "量化前的权重文件数是300个，量化之后是220个，以致于用量化之后权重的来预测，什么都预测不出来，我按着官方文档来的，但是不知道哪里出了问题\r\n![微信图片_20200914075341](https://user-images.githubusercontent.com/60954978/93031691-75fc0c80-f65f-11ea-810c-da0a9333dd5a.png)\r\n![2](https://user-images.githubusercontent.com/60954978/93031695-78f6fd00-f65f-11ea-81b1-5d616e586b80.png)\r\n\r\n",
        "state": "closed",
        "user": "ZhijunLStudio",
        "closed_by": "ZhijunLStudio",
        "created_at": "2020-09-13T23:54:17+00:00",
        "updated_at": "2023-02-26T09:07:50+00:00",
        "closed_at": "2023-02-26T09:07:50+00:00",
        "comments_count": [
            "wanghaoshuang",
            "ZhijunLStudio",
            "ZhijunLStudio",
            "wanghaoshuang",
            "ZhijunLStudio",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 459,
        "title": "检测模型在线量化",
        "body": "我在检测网络训练脚本train.py里加入了quant_aware函数，训练出现如下错误，请问是什么问题\r\n\r\n![image](https://user-images.githubusercontent.com/7603531/93284737-dcbb2a80-f805-11ea-8662-0b8a8ae7031a.png)\r\n\r\n",
        "state": "closed",
        "user": "Youngon",
        "closed_by": "Youngon",
        "created_at": "2020-09-16T02:17:54+00:00",
        "updated_at": "2020-09-28T02:05:28+00:00",
        "closed_at": "2020-09-28T02:05:11+00:00",
        "comments_count": [
            "ceci3",
            "Youngon",
            "ceci3",
            "Youngon"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 453,
        "title": "请问一下，在使用词嵌入量化时，报错",
        "body": "----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The Tensor in the lookup_table Op's Input Variable W(word_emb) is not initialized.\r\n  [Hint: Expected t->IsInitialized() == true, but received t->IsInitialized():0 != true:1.] at (D:\\1.8.4\\paddle\\paddle\\fluid\\framework\\operator.cc:1289)\r\n  [operator < lookup_table > error]\r\n",
        "state": "closed",
        "user": "18140663659",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-14T10:56:21+00:00",
        "updated_at": "2024-02-06T02:57:52+00:00",
        "closed_at": "2024-02-06T02:57:52+00:00",
        "comments_count": [
            "wanghaoshuang",
            "18140663659",
            "18140663659",
            "18140663659",
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 462,
        "title": "在量化训练中，训练正常，评估输出结果不正确，保存的模型也不正确",
        "body": " - PaddlePaddle 1.8.4\r\n\r\n代码 https://github.com/yeyupiaoling/PaddlePaddle-Classification/blob/ce5274cc23c60fcf5d9c8913bee4af7c5ec7f387/train.py#L137-L176\r\n```python\r\ndef main(args):\r\n    config = get_config(args.config, overrides=args.override, show=True)\r\n    # 如果需要量化训练，就必须开启评估\r\n    if not config.validate and args.use_quant:\r\n        logger.error(\"=====>Train quant model must use validate!\")\r\n        sys.exit(1)\r\n    if config.epochs < 6 and args.use_quant:\r\n        logger.error(\"=====>Train quant model epochs must greater than 6!\")\r\n        sys.exit(1)\r\n    # 设置是否使用 GPU\r\n    use_gpu = config.get(\"use_gpu\", True)\r\n    places = fluid.cuda_places() if use_gpu else fluid.cpu_places()\r\n\r\n    startup_prog = fluid.Program()\r\n    train_prog = fluid.Program()\r\n\r\n    best_top1_acc = 0.0\r\n\r\n    # 获取训练数据和模型输出\r\n    if not config.get('use_ema'):\r\n        train_dataloader, train_fetchs, out = program.build(config,\r\n                                                            train_prog,\r\n                                                            startup_prog,\r\n                                                            is_train=True,\r\n                                                            is_distributed=False)\r\n    else:\r\n        train_dataloader, train_fetchs, ema, out = program.build(config,\r\n                                                                 train_prog,\r\n                                                                 startup_prog,\r\n                                                                 is_train=True,\r\n                                                                 is_distributed=False)\r\n    # 获取评估数据和模型输出\r\n    if config.validate:\r\n        valid_prog = fluid.Program()\r\n        valid_dataloader, valid_fetchs, _ = program.build(config,\r\n                                                          valid_prog,\r\n                                                          startup_prog,\r\n                                                          is_train=False,\r\n                                                          is_distributed=False)\r\n        # 克隆评估程序，可以去掉与评估无关的计算\r\n        valid_prog = valid_prog.clone(for_test=True)\r\n\r\n    # 创建执行器\r\n    exe = fluid.Executor(places[0])\r\n    exe.run(startup_prog)\r\n\r\n    # 加载模型，可以是预训练模型，也可以是检查点\r\n    init_model(config, train_prog, exe)\r\n\r\n    train_reader = Reader(config, 'train')()\r\n    train_dataloader.set_sample_list_generator(train_reader, places)\r\n\r\n    compiled_train_prog = program.compile(config, train_prog, train_fetchs['loss'][0].name)\r\n\r\n    if config.validate:\r\n        valid_reader = Reader(config, 'valid')()\r\n        valid_dataloader.set_sample_list_generator(valid_reader, places)\r\n        compiled_valid_prog = program.compile(config, valid_prog, share_prog=compiled_train_prog)\r\n\r\n    vdl_writer = LogWriter(args.vdl_dir)\r\n\r\n    for epoch_id in range(config.epochs - 5):\r\n        # 训练一轮\r\n        program.run(train_dataloader, exe, compiled_train_prog, train_fetchs, epoch_id, 'train', config, vdl_writer)\r\n\r\n        # 执行一次评估\r\n        if config.validate and epoch_id % config.valid_interval == 0:\r\n            if config.get('use_ema'):\r\n                logger.info(logger.coloring(\"EMA validate start...\"))\r\n                with ema.apply(exe):\r\n                    _ = program.run(valid_dataloader, exe,\r\n                                    compiled_valid_prog, valid_fetchs,\r\n                                    epoch_id, 'valid', config)\r\n                logger.info(logger.coloring(\"EMA validate over!\"))\r\n\r\n            top1_acc = program.run(valid_dataloader, exe, compiled_valid_prog, valid_fetchs, epoch_id, 'valid', config)\r\n            if top1_acc > best_top1_acc:\r\n                best_top1_acc = top1_acc\r\n                message = \"The best top1 acc {:.5f}, in epoch: {:d}\".format(best_top1_acc, epoch_id)\r\n                logger.info(\"{:s}\".format(logger.coloring(message, \"RED\")))\r\n                if epoch_id % config.save_interval == 0:\r\n                    model_path = os.path.join(config.model_save_dir, config.ARCHITECTURE[\"name\"])\r\n                    save_model(train_prog, model_path, \"best_model\")\r\n\r\n        # 保存模型\r\n        if epoch_id % config.save_interval == 0:\r\n            model_path = os.path.join(config.model_save_dir, config.ARCHITECTURE[\"name\"])\r\n            if epoch_id >= 3 and os.path.exists(os.path.join(model_path, str(epoch_id - 3))):\r\n                shutil.rmtree(os.path.join(model_path, str(epoch_id - 3)), ignore_errors=True)\r\n            save_model(train_prog, model_path, epoch_id)\r\n\r\n    # 量化训练\r\n    if args.use_quant and config.validate:\r\n        # 执行量化训练\r\n        quant_program = slim.quant.quant_aware(train_prog, exe.place, for_test=False)\r\n\r\n        fetch_list = [f[0] for f in train_fetchs.values()]\r\n        metric_list = [f[1] for f in train_fetchs.values()]\r\n        for i in range(5):\r\n            for idx, batch in enumerate(train_dataloader()):\r\n                metrics = exe.run(program=quant_program, feed=batch, fetch_list=fetch_list)\r\n                for i, m in enumerate(metrics):\r\n                    metric_list[i].update(np.mean(m), len(batch[0]))\r\n                fetchs_str = ''.join([str(m.value) + ' ' for m in metric_list])\r\n\r\n                if idx % 10 == 0:\r\n                    logger.info(\"quant train : \" + fetchs_str)\r\n\r\n        # 评估量化的结果\r\n        val_quant_program = slim.quant.quant_aware(valid_prog, exe.place, for_test=True)\r\n\r\n        fetch_list = [f[0] for f in valid_fetchs.values()]\r\n        metric_list = [f[1] for f in valid_fetchs.values()]\r\n        for idx, batch in enumerate(valid_dataloader()):\r\n            metrics = exe.run(program=val_quant_program, feed=batch, fetch_list=fetch_list)\r\n            for i, m in enumerate(metrics):\r\n                metric_list[i].update(np.mean(m), len(batch[0]))\r\n            fetchs_str = ''.join([str(m.value) + ' ' for m in metric_list])\r\n\r\n            if idx % 10 == 0:\r\n                logger.info(\"quant valid: \" + fetchs_str)\r\n\r\n        # 保存量化训练模型\r\n        float_prog, int8_prog = slim.quant.convert(val_quant_program, exe.place, save_int8=True)\r\n        fluid.io.save_inference_model(dirname=args.output_path,\r\n                                      feeded_var_names=['feed_image'],\r\n                                      target_vars=out,\r\n                                      executor=exe,\r\n                                      main_program=float_prog,\r\n                                      model_filename='__model__',\r\n                                      params_filename='__params__')\r\n```\r\n\r\n输出结果如下，可以看出来量化评估的准确率非常低，相当于没有训练\r\n```\r\n2020-09-17 02:50:44,995-INFO: epoch:394 train step:190  loss:  1.2416 lr: 0.000028 elapse: 0.275s\r\n2020-09-17 02:50:47,746-INFO: epoch:394 train step:200  loss:  1.0109 lr: 0.000028 elapse: 0.274s\r\n2020-09-17 02:50:50,503-INFO: epoch:394 train step:210  loss:  0.9340 lr: 0.000028 elapse: 0.277s\r\n2020-09-17 02:50:53,257-INFO: epoch:394 train step:220  loss:  0.9204 lr: 0.000028 elapse: 0.275s\r\n2020-09-17 02:50:56,010-INFO: epoch:394 train step:230  loss:  2.4909 lr: 0.000028 elapse: 0.274s\r\n2020-09-17 02:50:58,765-INFO: epoch:394 train step:240  loss:  0.8378 lr: 0.000028 elapse: 0.275s\r\n2020-09-17 02:51:01,520-INFO: epoch:394 train step:250  loss:  0.8325 lr: 0.000028 elapse: 0.275s\r\n2020-09-17 02:51:04,273-INFO: epoch:394 train step:260  loss:  0.8397 lr: 0.000028 elapse: 0.274s\r\n2020-09-17 02:51:07,029-INFO: epoch:394 train step:270  loss:  0.8546 lr: 0.000028 elapse: 0.275s\r\n2020-09-17 02:51:07,579-INFO: END epoch:394 train loss_avg:  1.2111  elapse_sum: 75.699s\r\n2020-09-17 02:51:07,936-INFO: epoch:394 valid step:0    loss:  1.4642 top1: 0.7031 top5: 0.9062 elapse: 0.357s\r\n2020-09-17 02:51:09,953-INFO: epoch:394 valid step:10   loss:  1.4104 top1: 0.7344 top5: 0.9062 elapse: 0.082s\r\n2020-09-17 02:51:10,806-INFO: epoch:394 valid step:20   loss:  1.3292 top1: 0.7344 top5: 0.9531 elapse: 0.095s\r\n2020-09-17 02:51:12,113-INFO: END epoch:394 valid loss_avg:  1.4435 top1_avg: 0.7120 top5_avg: 0.9125 elapse_sum: 4.530s\r\n2020-09-17 02:51:13,980-INFO: Already save model in ./output/ResNet50_vd/394\r\n2020-09-17 02:51:13,980-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False}\r\n2020-09-17 02:51:17,966-INFO: quant train : loss:  0.8532 lr: 0.000019 \r\n2020-09-17 02:51:21,137-INFO: quant train : loss:  1.0666 lr: 0.000019 \r\n2020-09-17 02:51:24,206-INFO: quant train : loss:  0.9276 lr: 0.000019 \r\n2020-09-17 02:57:51,909-INFO: quant train : loss:  2.4494 lr: 0.000001 \r\n.......................................\r\n2020-09-17 02:58:16,551-INFO: quant train : loss:  1.6833 lr: 0.000001 \r\n2020-09-17 02:58:19,624-INFO: quant train : loss:  2.1616 lr: 0.000001 \r\n2020-09-17 02:58:22,701-INFO: quant train : loss:  0.8692 lr: 0.000001 \r\n2020-09-17 02:58:23,315-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False}\r\n2020-09-17 02:58:24,427-INFO: quant valid: loss:  3.0968 top1: 0.0625 top5: 0.3125 \r\n2020-09-17 02:58:25,943-INFO: quant valid: loss:  3.0719 top1: 0.0625 top5: 0.3750 \r\n2020-09-17 02:58:27,448-INFO: quant valid: loss:  3.1283 top1: 0.0625 top5: 0.3750 \r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2020-09-17T07:37:34+00:00",
        "updated_at": "2020-09-18T06:34:45+00:00",
        "closed_at": "2020-09-18T06:34:45+00:00",
        "comments_count": [
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 465,
        "title": "模型剪裁是否支持pytorch训练好的模型？",
        "body": "模型剪裁功能是否支持pytorch训练好的模型？谢谢",
        "state": "closed",
        "user": "Ultraopxt",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-22T02:41:17+00:00",
        "updated_at": "2024-02-06T02:57:53+00:00",
        "closed_at": "2024-02-06T02:57:53+00:00",
        "comments_count": [
            "AIpioneer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 466,
        "title": "使用X2paddle将tf转paddle模型后，根据敏感度剪枝的问题",
        "body": "我现在有一个tf转成paddle的模型，如果我想对该paddle模型模型压缩，然后进行finetune，请问应该用什么载入模型？\r\n我现在使用的代码如下：\r\n`\r\nimport numpy as np\r\nimport paddle.fluid as fluid\r\nimport paddleslim as slim\r\nimport paddle\r\nimport time\r\nimport cv2\r\nimport os\r\n\r\ndata_path = r'E:\\paddleslim\\ILSVRC2012_img_val'\r\nmodel_path = r'E:\\paddleslim\\paddle_models\\mobilenet_imagenet\\inference_model'\r\nlabels_path = 'labels.npy'\r\nlabels = np.load(labels_path)\r\nimages = os.listdir(data_path)\r\nnum_sample = len(images)\r\nbatch_size = 2\r\nnum_sample = 100\r\n\r\n\r\ndef reader_train():\r\n    for i in range(num_sample):\r\n        image = images[i]\r\n        image_path = os.path.join(data_path, image)\r\n        img = cv2.imread(image_path)\r\n        img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_LINEAR)\r\n        img = img.astype(np.float32) / 255\r\n        img = img * 2 - 1\r\n        img = np.transpose(img, (2, 0, 1))\r\n        label = labels[i] + 1\r\n        yield img, label\r\n\r\n\r\ndef reader_test():\r\n    for i in range(num_sample, num_sample+num_sample):\r\n        image = images[i]\r\n        image_path = os.path.join(data_path, image)\r\n        img = cv2.imread(image_path)\r\n        img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_LINEAR)\r\n        img = img.astype(np.float32) / 255\r\n        img = img * 2 - 1\r\n        img = np.transpose(img, (2, 0, 1))\r\n        label = labels[i] + 1\r\n        yield img, label\r\n\r\n\r\ndef test(program):\r\n    acc_top1_ns = []\r\n    acc_top5_ns = []\r\n    for data in test_reader():\r\n        acc_top1_n, acc_top5_n, _ = exe.run(program, feed=data_feeder.feed(data), fetch_list=outputs)\r\n        acc_top1_ns.append(np.mean(acc_top1_n))\r\n        acc_top5_ns.append(np.mean(acc_top5_n))\r\n    print(\"Final eva - acc_top1: {}; acc_top5: {}\".format(np.mean(np.array(acc_top1_ns)), np.mean(np.array(acc_top5_ns))))\r\n    return np.mean(np.array(acc_top1_ns))\r\n\r\n\r\n# 定义调试器\r\nplace = fluid.CPUPlace()\r\nexe = fluid.Executor(place)\r\n\r\n# 载入模型\r\n[inference_program, feed_target_names, outputs] = fluid.io.load_inference_model(model_path, exe)\r\n\r\n# 加载数据\r\ntrain_reader = fluid.io.batch(reader_train, batch_size=batch_size)\r\ntest_reader = fluid.io.batch(reader_test, batch_size=batch_size)\r\nfeed_list = [inference_program.global_block().var(var_name) for var_name in feed_target_names]  # feed_vars_name 是一个由变量名组成的列表\r\ndata_feeder = fluid.DataFeeder(feed_list, place)\r\n\r\n# 计算剪枝之前的FLOPs\r\nFLOPs = slim.analysis.flops(inference_program)\r\nprint(\"剪枝前的FLOPs: {}\".format(FLOPs))\r\n\r\n# 测试网络\r\ntest(inference_program)\r\n\r\n# 获取待分析的卷积层参数\r\nparams = []\r\nfor param in inference_program.global_block().all_parameters():\r\n    if \"_sep_weights\" in param.name:\r\n        params.append(param.name)\r\nprint(\"-\"*30 + \"待分析的卷积参数\" + \"-\"*30)\r\nprint(params)\r\n\r\n# 调用sensitivity接口对训练好的模型进行敏感度分析\r\nprint(\"-\"*30 + \"裁剪率为40%敏感度分析结果\" + \"-\"*30)\r\nsens_1 = slim.prune.sensitivity(inference_program, place, params, test, sensitivities_file=\"sensitivities_1.data\", pruned_ratios=[0.4])\r\nprint(sens_1)\r\n\r\n# 加载多个进行产出的敏感度文件\r\ns_1 = slim.prune.load_sensitivities(\"sensitivities_1.data\")\r\nprint(\"-\"*30 + \"加载裁减率为40%的敏感度\" + \"-\"*30)\r\nprint(s_1)\r\n\r\n# 调用get_ratios_by_loss根据敏感度计算裁减率，通过调整参数loss大小获得合适的一组裁剪率\r\nloss = 0.05\r\nratios = slim.prune.get_ratios_by_loss(s_1, loss)\r\nprint(\"-\"*30 + \"获取的合适的一组裁剪率\" + \"-\"*30)\r\nprint(ratios)\r\n`\r\n任务描述：\r\n使用x2paddle模型将tf转化为paddle模型，然后基于该模型使用paddleslim做剪枝，但是里面涉及到需要将剪枝后的网络进行finetune，所以在构建数据时需要image和label，但是从上面获得的inputs只能够获得image，所以会出现以下报错：\r\n![image](https://user-images.githubusercontent.com/71812360/94128523-d9badc80-fe8c-11ea-945b-55419ae815f5.png)\r\n请问一下怎么获得label的输入接口。",
        "state": "closed",
        "user": "down-to-earth-WYL",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-24T07:05:49+00:00",
        "updated_at": "2024-02-06T02:57:53+00:00",
        "closed_at": "2024-02-06T02:57:53+00:00",
        "comments_count": [
            "wanghaoshuang",
            "down-to-earth-WYL",
            "jiangjiajun",
            "down-to-earth-WYL",
            "jiangjiajun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 467,
        "title": "蒸馏模型训练报错",
        "body": "**用的paddleslim现成的蒸馏函数，训练的时候报错\r\n```bash\r\nC:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py:789: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"C:/Users/虹虹/Desktop/加油4/qinglianghua_python/copy999999999999999.py\", line 133, in <module>\r\n    acc1, loss_np = exe.run(student_program, feed=train_feeder.feed(data), fetch_list=[acc_top1.name, avg_cost.name])\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 790, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\six.py\", line 703, in reraise\r\n    raise value\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 785, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 838, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 912, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\nWindows not support stack backtrace yet.\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\paddleslim\\dist\\single_distiller.py\", line 95, in merge\r\n    type=op.type, inputs=inputs, outputs=outputs, attrs=attrs)\r\n  File \"C:/Users/虹虹/Desktop/加油4/qinglianghua_python/copy999999999999999.py\", line 111, in <module>\r\n    main = slim.dist.merge(teacher_program, student_program, data_name_map, fluid.CPUPlace())\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The Tensor in the conv2d Op's Input Variable Input(teacher_data) is not initialized.\r\n  [Hint: Expected t->IsInitialized() == true, but received t->IsInitialized():0 != true:1.] at (D:\\1.7.2\\paddle\\paddle\\fluid\\framework\\operator.cc:1264)\r\n  [operator < conv2d > error]\r\n```\r\n源代码：\r\n```python\r\n1. 导入依赖\r\nimport paddle\r\nimport os\r\nimport paddle.fluid as fluid\r\nimport paddleslim as slim\r\nimport models\r\nimport reader\r\nimport numpy as np\r\n```\r\n\r\n2. 定义student_program和teacher_program\r\n\r\n```python\r\ntokens_student = [5, 13, 0, 0]  #1个\r\ntokens_teacher = [5,13,0,0,3,1,2,1,4,16,0,1,3,18,0,0]  #4个\r\n\r\nstudent_program = fluid.Program()\r\nstudent_startup = fluid.Program()\r\n\r\nwith fluid.program_guard(student_program, student_startup):\r\n\r\n        config1 = [('MobileNetV2BlockSpace', {'input_size': 224, 'output_size': 112, 'block_num': 1})]\r\n        sanas1 = slim.nas.SANAS(configs=config1, server_addr=(\"\", 9887), init_temperature=1000, reduce_rate=0.99,\r\n                            search_steps=None, init_tokens=None, save_checkpoint='/home/aistudio/work/nas_checkpoint',\r\n                            load_checkpoint=None, is_server=True)\r\n        model1 = sanas1.tokens2arch(tokens_student)[0]\r\n\r\n        image = fluid.data(name='data', shape=[None, 3, 224, 224], dtype='float32')\r\n        label = fluid.data(name='label', shape=[None, 1], dtype='int64')\r\n\r\n        output = model1(image)\r\n        out = fluid.layers.fc(input=output, size=5)\r\n\r\n        cost = fluid.layers.cross_entropy(input=out, label=label)\r\n        avg_cost = fluid.layers.mean(x=cost)\r\n        acc_top1 = fluid.layers.accuracy(input=out, label=label, k=1)\r\n\r\nplace = fluid.CPUPlace()\r\nexe = fluid.Executor(place)\r\n\r\nteacher_program = fluid.Program()\r\nteacher_startup = fluid.Program()\r\n\r\nwith fluid.program_guard(teacher_program, teacher_startup):\r\n        with fluid.unique_name.guard():\r\n\r\n                config3 = [('MobileNetV2BlockSpace', {'input_size': 224, 'output_size': 14, 'block_num': 4})]\r\n                sanas3 = slim.nas.SANAS(configs=config3, server_addr=(\"\", 9997), init_temperature=1000, reduce_rate=0.99,\r\n                                search_steps=None, init_tokens=None,\r\n                                save_checkpoint='/home/aistudio/work/nas_checkpoint', load_checkpoint=None,\r\n                                is_server=True)\r\n                model3 = sanas3.tokens2arch(tokens_teacher)[0]\r\n\r\n                image3 = fluid.data(name='data', shape=[None, 3, 224, 224], dtype='float32')\r\n                label3 = fluid.data(name='label', shape=[None, 1], dtype='int64')\r\n\r\n                output3 = model3(image3)\r\n                out3 = fluid.layers.fc(input=output3, size=5)\r\n\r\n                cost3 = fluid.layers.cross_entropy(input=out3, label=label3)\r\n                avg_cost3= fluid.layers.mean(x=cost3)\r\n                acc_top13 = fluid.layers.accuracy(input=out3, label=label3, k=1)\r\n\r\nexe.run(teacher_startup)\r\n```\r\n4. 合并program (merge)并添加蒸馏loss\r\n```python\r\ndata_name_map = {'image3': 'image'}\r\nmain = slim.dist.merge(teacher_program, student_program, data_name_map, fluid.CPUPlace())\r\n\r\nwith fluid.program_guard(student_program, student_startup):\r\n\r\n        l2_loss = slim.dist.l2_loss('teacher_depthwise_conv2d_0.tmp_0', 'depthwise_conv2d_0.tmp_0', student_program)\r\n        print(l2_loss)\r\n        loss = l2_loss + avg_cost\r\n\r\n        opt = fluid.optimizer.Momentum(0.01, 0.9)\r\n        opt.minimize(loss)\r\n\r\nexe.run(student_startup)\r\n```\r\n5. 模型训练\r\n```python\r\ntrain_reader = paddle.batch(reader=reader.train_reader('target/train.list',224,250), batch_size=64, drop_last=True)\r\ntrain_feeder = fluid.DataFeeder(place=place, feed_list=[image, label])\r\n\r\nfor pass_id in range(100):\r\n\r\n      for batch_id, data in enumerate(train_reader()):\r\n\r\n            acc1, loss_np = exe.run(student_program, feed=train_feeder.feed(data), fetch_list=[acc_top1.name, avg_cost.name])\r\n\r\n            print('Pass:%d, Batch:%d, Acc1:%0.5f, Loss:%0.5f' % (pass_id, batch_id, acc1.mean(), loss_np.mean()))\r\n```\r\n",
        "state": "closed",
        "user": "1558513572",
        "closed_by": "XGZhang11",
        "created_at": "2020-09-25T01:50:17+00:00",
        "updated_at": "2024-02-06T03:52:09+00:00",
        "closed_at": "2024-02-06T03:51:45+00:00",
        "comments_count": [
            "baiyfbupt",
            "1558513572",
            "baiyfbupt",
            "1558513572",
            "baiyfbupt",
            "1558513572",
            "baiyfbupt",
            "1558513572",
            "1558513572"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 468,
        "title": "请问一下，在进行模型裁剪时，需要先进性的敏感度分析的原则是什么？也就是说敏感度是怎么算出来的？",
        "body": null,
        "state": "closed",
        "user": "CVdandelion",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-26T02:25:13+00:00",
        "updated_at": "2024-02-06T02:57:54+00:00",
        "closed_at": "2024-02-06T02:57:54+00:00",
        "comments_count": [
            "yukavio"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 469,
        "title": "检测模型量化误差",
        "body": "我用的相同的数据集，相同的配置文件，分别训练了非量化版本以及量化版本，为什么测试mAP差别这么大？\r\n（PaddleDetection/tools/train.py）非量化迭代30000次：\r\n![image](https://user-images.githubusercontent.com/7603531/94383374-6eb22400-0172-11eb-8d39-e56c43706168.png)\r\n（PaddleDetection/slin/quantization/train.py）量化迭代30000次：\r\n![image](https://user-images.githubusercontent.com/7603531/94383384-783b8c00-0172-11eb-8bd5-2f3fa2a5f4a3.png)\r\n差的不是一点半点",
        "state": "closed",
        "user": "Youngon",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-28T02:09:28+00:00",
        "updated_at": "2024-02-06T02:57:55+00:00",
        "closed_at": "2024-02-06T02:57:55+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Youngon",
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 473,
        "title": "预训练模型的量化压缩",
        "body": "目前想要把PaddleClas中ResNet50_vd_ssld的预训练模型进行量化并评估，请问大致的方法思路是怎么样的呢？谢谢！",
        "state": "closed",
        "user": "yhhu99",
        "closed_by": "yhhu99",
        "created_at": "2020-10-14T11:30:37+00:00",
        "updated_at": "2020-10-15T05:32:18+00:00",
        "closed_at": "2020-10-15T05:32:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 470,
        "title": "PaddleSlim是否支持FP16量化",
        "body": null,
        "state": "closed",
        "user": "down-to-earth-WYL",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-28T09:55:07+00:00",
        "updated_at": "2024-02-06T02:57:56+00:00",
        "closed_at": "2024-02-06T02:57:56+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Water2style"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 474,
        "title": "关于使用quant_post_static的版本问题",
        "body": "电脑上装的是paddlepaddle1.8，所以根据github安装的提示安装了paddleslim1.1.1，但是按照快速开始里的离线静态量化教程：\r\n![image](https://user-images.githubusercontent.com/69721135/96080780-70a61200-0eea-11eb-90ca-acd18eb6cc1a.png)\r\n却是会报错paddleslim.quant里没有quant_post_static这个attribute：\r\n![image](https://user-images.githubusercontent.com/69721135/96080892-b7940780-0eea-11eb-92bc-0f6dc057b0a8.png)\r\n感觉可能是版本的问题，求大佬解答下正确的版本应该是啥，或者怎么在paddleslim1.1.1下使用quant_post_static",
        "state": "closed",
        "user": "yhhu99",
        "closed_by": "yhhu99",
        "created_at": "2020-10-15T05:31:42+00:00",
        "updated_at": "2020-10-18T05:53:17+00:00",
        "closed_at": "2020-10-18T05:53:17+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 472,
        "title": "SlimMobilenet accuracy",
        "body": "I tried to reproduce the 80% top1 performance of SlimMobilenet(V5), but can only get around 72.3% top 1 accuracy. Would you release the pretrained model in the future? ",
        "state": "closed",
        "user": "liyy201912",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-09-29T21:40:53+00:00",
        "updated_at": "2024-02-06T02:57:57+00:00",
        "closed_at": "2024-02-06T02:57:57+00:00",
        "comments_count": [
            "xiteng1988"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 476,
        "title": "请问动态图怎么用paddleslim进行裁剪",
        "body": "现在是可以通过转换为静态图，保存为推断模型，但是不知道怎么进行模型通道裁剪。\r\n` out_dygraph, static_layer = TracedLayer.trace(DeepSortNet, inputs=[image])\r\n    static_layer.save_inference_model('infer_model')\r\n`\r\n因为 pruner.prune裁剪时需要传入program，但是动态图训练时并没有用programe",
        "state": "closed",
        "user": "doge-ac-cn",
        "closed_by": "doge-ac-cn",
        "created_at": "2020-10-19T03:20:08+00:00",
        "updated_at": "2020-11-03T01:18:04+00:00",
        "closed_at": "2020-11-03T01:18:04+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 477,
        "title": "量化模型每一层的细节参数",
        "body": "在已经成功量化并得到了inference模型文件（\\__model__与__params\\__），请问如果想要得到网络中每一层的量化参数（细节），需要怎么做呢？谢谢！",
        "state": "closed",
        "user": "yhhu99",
        "closed_by": "yhhu99",
        "created_at": "2020-10-21T03:07:26+00:00",
        "updated_at": "2020-10-27T15:20:31+00:00",
        "closed_at": "2020-10-27T15:20:31+00:00",
        "comments_count": [
            "baiyfbupt",
            "yhhu99",
            "yhhu99",
            "baiyfbupt",
            "yhhu99",
            "yhhu99"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 480,
        "title": "直接贴的教程里的代码运行，结果报错InvalidArgumentError",
        "body": "代码\r\n`import paddle\r\nimport paddle.fluid as fluid\r\nimport paddleslim as slim\r\n\r\nexe, train_program, val_program, inputs, outputs = slim.models.image_classification(\"MobileNet\", [1, 28, 28], 10,\r\n                                                                                    use_gpu=True)\r\nplace = fluid.CUDAPlace(0)\r\nimport paddle.dataset.mnist as reader\r\n\r\ntrain_reader = paddle.fluid.io.batch(\r\n    reader.train(), batch_size=128, drop_last=True)\r\ntest_reader = paddle.fluid.io.batch(\r\n    reader.test(), batch_size=128, drop_last=True)\r\ndata_feeder = fluid.DataFeeder(inputs, place)\r\nimport numpy as np\r\n\r\n\r\ndef test(program):\r\n    acc_top1_ns = []\r\n    acc_top5_ns = []\r\n    for data in test_reader():\r\n        acc_top1_n, acc_top5_n, _ = exe.run(\r\n            program,\r\n            feed=data_feeder.feed(data),\r\n            fetch_list=outputs)\r\n        acc_top1_ns.append(np.mean(acc_top1_n))\r\n        acc_top5_ns.append(np.mean(acc_top5_n))\r\n    print(\"Final eva - acc_top1: {}; acc_top5: {}\".format(\r\n        np.mean(np.array(acc_top1_ns)), np.mean(np.array(acc_top5_ns))))\r\n    return np.mean(np.array(acc_top1_ns))\r\n\r\n\r\nfor data in train_reader():\r\n    acc1, acc5, loss = exe.run(train_program, feed=data_feeder.feed(data), fetch_list=outputs)\r\nprint(np.mean(acc1), np.mean(acc5), np.mean(loss))\r\n\r\ntest(val_program)\r\n\r\nparams = []\r\nfor param in train_program.global_block().all_parameters():\r\n    if \"_sep_weights\" in param.name:\r\n        params.append(param.name)\r\nprint(params)\r\nparams = params[:5]\r\n\r\nsens_0 = slim.prune.sensitivity(\r\n    val_program,\r\n    place,\r\n    params,\r\n    test,\r\n    sensitivities_file=\"sensitivities_0.data\",\r\n    pruned_ratios=[0.1, 0.2])\r\nprint(sens_0)\r\n\r\nsens_0 = slim.prune.sensitivity(\r\n    val_program,\r\n    place,\r\n    params,\r\n    test,\r\n    sensitivities_file=\"sensitivities_0.data\",\r\n    pruned_ratios=[0.3])\r\nprint(sens_0)\r\n\r\nsens_1 = slim.prune.sensitivity(\r\n    val_program,\r\n    place,\r\n    params,\r\n    test,\r\n    sensitivities_file=\"sensitivities_1.data\",\r\n    pruned_ratios=[0.4])\r\nprint(sens_1)\r\n\r\ns_0 = slim.prune.load_sensitivities(\"sensitivities_0.data\")\r\ns_1 = slim.prune.load_sensitivities(\"sensitivities_1.data\")\r\nprint(s_0)\r\nprint(s_1)\r\n\r\ns = slim.prune.merge_sensitive([s_0, s_1])\r\nprint(s)\r\n\r\nloss = 0.01\r\nratios = slim.prune.get_ratios_by_loss(s_0, loss)\r\nprint(ratios)\r\n\r\npruner = slim.prune.Pruner()\r\nprint(\"FLOPs before pruning: {}\".format(slim.analysis.flops(train_program)))\r\npruned_program, _, _ = pruner.prune(\r\n    train_program,\r\n    fluid.global_scope(),\r\n    params=ratios.keys(),\r\n    ratios=ratios.values(),\r\n    place=place)\r\nprint(\"FLOPs after pruning: {}\".format(slim.analysis.flops(pruned_program)))\r\n\r\npruner = slim.prune.Pruner()\r\nprint(\"FLOPs before pruning: {}\".format(slim.analysis.flops(val_program)))\r\npruned_val_program, _, _ = pruner.prune(\r\n    val_program,\r\n    fluid.global_scope(),\r\n    params=ratios.keys(),\r\n    ratios=ratios.values(),\r\n    place=place,\r\n    only_graph=True)\r\nprint(\"FLOPs after pruning: {}\".format(slim.analysis.flops(pruned_val_program)))\r\n\r\ntest(pruned_val_program)\r\n\r\nfor data in train_reader():\r\n    acc1, acc5, loss = exe.run(pruned_program, feed=data_feeder.feed(data), fetch_list=outputs)\r\nprint(np.mean(acc1), np.mean(acc5), np.mean(loss))\r\n\r\ntest(pruned_val_program)\r\n`\r\n\r\n报错\r\n`0.9921875 1.0 0.02577366\r\nFinal eva - acc_top1: 0.9693509340286255; acc_top5: 0.9984976053237915\r\n['conv2_1_sep_weights', 'conv2_2_sep_weights', 'conv3_1_sep_weights', 'conv3_2_sep_weights', 'conv4_1_sep_weights', 'conv4_2_sep_weights', 'conv5_1_sep_weights', 'conv5_2_sep_weights', 'conv5_3_sep_weights', 'conv5_4_sep_weights', 'conv5_5_sep_weights', 'conv5_6_sep_weights', 'conv6_sep_weights']\r\n2020-10-23 11:56:39,170-INFO: sensitive - param: conv2_1_sep_weights; ratios: 0.1\r\nFinal eva - acc_top1: 0.9693509340286255; acc_top5: 0.9984976053237915\r\n2020-10-23 11:56:39,186-INFO: pruning: conv2_1_sep_weights\r\nTraceback (most recent call last):\r\n  File \"C:/Users/83942/Desktop/github/paddleslim模型裁剪/main.py\", line 46, in <module>\r\n    pruned_ratios=[0.1, 0.2])\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddleslim\\prune\\sensitive.py\", line 99, in sensitivity\r\n    param_backup=True)\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddleslim\\prune\\pruner.py\", line 165, in prune\r\n    graph.infer_shape()\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddleslim\\core\\graph_wrapper.py\", line 362, in infer_shape\r\n    op._op.desc.infer_shape(op._op.block.desc)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\nWindows not support stack backtrace yet.\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py\", line 2938, in conv2d\r\n    \"data_format\": data_format,\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddleslim\\models\\mobilenet.py\", line 162, in conv_bn_layer\r\n    bias_attr=False)\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddleslim\\models\\mobilenet.py\", line 188, in depthwise_separable\r\n    name=name + \"_dw\")\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddleslim\\models\\mobilenet.py\", line 55, in net\r\n    name=\"conv2_2\")\r\n  File \"C:\\Users\\83942\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\paddleslim\\models\\util.py\", line 19, in image_classification\r\n    out = model.net(input=image, class_dim=class_num)\r\n  File \"C:/Users/83942/Desktop/github/paddleslim模型裁剪/main.py\", line 4, in <module>\r\n    exe, train_program, val_program, inputs, outputs = slim.models.image_classification(\"MobileNet\", [1, 28, 28], 10, use_gpu=True)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The number of input's channels should be equal to filter's channels * groups for Op(Conv). But received: the input's channels is 64, the input's shape is [-1, 64, 14, 14]; the filter's channels is 1, the filter's shape is [64, 1, 3, 3]; the groups is 63, the data_format is NCHW. The error may come from wrong data_format setting.\r\n  [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:64 != filter_dims[1] * groups:63.] at (D:\\1.8.5\\paddle\\paddle\\fluid\\operators\\conv_op.cc:94)\r\n  [operator < depthwise_conv2d > error]\r\nW1023 11:56:00.958933  3628 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW1023 11:56:00.966912  3628 device_context.cc:260] device: 0, cuDNN Version: 7.6.`",
        "state": "closed",
        "user": "doge-ac-cn",
        "closed_by": "doge-ac-cn",
        "created_at": "2020-10-23T05:34:45+00:00",
        "updated_at": "2021-08-19T06:09:49+00:00",
        "closed_at": "2021-08-19T06:09:49+00:00",
        "comments_count": [
            "wanghaoshuang",
            "doge-ac-cn",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 479,
        "title": "使用SlimFaceNet_C_x0_75()网络进行训练时出现错误InvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [2, 3427] and the shape of Y = [4, 3427]. Received [2] in X is not equal to [4] in Y at i:0.",
        "body": "求大佬指点，在使用SlimFaceNet_C_x0_75()模型训练时出现InvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [2, 3427] and the shape of Y = [4, 3427]. Received [2] in X is not equal to [4] in Y at i:0.错误，感谢",
        "state": "closed",
        "user": "zhudibo",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-10-23T04:00:08+00:00",
        "updated_at": "2024-02-06T02:57:59+00:00",
        "closed_at": "2024-02-06T02:57:59+00:00",
        "comments_count": [
            "xiteng1988"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 478,
        "title": "使用slim.quant.quant_post量化时出错",
        "body": "对YOLOv3模型进行量化，将slim.quant.quant_post安排到了paddledetection中的得infer.py文件中，借助其exe与program\r\n```\r\nTraceback (most recent call last):\r\n  File \"tools/infer.py\", line 278, in <module>\r\n    main()\r\n  File \"tools/infer.py\", line 242, in main\r\n    batch_nums=10)\r\n  File \"/home/robot/anaconda3/envs/paddle/lib/python3.7/site-packages/paddleslim/quant/quanter.py\", line 331, in quant_post\r\n    post_training_quantization.quantize()\r\n  File \"/home/robot/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 300, in quantize\r\n    self._calculate_kl_threshold()\r\n  File \"/home/robot/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 503, in _calculate_kl_threshold\r\n    weight_data = self._sampling_data[var_name]\r\nKeyError: 'stage.3.6.1.conv.weights'\r\n```\r\n而且每次KeyError:后面的内容都会变化，请问是什么原因",
        "state": "closed",
        "user": "CVdandelion",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-10-21T11:38:05+00:00",
        "updated_at": "2024-02-06T02:57:58+00:00",
        "closed_at": "2024-02-06T02:57:58+00:00",
        "comments_count": [
            "CVdandelion",
            "baiyfbupt",
            "CVdandelion",
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 481,
        "title": "arc_margin_product（）函数中报错",
        "body": "大佬我在运行SlimFaceNet_C_x0_75()网络时，在arc_margin_product（）中one_hot = fluid.one_hot(input=label, depth=out_dim)行报以下的错误\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/un/.local/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/un/.local/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/un/.local/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 12212, in _elementwise_op\r\n    'use_mkldnn': use_mkldnn})\r\n  File \"/home/un/.local/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 12643, in elementwise_mul\r\n    return _elementwise_op(LayerHelper('elementwise_mul', **locals()))\r\n  File \"/home/un/work/mobilenetv2/arcmarginloss.py\", line 120, in arc_margin_product\r\n    one_hot, phi) + fluid.layers.elementwise_mul(\r\n  File \"/home/un/work/mobilenetv2/arcmarginloss.py\", line 29, in loss\r\n    out = self.arc_margin_product(input, label, self.class_dim, self.margin, self.scale, self.easy_margin)\r\n  File \"/home/un/work/mobilenetv2/train.py\", line 865, in train\r\n    cost,out = metricloss.loss(out_featrue, label)\r\n  File \"/home/un/work/mobilenetv2/train.py\", line 969, in <module>\r\n    train()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [10, 3427] and the shape of Y = [20, 3427]. Received [10] in X is not equal to [20] in Y at i:0.\r\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] at (/paddle/paddle/fluid/operators/elementwise/elementwise_op_function.h:157)\r\n  [operator < elementwise_mul > error]\r\n",
        "state": "closed",
        "user": "zhudibo",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-10-23T09:19:35+00:00",
        "updated_at": "2024-02-06T02:58:00+00:00",
        "closed_at": "2024-02-06T02:58:00+00:00",
        "comments_count": [
            "xiteng1988",
            "zhudibo-unwulian",
            "yangy996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 482,
        "title": "使用slimfacenet在训练模型遇到如下问题",
        "body": "大佬我在使用slimfacenet训练模型时，网络的输出               x = fluid.layers.conv2d(\r\n            x,\r\n            num_filters=128,\r\n            filter_size=1,\r\n            stride=1,\r\n            padding=0,\r\n            groups=1,\r\n            act=None,\r\n            use_cudnn=True,\r\n            param_attr=ParamAttr(\r\n                name='linear_conv1x1_weights',\r\n                initializer=MSRA(),\r\n                regularizer=fluid.regularizer.L2Decay(4e-4)),\r\n            bias_attr=False)\r\n        bn_name = 'linear_conv1x1_bn'\r\n        x = fluid.layers.batch_norm(\r\n            x,\r\n            param_attr=ParamAttr(name=bn_name + \"_scale\"),\r\n            bias_attr=ParamAttr(name=bn_name + \"_offset\"),\r\n            moving_mean_name=bn_name + '_mean',\r\n            moving_variance_name=bn_name + '_variance')\r\n        print(x.shape,x.shape[0],x.shape[1])\r\n        x = fluid.layers.reshape(x, shape=[x.shape[0], x.shape[1]])\r\n的卷积层的输出特征输入到损失网络时报一下的错误：\r\nInvalidArgumentError: Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [80, 3427] and the shape of Y = [160, 3427]. Received [80] in X is not equal to [160] in Y at i:0.恳请大佬给予指点啊",
        "state": "closed",
        "user": "zhudibo",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-10-26T02:35:40+00:00",
        "updated_at": "2024-02-06T02:58:01+00:00",
        "closed_at": "2024-02-06T02:58:01+00:00",
        "comments_count": [
            "xiteng1988"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 483,
        "title": "无法成功提交pr",
        "body": "在提交pr时遇到一下问题：\r\nUsername for 'https://github.com': zhudibo-unwulian\r\nPassword for 'https://zhudibo-unwulian@github.com': \r\nremote: Permission to PaddlePaddle/PaddleSlim.git denied to zhudibo-unwulian.\r\nfatal: unable to access 'https://github.com/PaddlePaddle/PaddleSlim/': The requested URL returned error: 403\r\n",
        "state": "closed",
        "user": "zhudibo-unwulian",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-10-26T07:26:21+00:00",
        "updated_at": "2024-02-06T02:58:02+00:00",
        "closed_at": "2024-02-06T02:58:02+00:00",
        "comments_count": [
            "baiyfbupt",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 489,
        "title": "iou_loss  loss 为nan",
        "body": "INFO: iter: 0, lr: 0.000010, 'loss_xy': '1.828222', 'loss_wh': '5.254690', 'loss_obj': '130.993652', 'loss_cls': '30.401878', 'loss_iou': 'nan', 'loss': 'nan', time: 0.000, eta: 0:00:00\r\n\r\npaddlepaddle 1.8.4，paddleslim 1.1.0  yolov3_darknet_voc_diouloss配置，LR 1e-1 - 1e-6都试过，使用 iou_loss ,dioulossyolo, diouloss ciou_term: False, diouloss ciou_term: True, iou loss 均为nan ,偶尔第一个迭代不为nan，检查代码和配置均没发现问题，请问是什么原因导致的？\r\n补充：0.4分支代码\r\n\r\n",
        "state": "closed",
        "user": "aboutmei",
        "closed_by": "aboutmei",
        "created_at": "2020-10-30T06:58:49+00:00",
        "updated_at": "2020-11-08T08:14:29+00:00",
        "closed_at": "2020-11-08T08:14:29+00:00",
        "comments_count": [
            "aboutmei",
            "aboutmei",
            "aboutmei",
            "yghstill",
            "qingqing01",
            "aboutmei",
            "baiyfbupt",
            "aboutmei",
            "aboutmei",
            "aboutmei",
            "baiyfbupt",
            "aboutmei"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 491,
        "title": "使用slimface训练好的模型在移动端部署进行预测，使用predictor=createpaddlepredictor<mobileconfig>(config)无法加载模型",
        "body": "大佬，请求指导，使用slimface训练好模型，在移动端部署模型进行预测，函数如下：\r\nmobileconfig config；\r\nstd::shared_ptr<paddlepredictor>predictor:\r\nconfig.set_model_from_file(model_file);\r\npredictor=createpaddlepredictor<mobileconfig>(config)无法加载slimface模型。\r\n",
        "state": "closed",
        "user": "zhudibo",
        "closed_by": "XGZhang11",
        "created_at": "2020-11-02T02:53:59+00:00",
        "updated_at": "2024-02-06T03:51:35+00:00",
        "closed_at": "2024-02-06T03:51:35+00:00",
        "comments_count": [
            "qingqing01",
            "zhudibo",
            "zhudibo",
            "zhudibo-unwulian",
            "AIpioneer",
            "zhudibo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 497,
        "title": "使用ppyolo训练自己的voc格式数据集，出现loss较大，精度也比其它算法低",
        "body": "使用ppyolo训练自己的单类 voc格式数据集，数据集含有小目标较多，只修改了ppyolovoc.yml文件的部分参数：\r\nmax_iters: 8000\r\nnum_classes: 1\r\nLearningRate:\r\n  #base_lr: 0.00333\r\n  base_lr: 0.001\r\n  schedulers:\r\n  - !PiecewiseDecay\r\n    gamma: 0.1\r\n    milestones:\r\n    - 3000\r\n    - 5000\r\n  - !LinearWarmup\r\n    start_factor: 0.\r\n    steps: 1000\r\n其中base_lr: 0.00333也试过，部分训练结果如下：\r\n![image](https://user-images.githubusercontent.com/52195642/97938909-9c1b6e80-1dbd-11eb-8da5-9e686278917f.png)\r\nloss在iter: 6000左右就稳定在70左右，AP0.5在此也达到最高0.7419，精度比YOLOv3和二阶段算法都低。\r\nloss_obj和loss_iou较大，请问该如何调整参数？",
        "state": "closed",
        "user": "May52",
        "closed_by": "May52",
        "created_at": "2020-11-03T02:23:09+00:00",
        "updated_at": "2020-11-03T02:43:54+00:00",
        "closed_at": "2020-11-03T02:43:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 501,
        "title": "facenet using pre_train_model and load_vars error",
        "body": "pretrained_model_path=\"work/models/quant_model_SlimFaceNet_B_x0_75\"\r\n\r\n# SlimFaceNet_B_x0_75 paddleslim/models/\r\n\r\ndef network(image, train_base_model=False):\r\n    base_model = SlimFaceNet_B_x0_75(class_dim=1).net(image)\r\n    base_model.stop_gradient = not train_base_model \r\n    base_model_program = fluid.default_main_program().clone() \r\n    return base_model_program\r\n\r\ndef load_pretrained_params(exe, program):\r\n\r\n    # load exist var\r\n    def if_exist(var):\r\n        path = os.path.join(pretrained_model_path, var.name)\r\n        exist = os.path.exists(path)\r\n        if exist:\r\n                print(\"Load\", path)\r\n        return exist\r\n    fluid.io.load_vars(exe, pretrained_model_path, predicate=if_exist, main_program=program)\r\n\r\nmain = fluid.Program()\r\nstartup = fluid.Program()\r\nexe = fluid.Executor(place)\r\nplace = fluid.CUDAPlace(0)\r\nwith fluid.unique_name.guard():\r\n    with fluid.program_guard(main, startup):\r\n        x = fluid.data(name='x', shape=[-1, 3, 112, 112], dtype='float32')\r\n        base_model_program = network(x, False)\r\n        load_pretrained_params(exe, base_model_program)\r\n\r\n\r\n\r\n错误信息如下:\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_bn_mean\r\n---------------------------------------------------------------------------RuntimeError                              Traceback (most recent call last)<ipython-input-132-34c4c4c9e9aa> in <module>\r\n     26         x = fluid.data(name='x', shape=[-1, 3, 112, 112], dtype='float32')\r\n     27         base_model_program = network(x, False)\r\n---> 28         load_pretrained_params(exe, base_model_program)\r\n<ipython-input-132-34c4c4c9e9aa> in load_pretrained_params(exe, program)\r\n     16                 print(\"Load\", path)\r\n     17         return exist\r\n---> 18     fluid.io.load_vars(exe, pretrained_model_path, predicate=if_exist, main_program=program)\r\n     19 \r\n     20 main = fluid.Program()\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py in load_vars(executor, dirname, main_program, vars, predicate, filename)\r\n    749             main_program=main_program,\r\n    750             vars=list(filter(predicate, main_program.list_vars())),\r\n--> 751             filename=filename)\r\n    752     else:\r\n    753         load_prog = Program()\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py in load_vars(executor, dirname, main_program, vars, predicate, filename)\r\n    818                     \"Variable's shape does not match, the Program requires a parameter with the shape of ({}), \"\r\n    819                     \"while the loaded parameter (namely [ {} ]) has a shape of  ({}).\".\r\n--> 820                     format(orig_shape, each_var.name, new_shape))\r\n    821 \r\n    822 \r\nRuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((192,)), while the loaded parameter (namely [ residual_unit9_expand_bn_mean ]) has a shape of  ((152,)).\r\n\r\n",
        "state": "closed",
        "user": "lastrei",
        "closed_by": "lastrei",
        "created_at": "2020-11-06T10:19:16+00:00",
        "updated_at": "2020-11-06T11:08:57+00:00",
        "closed_at": "2020-11-06T11:08:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 495,
        "title": "AttributeError: module 'paddleslim.quant' has no attribute 'quant_post_static'",
        "body": "跑静态离线量化的实例代码：https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/quick_start/quant_post_static_tutorial.md\r\n会报 module 'paddleslim.quant' has no attribute 'quant_post_static'的错误\r\npaddle version:1.8.5\r\npaddlesslim version:1.1.1",
        "state": "closed",
        "user": "zhuguiqian",
        "closed_by": "zhuguiqian",
        "created_at": "2020-11-02T07:17:30+00:00",
        "updated_at": "2020-11-03T08:32:39+00:00",
        "closed_at": "2020-11-03T08:32:39+00:00",
        "comments_count": [
            "qingqing01",
            "zhuguiqian",
            "qingqing01",
            "zhuguiqian"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 499,
        "title": "PaddleSlim是否支持多标签网络的量化和以及逐层量化",
        "body": "请教一下，PaddleSlim是否支持多标签网络的量化（例如人脸关键点网络），我这边试了一下报下图的错误，不确定是不支持多标签网络，还是其他错误。\r\n环境：\r\npaddlepaddle:1.8.5\r\npaddleslim:1.1.1\r\n![image](https://user-images.githubusercontent.com/7693110/97967619-6e075000-1df8-11eb-9c67-c5f124bbf972.png)\r\n另外，aistudio上跑的slim例子，跑出来的量化结果是逐通道量化的（如下图），想问一下是否有选项可以选择逐层量化？\r\n![image](https://user-images.githubusercontent.com/7693110/97968970-55983500-1dfa-11eb-8405-b1ab8e3d978f.png)\r\n\r\n\r\n最后今天开始发现pip安装paddleslim一直报错，如果只是我这边问题请忽略\r\n![image](https://user-images.githubusercontent.com/7693110/97968567-c68b1d00-1df9-11eb-892a-37fa82173a4b.png)\r\n",
        "state": "closed",
        "user": "zhuguiqian",
        "closed_by": "XGZhang11",
        "created_at": "2020-11-03T09:32:29+00:00",
        "updated_at": "2024-02-06T03:57:08+00:00",
        "closed_at": "2024-02-06T03:57:08+00:00",
        "comments_count": [
            "baiyfbupt",
            "zhuguiqian",
            "baiyfbupt",
            "zhuguiqian",
            "baiyfbupt",
            "zhuguiqian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 494,
        "title": "离线量化slim.quant.quant_post的问题",
        "body": "我用paddledetection将模型训练后进行量化，结果出现了这个问题，请问以下是什么原因\r\n以下是报错：\r\n```bash\r\n2020-11-02 14:35:07,899-INFO: Load model and set data loader ...\r\n2020-11-02 14:35:07,977-INFO: Collect quantized variable names ...\r\n2020-11-02 14:35:09,990-WARNING: Your reader has raised an exception!\r\nException in thread Thread-7:\r\nTypeError: only size-1 arrays can be converted to Python scalars\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddle/fluid/reader.py\", line 1145, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddle/fluid/reader.py\", line 1125, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddle/fluid/data_feeder.py\", line 204, in __call__\r\n    yield self._done()\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddle/fluid/data_feeder.py\", line 192, in _done\r\n    return [c.done() for c in self.converters]\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddle/fluid/data_feeder.py\", line 192, in <listcomp>\r\n    return [c.done() for c in self.converters]\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddle/fluid/data_feeder.py\", line 157, in done\r\n    arr = np.array(self.data, dtype=self.dtype)\r\nValueError: setting an array element with a sequence.\r\n\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 379, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 317, in main\r\n    batch_nums=10)\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddleslim/quant/quanter.py\", line 306, in quant_post\r\n    post_training_quantization.quantize()\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 280, in quantize\r\n    for data in self._data_loader():\r\n  File \"/home/w/anaconda3/envs/vgg/lib/python3.6/site-packages/paddle/fluid/reader.py\", line 1104, in __next__\r\n    return self._reader.read_next()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\r\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\r\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Blocking queue is killed because the data reader raises an exception\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)\r\n```\r\n具体执行的程序是：其中##之间为调用op的内容\r\n\r\n\r\n\r\n\r\n\r\n\r\n```python\r\n# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os, sys\r\n# add python path of PadleDetection to sys.path\r\nparent_path = os.path.abspath(os.path.join(__file__, *(['..'] * 2)))\r\nif parent_path not in sys.path:\r\n    sys.path.append(parent_path)\r\n\r\nimport time\r\nimport numpy as np\r\nimport random\r\nimport datetime\r\nimport six\r\nfrom collections import deque\r\nfrom paddle.fluid import profiler\r\n\r\nimport paddleslim as slim\r\n\r\nfrom paddle import fluid\r\nfrom paddle.fluid.layers.learning_rate_scheduler import _decay_step_counter\r\nfrom paddle.fluid.optimizer import ExponentialMovingAverage\r\n\r\nfrom ppdet.experimental import mixed_precision_context\r\nfrom ppdet.core.workspace import load_config, merge_config, create\r\nfrom ppdet.data.reader import create_reader\r\n\r\nfrom ppdet.utils import dist_utils\r\nfrom ppdet.utils.eval_utils import parse_fetches, eval_run, eval_results\r\nfrom ppdet.utils.stats import TrainingStats\r\nfrom ppdet.utils.cli import ArgsParser\r\nfrom ppdet.utils.check import check_gpu, check_version, check_config\r\nimport ppdet.utils.checkpoint as checkpoint\r\n\r\nimport logging\r\nFORMAT = '%(asctime)s-%(levelname)s: %(message)s'\r\nlogging.basicConfig(level=logging.INFO, format=FORMAT)\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\ndef main():\r\n    env = os.environ\r\n    FLAGS.dist = 'PADDLE_TRAINER_ID' in env and 'PADDLE_TRAINERS_NUM' in env\r\n    if FLAGS.dist:\r\n        trainer_id = int(env['PADDLE_TRAINER_ID'])\r\n        local_seed = (99 + trainer_id)\r\n        random.seed(local_seed)\r\n        np.random.seed(local_seed)\r\n\r\n    if FLAGS.enable_ce:\r\n        random.seed(0)\r\n        np.random.seed(0)\r\n\r\n    cfg = load_config(FLAGS.config)\r\n    merge_config(FLAGS.opt)\r\n    check_config(cfg)\r\n    # check if set use_gpu=True in paddlepaddle cpu version\r\n    check_gpu(cfg.use_gpu)\r\n    # check if paddlepaddle version is satisfied\r\n    check_version()\r\n\r\n    save_only = getattr(cfg, 'save_prediction_only', False)\r\n    if save_only:\r\n        raise NotImplementedError('The config file only support prediction,'\r\n                                  ' training stage is not implemented now')\r\n    main_arch = cfg.architecture\r\n\r\n    if cfg.use_gpu:\r\n        devices_num = fluid.core.get_cuda_device_count()\r\n    else:\r\n        devices_num = int(os.environ.get('CPU_NUM', 1))\r\n\r\n    if 'FLAGS_selected_gpus' in env:\r\n        device_id = int(env['FLAGS_selected_gpus'])\r\n    else:\r\n        device_id = 0\r\n    place = fluid.CUDAPlace(device_id) if cfg.use_gpu else fluid.CPUPlace()\r\n    exe = fluid.Executor(place)\r\n\r\n    lr_builder = create('LearningRate')\r\n    optim_builder = create('OptimizerBuilder')\r\n\r\n    # build program\r\n    startup_prog = fluid.Program()\r\n    train_prog = fluid.Program()\r\n    if FLAGS.enable_ce:\r\n        startup_prog.random_seed = 1000\r\n        train_prog.random_seed = 1000\r\n    with fluid.program_guard(train_prog, startup_prog):\r\n        with fluid.unique_name.guard():\r\n            model = create(main_arch)\r\n            if FLAGS.fp16:\r\n                assert (getattr(model.backbone, 'norm_type', None)\r\n                        != 'affine_channel'), \\\r\n                    '--fp16 currently does not support affine channel, ' \\\r\n                    ' please modify backbone settings to use batch norm'\r\n\r\n            with mixed_precision_context(FLAGS.loss_scale, FLAGS.fp16) as ctx:\r\n                inputs_def = cfg['TrainReader']['inputs_def']\r\n                feed_vars, train_loader = model.build_inputs(**inputs_def)\r\n                train_fetches = model.train(feed_vars)\r\n                loss = train_fetches['loss']\r\n                if FLAGS.fp16:\r\n                    loss *= ctx.get_loss_scale_var()\r\n                lr = lr_builder()\r\n                optimizer = optim_builder(lr)\r\n                optimizer.minimize(loss)\r\n\r\n                if FLAGS.fp16:\r\n                    loss /= ctx.get_loss_scale_var()\r\n\r\n            if 'use_ema' in cfg and cfg['use_ema']:\r\n                global_steps = _decay_step_counter()\r\n                ema = ExponentialMovingAverage(\r\n                    cfg['ema_decay'], thres_steps=global_steps)\r\n                ema.update()\r\n\r\n    # parse train fetches\r\n    train_keys, train_values, _ = parse_fetches(train_fetches)\r\n    train_values.append(lr)\r\n\r\n    if FLAGS.eval:\r\n        eval_prog = fluid.Program()\r\n        with fluid.program_guard(eval_prog, startup_prog):\r\n            with fluid.unique_name.guard():\r\n                model = create(main_arch)\r\n                inputs_def = cfg['EvalReader']['inputs_def']\r\n                feed_vars, eval_loader = model.build_inputs(**inputs_def)\r\n                fetches = model.eval(feed_vars)\r\n        eval_prog = eval_prog.clone(True)\r\n\r\n        eval_reader = create_reader(cfg.EvalReader, devices_num=1)\r\n        eval_loader.set_sample_list_generator(eval_reader, place)\r\n\r\n        # parse eval fetches\r\n        extra_keys = []\r\n        if cfg.metric == 'COCO':\r\n            extra_keys = ['im_info', 'im_id', 'im_shape']\r\n        if cfg.metric == 'VOC':\r\n            extra_keys = ['gt_bbox', 'gt_class', 'is_difficult']\r\n        if cfg.metric == 'WIDERFACE':\r\n            extra_keys = ['im_id', 'im_shape', 'gt_bbox']\r\n        eval_keys, eval_values, eval_cls = parse_fetches(fetches, eval_prog,\r\n                                                         extra_keys)\r\n\r\n    # compile program for multi-devices\r\n    build_strategy = fluid.BuildStrategy()\r\n    build_strategy.fuse_all_optimizer_ops = False\r\n    # only enable sync_bn in multi GPU devices\r\n    sync_bn = getattr(model.backbone, 'norm_type', None) == 'sync_bn'\r\n    build_strategy.sync_batch_norm = sync_bn and devices_num > 1 \\\r\n        and cfg.use_gpu\r\n\r\n    exec_strategy = fluid.ExecutionStrategy()\r\n    # iteration number when CompiledProgram tries to drop local execution scopes.\r\n    # Set it to be 1 to save memory usages, so that unused variables in\r\n    # local execution scopes can be deleted after each iteration.\r\n    exec_strategy.num_iteration_per_drop_scope = 1\r\n    if FLAGS.dist:\r\n        dist_utils.prepare_for_multi_process(exe, build_strategy, startup_prog,\r\n                                             train_prog)\r\n        exec_strategy.num_threads = 1\r\n\r\n    exe.run(startup_prog)\r\n    compiled_train_prog = fluid.CompiledProgram(train_prog).with_data_parallel(\r\n        loss_name=loss.name,\r\n        build_strategy=build_strategy,\r\n        exec_strategy=exec_strategy)\r\n\r\n    if FLAGS.eval:\r\n        compiled_eval_prog = fluid.CompiledProgram(eval_prog)\r\n\r\n    fuse_bn = getattr(model.backbone, 'norm_type', None) == 'affine_channel'\r\n\r\n    ignore_params = cfg.finetune_exclude_pretrained_params \\\r\n                 if 'finetune_exclude_pretrained_params' in cfg else []\r\n\r\n    start_iter = 0\r\n    if FLAGS.resume_checkpoint:\r\n        checkpoint.load_checkpoint(exe, train_prog, FLAGS.resume_checkpoint)\r\n        start_iter = checkpoint.global_step()\r\n    elif cfg.pretrain_weights and fuse_bn and not ignore_params:\r\n        checkpoint.load_and_fusebn(exe, train_prog, cfg.pretrain_weights)\r\n    elif cfg.pretrain_weights:\r\n        checkpoint.load_params(\r\n            exe, train_prog, cfg.pretrain_weights, ignore_params=ignore_params)\r\n\r\n    train_reader = create_reader(\r\n        cfg.TrainReader, (cfg.max_iters - start_iter) * devices_num,\r\n        cfg,\r\n        devices_num=devices_num)\r\n    train_loader.set_sample_list_generator(train_reader, place)\r\n\r\n    # whether output bbox is normalized in model output layer\r\n    is_bbox_normalized = False\r\n    if hasattr(model, 'is_bbox_normalized') and \\\r\n            callable(model.is_bbox_normalized):\r\n        is_bbox_normalized = model.is_bbox_normalized()\r\n\r\n    # if map_type not set, use default 11point, only use in VOC eval\r\n    map_type = cfg.map_type if 'map_type' in cfg else '11point'\r\n\r\n    train_stats = TrainingStats(cfg.log_smooth_window, train_keys)\r\n    train_loader.start()\r\n    start_time = time.time()\r\n    end_time = time.time()\r\n\r\n    cfg_name = os.path.basename(FLAGS.config).split('.')[0]\r\n    save_dir = os.path.join(cfg.save_dir, cfg_name)\r\n    time_stat = deque(maxlen=cfg.log_smooth_window)\r\n    best_box_ap_list = [0.0, 0]  #[map, iter]\r\n\r\n    # use VisualDL to log data\r\n    if FLAGS.use_vdl:\r\n        assert six.PY3, \"VisualDL requires Python >= 3.5\"\r\n        from visualdl import LogWriter\r\n        vdl_writer = LogWriter(FLAGS.vdl_log_dir)\r\n        vdl_loss_step = 0\r\n        vdl_mAP_step = 0\r\n\r\n    for it in range(start_iter, cfg.max_iters):\r\n        start_time = end_time\r\n        end_time = time.time()\r\n        time_stat.append(end_time - start_time)\r\n        time_cost = np.mean(time_stat)\r\n        eta_sec = (cfg.max_iters - it) * time_cost\r\n        eta = str(datetime.timedelta(seconds=int(eta_sec)))\r\n        outs = exe.run(compiled_train_prog, fetch_list=train_values)\r\n        stats = {k: np.array(v).mean() for k, v in zip(train_keys, outs[:-1])}\r\n\r\n        # use vdl-paddle to log loss\r\n        if FLAGS.use_vdl:\r\n            if it % cfg.log_iter == 0:\r\n                for loss_name, loss_value in stats.items():\r\n                    vdl_writer.add_scalar(loss_name, loss_value, vdl_loss_step)\r\n                vdl_loss_step += 1\r\n\r\n        train_stats.update(stats)\r\n        logs = train_stats.log()\r\n        if it % cfg.log_iter == 0 and (not FLAGS.dist or trainer_id == 0):\r\n            strs = 'iter: {}, lr: {:.6f}, {}, time: {:.3f}, eta: {}'.format(\r\n                it, np.mean(outs[-1]), logs, time_cost, eta)\r\n            logger.info(strs)\r\n\r\n        # NOTE : profiler tools, used for benchmark\r\n        if FLAGS.is_profiler and it == 5:\r\n            profiler.start_profiler(\"All\")\r\n        elif FLAGS.is_profiler and it == 10:\r\n            profiler.stop_profiler(\"total\", FLAGS.profiler_path)\r\n            return\r\n\r\n\r\n        if (it > 0 and it % cfg.snapshot_iter == 0 or it == cfg.max_iters - 1) \\\r\n           and (not FLAGS.dist or trainer_id == 0):\r\n            save_name = str(it) if it != cfg.max_iters - 1 else \"model_final\"\r\n            if 'use_ema' in cfg and cfg['use_ema']:\r\n                exe.run(ema.apply_program)\r\n            checkpoint.save(exe, train_prog, os.path.join(save_dir, save_name))\r\n            if FLAGS.eval:\r\n                # evaluation\r\n                resolution = None\r\n                if 'Mask' in cfg.architecture:\r\n                    resolution = model.mask_head.resolution\r\n                results = eval_run(\r\n                    exe,\r\n                    compiled_eval_prog,\r\n                    eval_loader,\r\n                    eval_keys,\r\n                    eval_values,\r\n                    eval_cls,\r\n                    cfg,\r\n                    resolution=resolution)\r\n                box_ap_stats = eval_results(\r\n                    results, cfg.metric, cfg.num_classes, resolution,\r\n                    is_bbox_normalized, FLAGS.output_eval, map_type,\r\n                    cfg['EvalReader']['dataset'])\r\n\r\n                # use vdl_paddle to log mAP\r\n                if FLAGS.use_vdl:\r\n                    vdl_writer.add_scalar(\"mAP\", box_ap_stats[0], vdl_mAP_step)\r\n                    vdl_mAP_step += 1\r\n\r\n                if box_ap_stats[0] > best_box_ap_list[0]:\r\n                    best_box_ap_list[0] = box_ap_stats[0]\r\n                    best_box_ap_list[1] = it\r\n                    checkpoint.save(exe, train_prog,\r\n                                    os.path.join(save_dir, \"best_model\"))\r\n                logger.info(\"Best test box ap: {}, in iter: {}\".format(\r\n                    best_box_ap_list[0], best_box_ap_list[1]))\r\n\r\n            if 'use_ema' in cfg and cfg['use_ema']:\r\n                exe.run(ema.restore_program)\r\n        #############################################################################\r\n        if (it == cfg.max_iters - 1):\r\n            slim.quant.quant_post(\r\n                executor=exe,\r\n                model_dir='./aaa',\r\n                quantize_model_path='./quant_post_static_model',\r\n                sample_generator=train_reader,\r\n                model_filename='__model__',\r\n                params_filename='__params__',\r\n                batch_nums=10)\r\n        ################################################################################\r\n    train_loader.reset()\r\n\r\n\r\nif __name__ == '__main__':\r\n    parser = ArgsParser()\r\n    parser.add_argument(\r\n        \"-r\",\r\n        \"--resume_checkpoint\",\r\n        default=None,\r\n        type=str,\r\n        help=\"Checkpoint path for resuming training.\")\r\n    parser.add_argument(\r\n        \"--fp16\",\r\n        action='store_true',\r\n        default=False,\r\n        help=\"Enable mixed precision training.\")\r\n    parser.add_argument(\r\n        \"--loss_scale\",\r\n        default=8.,\r\n        type=float,\r\n        help=\"Mixed precision training loss scale.\")\r\n    parser.add_argument(\r\n        \"--eval\",\r\n        action='store_true',\r\n        default= True,\r\n        help=\"Whether to perform evaluation in train\")\r\n    parser.add_argument(\r\n        \"--output_eval\",\r\n        default=None,\r\n        type=str,\r\n        help=\"Evaluation directory, default is current directory.\")\r\n    parser.add_argument(\r\n        \"--use_vdl\",\r\n        type=bool,\r\n        default=False,\r\n        help=\"whether to record the data to VisualDL.\")\r\n    parser.add_argument(\r\n        '--vdl_log_dir',\r\n        type=str,\r\n        default=\"vdl_log_dir/scalar\",\r\n        help='VisualDL logging directory for scalar.')\r\n    parser.add_argument(\r\n        \"--enable_ce\",\r\n        type=bool,\r\n        default=False,\r\n        help=\"If set True, enable continuous evaluation job.\"\r\n        \"This flag is only used for internal test.\")\r\n\r\n    #NOTE:args for profiler tools, used for benchmark\r\n    parser.add_argument(\r\n        '--is_profiler',\r\n        type=int,\r\n        default=0,\r\n        help='The switch of profiler tools. (used for benchmark)')\r\n    parser.add_argument(\r\n        '--profiler_path',\r\n        type=str,\r\n        default=\"./detection.profiler\",\r\n        help='The profiler output file path. (used for benchmark)')\r\n    FLAGS = parser.parse_args()\r\n    main()\r\n```",
        "state": "closed",
        "user": "CVdandelion",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-11-02T06:46:04+00:00",
        "updated_at": "2024-02-06T02:58:02+00:00",
        "closed_at": "2024-02-06T02:58:02+00:00",
        "comments_count": [
            "baiyfbupt",
            "CVdandelion",
            "CVdandelion",
            "CVdandelion",
            "baiyfbupt",
            "CVdandelion",
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 500,
        "title": "get_ratios_by_loss()函数怎么依据敏感度信息和损失阈值确定最佳的剪裁率？",
        "body": "get_ratios_by_loss()函数根据敏感度信息，在满足精度损失阈值的情况下，确定最大的剪裁率。怎么确定的呢？换句话说，不同层之间的精度损失是什么样的关系，累加吗，然后总和小于损失阈值？",
        "state": "closed",
        "user": "junjun210",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-11-05T02:45:57+00:00",
        "updated_at": "2024-02-06T02:58:03+00:00",
        "closed_at": "2024-02-06T02:58:03+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 502,
        "title": "loadvar error with facenet pre_train_model",
        "body": "pretrained_model_path=\"work/models/quant_model_SlimFaceNet_B_x0_75\"\r\n\r\n# SlimFaceNet_B_x0_75 paddleslim/models/\r\n\r\ndef network(image, train_base_model=False):\r\n\r\n     base_model = SlimFaceNet_B_x0_75(class_dim=1).net(image)\r\n     base_model.stop_gradient = not train_base_model \r\n     base_model_program = fluid.default_main_program().clone() \r\n     return base_model_program\r\n\r\ndef load_pretrained_params(exe, program):\r\n\r\n    # load exist var\r\n    def if_exist(var):\r\n        path = os.path.join(pretrained_model_path, var.name)\r\n        exist = os.path.exists(path)\r\n        if exist:\r\n                print(\"Load\", path)\r\n        return exist\r\n    fluid.io.load_vars(exe, pretrained_model_path, predicate=if_exist, main_program=program)\r\n\r\nmain = fluid.Program()\r\nstartup = fluid.Program()\r\nexe = fluid.Executor(place)\r\nplace = fluid.CUDAPlace(0)\r\n\r\nwith fluid.unique_name.guard():\r\n\r\n    with fluid.program_guard(main, startup):\r\n\r\n        x = fluid.data(name='x', shape=[-1, 3, 112, 112], dtype='float32')\r\n        base_model_program = network(x, False)\r\n        load_pretrained_params(exe, base_model_program)\r\n\r\n\r\n\r\n错误信息如下:\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit8_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_1_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv1x1_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/linear_conv1x1_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_2_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/global_dw_conv7x7_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_se_2_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit10_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit3_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_depthwise_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit5_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit9_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit15_depthwise_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_se_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_depthwise_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit14_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_expand_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit13_expand_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit2_expand_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_linear_bn_offset\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/conv3x3_weights\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_linear_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit6_depthwise_prelu\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/dw_conv3x3_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit7_expand_bn_variance\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit4_depthwise_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit11_expand_bn_mean\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit12_linear_bn_scale\r\nLoad work/models/quant_model_SlimFaceNet_B_x0_75/residual_unit1_linear_bn_mean\r\n---------------------------------------------------------------------------RuntimeError                              Traceback (most recent call last)<ipython-input-132-34c4c4c9e9aa> in <module>\r\n     26         x = fluid.data(name='x', shape=[-1, 3, 112, 112], dtype='float32')\r\n     27         base_model_program = network(x, False)\r\n---> 28         load_pretrained_params(exe, base_model_program)\r\n<ipython-input-132-34c4c4c9e9aa> in load_pretrained_params(exe, program)\r\n     16                 print(\"Load\", path)\r\n     17         return exist\r\n---> 18     fluid.io.load_vars(exe, pretrained_model_path, predicate=if_exist, main_program=program)\r\n     19 \r\n     20 main = fluid.Program()\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py in load_vars(executor, dirname, main_program, vars, predicate, filename)\r\n    749             main_program=main_program,\r\n    750             vars=list(filter(predicate, main_program.list_vars())),\r\n--> 751             filename=filename)\r\n    752     else:\r\n    753         load_prog = Program()\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py in load_vars(executor, dirname, main_program, vars, predicate, filename)\r\n    818                     \"Variable's shape does not match, the Program requires a parameter with the shape of ({}), \"\r\n    819                     \"while the loaded parameter (namely [ {} ]) has a shape of  ({}).\".\r\n--> 820                     format(orig_shape, each_var.name, new_shape))\r\n    821 \r\n    822 \r\nRuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((192,)), while the loaded parameter (namely [ residual_unit9_expand_bn_mean ]) has a shape of  ((152,)).\r\n\r\n",
        "state": "closed",
        "user": "lastrei",
        "closed_by": "lastrei",
        "created_at": "2020-11-06T10:19:51+00:00",
        "updated_at": "2023-04-07T04:08:02+00:00",
        "closed_at": "2023-04-07T04:08:02+00:00",
        "comments_count": [
            "xiteng1988",
            "lastrei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 503,
        "title": "module 'paddleslim.models' has no attribute 'MobileNet'",
        "body": "paddlepaddle 1.7  paddleslim 1.2.0 \r\n\r\n```\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport paddleslim as slim\r\n\r\nmodel = slim.models.MobileNet()\r\n```\r\n\r\n报错如下：\r\n···\r\nTraceback (most recent call last):\r\n  File \"/Users/casfive-public/projects/NERCheck/zhengliu/test.py\", line 5, in <module>\r\n    model = slim.models.MobileNet()\r\nAttributeError: module 'paddleslim.models' has no attribute 'MobileNet'\r\n````\r\n",
        "state": "closed",
        "user": "biubiuyi",
        "closed_by": "baiyfbupt",
        "created_at": "2020-11-08T03:18:46+00:00",
        "updated_at": "2020-11-10T06:13:02+00:00",
        "closed_at": "2020-11-10T06:13:02+00:00",
        "comments_count": [
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 504,
        "title": "module 'paddleslim.models' has no attribute 'MobileNet'",
        "body": "paddlepaddle 1.7  paddleslim 1.2.0 \r\n\r\n```\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport paddleslim as slim\r\n\r\nmodel = slim.models.MobileNet()\r\n```\r\n\r\n报错如下：\r\n···\r\nTraceback (most recent call last):\r\n  File \"/Users/casfive-public/projects/NERCheck/zhengliu/test.py\", line 5, in <module>\r\n    model = slim.models.MobileNet()\r\nAttributeError: module 'paddleslim.models' has no attribute 'MobileNet'\r\n````\r\n",
        "state": "closed",
        "user": "biubiuyi",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-11-08T03:19:23+00:00",
        "updated_at": "2024-02-06T02:58:04+00:00",
        "closed_at": "2024-02-06T02:58:04+00:00",
        "comments_count": [
            "biubiuyi",
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 517,
        "title": "能不能出一个paddleclas得到的模型如何使用paddleslim里面float到int的readme，就像paddledetection一样",
        "body": "官方文档关于qunt的介绍实在是搞不懂，希望能够出一个与paddleclas配合使用readme，就像paddledetection一样的",
        "state": "closed",
        "user": "zhouyuxixixi",
        "closed_by": "XGZhang11",
        "created_at": "2020-11-18T07:20:52+00:00",
        "updated_at": "2024-02-06T03:51:01+00:00",
        "closed_at": "2024-02-06T03:51:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 508,
        "title": "模型蒸馏通过merge来对teacher_program重命名时出现变量不在当前block内的问题",
        "body": "```bash\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.2.1\\plugins\\python-ce\\helpers\\pydev\\pydevd.py\", line 1448, in _exec\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"D:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.2.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"D:/NLP_SRO/逐步改进版本/SimpleInterface/JointTrainner.py\", line 88, in <module>\r\n    slim.dist.merge(teacher_program,student_train_program,data_name_map,place)\r\n  File \"C:\\Users\\bsw12\\code\\lib\\site-packages\\paddleslim\\dist\\single_distiller.py\", line 66, in merge\r\n    teacher_var.name, new_name)\r\n  File \"C:\\Users\\bsw12\\code\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2378, in _rename_var\r\n    raise ValueError(\"var %s is not in current block\" % name)\r\nValueError: var transpose_4.tmp_0 is not in current block\r\n```\r\n上述为完整的报错信息，代码如图\r\n",
        "state": "closed",
        "user": "Heuchler7",
        "closed_by": "Heuchler7",
        "created_at": "2020-11-11T09:18:39+00:00",
        "updated_at": "2023-09-04T05:59:24+00:00",
        "closed_at": "2020-11-13T08:18:11+00:00",
        "comments_count": [
            "Heuchler7",
            "Heuchler7",
            "baiyfbupt",
            "Heuchler7",
            "baiyfbupt",
            "Heuchler7",
            "baiyfbupt",
            "Heuchler7",
            "baiyfbupt",
            "Heuchler7",
            "Heuchler7",
            "Heuchler7",
            "lrp123456"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 511,
        "title": "急：：在paddleSlim1.0.1版本下面重构distill.py内的merge方法以适应多block模型遇到问题",
        "body": "如题：出于原本的paddleSlim不支持多block模型蒸馏原因，故决定重构merge以支持多block模型，现进度为：\r\n所有的teacher模型内vars以被加上新前缀添加到对应block内，但在最后增加teacher内op入student中报错如下：\r\n```\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.2.1\\plugins\\python-ce\\helpers\\pydev\\pydevd.py\", line 1448, in _exec\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"D:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.2.1\\plugins\\python-ce\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"D:/SimpleInterface/JointTrainner.py\", line 145, in <module>\r\n    merge(teacher_program,student_train_program,data_name_map,place)\r\n  File \"D:/SimpleInterface/JointTrainner.py\", line 94, in merge\r\n    type=op.type, inputs=inputs, outputs=outputs, attrs=attrs)\r\n  File \"C:\\Users\\aaa\\code\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2525, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"C:\\Users\\aaa\\code\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 1877, in __init__\r\n    self.desc.check_attrs()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\nWindows not support stack backtrace yet.\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Cannot get attribute sub_block by type class paddle::framework::BlockDesc * __ptr64, its type is class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > at (D:\\1.7.2\\paddle\\paddle/fluid/framework/attribute.h:42)\r\n```\r\n改写后的算子加入代码如下：\r\n```python\r\n    for i in range(teacher_program.num_blocks):\r\n        for op in teacher_program.block(i).ops:\r\n            if op.type != 'feed' and op.type != 'fetch':\r\n                inputs = {}\r\n                outputs = {}\r\n                attrs = {}\r\n                for input_name in op.input_names:\r\n                    inputs[input_name] = [\r\n                        teacher_program.block(i).var(in_var_name)\r\n                        for in_var_name in op.input(input_name)\r\n                    ]\r\n\r\n                for output_name in op.output_names:\r\n                    outputs[output_name] = [\r\n                        teacher_program.block(i).var(out_var_name)\r\n                        for out_var_name in op.output(output_name)\r\n                    ]\r\n                for attr_name in op.attr_names:\r\n                    attrs[attr_name] = op.attr(attr_name)\r\n                student_program.block(i).append_op(\r\n                    type=op.type, inputs=inputs, outputs=outputs, attrs=attrs)\r\n```\r\n\r\n\r\n",
        "state": "closed",
        "user": "Heuchler7",
        "closed_by": "XGZhang11",
        "created_at": "2020-11-13T08:02:20+00:00",
        "updated_at": "2024-02-06T03:51:25+00:00",
        "closed_at": "2024-02-06T03:51:25+00:00",
        "comments_count": [
            "baiyfbupt",
            "Heuchler7",
            "Heuchler7",
            "baiyfbupt",
            "Heuchler7"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 513,
        "title": "module 'paddle' has no attribute 'static'",
        "body": "按照[教程](https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/tutorials/image_classification_sensitivity_analysis_tutorial.md)运行，报错：\r\n```\r\nTraceback (most recent call last):\r\n  File \"prune.py\", line 73, in <module>\r\n    if __name__ == '__main__':\r\n  File \"prune.py\", line 68, in main\r\n    sensitivities_file=\"sensitivities_0.data\",\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/prune/sensitive.py\", line 70, in sensitivity\r\nAttributeError: module 'paddle' has no attribute 'static'\r\n```",
        "state": "closed",
        "user": "YukSing12",
        "closed_by": "XGZhang11",
        "created_at": "2020-11-13T15:01:18+00:00",
        "updated_at": "2024-02-06T03:51:14+00:00",
        "closed_at": "2024-02-06T03:51:14+00:00",
        "comments_count": [
            "wanghaoshuang",
            "YukSing12",
            "wanghaoshuang",
            "YukSing12"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 518,
        "title": "图像分类INT8量化模型在CPU上的部署和预测，转化产出的量化模型为DNNL优化后的INT8模型，下载的save_quant_model.py，报没有Quant2Int8MkldnnPass错误",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/tree/release/1.1.2/demo/mkldnn_quant\r\n![image](https://user-images.githubusercontent.com/65207014/99612799-3da6ef00-2a51-11eb-9364-30217018f467.png)\r\n![image](https://user-images.githubusercontent.com/65207014/99612830-59aa9080-2a51-11eb-975a-e5481f52380b.png)\r\n在AISTUDIO上运行，paddlepaddle已卸载安装多个版本，多个版本都没有找到Quant2Int8MkldnnPass\r\n",
        "state": "closed",
        "user": "zhouyuxixixi",
        "closed_by": "XGZhang11",
        "created_at": "2020-11-19T02:23:29+00:00",
        "updated_at": "2024-02-06T03:50:45+00:00",
        "closed_at": "2024-02-06T03:50:45+00:00",
        "comments_count": [
            "zhouyuxixixi",
            "zhouyuxixixi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 515,
        "title": "PaddleSlim静态离线量化模型大小不变，推理速度下降",
        "body": "请问一个问题，为什么我使用paddleslim进行模型(模型使用resnet18_vd)的静态离线量化quntpost，模型大小一点都没改变，这是正常现象？而且我试了推理速度，量化后的还变慢了、\r\n\r\n## 对训练的模型进行静态离线量化\r\n## 不能使用CPU进行离线量化，否则内存溢出被kill\r\n!cd /home/aistudio/work/PaddleSlim-release-1.1.1/demo/quant/quant_post \\\r\n&& python quant_post.py --model_path /home/aistudio/work/PaddleClas-master/inference/ResNet18_vd \\\r\n                        --save_path /home/aistudio/work/PaddleSlim-release-1.1.1/model/post_quant_model/ResNet18_vd \\\r\n                        --model_filename model \\\r\n                        --params_filename params \\\r\n                        # --image_shape \"3, 224, 224\" \\\r\n                        --batch_size 32 \\\r\n                        --batch_num 10 \\\r\n                        # --activation_quantize_type \"range_abs_max\" \\\r\n                        # --train_list_name \"eval.txt\" \\\r\n                        # --data_dir \"/home/aistudio/work/dataset/PCB_DATASET\" \\\r\n                        --use_gpu true\r\n\r\n\r\n-----------  Configuration Arguments -----------\r\nbatch_num: 10\r\nbatch_size: 16\r\nmodel_filename: model\r\nmodel_path: /home/aistudio/work/PaddleClas-master/inference/ResNet18_vd\r\nparams_filename: params\r\nsave_path: /home/aistudio/work/PaddleSlim-release-1.1.1/model/post_quant_model/ResNet18_vd\r\nuse_gpu: True\r\n------------------------------------------------\r\n2020-11-18 09:49:35,362-INFO: Load model and set data loader ...\r\nW1118 09:49:35.380448  1168 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 11.0, Runtime API Version: 9.0\r\nW1118 09:49:35.385556  1168 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\n2020-11-18 09:49:37,717-INFO: Collect quantized variable names ...\r\n2020-11-18 09:49:41,997-INFO: Run batch: 0\r\n2020-11-18 09:49:56,495-INFO: Run batch: 5\r\n2020-11-18 09:50:04,377-INFO: Finish all batch: 10\r\n2020-11-18 09:50:04,378-INFO: Calculate KL threshold ...\r\n2020-11-18 09:51:04,922-INFO: Update the program ...\r\n\r\n\r\n",
        "state": "closed",
        "user": "zhouyuxixixi",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-11-18T02:08:44+00:00",
        "updated_at": "2024-02-06T02:58:05+00:00",
        "closed_at": "2024-02-06T02:58:05+00:00",
        "comments_count": [
            "baiyfbupt",
            "Dora1483"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 522,
        "title": "分类任务蒸馏训练完成后如何保存预测模型",
        "body": "蒸馏后模型保存的api是什么",
        "state": "closed",
        "user": "maoyun95",
        "closed_by": "maoyun95",
        "created_at": "2020-11-22T06:49:15+00:00",
        "updated_at": "2020-11-23T06:22:53+00:00",
        "closed_at": "2020-11-23T06:22:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 519,
        "title": "PaddleSlim的使用",
        "body": "您好，请问有适用于paddle 2.0-rc版本程序的paddleslim包吗？正常pip install paddleslim 安装的包是否可以用于paddle 2.0-rc 编写的网络？",
        "state": "closed",
        "user": "liuxi1007",
        "closed_by": "liuxi1007",
        "created_at": "2020-11-19T07:02:37+00:00",
        "updated_at": "2020-11-20T03:06:27+00:00",
        "closed_at": "2020-11-20T03:06:27+00:00",
        "comments_count": [
            "zhouyuxixixi",
            "liuxi1007"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 532,
        "title": "卷积层通道剪裁报错",
        "body": "在使用slim.prune进行剪裁时会报错，模型可以正常推理。\r\nerrror信息如下：\r\n[12-03 16:06:43 MainThread @logger.py:224] Argv: paddle_pruning.py\r\n/home/zgq/anaconda3/envs/paddle/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\r\n  return f(*args, **kwds)\r\nFLOPs: 37047296.0\r\n2020-12-03 16:06:44,036-INFO: pruning: x2paddle_convolution_W\r\nTraceback (most recent call last):\r\n  File \"paddle_pruning.py\", line 52, in <module>\r\n    place=fluid.CPUPlace())\r\n  File \"/home/zgq/anaconda3/envs/paddle/lib/python3.7/site-packages/paddleslim/prune/pruner.py\", line 165, in prune\r\n    graph.infer_shape()\r\n  File \"/home/zgq/anaconda3/envs/paddle/lib/python3.7/site-packages/paddleslim/core/graph_wrapper.py\", line 362, in infer_shape\r\n    op._op.desc.infer_shape(op._op.block.desc)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/zgq/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2679, in _prepend_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/zgq/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1048, in prepend_feed_ops\r\n    attrs={'col': i})\r\n  File \"/home/zgq/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1247, in save_inference_model\r\n    prepend_feed_ops(main_program, feeded_var_names)\r\n  File \"/home/zgq/anaconda3/envs/paddle/lib/python3.7/site-packages/x2paddle/core/op_mapper.py\", line 193, in save_inference_model\r\n    params_filename=None)\r\n  File \"/home/zgq/anaconda3/envs/paddle/lib/python3.7/site-packages/x2paddle/convert.py\", line 184, in onnx2paddle\r\n    mapper.save_inference_model(save_dir, params_merge)\r\n  File \"/home/zgq/anaconda3/envs/paddle/lib/python3.7/site-packages/x2paddle/convert.py\", line 306, in main\r\n    onnx2paddle(args.model, args.save_dir, params_merge)\r\n  File \"/home/zgq/anaconda3/envs/paddle/bin/x2paddle\", line 8, in <module>\r\n    sys.exit(main())\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: feed's infer_shape has not been registered at (/paddle/paddle/fluid/framework/op_desc.cc:686)\r\n  [operator < feed > error]\r\n\r\n请问有什么建议吗\r\n",
        "state": "closed",
        "user": "zhuguiqian",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-12-03T08:24:42+00:00",
        "updated_at": "2024-02-06T02:58:07+00:00",
        "closed_at": "2024-02-06T02:58:07+00:00",
        "comments_count": [
            "qingqing01",
            "Water2style"
        ],
        "labels": [
            "pruning"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 525,
        "title": "idx_selector 在通道较少时出错",
        "body": "PaddleSlim/paddleslim/prune/idx_selector.py line 60:\r\n```\r\npruned_num = int(round(len(sorted_idx) * ratio))\r\npruned_idx = sorted_idx[:pruned_num]\r\n```\r\n\r\n当网络某一层通道较少时，会出现pruned_num = 0，从而导致 pruned_idx = [] 而引发错误\r\n是否需要增加一个判断，令pruned_idx 至少为1呢？\r\n\r\n",
        "state": "closed",
        "user": "YukSing12",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-11-26T12:40:27+00:00",
        "updated_at": "2024-02-06T02:58:06+00:00",
        "closed_at": "2024-02-06T02:58:06+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 534,
        "title": "请教两个剪枝的问题",
        "body": "1、现在paddleslim开放了四种剪枝算法，是否有各个算法的对比，最好是目标检测模型的，现在最优的剪枝算法还是sensitive 这种吗？\r\n2、pruner使用bn scaler 或者FPGM，是不是没有复现原文中稀疏化训练的过程？ 使用这两种算法后面是否还进行逐层尝试敏感度分析loss损失？",
        "state": "closed",
        "user": "Gaondong",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-12-08T07:51:42+00:00",
        "updated_at": "2024-02-06T02:58:08+00:00",
        "closed_at": "2024-02-06T02:58:08+00:00",
        "comments_count": [
            "Gaondong",
            "qingqing01",
            "Gaondong",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 539,
        "title": "请问下，对mobilenet v2剪枝时如何处理short机制，是有规则约束了吗？",
        "body": "请问下，对mobilenet v2剪枝时如何处理short机制，是有规则约束了吗？",
        "state": "closed",
        "user": "cjt222",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-12-11T02:59:10+00:00",
        "updated_at": "2024-02-06T02:58:09+00:00",
        "closed_at": "2024-02-06T02:58:08+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 544,
        "title": "PaddleOCR识别模型8.6ms是哪个模型",
        "body": "看到PaddleOCR的评测时耗是8.6ms，想确定下是哪个模型？\r\n然后用意见benchmark并不能跑通PaddleOCR发布的模型，请问有什么其他方法可以评测PaddleOCR模型的时耗么",
        "state": "closed",
        "user": "neptune4year",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-12-14T13:06:19+00:00",
        "updated_at": "2024-02-06T02:58:09+00:00",
        "closed_at": "2024-02-06T02:58:09+00:00",
        "comments_count": [
            "qingqing01"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 557,
        "title": "运行setup.py报错：“No module named 'paddle.jit”",
        "body": "              已安装paddlepaddle—gpu 2.0.0a0版本，控制台运行命令：python setup.py install，报错信息为“No module named 'paddle.jit”，是什么原因？\r\n<img width=\"508\" alt=\"微信截图_20201218104041\" src=\"https://user-images.githubusercontent.com/68883664/102567955-82d84280-411d-11eb-8653-c5e7de5b8365.png\">\r\n",
        "state": "closed",
        "user": "stefan252423",
        "closed_by": "XGZhang11",
        "created_at": "2020-12-18T02:41:11+00:00",
        "updated_at": "2024-02-06T03:50:13+00:00",
        "closed_at": "2024-02-06T03:50:13+00:00",
        "comments_count": [
            "baiyfbupt",
            "Zhangwei1215"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 570,
        "title": "运行官网图像分类模型知识蒸馏教程报错",
        "body": "我安装的是paddlepaddle2.0版本，我将下面网站教程中的代码输入进去https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/quick_start/distillation_tutorial.md\r\n然后报错AssertionError: In PaddlePaddle 2.x, we turn on dynamic graph mode by default, and 'data()' is only supported in static graph mode. So if you want to use this api, please call 'paddle.enable_static()' before this api to enter static graph mode.\r\n请问这种怎么解决？\r\n![报错](https://user-images.githubusercontent.com/55349793/103069430-554a3800-45fa-11eb-89e4-56b9b2fe3f6a.PNG)\r\n",
        "state": "closed",
        "user": "musketeera",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-12-24T07:12:06+00:00",
        "updated_at": "2024-02-06T02:58:11+00:00",
        "closed_at": "2024-02-06T02:58:11+00:00",
        "comments_count": [
            "baiyfbupt",
            "xbzd315"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 569,
        "title": "请问一下dygraph_flops(model, input_shape, only_conv=False, detail=False)中的model参数传入的是什么？",
        "body": "我现在有训练好的*.pdmodel,         *.pdopt,      *.pdparams三个文件，如何使用dygraph_flops计算模型的flops",
        "state": "closed",
        "user": "gyr-kdgc",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-12-24T06:35:06+00:00",
        "updated_at": "2024-02-06T02:58:10+00:00",
        "closed_at": "2024-02-06T02:58:10+00:00",
        "comments_count": [
            "yukavio"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 571,
        "title": "图像分类模型知识蒸馏",
        "body": "在定义student_program和teacher_program的代码中，teacher_model没有定义，怎么解决",
        "state": "closed",
        "user": "musketeera",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2020-12-24T08:51:54+00:00",
        "updated_at": "2024-02-06T02:58:12+00:00",
        "closed_at": "2024-02-06T02:58:12+00:00",
        "comments_count": [
            "baiyfbupt"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 575,
        "title": "在线量化后转换问题",
        "body": "您好，\r\n使用paddleseg中deeplabv3+mobilenetv2模型，量化训练成功，模型保存成功，但进过转换工具后模型大小没有变化，速度也基本一致，看转换日志中大部分的卷积层量化都被跳过了。\r\n现在支持mobilenetv2模型量化吗？",
        "state": "closed",
        "user": "sadknight0001",
        "closed_by": "XGZhang11",
        "created_at": "2020-12-28T02:52:10+00:00",
        "updated_at": "2024-02-06T03:50:03+00:00",
        "closed_at": "2024-02-06T03:50:03+00:00",
        "comments_count": [
            "baiyfbupt",
            "sadknight0001"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 577,
        "title": "文档错别字",
        "body": "PaddleSlim/docs/zh_cn/api_cn/prune_api.rst\r\n“卷基”应改为“卷积”",
        "state": "closed",
        "user": "bobo0810",
        "closed_by": "yukavio",
        "created_at": "2020-12-31T03:52:01+00:00",
        "updated_at": "2021-01-06T07:32:37+00:00",
        "closed_at": "2021-01-06T07:32:37+00:00",
        "comments_count": [
            "yukavio"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 594,
        "title": "humanseg模型量化问题",
        "body": "Humanseg里的模型量化后(offline)，体积并未减小",
        "state": "closed",
        "user": "wsy1991",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-01-08T07:00:31+00:00",
        "updated_at": "2024-02-06T02:58:13+00:00",
        "closed_at": "2024-02-06T02:58:13+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 601,
        "title": "mkldnn_quant demo文档和编译问题",
        "body": "\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/mkldnn_quant/\r\n\r\n![image](https://user-images.githubusercontent.com/52520497/104889645-760f6e80-59a9-11eb-81da-c4f48da449df.png)\r\nrun.sh 并没有接收输入参数\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSlim/blob/develop/demo/mkldnn_quant/cmake/FindFluid.cmake#L131\r\n![image](https://user-images.githubusercontent.com/52520497/104890355-6e9c9500-59aa-11eb-81f9-ecac2841dfd0.png)\r\n此处编译产出了 libmkldnn.so.0 ，但是没有 libmkldnn.so 时，会cmake失败\r\n\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSlim/blob/develop/demo/mkldnn_quant/cmake/FindFluid.cmake#L142\r\n![image](https://user-images.githubusercontent.com/52520497/104890377-73f9df80-59aa-11eb-9d75-9333d2f3fbee.png)\r\n新版本paddle中已经不依赖 zlib，snappy和snappystream了，会cmake失败\r\n\r\n",
        "state": "closed",
        "user": "juncaipeng",
        "closed_by": "juncaipeng",
        "created_at": "2021-01-18T08:30:41+00:00",
        "updated_at": "2021-09-09T03:53:59+00:00",
        "closed_at": "2021-09-09T03:53:59+00:00",
        "comments_count": [
            "lidanqing-intel"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 674,
        "title": "Out of bounds when pruning conv2d with small channel number",
        "body": "如果卷积层的参数为[2, 3, 3, 3], 剪枝比例为0.9， 则剪枝后为[0, 3, 3, 3], 需要修正为[1, 3, 3, 3]:\r\n\r\n```\r\npruned_number = min(shape[0]-1, pruned_number)\r\n```\r\n以上修正会加入PaddleSlim v2.1.0版本，预计在三月中下旬发版。\r\n\r\n在PaddleSlim v2.1.0发版之前，用户可以通过以下方法跳过输出filters数较少的卷积层：\r\n```\r\nskips = []\r\nfor param in net.parameters():\r\nif param.shape[0] <= 8:\r\n    skips.append(param.name)\r\npruner.sensitive_prune(args.pruning_ratio, skip_vars=skips)\r\n```\r\n\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2021-02-25T04:17:55+00:00",
        "updated_at": "2021-03-15T03:43:13+00:00",
        "closed_at": "2021-03-15T03:43:13+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 603,
        "title": "paddleslim版本问题",
        "body": "最近在做ppyolo检测模型的训练量化， 遇到了一些问题，需要确认一下：\r\n\r\n1. paddledetection master（https://github.com/PaddlePaddle/PaddleDetection/tree/master） 分支应该是paddle静态图最新的版本， 支持paddle1.8.5\r\n2.paddle1.1.1和paddledetection master部分接口是冲突的\r\n， paddledetection master 对应的paddleslim最新分支应该是1.3.0？ \r\n3. 是否有paddleslim 1.3.0的whl包呢\r\n4. python2.7 paddle1.8.5通过python setup.py install 安装paddleslim-develop分支遇到以下问题\r\n![image](https://user-images.githubusercontent.com/6135871/104928266-6447be80-59dd-11eb-9a9f-3f7ae3c51fc1.png)\r\n",
        "state": "closed",
        "user": "zzchust",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-01-18T14:39:59+00:00",
        "updated_at": "2024-02-06T02:58:14+00:00",
        "closed_at": "2024-02-06T02:58:14+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 609,
        "title": "opt转2.0识别模型失败",
        "body": "opt转en_number_mobile_v2.0_rec_infer会显示‘rnn'不支持\r\n Error: This model is not supported, because 1 ops are not supported on 'arm'. These unsupported ops are: 'rnn'.\r\n如果转量化后的识别模型，会多报错一个op不支持\r\nError: This model is not supported, because 2 ops are not supported on 'arm'. These unsupported ops are: 'fake_channel_wise_quantize_dequantize_abs_max, rnn'\r\n",
        "state": "closed",
        "user": "maoxiaoming86",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-01-21T11:03:11+00:00",
        "updated_at": "2024-02-06T02:58:16+00:00",
        "closed_at": "2024-02-06T02:58:16+00:00",
        "comments_count": [
            "maoxiaoming86",
            "AIpioneer",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 605,
        "title": "ImportError: cannot import name 'dygraph_flops' from 'paddleslim.analysis'",
        "body": "你好，这是我的环境\r\npaddlepaddle          2.0.0rc1\r\npaddleslim               1.2.0\r\n然后在执行PaddleSlim/demo/dygraph/pruning/train.py文件时候，报错：\r\nImportError: cannot import name 'dygraph_flops' from 'paddleslim.analysis'\r\n\r\n请问是我上面装的两个大哥的版本问题吗？",
        "state": "closed",
        "user": "Salary-only-17k",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-01-20T07:47:32+00:00",
        "updated_at": "2024-02-06T02:58:15+00:00",
        "closed_at": "2024-02-06T02:58:15+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 619,
        "title": "paddleslim官方给的那个mobilenetv1剪枝的例子，敏感度计算那一部分运行报错",
        "body": "该链接中分析mobilenetv1的卷积通道敏感度的例子无法运行成功\r\nhttps://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/tutorials/image_classification_sensitivity_analysis_tutorial.md\r\n\r\nsens_0 = slim.prune.sensitivity(\r\n        val_program,\r\n        place,\r\n        params,\r\n        test,\r\n        sensitivities_file=\"sensitivities_0.data\",\r\n        pruned_ratios=[0.1, 0.2])\r\nprint(sens_0)\r\n上述代码段运行出错，报错如下：\r\n\r\nValueError: (InvalidArgument) The number of input's channels should be equal to filter's channels * groups for Op(Conv). But received: the input's channels is 64, the input's shape is [-1, 64, 14, 14]; the filter's channels is 1, the filter's shape is [64, 1, 3, 3]; the groups is 63, the data_format is NCHW. The error may come from wrong data_format setting.\r\n  [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:64 != filter_dims[1] * groups:63.] (at /paddle/paddle/fluid/operators/conv_op.cc:96)\r\n  [Hint: If you need C++ stacktraces for debugging, please set `FLAGS_call_stack_level=2`.]\r\n  [operator < depthwise_conv2d > error]\r\n\r\n是否有人可以帮忙看一下，感谢",
        "state": "closed",
        "user": "shenhao2954988368",
        "closed_by": "XGZhang11",
        "created_at": "2021-01-25T05:08:11+00:00",
        "updated_at": "2024-02-06T03:49:14+00:00",
        "closed_at": "2024-02-06T03:49:14+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "shenhao2954988368"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 676,
        "title": "使用离线量化paddlex的模型出错",
        "body": "针对paddlex的工业质检yolov3模型导出，然后利用paddleslim进行离线量化\r\npaddleslim版本1.1.1\r\n\r\n执行下面的命令\r\n```\r\npython3 quant_post.py --model_path ./yolov3/ --save_path ./quant_model_train/easydl-yolov3 --model_filename __model__ --params_filename __params__ --use_gpu false\r\n```\r\n报错信息\r\n```\r\n/home/awcloud/Desktop/paddle/PaddleSlim/demo/data/ILSVRC2012/\r\ntrain_list.txt\r\n2021-02-25 18:14:16,461-INFO: Load model and set data loader ...\r\n2021-02-25 18:14:16,538-INFO: Collect quantized variable names ...\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/paddle/reader/decorator.py\", line 398, in read_worker\r\n    for i in reader():\r\n  File \"../../reader_cv2.py\", line 465, in reader\r\n    yield img_path, int(label)\r\nValueError: invalid literal for int() with base 10: 'Annotations/jiaoweiloudi-188.xml'\r\n```",
        "state": "closed",
        "user": "Huihuihh",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-02-25T10:10:53+00:00",
        "updated_at": "2025-02-11T06:41:24+00:00",
        "closed_at": "2025-02-11T06:41:24+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Huihuihh",
            "wanghaoshuang",
            "Huihuihh",
            "dium6i",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 681,
        "title": "裁剪好模型后导出报错，我该怎么改？",
        "body": "PaddleDetection是2.0版本\r\n项目是在平台上运行的\r\n使用PaddleDetection训练好yolov3_mobilenet_v3模型后进行模型裁剪\r\n裁剪完评估完成后导出报错\r\n这是我执行的脚本\r\n`\r\n!python slim/prune/export_model.py \\\r\n-c configs/yolov3_mobilenet_v3.yml \\\r\n--pruned_params \"yolo_block.0.0.0.conv.weights,yolo_block.0.0.1.conv.weights,yolo_block.0.1.0.conv.weights,yolo_block.0.1.1.conv.weights,yolo_block.0.2.conv.weights,yolo_block.0.tip.conv.weights,yolo_block.1.0.0.conv.weights,yolo_block.1.0.1.conv.weights,yolo_block.1.1.0.conv.weights,yolo_block.1.1.1.conv.weights,yolo_block.1.2.conv.weights,yolo_block.1.tip.conv.weights,yolo_block.2.0.0.conv.weights,yolo_block.2.0.1.conv.weights,yolo_block.2.1.0.conv.weights,yolo_block.2.1.1.conv.weights,yolo_block.2.2.conv.weights,yolo_block.2.tip.conv.weights\" \\\r\n--pruned_ratios=\"0.7150126596733395,0.8177442961035291,0.8274278897456334,0.8373393786362668,0.7956892620674756,0.8445719578292334,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9\" \\\r\n-o weights=output/yolov3_mobilenet_v3/model_final\r\n`\r\n\r\n以下是报错信息，\r\n\r\n`\r\n[03-04 10:10:58 MainThread @logger.py:242] Argv: slim/prune/export_model.py -c configs/yolov3_mobilenet_v3.yml --pruned_params yolo_block.0.0.0.conv.weights,yolo_block.0.0.1.conv.weights,yolo_block.0.1.0.conv.weights,yolo_block.0.1.1.conv.weights,yolo_block.0.2.conv.weights,yolo_block.0.tip.conv.weights,yolo_block.1.0.0.conv.weights,yolo_block.1.0.1.conv.weights,yolo_block.1.1.0.conv.weights,yolo_block.1.1.1.conv.weights,yolo_block.1.2.conv.weights,yolo_block.1.tip.conv.weights,yolo_block.2.0.0.conv.weights,yolo_block.2.0.1.conv.weights,yolo_block.2.1.0.conv.weights,yolo_block.2.1.1.conv.weights,yolo_block.2.2.conv.weights,yolo_block.2.tip.conv.weights --pruned_ratios=0.7150126596733395,0.8177442961035291,0.8274278897456334,0.8373393786362668,0.7956892620674756,0.8445719578292334,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9 -o weights=output/yolov3_mobilenet_v3/model_final\r\n[03-04 10:10:58 MainThread @utils.py:79] WRN paddlepaddle version: 2.0.0. The dynamic graph version of PARL is under development, not fully tested and supported\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\r\n  context = pyarrow.default_serialization_context()\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/tools/datetimes.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import MutableMapping\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Iterable, Mapping\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Sized\r\n2021-03-04 10:11:00,126-INFO: pruned params: ['yolo_block.0.0.0.conv.weights', 'yolo_block.0.0.1.conv.weights', 'yolo_block.0.1.0.conv.weights', 'yolo_block.0.1.1.conv.weights', 'yolo_block.0.2.conv.weights', 'yolo_block.0.tip.conv.weights', 'yolo_block.1.0.0.conv.weights', 'yolo_block.1.0.1.conv.weights', 'yolo_block.1.1.0.conv.weights', 'yolo_block.1.1.1.conv.weights', 'yolo_block.1.2.conv.weights', 'yolo_block.1.tip.conv.weights', 'yolo_block.2.0.0.conv.weights', 'yolo_block.2.0.1.conv.weights', 'yolo_block.2.1.0.conv.weights', 'yolo_block.2.1.1.conv.weights', 'yolo_block.2.2.conv.weights', 'yolo_block.2.tip.conv.weights']\r\n2021-03-04 10:11:00,126-INFO: pruned ratios: [0.7150126596733395, 0.8177442961035291, 0.8274278897456334, 0.8373393786362668, 0.7956892620674756, 0.8445719578292334, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]\r\n2021-03-04 10:11:00,169-INFO: pruning: yolo_block.0.0.0.conv.weights\r\nTraceback (most recent call last):\r\n  File \"slim/prune/export_model.py\", line 123, in <module>\r\n    main()\r\n  File \"slim/prune/export_model.py\", line 88, in main\r\n    only_graph=True)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/prune/pruner.py\", line 112, in prune\r\n    g = self._transform(self.idx_selector(scores, ratio))\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/prune/idx_selector.py\", line 57, in default_idx_selector\r\n    0]  # sort channels by the first convolution's score\r\nIndexError: list index out of range\r\n`",
        "state": "closed",
        "user": "Reatris",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-03-04T02:23:01+00:00",
        "updated_at": "2024-02-06T02:58:17+00:00",
        "closed_at": "2024-02-06T02:58:17+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Reatris",
            "Reatris",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 682,
        "title": "paddleslim的doc中的图片链接出错",
        "body": "在https://paddlepaddle.github.io/PaddleSlim/algo/algo/ 中 相关的算法图片链接报错,根据html的链接中,发现图片原链接地址已经被删除,更改了新的路径,如旧的路径为:\r\n```\r\n<img src=\"https://raw.githubusercontent.com/PaddlePaddle/PaddleSlim/develop/docs/docs/images/algo/quan_table_0.png\" height=\"258\" width=\"600\" hspace=\"10\">\r\n```\r\n\r\n中的src地址需要更改为\r\n```\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/release/2.0.0/docs/images/algo/quan_table_0.png.\r\n```\r\n依次类推.\r\n希望维护人员可以修改下图片的引用.",
        "state": "closed",
        "user": "zhucheng725",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-03-08T07:09:41+00:00",
        "updated_at": "2024-02-06T02:58:18+00:00",
        "closed_at": "2024-02-06T02:58:18+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 685,
        "title": "直接运行教程中通道裁剪代码报错",
        "body": "软件版本：\r\nPython 3.6.2\r\nPaddlePaddle (gpu) 2.0.1\r\nPaddleSlim 2.0.0\r\n\r\n文档地址：\r\nhttps://github.com/PaddlePaddle/PaddleSlim/blob/release/2.0.0/docs/zh_cn/quick_start/static/pruning_tutorial.md\r\n\r\n代码：\r\n```\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport paddleslim as slim\r\npaddle.enable_static()\r\n\r\nexe, train_program, val_program, inputs, outputs = slim.models.image_classification(\"MobileNet\", [1, 28, 28], 10, use_gpu=False)\r\nFLOPs = slim.analysis.flops(train_program)\r\nprint(\"FLOPs: {}\".format(FLOPs))\r\n\r\npruner = slim.prune.Pruner()\r\npruned_program, _, _ = pruner.prune(train_program, fluid.global_scope(), params=[\"conv2_1_sep_weights\", \"conv2_2_sep_weights\"],ratios=[0.33] * 2, place=fluid.CPUPlace())\r\n\r\nFLOPs = slim.analysis.flops(pruned_program)\r\nprint(\"FLOPs: {}\".format(FLOPs))\r\n\r\nimport paddle.dataset.mnist as reader\r\ntrain_reader = paddle.fluid.io.batch(reader.train(), batch_size=128, drop_last=True)\r\ntrain_feeder = fluid.DataFeeder(inputs, fluid.CPUPlace())\r\n\r\nfor data in train_reader():\r\n    acc1, acc5, loss, _ = exe.run(pruned_program, feed=train_feeder.feed(data), fetch_list=outputs)\r\n    print(acc1, acc5, loss)\r\n```\r\n\r\n核心错误信息：\r\n```\r\n    InvalidArgumentError: The start row index must be less than the end row index.But received the start index = 0, the end index = 0.\r\n      [Hint: Expected begin_idx < end_idx, but received begin_idx:0 >= end_idx:0.] (at D:\\v2.0.1\\paddle\\paddle\\fluid\\framework\\tensor.cc:120)\r\n      [operator < depthwise_conv2d_grad > error]\r\n```\r\n\r\n完整错误信息：\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-6-86853272bf05> in <module>\r\n      1 for data in train_reader():\r\n----> 2     acc1, acc5, loss, _ = exe.run(pruned_program, feed=train_feeder.feed(data), fetch_list=outputs)\r\n      3     print(acc1, acc5, loss)\r\n\r\nd:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddle\\fluid\\executor.py in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)\r\n   1108                 return_merged=return_merged)\r\n   1109         except Exception as e:\r\n-> 1110             six.reraise(*sys.exc_info())\r\n   1111 \r\n   1112     def _run_impl(self, program, feed, fetch_list, feed_var_name,\r\n\r\nd:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\six.py in reraise(tp, value, tb)\r\n    691             if value.__traceback__ is not tb:\r\n    692                 raise value.with_traceback(tb)\r\n--> 693             raise value\r\n    694         finally:\r\n    695             value = None\r\n\r\nd:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddle\\fluid\\executor.py in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)\r\n   1106                 use_program_cache=use_program_cache,\r\n   1107                 use_prune=use_prune,\r\n-> 1108                 return_merged=return_merged)\r\n   1109         except Exception as e:\r\n   1110             six.reraise(*sys.exc_info())\r\n\r\nd:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddle\\fluid\\executor.py in _run_impl(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)\r\n   1236                 scope=scope,\r\n   1237                 return_numpy=return_numpy,\r\n-> 1238                 use_program_cache=use_program_cache)\r\n   1239 \r\n   1240         program._compile(scope, self.place)\r\n\r\nd:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddle\\fluid\\executor.py in _run_program(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\r\n   1326         if not use_program_cache:\r\n   1327             self._default_executor.run(program.desc, scope, 0, True, True,\r\n-> 1328                                        [fetch_var_name])\r\n   1329         else:\r\n   1330             self._default_executor.run_prepared_ctx(ctx, scope, False, False,\r\n\r\nValueError: In user code:\r\n\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n      \"__main__\", mod_spec)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\runpy.py\", line 85, in _run_code\r\n      exec(code, run_globals)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\r\n      app.launch_new_instance()\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\r\n      app.start()\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\r\n      self.io_loop.start()\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\r\n      self.asyncio_loop.run_forever()\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\asyncio\\base_events.py\", line 421, in run_forever\r\n      self._run_once()\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\asyncio\\base_events.py\", line 1426, in _run_once\r\n      handle._run()\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\asyncio\\events.py\", line 127, in _run\r\n      self._callback(*self._args)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\r\n      lambda f: self._run_callback(functools.partial(callback, future))\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\r\n      ret = callback()\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\r\n      self.run()\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\r\n      yielded = self.gen.send(value)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\r\n      yield gen.maybe_future(dispatch(*args))\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\r\n      yielded = next(result)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\r\n      yield gen.maybe_future(handler(stream, idents, msg))\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\r\n      yielded = next(result)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\r\n      user_expressions, allow_stdin,\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\r\n      yielded = next(result)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\r\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\r\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\r\n      raw_cell, store_history, silent, shell_futures)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\r\n      return runner(coro)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\r\n      coro.send(None)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\r\n      interactivity=interactivity, compiler=compiler, result=result)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\r\n      if (await self.run_code(code, result,  async_=asy)):\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n      exec(code_obj, self.user_global_ns, self.user_ns)\r\n    File \"<ipython-input-2-e232f8a80cb4>\", line 3, in <module>\r\n      exe, train_program, val_program, inputs, outputs = slim.models.image_classification(\"MobileNet\", [1, 28, 28], 10, use_gpu=False)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddleslim\\models\\util.py\", line 19, in image_classification\r\n      out = model.net(input=image, class_dim=class_num)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddleslim\\models\\mobilenet.py\", line 65, in net\r\n      name=\"conv3_1\")\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddleslim\\models\\mobilenet.py\", line 188, in depthwise_separable\r\n      name=name + \"_dw\")\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddleslim\\models\\mobilenet.py\", line 162, in conv_bn_layer\r\n      bias_attr=False)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddle\\fluid\\layers\\nn.py\", line 1622, in conv2d\r\n      \"data_format\": data_format,\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddle\\fluid\\layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 3023, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"d:\\users\\leon\\miniconda3\\envs\\dl\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2107, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: The start row index must be less than the end row index.But received the start index = 0, the end index = 0.\r\n      [Hint: Expected begin_idx < end_idx, but received begin_idx:0 >= end_idx:0.] (at D:\\v2.0.1\\paddle\\paddle\\fluid\\framework\\tensor.cc:120)\r\n      [operator < depthwise_conv2d_grad > error]```",
        "state": "closed",
        "user": "Entromorgan",
        "closed_by": "Entromorgan",
        "created_at": "2021-03-10T13:28:21+00:00",
        "updated_at": "2021-03-17T13:08:03+00:00",
        "closed_at": "2021-03-17T13:08:03+00:00",
        "comments_count": [
            "yike725",
            "wanghaoshuang",
            "Entromorgan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 688,
        "title": "基于paddledetection的剪裁",
        "body": "使用paddletection训练好的模型，使用剪裁时发现如下：\r\n2021-03-14 16:35:02,283-INFO: sensitive - param: res2c_branch2c_weights; ratios: 0.6\r\n2021-03-14 16:35:02,343-INFO: pruning: res2c_branch2c_weights\r\n2021-03-14 16:35:12,415 - INFO - Test iter 0\r\n2021-03-14 16:35:14,065 - INFO - Test finish iter 19\r\n2021-03-14 16:35:14,065 - INFO - Total number of images: 19, inference time: 10.222864249571384 fps.\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\n2021-03-14 16:35:14,068 - WARNING - The number of valid bbox detected is zero.\r\n             Please use reasonable model and check input data.\r\n             stop eval!\r\n正常情况，我的test image number是147，这里显示19，而且提示bbox无效，检查数据，是什么原因呢",
        "state": "closed",
        "user": "guotongjian",
        "closed_by": "guotongjian",
        "created_at": "2021-03-14T08:43:57+00:00",
        "updated_at": "2021-03-15T08:49:06+00:00",
        "closed_at": "2021-03-15T08:16:19+00:00",
        "comments_count": [
            "V5peng",
            "wanghaoshuang",
            "wanghaoshuang",
            "guotongjian",
            "wanghaoshuang",
            "guotongjian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 690,
        "title": "执行A2C例子中出现的问题",
        "body": "![2021-03-16 10-31-19 的屏幕截图](https://user-images.githubusercontent.com/38377756/111247489-07662e80-8643-11eb-8d5d-3cdc3f304b29.png)\r\n",
        "state": "closed",
        "user": "WuLayman",
        "closed_by": "XGZhang11",
        "created_at": "2021-03-16T02:33:32+00:00",
        "updated_at": "2024-02-06T03:48:19+00:00",
        "closed_at": "2024-02-06T03:48:19+00:00",
        "comments_count": [
            "qingqing01",
            "WuLayman",
            "qingqing01",
            "WuLayman",
            "wanghaoshuang",
            "WuLayman"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 703,
        "title": "请问一下，粒子群算法的项目还有在开源吗？",
        "body": "尊敬的开发者，你好，\r\n请问一下，粒子群算法的项目还有在开源吗？\r\n\r\n期待你的回复！",
        "state": "closed",
        "user": "songyuc",
        "closed_by": "songyuc",
        "created_at": "2021-04-01T05:03:16+00:00",
        "updated_at": "2021-04-08T04:14:01+00:00",
        "closed_at": "2021-04-08T04:14:01+00:00",
        "comments_count": [
            "wanghaoshuang",
            "songyuc"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 694,
        "title": "slimfacenet训练报错",
        "body": "PaddlePaddle版本：2.0.1\r\n数据集：CASIA和LFW\r\n\r\n报错如下：\r\nTraceback (most recent call last):\r\n  File \"train_eval.py\", line 389, in <module>\r\n    main()\r\n  File \"train_eval.py\", line 335, in main\r\n    train(exe, train_program, train_out, test_program, test_out, args)\r\n  File \"train_eval.py\", line 127, in train\r\n    loss, acc, global_lr = exe.run(compiled_prog,\r\n  File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1098, in run\r\n    return self._run_impl(\r\n  File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1244, in _run_impl\r\n    return self._run_parallel(\r\n  File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 913, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\nValueError: In user code:\r\n\r\n    File \"train_eval.py\", line 389, in <module>\r\n      main()\r\n    File \"train_eval.py\", line 327, in main\r\n      train_out = build_program(train_program, startup_program, args, True)\r\n    File \"train_eval.py\", line 186, in build_program\r\n      loss, acc = model.net(image, label)\r\n    File \"/home/su/PycharmProjects/SlimFaceNet/SlimFaceNet/models/slimfacenet.py\", line 176, in net\r\n      cost = fluid.layers.cross_entropy(input=softmax, label=label)\r\n    File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/layers/loss.py\", line 260, in cross_entropy\r\n      return cross_entropy2(input, label, ignore_index)\r\n    File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/layers/loss.py\", line 292, in cross_entropy2\r\n      helper.append_op(\r\n    File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3017, in append_op\r\n      op = Operator(\r\n    File \"/home/su/PycharmProjects/SlimFaceNet/venv/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 2107, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: Input(X) and Input(Label) shall have the same shape except the last dimension. But received: the shape of Input(X) is [64, 64, 10572], the shape of Input(Label) is [64, 1].\r\n      [Hint: Expected framework::slice_ddim(x_dims, 0, rank - 1) == framework::slice_ddim(label_dims, 0, rank - 1), but received framework::slice_ddim(x_dims, 0, rank - 1):64, 64 != framework::slice_ddim(label_dims, 0, rank - 1):64, 1.] (at /paddle/paddle/fluid/operators/cross_entropy_op.cc:49)\r\n      [operator < cross_entropy2 > error]\r\n",
        "state": "closed",
        "user": "yangy996",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-03-22T09:05:18+00:00",
        "updated_at": "2024-02-06T02:58:19+00:00",
        "closed_at": "2024-02-06T02:58:19+00:00",
        "comments_count": [
            "yangy996",
            "scott-mao",
            "scott-mao"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 706,
        "title": "在aistudio上运行paddleslim中的demo/prune时出行错误ModuleNotFoundError: No module named 'models'",
        "body": "import models时出现下面错误\r\nModuleNotFoundError: No module named 'models'",
        "state": "closed",
        "user": "PQ-girl",
        "closed_by": "XGZhang11",
        "created_at": "2021-04-03T02:38:14+00:00",
        "updated_at": "2024-02-06T03:48:08+00:00",
        "closed_at": "2024-02-06T03:48:08+00:00",
        "comments_count": [
            "wanghaoshuang",
            "PQ-girl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 707,
        "title": "把ResNet里的网络层替换成Super系列后，精度低",
        "body": "把conv和batchnorm替换成SuperConv2D，SuperBatchNorm2D。完整训练替换后网络，不改变任何参数，在相同训练配置的情况下，Top-1只能到 10%。替换前的网络训练几个epoch就能到达10%。",
        "state": "closed",
        "user": "zhengzhe97",
        "closed_by": "XGZhang11",
        "created_at": "2021-04-04T01:57:32+00:00",
        "updated_at": "2024-02-06T03:47:48+00:00",
        "closed_at": "2024-02-06T03:47:48+00:00",
        "comments_count": [
            "zhengzhe97",
            "wanghaoshuang",
            "ceci3",
            "zhengzhe97",
            "zhengzhe97",
            "zhengzhe97",
            "zhengzhe97",
            "ceci3",
            "ceci3",
            "zhengzhe97",
            "ceci3",
            "zhengzhe97",
            "zhengzhe97",
            "ceci3",
            "zhengzhe97",
            "ceci3",
            "zhengzhe97"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 724,
        "title": "SSD-MobileNet_v1量化动转静导出模型时出错",
        "body": "![image](https://user-images.githubusercontent.com/56854540/115392268-f3e64e80-a212-11eb-9f59-fcede4d15124.png)\r\nValueError: \r\n        We don't support to define layer with parameters in the function decorated by `@declarative`.\r\n        Because that will re-defined parameters every time when you run the function.\r\n        But we found parameter(conv2d_47.tmp_0.scale_0) was created in the decorated function.\r\n        Please define the layer with parameters in `__init__` function.\r\n您好 我按照模型压缩里快速开始的教程对SSD-MobileNet_v1训练自己训练集进行量化，在动转静导出模型时报错",
        "state": "closed",
        "user": "xry644854073",
        "closed_by": "xry644854073",
        "created_at": "2021-04-20T12:02:39+00:00",
        "updated_at": "2021-04-20T13:15:59+00:00",
        "closed_at": "2021-04-20T13:15:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 709,
        "title": "裁剪问题：PaddleDetection模型",
        "body": "执行命令：（jupyter notebook）\r\n!python slim/prune/prune.py \r\n-c ./configs/ssd/ssd_mobilenet_v1_voc.yml \r\n--pruned_params \"conv1_weights\" \r\n--pruned_ratios=\"0.2\"\r\n\r\n报错：\r\nC:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddle\\fluid\\layers\\math_op_patch.py:298: UserWarning: C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddle\\fluid\\layers\\detection.py:1751\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\nop_type, op_type, EXPRESSION_MAP[method_name]))\r\n2021-04-06 13:29:54,175-INFO: If regularizer of a Parameter has been set by 'fluid.ParamAttr' or 'fluid.WeightNormParamAttr' already. The Regularization[L2Decay, regularization_coeff=0.000050] in Optimizer will not take effect, and it will only be applied to other Parameters!\r\n2021-04-06 13:30:19,093-INFO: pruned params: ['conv7_2_extra1_weights']\r\n2021-04-06 13:30:19,094-INFO: pruned ratios: [0.2]\r\n2021-04-06 13:30:19,354-INFO: pruning: conv7_2_extra1_weights\r\nC:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py:96: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\r\n_logger.warn(\"Skip operator [{}]\".format(op.type()))\r\n2021-04-06 13:30:21,463-WARNING: Skip operator [conditional_block]\r\n2021-04-06 13:30:21,463-WARNING: Skip operator [conditional_block]\r\n2021-04-06 13:30:21,463-WARNING: Skip operator [conditional_block]\r\n2021-04-06 13:30:21,463-WARNING: Skip operator [conditional_block]\r\n2021-04-06 13:30:21,463-WARNING: Skip operator [conditional_block]\r\nTraceback (most recent call last):\r\nFile \"slim/prune/prune.py\", line 415, in \r\nmain()\r\nFile \"slim/prune/prune.py\", line 199, in main\r\nonly_graph=False)[0]\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\pruner.py\", line 102, in prune\r\nvisited)[0] # [(name, axis, pruned_idx)]\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\group_param.py\", line 87, in collect_convs\r\nwalker.prune(param, pruned_axis=0, pruned_idx=[])\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 60, in prune\r\nself._prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 169, in _prune\r\nself._prune_op(op, output_var, channel_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 109, in _prune_op\r\nwalker.prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 60, in prune\r\nself._prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 258, in _prune\r\nself._prune_op(op, param_var, 0, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 109, in _prune_op\r\nwalker.prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 60, in prune\r\nself._prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 610, in _prune\r\nself._prune_op(op, out_var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 109, in _prune_op\r\nwalker.prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 60, in prune\r\nself._prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 443, in _prune\r\nself._prune_op(op, in_var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 109, in _prune_op\r\nwalker.prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 60, in prune\r\nself._prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 437, in _prune\r\nself._prune_op(op, in_var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 109, in _prune_op\r\nwalker.prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 60, in prune\r\nself._prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 614, in _prune\r\nself._prune_op(op, in_var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 109, in _prune_op\r\nwalker.prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 60, in prune\r\nself._prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 370, in _prune\r\nself._visit_and_search(in_var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 80, in _visit_and_search\r\nself._prune_op(op, var, axis, transforms)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 109, in _prune_op\r\nwalker.prune(var, pruned_axis, pruned_idx)\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 58, in prune\r\nif self._visit(var, pruned_axis):\r\nFile \"C:\\Users\\Administrator.conda\\envs\\paddle_gpu_2\\lib\\site-packages\\paddleslim\\prune\\prune_walker.py\", line 65, in visit\r\nkey = \"\".join([key, self.op.all_inputs()[0].name()])\r\nIndexError: list index out of range\r\nW0406 13:29:55.975282 10404 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 5.0, Driver API Version: 10.2, Runtime API Version: 10.0\r\nW0406 13:29:55.987251 10404 device_context.cc:372] device: 0, cuDNN Version: 7.6.\r\n\r\n请问如何排除问题？用的是PaddleDetection自带的模型配置文件。\r\n",
        "state": "closed",
        "user": "GZHUZhao",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-04-06T10:41:13+00:00",
        "updated_at": "2024-02-06T02:58:19+00:00",
        "closed_at": "2024-02-06T02:58:19+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 730,
        "title": "FasterRCNN+ResNet能不能进行量化的",
        "body": "PaddleX训练出来的模型\r\n\r\nFasterRCNN+ResNet v50\r\n---------------\r\n__params__\r\n__model__\r\nmodel.yml\r\n---------------\r\n\r\n这种应该用哪些命令来进行量化的操作  谢谢",
        "state": "closed",
        "user": "monkeycc",
        "closed_by": "XGZhang11",
        "created_at": "2021-04-29T02:59:16+00:00",
        "updated_at": "2024-02-06T03:47:10+00:00",
        "closed_at": "2024-02-06T03:47:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 716,
        "title": "RoBERTa模型压缩",
        "body": "请教一下，我用paddleslim中的bert模型dynabert方法压缩案例，改了一个roberta模型的压缩，导出了dynamic_model和static_model。\r\n\r\n当把dynamic_model测试程序时，如果导出模型的width_mult 为1.0时，可以顺利测试，测试的结果正确率为0.9000左右。如下：\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for classifier.weight. classifier.weight receives a shape [768, 2], but the expected shape is [768, 217].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for classifier.bias. classifier.bias receives a shape [2], but the expected shape is [217].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\nLoaded checkpoint from checkpoints/dstc2/sub\r\n\r\nTest begin...\r\nTotal samples: 9896\r\nJoint_acc: 0.9005\r\n\r\n当width_mult为0.5时，显示roberta模型的某些层尺寸不对，测试的结果正确率为0.0001。如下：\r\n#以上省略\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.10.linear2.weight. roberta.encoder.layers.10.linear2.weight receives a shape [1536, 768], but the expected shape is [3072, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.q_proj.weight. roberta.encoder.layers.11.self_attn.q_proj.weight receives a shape [768, 384], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.q_proj.bias. roberta.encoder.layers.11.self_attn.q_proj.bias receives a shape [384], but the expected shape is [768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.k_proj.weight. roberta.encoder.layers.11.self_attn.k_proj.weight receives a shape [768, 384], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.k_proj.bias. roberta.encoder.layers.11.self_attn.k_proj.bias receives a shape [384], but the expected shape is [768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.v_proj.weight. roberta.encoder.layers.11.self_attn.v_proj.weight receives a shape [768, 384], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.v_proj.bias. roberta.encoder.layers.11.self_attn.v_proj.bias receives a shape [384], but the expected shape is [768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.out_proj.weight. roberta.encoder.layers.11.self_attn.out_proj.weight receives a shape [384, 768], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.linear1.weight. roberta.encoder.layers.11.linear1.weight receives a shape [768, 1536], but the expected shape is [768, 3072].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.linear1.bias. roberta.encoder.layers.11.linear1.bias receives a shape [1536], but the expected shape is [3072].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.linear2.weight. roberta.encoder.layers.11.linear2.weight receives a shape [1536, 768], but the expected shape is [3072, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\nLoaded checkpoint from checkpoints/dstc2/sub\r\n\r\nTest begin...\r\nTotal samples: 9896\r\nJoint_acc: 0.0001\r\n\r\n把\"intermediate_size\": 由3072改为1536时，测试的结果正确率为大概0.4300左右，任然显示roberta模型的某些层尺寸不对，但比改之前少了一些错误。如下：\r\n#以上省略\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.10.self_attn.out_proj.weight. roberta.encoder.layers.10.self_attn.out_proj.weight receives a shape [384, 768], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.q_proj.weight. roberta.encoder.layers.11.self_attn.q_proj.weight receives a shape [768, 384], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.q_proj.bias. roberta.encoder.layers.11.self_attn.q_proj.bias receives a shape [384], but the expected shape is [768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.k_proj.weight. roberta.encoder.layers.11.self_attn.k_proj.weight receives a shape [768, 384], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.k_proj.bias. roberta.encoder.layers.11.self_attn.k_proj.bias receives a shape [384], but the expected shape is [768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.v_proj.weight. roberta.encoder.layers.11.self_attn.v_proj.weight receives a shape [768, 384], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.v_proj.bias. roberta.encoder.layers.11.self_attn.v_proj.bias receives a shape [384], but the expected shape is [768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n/home/richard/anaconda2/envs/paddlenlp/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1263: UserWarning: Skip loading for roberta.encoder.layers.11.self_attn.out_proj.weight. roberta.encoder.layers.11.self_attn.out_proj.weight receives a shape [384, 768], but the expected shape is [768, 768].\r\n  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\nLoaded checkpoint from checkpoints/dstc2/sub\r\n\r\nTest begin...\r\nTotal samples: 9896\r\nJoint_acc: 0.4304\r\n\r\n\r\n请问应该如何读取dynamic_model每一层的信息，还是有其他什么办法？\r\n\r\n读取static_model时，也有同样的问题。\r\n\r\n程序原模型保存的是pdparams，重写了一下读取模型的方法，可以读，但是测试总有问题。",
        "state": "closed",
        "user": "AlinLaw",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-04-16T14:00:45+00:00",
        "updated_at": "2024-02-06T02:58:20+00:00",
        "closed_at": "2024-02-06T02:58:20+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 731,
        "title": "直接贴官方教程导致【InvalidArgumentError】",
        "body": "直接贴官方教程（https://paddleslim.readthedocs.io/zh_CN/latest/quick_start/static/nas_tutorial.html）导致以下错误：\r\n\r\n```\r\nInvalidArgumentError: If Attr(soft_label) == false, the axis dimension of Input(Label) should be 1.\r\n      [Hint: Expected labels_dims[axis] == 1UL, but received labels_dims[axis]:0 != 1UL:1.] (at /home/teamcity/work/ef54dc8a5b211854/paddle/fluid/operators/softmax_with_cross_entropy_op.cc:179)\r\n      [operator < softmax_with_cross_entropy > error]\r\n```\r\n\r\n环境：\r\nMacOS-10.15.7 \r\npaddlepaddle-2.0.2\r\npaddleslim-2.0.0\r\n",
        "state": "closed",
        "user": "670133189",
        "closed_by": "XGZhang11",
        "created_at": "2021-05-06T03:10:07+00:00",
        "updated_at": "2024-02-06T03:46:57+00:00",
        "closed_at": "2024-02-06T03:46:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 717,
        "title": "BERT模型压缩",
        "body": "在BERT模型压缩的案例中，export_model.py有这样一段代码：\r\nbest_config = utils.dynabert_config(ofa_model, args.width_mult)\r\nofa_model.export(\r\n        origin_model,\r\n        best_config,\r\n        input_shapes=[[1, args.max_seq_length], [1, args.max_seq_length]],\r\n        input_dtypes=['int64', 'int64'])\r\n\r\n在读取模型时，是不是要考虑读取best_config？\r\n\r\n使用了ofa后，需要在读模型时加上OFA(model)吗？\r\n\r\n在PaddleSlime源码ofa.py中的def _export_sub_model_config(self, origin_model, config, input_shapes, input_dtypes):方法是不是用来导出子模型参数的？",
        "state": "closed",
        "user": "AlinLaw",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-04-17T10:38:47+00:00",
        "updated_at": "2024-02-06T02:58:21+00:00",
        "closed_at": "2024-02-06T02:58:21+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 719,
        "title": "离线量化文本识别crnn模型报错",
        "body": "**模型来自PaddleOCR**：https://github.com/PaddlePaddle/PaddleOCR#pp-ocr-20-series-model-listupdate-on-dec-15\r\n**运行命令**：python tools/quant.py -c configs/rec/ch_ppocr_v2.0/rec_chinese_lite_train_v2.0.yml\r\n**quant.py的主要代码：**\r\n```python\r\ndef main(config, device, logger, vdl_writer):\r\n    # build dataloader\r\n    loader = build_dataloader(config, 'Train', device, logger)\r\n\r\n    paddle.enable_static()\r\n    place = paddle.CPUPlace()\r\n    exe = paddle.static.Executor(place)\r\n#     model_dir = 'inference/ch_ppocr_mobile_v2.0_det_infer/'\r\n    model_dir = 'inference/ch_ppocr_mobile_v2.0_rec_infer/'\r\n    paddleslim.quant.quant_post_static(\r\n            executor=exe,\r\n            model_dir=model_dir,\r\n            model_filename='inference.pdmodel',\r\n            params_filename='inference.pdiparams',\r\n            quantize_model_path='quant_post_static_model',\r\n            sample_generator=loader,\r\n            batch_size=256,\r\n            batch_nums=10)\r\n\r\nif __name__ == '__main__':\r\n    config, device, logger, vdl_writer = program.preprocess(is_train=True)\r\n    main(config, device, logger, vdl_writer)\r\n```\r\n**报错信息：**\r\n![image](https://user-images.githubusercontent.com/25809855/115332814-2d936700-a1cb-11eb-84f1-5cdf76be7a82.png)\r\n多次运行报错信息会变，再贴一个：\r\n![image](https://user-images.githubusercontent.com/25809855/115333308-038e7480-a1cc-11eb-87bd-8059e39337e8.png)\r\n",
        "state": "closed",
        "user": "MissPenguin",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-04-20T03:32:58+00:00",
        "updated_at": "2024-02-06T02:58:22+00:00",
        "closed_at": "2024-02-06T02:58:22+00:00",
        "comments_count": [
            "MissPenguin",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 721,
        "title": "Pruning models in PaddleClas dynamic graph",
        "body": "安装PaddleSlim develop分支，或PaddleSlim2.1版本（预计5月20日前发布）。\r\n\r\n在PaddleClas路径下执行以下命令，验证PaddleClas中所有模型的剪裁效果（仅计算FLOPs, 不重训模型）：\r\n```\r\nfind configs/ -name *.yaml | xargs -i python tools/prune.py -c {}\r\n```\r\n以上命令生成测试结果在文件`PaddleClas/test_result`中。\r\n\r\n\r\nPaddleClas/tools/prune.py代码如下：\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport os\r\nimport sys\r\n__dir__ = os.path.dirname(os.path.abspath(__file__))\r\nsys.path.append(__dir__)\r\nsys.path.append(os.path.abspath(os.path.join(__dir__, '..')))\r\n\r\nimport paddle\r\n\r\nfrom ppcls.data import Reader\r\nfrom ppcls.utils.config import get_config\r\nfrom ppcls.utils.save_load import init_model, save_model\r\nfrom ppcls.utils import logger\r\nimport program\r\nfrom paddleslim.dygraph import L1NormFilterPruner\r\n\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser(\"PaddleClas train script\")\r\n    parser.add_argument(\r\n        '-c',\r\n        '--config',\r\n        type=str,\r\n        default='configs/ResNet/ResNet50.yaml',\r\n        help='config file path')\r\n    parser.add_argument(\r\n        '-o',\r\n        '--override',\r\n        action='append',\r\n        default=[],\r\n        help='config options to be overridden')\r\n    args = parser.parse_args()\r\n    return args\r\n\r\n\r\ndef main(args):\r\n    config = get_config(args.config, overrides=args.override, show=True)\r\n    net = program.create_model(config.ARCHITECTURE, config.classes_num)\r\n    params = {}\r\n    for param in net.parameters():\r\n        if len(param.shape) == 4:\r\n            params[param.name] = 0.5\r\n\r\n    pruner = L1NormFilterPruner(net, [1, 3, 32, 32])\r\n    b_FLOPs = paddle.flops(net, input_size=[1, 3, 32, 32])\r\n    plan = pruner.prune_vars(params, axis=0)\r\n    a_FLOPs = paddle.flops(net, input_size=[1, 3, 32, 32])\r\n    ret = (float(b_FLOPs - a_FLOPs) / (b_FLOPs)) * 100\r\n    ret = \"model: {}; FLOPs -{:.1f}%\\n\".format(args.config, ret)\r\n    with open(\"./test_result\", 'a') as f:\r\n        f.write(ret)\r\n    print(ret)\r\n\r\nif __name__ == '__main__':\r\n    args = parse_args()\r\n    main(args)\r\n```",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-04-20T08:12:34+00:00",
        "updated_at": "2024-02-06T02:58:23+00:00",
        "closed_at": "2024-02-06T02:58:23+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "ChrisMengxl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 765,
        "title": "Pruning models in PaddleDetection",
        "body": "PaddlePaddle v2.1.0\r\n[PaddleDetection v2.1.0](https://github.com/PaddlePaddle/PaddleDetection/tree/develop)\r\nPaddleSlim v2.1.0\r\n\r\n剪枝功能支持动态图模型列表如下：\r\n\r\n| 模型             | 是否已支持 | \r\n| :--------------:| :-----: |\r\n| YOLOv3          |  Yes    |\r\n| PPYOLO/PPYOLOv2 |  Yes    |\r\n| FCOS            |  Yse    |\r\n| TTFNet          |  Yes    |\r\n| SSD             |  Yes    |\r\n| BlazeFace       |  Yes    |\r\n| SOLOv2          |  Yes    |\r\n| Faster-RCNN     |  No     |\r\n| Mask-RCNN       |  No     |\r\n| Cascade-RCNN    |  No     |",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2021-05-20T06:52:43+00:00",
        "updated_at": "2022-05-20T06:47:43+00:00",
        "closed_at": "2022-05-20T06:47:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 736,
        "title": "有没有关于如何使用paddle-rt，也就是在paddle中使用TensorRT的完整文档？？",
        "body": "其实就是在jetson xavier nx上使用paddle-trt的文档，包括 需不需要量化，怎么量化，量化之后怎么评估的问题？？\r\n我不是想部署，而是仅仅做评估，看看量化之后模型的帧率？？",
        "state": "closed",
        "user": "dengxinlong",
        "closed_by": "dengxinlong",
        "created_at": "2021-05-12T08:35:47+00:00",
        "updated_at": "2021-05-13T07:28:51+00:00",
        "closed_at": "2021-05-13T07:28:51+00:00",
        "comments_count": [
            "wanghaoshuang",
            "dengxinlong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 739,
        "title": "敏感度分析训练时报错",
        "body": "paddlepaddle-gpu 2.0.0.post100\r\npaddleslim 2.0.0\r\n想对一个目标检测模型剪枝，执行完敏感度分析后，在分析训练时报错\r\n  File \"deploy/slim/prune/sensitivity_anal.py\", line 146, in <module>\r\n    main(config, device, logger, vdl_writer)\r\n  File \"deploy/slim/prune/sensitivity_anal.py\", line 141, in main\r\n    eval_class, pre_best_model_dict, logger, vdl_writer)\r\n  File \"deploy/slim/prune/../../../tools/program.py\", line 214, in train\r\n    optimizer.step()\r\n  File \"<decorator-gen-198>\", line 2, in step\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/base.py\", line 260, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"<decorator-gen-196>\", line 2, in step\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py\", line 225, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/optimizer/adam.py\", line 367, in step\r\n    loss=None, startup_program=None, params_grads=params_grads)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/optimizer/optimizer.py\", line 775, in _apply_optimize\r\n    optimize_ops = self._create_optimization_pass(params_grads)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/optimizer/optimizer.py\", line 597, in _create_optimization_pass\r\n    [p[0] for p in parameters_and_grads if p[0].trainable])\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/optimizer/adam.py\", line 249, in _create_accumulators\r\n    self._add_moments_pows(p)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/optimizer/adam.py\", line 216, in _add_moments_pows\r\n    self._add_accumulator(self._moment1_acc_str, p, dtype=acc_dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/optimizer/optimizer.py\", line 516, in _add_accumulator\r\n    var.set_value(self._accumulators_holder[var_name])\r\n  File \"<decorator-gen-113>\", line 2, in set_value\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/framework.py\", line 225, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 125, in set_value\r\n    self.name, self_tensor_np.shape, value_np.shape)\r\nAssertionError: Variable Shape not match, Variable [ conv2_expand_weights_moment1_0 ] need tensor with shape (7, 8, 1, 1) but load set tensor with shape (8, 8, 1, 1)",
        "state": "closed",
        "user": "Durianner",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-05-17T01:48:12+00:00",
        "updated_at": "2024-02-06T02:58:25+00:00",
        "closed_at": "2024-02-06T02:58:25+00:00",
        "comments_count": [
            "Zhang-O"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 767,
        "title": "模型静态量化时出错",
        "body": "我在对模型进行静态量化时，程序报错\r\n### 报错信息如下\r\n    2021-05-20 15:02:44,389-INFO: Load model and set data loader ...\r\n    2021-05-20 15:02:47,652-INFO: Collect quantized variable names ...\r\n    2021-05-20 15:02:47,692-INFO: Preparation stage ...\r\n    2021-05-20 15:02:54,276-INFO: Run batch: 0\r\n    2021-05-20 15:02:54,277-INFO: Finish preparation stage, all batch:1\r\n    2021-05-20 15:02:54,348-INFO: Sampling stage ...\r\n    2021-05-20 15:03:58,629-INFO: Run batch: 0\r\n    2021-05-20 15:03:58,630-INFO: Finish sampling stage, all batch: 1\r\n    2021-05-20 15:03:58,637-INFO: Calculate KL threshold ...\r\n    2021-05-20 15:19:03,373-INFO: Update the program ...\r\n    Traceback (most recent call last):\r\n      File \"F:/graduation_project_data/PyCharm Project/CPD_MNV3_Paddle/slim/slim.py\", line 136, in <module>\r\n        batch_size=20)\r\n      File \"E:\\Anaconda3\\envs\\Paddle\\lib\\site-packages\\paddleslim\\quant\\quanter.py\", line 407, in quant_post_static\r\n        post_training_quantization.quantize()\r\n      File \"E:\\Anaconda3\\envs\\Paddle\\lib\\site-packages\\paddle\\fluid\\contrib\\slim\\quantization\\post_training_quantization.py\", line 382, in quantize\r\n        self._update_program()\r\n      File \"E:\\Anaconda3\\envs\\Paddle\\lib\\site-packages\\paddle\\fluid\\contrib\\slim\\quantization\\post_training_quantization.py\", line 735, in _update_program\r\n        freeze_pass.apply(graph)\r\n      File \"E:\\Anaconda3\\envs\\Paddle\\lib\\site-packages\\paddle\\fluid\\contrib\\slim\\quantization\\quantization_pass.py\", line 1167, in apply\r\n        self._insert_post_channel_dequant_op(graph, op_node)\r\n      File \"E:\\Anaconda3\\envs\\Paddle\\lib\\site-packages\\paddle\\fluid\\contrib\\slim\\quantization\\quantization_pass.py\", line 1211, in _insert_post_channel_dequant_op\r\n        original_var_name)\r\n    AssertionError: The scale of parameter conv2d_209.w_0 is not a list.\r\n    \r\n    Process finished with exit code -1073740791 (0xC0000409)\r\n在使用Nettron打开模型结构图时，对比发现时我写的一个多层特征融合处发生了错误，错误对应的卷积为self.conv5\r\n模型静态图推理和动态图推理都没有异常，只有在量化的时候出现了这个问题，请问是哪里设置的有问题吗？\r\n### 代码如下\r\n    class aggregation(nn.Layer):\r\n        def __init__(self, channel):\r\n            super(aggregation, self).__init__()\r\n            self.relu = paddle.nn.ReLU(True)\r\n    \r\n            self.upsample = paddle.nn.UpsamplingBilinear2D(scale_factor=2)\r\n            self.conv_upsample1 = nn.Conv2D(channel, channel, 3, padding=1)\r\n            self.conv_upsample2 = nn.Conv2D(channel, channel, 3, padding=1)\r\n            self.conv_upsample3 = nn.Conv2D(channel, channel, 3, padding=1)\r\n            self.conv_upsample4 = nn.Conv2D(channel, channel, 3, padding=1)\r\n            self.conv_upsample5 = nn.Conv2D(2 * channel, 2 * channel, 3, padding=1)\r\n    \r\n            self.conv_concat2 = nn.Conv2D(2 * channel, 2 * channel, 3, padding=1)\r\n            self.conv_concat3 = nn.Conv2D(3 * channel, 3 * channel, 3, padding=1)\r\n            self.conv4 = nn.Conv2D(3 * channel, 3 * channel, 3, padding=1)\r\n            self.conv5 = nn.Conv2D(3 * channel, 1, 1)\r\n    \r\n        def forward(self, x1, x2, x3):\r\n            # x1: 1/32 x2: 1/16 x3: 1/8\r\n            x1_1 = x1\r\n            x2_1 = self.conv_upsample1(self.upsample(x1)) * x2\r\n            x3_1 = self.conv_upsample2(self.upsample(self.upsample(x1))) \\\r\n                   * self.conv_upsample3(self.upsample(x2)) * x3\r\n    \r\n            x2_2 = paddle.concat((x2_1, self.conv_upsample4(self.upsample(x1_1))), 1)\r\n            x2_2 = self.conv_concat2(x2_2)\r\n    \r\n            x3_2 = paddle.concat((x3_1, self.conv_upsample5(self.upsample(x2_2))), 1)\r\n            x3_2 = self.conv_concat3(x3_2)\r\n    \r\n            x = self.conv4(x3_2)\r\n            x = self.conv5(x)\r\n    \r\n            return x",
        "state": "closed",
        "user": "ZEROICEWANG",
        "closed_by": "XGZhang11",
        "created_at": "2021-05-20T07:29:48+00:00",
        "updated_at": "2021-10-04T11:49:34+00:00",
        "closed_at": "2021-06-24T10:50:39+00:00",
        "comments_count": [
            "juncaipeng",
            "ZEROICEWANG",
            "ZEROICEWANG",
            "XGZhang11",
            "ZEROICEWANG"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 732,
        "title": "量化后的模型如何利用paddle本身加载并预测结果呢？",
        "body": "目前我已经执行以下指令完成INT8量化：\r\npaddleslim.quant.quant_post_static(\r\n        executor=exe,\r\n        model_dir='./',\r\n        model_filename='fp32_inference_model.pdmodel',\r\n        params_filename='fp32_inference_model.pdiparams',\r\n        quantize_model_path='./quant_post_static_model2',\r\n        sample_generator=paddle.dataset.mnist.test(),\r\n        batch_nums=10)\r\n我接下来想载入这个模型、参数，去验证是否量化成功，查看量化的权重有啥不同之类的，不知道如何去进行。网络结构是参考零基础课程中手写数字识别LeNet网络的代码\r\n`def __init__(self):\r\n         super(MNIST, self).__init__()\r\n         \r\n         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\r\n         self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\r\n         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\r\n         self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\r\n         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\r\n         self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1)\r\n         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\r\n         self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\r\n         # 定义一层全连接层，输出维度是10\r\n         self.fc1 = Linear(in_features=500, out_features=120)\r\n         self.fc2 = Linear(in_features=120, out_features=10)\r\n     #加入对每一层输入和输出的尺寸和数据内容的打印，根据check参数决策是否打印每层的参数和输出尺寸\r\n     # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\r\n     def forward(self, inputs, label=None, check_shape=False, check_content=False):\r\n         # 给不同层的输出不同命名，方便调试\r\n         outputs1 = self.conv1(inputs)\r\n         outputs2 = F.relu(outputs1)\r\n         outputs3 = self.max_pool1(outputs2)\r\n         outputs4 = self.conv2(outputs3)\r\n         outputs5 = F.relu(outputs4)\r\n         outputs6 = self.max_pool2(outputs5)\r\n         outputs6 = paddle.reshape(outputs6, [outputs6.shape[0], -1])\r\n         outputs7 = self.fc1(outputs6)\r\n         outputs8 = self.fc2(outputs7)\r\n         outputs9 = F.softmax(outputs8)`\r\n\r\n，但这个是动态图模型，而量化后的是静态图，接下来应该怎么干有点手足无措。该怎么把静态图的模型读成动态图的方式呢？\r\n",
        "state": "closed",
        "user": "HotCoCoC",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-05-07T07:12:22+00:00",
        "updated_at": "2024-02-06T02:58:24+00:00",
        "closed_at": "2024-02-06T02:58:24+00:00",
        "comments_count": [
            "wanghaoshuang",
            "simplify23",
            "wanghaoshuang",
            "simplify23",
            "Water2style",
            "wanghaoshuang",
            "Water2style",
            "Water2style",
            "Water2style",
            "Water2style"
        ],
        "labels": [
            "quantization"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 776,
        "title": "Pruning models in PaddleSeg",
        "body": "PaddlePaddle v2.1.0\r\n[PaddleSeg v2.1.0](https://github.com/PaddlePaddle/PaddleSeg/releases/tag/v2.1.0)\r\nPaddleSlim v2.1.0\r\n\r\n剪枝功能支持动态图模型列表如下：\r\n\r\n- ANN\r\n- BiSeNet\r\n- DANet\r\n- DecoupledSegNet\r\n- Deeplabv3\r\n- DNLNet\r\n- FastSCNN\r\n- FCN\r\n- GCNet\r\n- HarDnet\r\n- OCRNet\r\n- PSPNet\r\n- UNet\r\n- UNet3+",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2021-05-24T02:16:48+00:00",
        "updated_at": "2022-05-20T06:47:58+00:00",
        "closed_at": "2022-05-20T06:47:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 773,
        "title": "教程有问题",
        "body": "裁剪了模型，优化器不支持啊， 难道需要重新在定义优化器么，教程没说。\r\n\r\n下面按照教程运行的报错结果，换了优化器一样，更新下教程吧！！！太难了。\r\n\r\n![1](https://user-images.githubusercontent.com/73922533/118978332-c6272d80-b9a9-11eb-93af-8469366dd6e0.png)\r\n![2](https://user-images.githubusercontent.com/73922533/118978345-c9bab480-b9a9-11eb-8714-7251756cdae5.png)\r\n",
        "state": "closed",
        "user": "tt8000",
        "closed_by": "minghaoBD",
        "created_at": "2021-05-20T12:27:55+00:00",
        "updated_at": "2021-06-04T09:01:46+00:00",
        "closed_at": "2021-06-04T03:05:17+00:00",
        "comments_count": [
            "tt8000",
            "wanghaoshuang",
            "minghaoBD",
            "minghaoBD"
        ],
        "labels": [
            "documentation",
            "pruning"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 774,
        "title": "Models Supported for OFA",
        "body": "Which are the Models supported(or implemented) for OFA in this Repo?\r\n\r\nThanks,\r\nDarshan",
        "state": "closed",
        "user": "Darshcg",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-05-20T20:36:51+00:00",
        "updated_at": "2024-02-06T02:58:25+00:00",
        "closed_at": "2024-02-06T02:58:25+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 775,
        "title": "Regarding OFA Implementation for Other Networks and Object Detection",
        "body": "Hi,\r\n\r\nI have explored about Once For All Network for MobileNetv1. I felt it very interesting and want to work on Implementing it for Other Networks and for Object Detection tasks. Can anyone please guide me with the same, how do I proceed if I want to Implement this for Other Networks and Object Detection Task?\r\n\r\nLooking forward to hearing from you\r\n\r\nBest Regards,\r\nDarshan C G,",
        "state": "closed",
        "user": "Darshcg",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-05-23T18:33:26+00:00",
        "updated_at": "2024-02-06T02:58:26+00:00",
        "closed_at": "2024-02-06T02:58:26+00:00",
        "comments_count": [
            "ceci3",
            "Darshcg",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 797,
        "title": "修改develop分支版本号",
        "body": "1、slim需要修改develop分支编出包的版本号为0.0.0，目前是1.0.0，容易引起歧义；\r\n2、提供包的commit查看函数，例如paddle中的paddle.version.commit()，这样用户使用develop分支自行编译的包安装后也可查看到具体的commit号，方便复现；",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2021-06-10T02:38:13+00:00",
        "updated_at": "2024-02-06T03:46:33+00:00",
        "closed_at": "2024-02-06T03:46:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 781,
        "title": "OFA-BERT示例用2.1.0 paddleslim压缩会导致不同宽度的子模型的精度相同",
        "body": "OFA-BERT示例用2.1.0 paddleslim压缩会导致不同宽度的子模型的精度相同",
        "state": "closed",
        "user": "ceci3",
        "closed_by": "XGZhang11",
        "created_at": "2021-05-26T08:05:54+00:00",
        "updated_at": "2024-02-06T03:46:43+00:00",
        "closed_at": "2024-02-06T03:46:43+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 785,
        "title": "量化模型以int8格式存储并加载",
        "body": "需求描述：\r\n需要将量化模型通过网络下发私有化现场，所以希望在存储时减小模型体积，以int8格式存储并下发，paddleinference部署时直接加载int8模型并转为fp32格式，用于tensorrt推理。\r\n\r\n模型和环境：\r\nppyolo_r18   paddle-develop   paddleslim2.0  paddledetection2.0\r\n\r\n问题描述：\r\n1. 模型离线量化后，将数据类型强制转为int8后存储，未考虑量化scale，加载此模型后，精度会降低为0。\r\n2. 如果将模型量化后分别存储scale与int8范围内的权重，加载模型后需要进行反量化操作。\r\n\r\n\r\n",
        "state": "closed",
        "user": "XGZhang11",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-06-02T12:15:56+00:00",
        "updated_at": "2024-02-06T02:58:27+00:00",
        "closed_at": "2024-02-06T02:58:27+00:00",
        "comments_count": [
            "XGZhang11",
            "Water2style"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 790,
        "title": "paddleslim训练得到的模型转onnx模型，出现问题。还是不允许这样转换呢？",
        "body": "paddleslim :2.1.0\r\npaddlepaddle-gpu :2.0.2\r\n通过slim训练得到的模型，导出为inference model \r\n利用paddle2onnx 脚本转换报错如下：\r\n![image](https://user-images.githubusercontent.com/32815600/121158132-b4d09300-c87c-11eb-9ae2-829e00dfc231.png)\r\n\r\n",
        "state": "closed",
        "user": "swithmn1",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-06-08T09:11:34+00:00",
        "updated_at": "2024-02-06T02:58:29+00:00",
        "closed_at": "2024-02-06T02:58:29+00:00",
        "comments_count": [
            "Zeref996",
            "swithmn1",
            "Lanme"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 786,
        "title": "请问，必须是paddle的模型才可以用paddleslim吗",
        "body": null,
        "state": "closed",
        "user": "lgf821793883",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-06-03T09:16:06+00:00",
        "updated_at": "2024-02-06T02:58:28+00:00",
        "closed_at": "2024-02-06T02:58:28+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 791,
        "title": "结构化剪裁中，pruner.prune中的idx = self.idx_selector(_collection, scores, ratios) 报错 KeyError。",
        "body": "原因：当某些参数的loss过大时，paddleslim.prune.sensitive.get_ratios_by_loss(sensitivities, loss)方法会忽略该参数。造成ratios长度减少。\r\n![image](https://user-images.githubusercontent.com/79566150/121170210-78eefb00-c887-11eb-8415-294d18f08c2e.png)\r\n",
        "state": "closed",
        "user": "minghaoBD",
        "closed_by": "minghaoBD",
        "created_at": "2021-06-08T10:24:30+00:00",
        "updated_at": "2021-06-09T11:43:02+00:00",
        "closed_at": "2021-06-09T11:41:34+00:00",
        "comments_count": [
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 796,
        "title": "量化paddleocr 自带的识别模型报错",
        "body": "报错如下\r\nTraceback (most recent call last):\r\nException in thread Thread-1:\r\n  File \"tools/quan.py\", line 50, in <module>\r\nTraceback (most recent call last):\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n    main(config, device, logger, vdl_writer)\r\n  File \"tools/quan.py\", line 37, in main\r\n    paddleslim.quant.quant_post_static(\r\n  File \"/home/jianguosun/.local/lib/python3.8/site-packages/paddleslim/quant/quanter.py\", line 417, in quant_post_static\r\n    self.run()\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/reader.py\", line 1295, in __thread_main__\r\n    post_training_quantization.quantize()\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 365, in quantize\r\n    for data in self._data_loader():\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/reader.py\", line 1251, in __next__\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/six.py\", line 703, in reraise\r\n    return self._reader.read_next()\r\n    raise value\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166)\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/reader.py\", line 1275, in __thread_main__\r\n\r\n    for tensors in self._tensor_reader():\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/data_feeder.py\", line 241, in __call__\r\n    for each_sample in self.generator():\r\n  File \"tools/quan.py\", line 24, in __reader__\r\n    for indx, data in enumerate(loader):\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/reader.py\", line 426, in __iter__\r\n    return _DataLoaderIterMultiProcess(self)\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 283, in __init__\r\n    self._init_workers()\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 332, in _init_workers\r\n    _set_SIGCHLD_handler()\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/multiprocess_utils.py\", line 142, in _set_SIGCHLD_handler\r\n    signal.signal(signal.SIGCHLD, __handler__)\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/signal.py\", line 47, in signal\r\n    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))\r\nValueError: signal only works in main thread\r\nException ignored in: <function _DataLoaderIterMultiProcess.__del__ at 0x7f2a1cc343a0>\r\nTraceback (most recent call last):\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 566, in __del__\r\n    self._try_shutdown_all()\r\n  File \"/home/jianguosun/.conda/envs/ppocr/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 371, in _try_shutdown_all\r\n    if not self._shutdown:\r\nAttributeError: '_DataLoaderIterMultiProcess' object has no attribute '_shutdown'\r\n-----------------------------------------------------------------------------\r\npaddlepaddle 2.1.0.post101\r\npaddleslim 2.1.0\r\n\r\nquant.py 代码如下\r\n\r\n      def sample_generator(loader):\r\n            def __reader__():\r\n                  for indx, data in enumerate(loader):\r\n                       images = np.array(data[0])\r\n                       yield images\r\n             return __reader__\r\n\r\n\r\n    def main(config, device, logger, vdl_writer):\r\n          loader = build_dataloader(config, 'Train', device, logger)\r\n          paddle.enable_static()\r\n          place = paddle.CPUPlace()\r\n          exe = paddle.static.Executor(place)\r\n          model_dir = 'ch_ppocr_server_v2.0_rec_infer/'\r\n\r\n          paddleslim.quant.quant_post_static(\r\n                  executor=exe,\r\n                  model_dir=model_dir,\r\n                  model_filename='inference.pdmodel',\r\n                  params_filename='inference.pdiparams',\r\n                  quantize_model_path='quant_post_static_model',\r\n                  sample_generator=sample_generator(loader),\r\n                  batch_size=64,\r\n                  batch_nums=10)\r\n\r\n\r\n    if __name__ == '__main__':\r\n          config, device, logger, vdl_writer = program.preprocess(is_train=True)\r\n          main(config, device, logger, vdl_writer)\r\n\r\n官方的教程里只有cifar集成包接口，还只是图像分类的，能提供一下自定义的reader的写法，和格式嘛",
        "state": "closed",
        "user": "wings0820",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-06-10T02:22:25+00:00",
        "updated_at": "2024-02-06T02:58:30+00:00",
        "closed_at": "2024-02-06T02:58:30+00:00",
        "comments_count": [
            "XGZhang11",
            "LiquorPerfect"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 793,
        "title": "L1NormFilterPruner没有opt参数",
        "body": " - PaddlePaddle 2.1.0\r\n - PaddleSlime 2.1.0\r\n -  [参考文档](https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/quick_start/dygraph/dygraph_pruning_tutorial.md)\r\n\r\n\r\n`L1NormFilterPruner`没有`opt`参数，但是文档说要加上`opt=optimizer`参数，怎么加？\r\n```python\r\nclass L1NormFilterPruner(FilterPruner):\r\n    def __init__(self, model, inputs, sen_file=None):\r\n        super(L1NormFilterPruner, self).__init__(\r\n            model, inputs, sen_file=sen_file)\r\n\r\n    def cal_mask(self, pruned_ratio, collection):\r\n        var_name = collection.master_name\r\n        pruned_axis = collection.master_axis\r\n        value = collection.values[var_name]\r\n        groups = 1\r\n        for _detail in collection.all_pruning_details():\r\n            assert (isinstance(_detail.axis, int))\r\n            if _detail.axis == 1:\r\n                _groups = _detail.op.attr('groups')\r\n                if _groups is not None and _groups > 1:\r\n                    groups = _groups\r\n                    break\r\n\r\n        reduce_dims = [i for i in range(len(value.shape)) if i != pruned_axis]\r\n        l1norm = np.mean(np.abs(value), axis=tuple(reduce_dims))\r\n        if groups > 1:\r\n            l1norm = l1norm.reshape([groups, -1])\r\n            l1norm = np.mean(l1norm, axis=1)\r\n\r\n        sorted_idx = l1norm.argsort()\r\n        pruned_num = int(round(len(sorted_idx) * pruned_ratio))\r\n        pruned_idx = sorted_idx[:pruned_num]\r\n\r\n        mask_shape = [value.shape[pruned_axis]]\r\n        mask = np.ones(mask_shape, dtype=\"int32\")\r\n        if groups > 1:\r\n            mask = mask.reshape([groups, -1])\r\n        mask[pruned_idx] = 0\r\n        return mask.reshape(mask_shape)\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2021-06-09T00:41:12+00:00",
        "updated_at": "2021-06-09T07:33:21+00:00",
        "closed_at": "2021-06-09T07:33:20+00:00",
        "comments_count": [
            "minghaoBD",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 804,
        "title": "知识蒸馏demo遇到问题",
        "body": "运行图像分类模型知识蒸馏的demo时遇到报错：\r\n\r\nTraceback (most recent call last):\r\n  File \"distiller.py\", line 71, in <module>\r\n    acc1, acc5, loss_np = exe.run(student_program, feed=data, fetch_list=[acc_top1.name, acc_top5.name, loss.name])\r\n  File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1239, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1329, in _run_program\r\n    [fetch_var_name])\r\nIndexError: In user code:\r\n\r\n    File \"distiller.py\", line 16, in <module>\r\n      cost = paddle.nn.functional.cross_entropy(input=out, label=gt)\r\n    File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/paddle/nn/functional/loss.py\", line 1492, in cross_entropy\r\n      attrs=attrs)\r\n    File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 3232, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/home/server1604-1/anaconda3/envs/yzc/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2312, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    OutOfRangeError: label value should less than the shape of axis dimension when label value(25) not equal to ignore_index(-100), But received label value as 25 and shape of axis dimension is 10\r\n      [Hint: Expected lbl < axis_dim, but received lbl:25 >= axis_dim:10.] (at /paddle/paddle/fluid/operators/math/cross_entropy.cc:75)\r\n      [operator < softmax_with_cross_entropy > error]\r\n",
        "state": "closed",
        "user": "yezechen",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-06-16T03:05:29+00:00",
        "updated_at": "2024-02-06T02:58:31+00:00",
        "closed_at": "2024-02-06T02:58:31+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 811,
        "title": "quant_post可支持传dataloader吗",
        "body": "`paddleslim.quant.quant_post`目前还不支持传入`paddle.io.DataLoader`，会支持吗，感谢！",
        "state": "closed",
        "user": "LiuChiachi",
        "closed_by": "XGZhang11",
        "created_at": "2021-06-21T12:38:09+00:00",
        "updated_at": "2024-02-06T03:46:24+00:00",
        "closed_at": "2024-02-06T03:46:24+00:00",
        "comments_count": [
            "wanghaoshuang",
            "LiuChiachi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 814,
        "title": "paddlehub输出的基于ernie自定义数据的序列标注模型支持压缩吗？",
        "body": "paddlepaddle-gpu=1.8.5.post97\r\npaddlehub=1.8.2\r\npaddlehub的ernie=1.2.0",
        "state": "closed",
        "user": "suntao2015005848",
        "closed_by": "XGZhang11",
        "created_at": "2021-06-23T06:26:56+00:00",
        "updated_at": "2024-02-06T03:45:49+00:00",
        "closed_at": "2024-02-06T03:45:49+00:00",
        "comments_count": [
            "wanghaoshuang",
            "suntao2015005848",
            "suntao2015005848"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 829,
        "title": "slim裁剪 敏感度分析",
        "body": "paddlepaddle 2.1版本\r\nslim 2.0.0 版本\r\npaddlex \r\n yolov3在敏感度分析之后在裁剪使出现 如下问题;\r\n<ipython-input-6-7cefec87ea6f> in <module>\r\n      2 import paddlex as pdx\r\n      3 model = pdx.load_model('output_dan_rats/yolov3_darknet53/best_model')\r\n----> 4 pdx.slim.visualize(model, 'yolov3.sensi.data', save_dir='./')\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/slim/visualize.py in visualize(model, sensitivities_file, save_dir)\r\n     46             sensitivities_file,\r\n     47             eval_metric_loss=loss_thresh,\r\n---> 48             scope=model.scope)\r\n     49         x.append(prune_ratio)\r\n     50         y.append(loss_thresh)\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/slim/prune.py in cal_model_size(program, place, sensitivities_file, eval_metric_loss, scope)\r\n    384                 prune_shape = prune_var.shape\r\n    385                 break\r\n--> 386         origin_size += reduce(lambda x, y: x * y, shape)\r\n    387         new_size += reduce(lambda x, y: x * y, prune_shape)\r\n    388     return (new_size * 1.0) / origin_size\r\nTypeError: reduce() of empty sequence with no initial value\r\npaddleX 版本不祥",
        "state": "closed",
        "user": "jiamingming-004",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-06-30T02:11:21+00:00",
        "updated_at": "2024-02-06T02:58:31+00:00",
        "closed_at": "2024-02-06T02:58:31+00:00",
        "comments_count": [
            "wanghaoshuang",
            "will-jl944"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 854,
        "title": "请问 NAS-BERT 会集成吗？",
        "body": "你好， 我看到了现在 paddleslim集承了 dynabert 和 OFA，那么 NAS-BERT 会集成进来吗？ https://arxiv.org/pdf/2105.14444.pdf",
        "state": "closed",
        "user": "OleNet",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-07-19T09:54:50+00:00",
        "updated_at": "2024-02-06T02:58:33+00:00",
        "closed_at": "2024-02-06T02:58:33+00:00",
        "comments_count": [
            "wanghaoshuang",
            "luoqishuai"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 831,
        "title": "您好，paddledetection的yolov3_darknet可以量化为8位共GPU调用的模型吗？我看给的例子都是基于mobileNet的量化？",
        "body": "跪求解答啊，新手不知道怎么量化yolov3_darknet",
        "state": "closed",
        "user": "zsffuture",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-06-30T09:27:24+00:00",
        "updated_at": "2024-02-06T02:58:32+00:00",
        "closed_at": "2024-02-06T02:58:32+00:00",
        "comments_count": [
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 860,
        "title": "网络搜索的current tokens的含义？",
        "body": "请教网络搜索的current tokens的含义？比如搜索**ResNetSpace**",
        "state": "closed",
        "user": "670133189",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-07-23T12:41:49+00:00",
        "updated_at": "2024-02-06T02:58:34+00:00",
        "closed_at": "2024-02-06T02:58:34+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 866,
        "title": "PaddleSlim使用model_size函数返回0",
        "body": "您好！我正在使用paddleslim的analysis api完成一个对模型文件进行分析的任务，遇到了一些问题。\r\n我目前手头没有数据集和模型，仅有以下保存好的模型文件：client_model_infer.pdiparams、client_model_infer.pdiparams.info、client_model_infer.pdmodel。经测试，它们可以用paddle.static.load_inference_model读取。\r\n\r\n我使用了paddleslim.analysis下的flops和model_size函数进行返回，其中flops能够返回一个正常的值，但model_size返回了0。请问这是什么问题？\r\n\r\n以下是我的代码：\r\n\r\n```\r\nimport paddle\r\nimport paddleslim\r\n\r\ncheckpoint_name_2 = './client_model_infer'\r\npaddle.enable_static()\r\npaddle_executor = paddle.static.Executor(paddle.CPUPlace())\r\nloaded_infer_model = paddle.static.load_inference_model(checkpoint_name_2, paddle_executor)\r\ninfer_program = loaded_infer_model[0]\r\n\r\nflops = paddleslim.analysis.flops(infer_program)\r\nprint('FLOPs:', flops) # FLOPs: 7127040.0\r\n\r\nmodel_size = paddleslim.analysis.model_size(infer_program)\r\nprint('Model Size:', model_size) # Model Size: 0\r\n```",
        "state": "closed",
        "user": "Disciple7",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-08-05T05:05:31+00:00",
        "updated_at": "2024-02-06T02:58:36+00:00",
        "closed_at": "2024-02-06T02:58:35+00:00",
        "comments_count": [
            "Disciple7",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 861,
        "title": "新版PaddleClas模型定义，使用pact量化报错",
        "body": "![图片](https://user-images.githubusercontent.com/11568925/126930810-cd1db56b-a48b-4bc5-b81a-b24757881890.png)\r\n按照[这个教程](https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/dygraph/quant)将mobinetv3改成新版PaddleClas的[定义](https://github.com/PaddlePaddle/PaddleClas/blob/release/2.2/ppcls/arch/backbone/legendary_models/mobilenet_v3.py)，就报如图所示错误",
        "state": "closed",
        "user": "RainFrost1",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-07-26T03:53:41+00:00",
        "updated_at": "2024-02-06T02:58:35+00:00",
        "closed_at": "2024-02-06T02:58:35+00:00",
        "comments_count": [
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 867,
        "title": "静态离线量化，推理耗时不降反升。",
        "body": "量化前模型推理速度：Avg Time: 0.03840347912000573\r\n量化后模型推理速度：Avg Time: 0.06539143562316894\r\n模型为paddleocr的det_r50_vd_db模型，每次测试数据集相同，500张。\r\n为什么呢？",
        "state": "closed",
        "user": "LiquorPerfect",
        "closed_by": "LiquorPerfect",
        "created_at": "2021-08-05T07:33:46+00:00",
        "updated_at": "2021-08-30T11:28:10+00:00",
        "closed_at": "2021-08-30T11:28:10+00:00",
        "comments_count": [
            "XGZhang11",
            "wanghaoshuang",
            "LiquorPerfect",
            "wanghaoshuang",
            "LiquorPerfect"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 869,
        "title": "训练出来的模型 导出后怎么 用于其他程序？",
        "body": null,
        "state": "closed",
        "user": "STUSER001",
        "closed_by": "STUSER001",
        "created_at": "2021-08-06T11:15:47+00:00",
        "updated_at": "2021-08-06T11:25:03+00:00",
        "closed_at": "2021-08-06T11:25:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 872,
        "title": "MobilenetV2 量化 save_quantized_model报错",
        "body": "网络：\r\n\r\n```\r\nimport paddle\r\nimport paddle.vision.transforms as T\r\nimport paddle.distributed as dist\r\nfrom paddleslim.dygraph.quant import QAT\r\nfrom dirty.slim import quant_config, PACT\r\n\r\nfrom dirty.dataset import DirtyDataset, read_corpus, read_labels\r\n\r\n# dist.get_world_size()\r\n# dist.init_parallel_env()\r\n\r\n# os.environ['CUDA_VISIBLE_DEVICES'] = '3'\r\n\r\nnet = paddle.vision.models.mobilenetv2.MobileNetV2(scale=0.5, num_classes=2, with_pool=True)\r\n\r\npaddle.flops(net, input_size=[1, 3, 224, 224])\r\n\r\nquanter = QAT(config=quant_config)\r\nquanter.quantize(net)\r\n\r\n# net = paddle.DataParallel(net)\r\n\r\ninputs = paddle.static.InputSpec(shape=[-1, 3, 224, 224], dtype=\"float32\", name=\"inputs\")\r\nlabels = paddle.static.InputSpec(shape=[-1, 2], dtype=\"int64\", name=\"labels\")\r\nmodel = paddle.Model(net, inputs, labels)\r\n\r\nmodel.summary()\r\n\r\ntransforms = T.Compose([\r\n    T.Resize((224, 224)),\r\n    T.RandomHorizontalFlip(0.5),\r\n    T.RandomVerticalFlip(0.5),\r\n    T.Transpose(),  # HWC -> CHW\r\n    T.Normalize(\r\n        mean=0,  # 归一化\r\n        std=1,\r\n        data_format='CHW',\r\n        to_rgb=True)\r\n])\r\n\r\n\r\nlabel_list = read_labels(\"data/corpus/label.txt\")\r\n\r\ntrain_corpus = read_corpus(\"data/corpus/train.csv\")\r\ntrain_dataset = DirtyDataset(train_corpus, label_list, transforms=transforms)\r\ntrain_loader = paddle.io.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=5)\r\n\r\nprint(\"train len:\", len(train_loader))\r\n\r\nvalid_corpus = read_corpus(\"data/corpus/eval.csv\")\r\nvalid_dataset = DirtyDataset(valid_corpus, label_list, transforms=transforms)\r\nvalid_loader = paddle.io.DataLoader(valid_dataset, batch_size=128, shuffle=True, num_workers=5)\r\n\r\noptimizer = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\r\nloss = paddle.nn.loss.CrossEntropyLoss()\r\nacc = paddle.metric.Accuracy()\r\n\r\nearly_stop = paddle.callbacks.EarlyStopping(patience=20)\r\nreduce_lr = paddle.callbacks.ReduceLROnPlateau(patience=5)\r\n\r\n\r\n# model.prepare(optimizer=optimizer, loss=loss, metrics=[acc])\r\n\r\n# model.fit(train_loader, valid_loader, epochs=3, save_dir=\"models\", callbacks=[early_stop, reduce_lr],\r\n#           verbose=1, log_freq=1, num_workers=5)\r\n\r\n# model.load(\"models/best_model\")\r\n\r\nquanter.save_quantized_model(net, \"quant_models/quant\", input_spec=[paddle.static.InputSpec(\r\n                shape=[None, 3, 224, 224], dtype='float32', name=\"inputs\")])\r\n\r\n```\r\n\r\n========================================================》\r\n报错信息：\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 76, in <module>\r\n    paddle.jit.save(net, \"quant_models/quant\", input_spec=[paddle.static.InputSpec(shape=[None, 3, 224, 224], dtype='float32')])\r\n  File \"<decorator-gen-67>\", line 2, in save\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/base.py\", line 40, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/jit.py\", line 729, in save\r\n    concrete_program = static_forward.concrete_program\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 454, in concrete_program\r\n    return self.concrete_program_specify_input_spec(input_spec=None)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 488, in concrete_program_specify_input_spec\r\n    *desired_input_spec)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 402, in get_concrete_program\r\n    concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 711, in __getitem__\r\n    self._caches[item] = self._build_once(item)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 702, in _build_once\r\n    class_instance=cache_key.class_instance)\r\n  File \"<decorator-gen-65>\", line 2, in from_func_spec\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/base.py\", line 40, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 620, in from_func_spec\r\n    static_func = convert_to_static(dygraph_function)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 141, in convert_to_static\r\n    static_func = _FUNCTION_CACHE.convert_with_cache(function)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 78, in convert_with_cache\r\n    static_func = self._convert(func)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 122, in _convert\r\n    create_and_update_origin_info_map(root_wrapper.node, static_func)\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/origin_info.py\", line 163, in create_and_update_origin_info_map\r\n    for t_node, s_node in ast_walk(transformed_node, static_node):\r\n  File \"/data/home/xuchunguang/.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/origin_info.py\", line 241, in ast_walk\r\n    t_node_child = getattr(t_node, field)\r\nAttributeError: 'Assign' object has no attribute 'type_comment'\r\n```\r\n\r\n麻烦帮忙看下该问题，急！",
        "state": "closed",
        "user": "kismit",
        "closed_by": "XGZhang11",
        "created_at": "2021-08-11T01:16:30+00:00",
        "updated_at": "2024-02-06T03:44:37+00:00",
        "closed_at": "2024-02-06T03:44:37+00:00",
        "comments_count": [
            "wanghaoshuang",
            "kismit"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 889,
        "title": "Device memory used by PACT quantization",
        "body": "## 结论\r\n\r\n### 未复现PaddleOCR动态图PACT量化显存异常问题\r\n\r\nPaddle develop + PaddleOCR2.2 + PaddleSlim develop： 正常\r\nPaddle develop + PaddleOCR2.2 + PaddleSlim 2.1.1（release/2.1.0）： 正常\r\nPaddle2.1.2 + PaddleOCR2.2 + PaddleSlim 2.1.1（release/2.1.0）： 正常\r\n\r\n\r\n## 关于PaddleOCR量化版本的说明\r\n\r\n在PaddleOCR dygraph分支下的quant.py为动态图量化： https://github.com/PaddlePaddle/PaddleOCR/blob/dygraph/deploy/slim/quantization/quant.py\r\n在PaddleOCR develop分支下的quant.py为静态图量化：\r\nhttps://github.com/PaddlePaddle/PaddleOCR/blob/develop/deploy/slim/quantization/quant.py\r\n在PaddleOCR release2.2分支下的quant.p为动态图量化：\r\nhttps://github.com/PaddlePaddle/PaddleOCR/blob/release/2.2/deploy/slim/quantization/quant.py\r\n\r\n## 动态图（正常）\r\n\r\npaddle.version.commit = 14fd6cfbd3db55b8421874f5ebb07bf7ddaf33bf\r\npaddleslim develop commit =  21394ded525ff8f072e58aa10ef34b02ad6e8b75\r\nPaddleOCR release/2.2 commit =  cadc04cf6cb599bb005be344010443bcfb65e82b\r\n\r\nGPUs |batch size per card | without PACT | with PACT\r\n-------|------------ | ------------- | -----------\r\n|1|4 | 3837MiB | 5000MiB\r\n|1|16 |  10407MiB| 15883MiB\r\n|1|32 |19589MiB  | 30471MiB\r\n|8|4|3853MiB|5295MiB\r\n\r\n## 动态图（正常）\r\n\r\npaddle.version.commit = 14fd6cfbd3db55b8421874f5ebb07bf7ddaf33bf\r\npaddleslim release/2.1.0 commit = f97603f0aa510713e879d0dd651ac97946636d60\r\nPaddleOCR release/2.2 commit =  cadc04cf6cb599bb005be344010443bcfb65e82b\r\n\r\nGPUs |batch size per card | without PACT | with PACT\r\n-------|------------ | ------------- | -----------\r\n|1|4 |   3699MiB | 5143MiB\r\n|1|8 |   6023MiB | 8591MiB\r\n|1|16|   10407MiB | 15883MiB\r\n|8|4|   3991MiB | 5295MiB\r\n\r\n## 动态图（正常）\r\n\r\npaddle.version.commit = e04b66f2d272d68f77dcd94cb2956938475411d8 (release/2.1.2)\r\npaddleslim release/2.1.0 commit = f97603f0aa510713e879d0dd651ac97946636d60\r\nPaddleOCR release/2.2 commit =  cadc04cf6cb599bb005be344010443bcfb65e82b\r\n\r\nGPUs |batch size per card | without PACT | with PACT| Inplace relu\r\n-------|------------ | ------------- | -----------| -------|\r\n|8|4|  3821MiB  | 5263MiB | False\r\n|1|16||15851MiB(inplace)|True|\r\n|1|16||15851MiB| False|\r\n\r\n## 静态图\r\npaddle.version.commit = e04b66f2d272d68f77dcd94cb2956938475411d8 (release/2.1.2)\r\npaddleslim release/2.1.0 commit = f97603f0aa510713e879d0dd651ac97946636d60\r\nPaddleOCR develop commit =  6b44a969d319307d42c1d0c5fdc6171514258f2d\r\n\r\nGPUs |batch size per card | without PACT | with PACT\r\n-------|------------ | ------------- | -----------\r\n|1|4| 2775MiB  | 3973MiB\r\n|1|16|6981MiB|11807MiB\r\n|1|32|   12971MiB| 19387MiB(OMM) \r\n\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2021-09-01T02:04:27+00:00",
        "updated_at": "2024-02-06T03:43:44+00:00",
        "closed_at": "2024-02-06T03:43:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 876,
        "title": "yolov5轻量backbone结构模型静态离线量化后耗时不降",
        "body": "下面是845处理器测试结果：\r\n```\r\n\\n--------------------------------------\r\nPaddleLite Benchmark\r\nThreads=1 Warmup=10 Repeats=30\r\nv2_3_1_yolov6_best.lite       min = 39.48200    max = 40.04200    average = 39.81643\r\nv2_3_1_yolov6_best_qpd_int8.litemin = 38.60500    max = 39.04400    average = 38.80820\r\n\r\nThreads=2 Warmup=10 Repeats=30\r\nv2_3_1_yolov6_best.lite       min = 23.04600    max = 23.64300    average = 23.21107\r\nv2_3_1_yolov6_best_qpd_int8.litemin = 22.70200    max = 23.02600    average = 22.81230\r\n\r\nThreads=4 Warmup=10 Repeats=30\r\nv2_3_1_yolov6_best.lite       min = 14.03400    max = 14.64800    average = 14.15510\r\nv2_3_1_yolov6_best_qpd_int8.litemin = 14.11500    max = 15.41000    average = 14.41863\r\n```\r\n\r\n下面是麒麟990处理器测速结果：\r\n```\r\n/data/local/tmp/result_armv8.txt: 1 file pulled. 0.2 MB/s (657 bytes in 0.003s)\r\n\\n--------------------------------------\r\nPaddleLite Benchmark\r\nThreads=1 Warmup=10 Repeats=30\r\nv2_3_1_yolov6_best.lite       min = 26.04500    max = 31.73300    average = 29.39377\r\nv2_3_1_yolov6_best_qpd_int8.litemin = 25.62900    max = 27.91400    average = 27.43620\r\n\r\nThreads=2 Warmup=10 Repeats=30\r\nv2_3_1_yolov6_best.lite       min = 15.95100    max = 22.25100    average = 18.75880\r\nv2_3_1_yolov6_best_qpd_int8.litemin = 16.92300    max = 18.92200    average = 17.77327\r\n\r\nThreads=4 Warmup=10 Repeats=30\r\nv2_3_1_yolov6_best.lite       min = 11.35500    max = 61.93500    average = 20.72140\r\nv2_3_1_yolov6_best_qpd_int8.litemin = 11.65800    max = 35.95400    average = 15.22043\r\n```",
        "state": "closed",
        "user": "youngstu",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-08-12T05:13:30+00:00",
        "updated_at": "2024-02-06T02:58:36+00:00",
        "closed_at": "2024-02-06T02:58:36+00:00",
        "comments_count": [
            "youngstu",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 875,
        "title": "yolov5检测模型离线静态量化失败",
        "body": "```\r\n2021-08-11 21:11:37,106-INFO: Load model and set data loader ...\r\nW0811 21:11:37.140259 30871 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 10.2, Runtime API Version: 10.2\r\nW0811 21:11:37.142552 30871 device_context.cc:422] device: 0, cuDNN Version: 7.6.\r\n2021-08-11 21:11:38,439-INFO: Collect quantized variable names ...\r\n2021-08-11 21:11:38,442-INFO: Preparation stage ...\r\nTraceback (most recent call last):\r\n  File \"quant_post.py\", line 69, in <module>\r\n    main()\r\n  File \"quant_post.py\", line 64, in main\r\n    quantize()\r\n  File \"quant_post.py\", line 50, in quantize\r\n    bias_correction=bias_correction)\r\n  File \"/home/ar/shaoxiong/envs/anaconda3/envs/py36_paddle2.1/lib/python3.6/site-packages/paddleslim/quant/quanter.py\", line 417, in quant_post_static\r\n    post_training_quantization.quantize()\r\n  File \"/home/ar/shaoxiong/envs/anaconda3/envs/py36_paddle2.1/lib/python3.6/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 370, in quantize\r\n    scope=self._scope)\r\n  File \"/home/ar/shaoxiong/envs/anaconda3/envs/py36_paddle2.1/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/ar/shaoxiong/envs/anaconda3/envs/py36_paddle2.1/lib/python3.6/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/ar/shaoxiong/envs/anaconda3/envs/py36_paddle2.1/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"/home/ar/shaoxiong/envs/anaconda3/envs/py36_paddle2.1/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1239, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/ar/shaoxiong/envs/anaconda3/envs/py36_paddle2.1/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1329, in _run_program\r\n    [fetch_var_name])\r\nValueError: In user code:\r\n\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/bin/x2paddle\", line 33, in <module>\r\n      sys.exit(load_entry_point('x2paddle==1.2.3', 'console_scripts', 'x2paddle')())\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/x2paddle-1.2.3-py3.8.egg/x2paddle/convert.py\", line 259, in main\r\n      onnx2paddle(args.model, args.save_dir)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/x2paddle-1.2.3-py3.8.egg/x2paddle/convert.py\", line 165, in onnx2paddle\r\n      mapper.paddle_graph.gen_model(save_dir)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/x2paddle-1.2.3-py3.8.egg/x2paddle/core/program.py\", line 274, in gen_model\r\n      self.dygraph2static(save_dir, input_shapes, input_types)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/x2paddle-1.2.3-py3.8.egg/x2paddle/core/program.py\", line 553, in dygraph2static\r\n      paddle.jit.save(static_model,\r\n    File \"<decorator-gen-67>\", line 2, in save\r\n      \r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 40, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/dygraph/jit.py\", line 718, in save\r\n      concrete_program = static_func.concrete_program_specify_input_spec(\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 487, in concrete_program_specify_input_spec\r\n      concrete_program, _ = self.get_concrete_program(\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 402, in get_concrete_program\r\n      concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 711, in __getitem__\r\n      self._caches[item] = self._build_once(item)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 698, in _build_once\r\n      concrete_program = ConcreteProgram.from_func_spec(\r\n    File \"<decorator-gen-65>\", line 2, in from_func_spec\r\n      \r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 40, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 652, in from_func_spec\r\n      outputs = static_func(*inputs)\r\n    File \"v2_3_1_yolov6_best.pd/x2paddle_code.py\", line 474, in forward\r\n      x2paddle_992 = paddle.reshape(x=x2paddle_974, shape=[1, 3, 6, 40, 40])\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/tensor/manipulation.py\", line 1575, in reshape\r\n      return paddle.fluid.layers.reshape(x=x, shape=shape, name=name)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/layers/nn.py\", line 6202, in reshape\r\n      helper.append_op(\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 2899, in append_op\r\n      op = Operator(\r\n    File \"/home/ar/shaoxiong/envs/anaconda3/envs/py38_pytorch1.7/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 1977, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [32, 18, 40, 40], X's size = 921600, 'shape' is [1, 3, 6, 40, 40], the capacity of 'shape' is 28800.\r\n      [Hint: Expected capacity == in_size, but received capacity:28800 != in_size:921600.] (at /paddle/paddle/fluid/operators/reshape_op.cc:222)\r\n      [operator < reshape2 > error]\r\n\r\n```",
        "state": "closed",
        "user": "youngstu",
        "closed_by": "wanghaoshuang",
        "created_at": "2021-08-11T13:13:15+00:00",
        "updated_at": "2021-08-12T04:13:10+00:00",
        "closed_at": "2021-08-12T04:13:10+00:00",
        "comments_count": [
            "wanghaoshuang",
            "youngstu",
            "youngstu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 883,
        "title": "有没有ssd_mobilenet_v1的全量化训练脚本demo可以参考一下？",
        "body": "目标检测的 ssd_mobilenet_v1 模型，有没有全量化训练的脚本demo可以参考一下？\r\n目前我在官方教程文档中，只看到有图像分类的PaddleSlim全量化训练demo，ssd_mobilenet_v1 的不知道应该怎么做。",
        "state": "closed",
        "user": "mzxhzhp",
        "closed_by": "XGZhang11",
        "created_at": "2021-08-23T15:07:37+00:00",
        "updated_at": "2024-02-06T03:44:11+00:00",
        "closed_at": "2024-02-06T03:44:11+00:00",
        "comments_count": [
            "XGZhang11",
            "mzxhzhp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 891,
        "title": "'L1NormFilterPruner' object has no attribute 'prun_var'",
        "body": "net = mobilenet_v1(pretrained=False)\r\npruner = L1NormFilterPruner(net, [1, 3, 224, 224])\r\n plan = pruner.prun_var(\"conv2d_26.w_0\", [0])",
        "state": "closed",
        "user": "jxncyym",
        "closed_by": "XGZhang11",
        "created_at": "2021-09-08T07:34:42+00:00",
        "updated_at": "2024-02-06T03:43:33+00:00",
        "closed_at": "2024-02-06T03:43:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 887,
        "title": "离线量化PaddleDetection模型库的yolov3报错",
        "body": "paddle版本：paddlepaddle-gpu          2.1.1.post101\r\npaddleslim版本：paddleslim                2.1.1\r\npaddledetection版本：            release v2.2.0\r\nCUDA版本：10.1\r\ncudnn版本：7.6.5\r\n\r\n**写在前面：**\r\n1、paddleocr模型已经可以离线量化，静态sample_generator也已经自己实现。\r\n2、在测试对paddledetection模型进行量化时出现报错。\r\n目前已经尝试量化的模型有：yolov3_darknet53_270e_coco.yml、yolov3_darknet53_270e_voc.yml、yolov3_r50vd_dcn_270e_coco.yml，均出现一样的报错，模型参数直接模型库下载，在export_model为inference模型。\r\n\r\n\r\n**报错信息如下：**\r\n_**1、CPU版本报错，使用模型是yolov3_r50vd_dcn_270e_coco.yml**_\r\n\r\n![image](https://user-images.githubusercontent.com/36955510/131336331-e1781d26-59d8-4ea3-af6e-3ef66bdbdf12.png)\r\n\r\n_**2、GPU版本报错，使用模型是yolov3_r50vd_dcn_270e_coco.yml**_\r\n\r\n2021-08-30 20:04:56,442-INFO: model_filename：model.pdmodel\r\n2021-08-30 20:04:56,443-INFO: params_filename: model.pdiparams\r\n2021-08-30 20:04:56,443-INFO: Load model and set data loader ...\r\nW0830 20:04:56.580090 64299 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 10.1, Runtime API Version: 10.1\r\nW0830 20:04:56.583691 64299 device_context.cc:422] device: 0, cuDNN Version: 7.6.\r\n2021-08-30 20:05:06,263-INFO: Collect quantized variable names ...\r\n2021-08-30 20:05:06,278-INFO: Preparation stage ...\r\nTraceback (most recent call last):\r\n  File \"/xxx/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddleslim/quant/quanter.py\", line 433, in quant_post_static\r\n    post_training_quantization.quantize()\r\n  File \"/xxx/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 370, in quantize\r\n    scope=self._scope)\r\n  File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/xxx/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/xxx/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1108, in run\r\n    return_merged=return_merged)\r\n  File \"/xxx/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1239, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/xxx/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 1329, in _run_program\r\n    [fetch_var_name])\r\nOSError: \r\n\r\n  Compile Traceback (most recent call last):       _**为什么这里会涉及到inference模型导出**_\r\n    File \"PaddleDetection-2.2.0/tools/export_model.py\", line 114, in <module>\r\n      main()\r\n    File \"PaddleDetection-2.2.0/tools/export_model.py\", line 110, in main\r\n      run(FLAGS, cfg)\r\n    File \"PaddleDetection-2.2.0/tools/export_model.py\", line 78, in run\r\n      trainer.export(FLAGS.output_dir)\r\n    File \"/mnt/ssd1/zhangjinlong21/paddle/PaddleDetection-2.2.0/ppdet/engine/trainer.py\", line 573, in export\r\n      input_spec, static_model.forward.main_program,\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 534, in main_program\r\n      concrete_program = self.concrete_program\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 454, in concrete_program\r\n      return self.concrete_program_specify_input_spec(input_spec=None)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 488, in concrete_program_specify_input_spec\r\n      *desired_input_spec)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 402, in get_concrete_program\r\n      concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 711, in __getitem__\r\n      self._caches[item] = self._build_once(item)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 702, in _build_once\r\n      class_instance=cache_key.class_instance)\r\n    File \"<decorator-gen-65>\", line 2, in from_func_spec\r\n      \r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/base.py\", line 40, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 652, in from_func_spec\r\n      outputs = static_func(*inputs)\r\n    File \"/tmp/tmpc1ycg8eo.py\", line 27, in forward\r\n      false_fn_1, (), (), (out,))\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 210, in convert_ifelse\r\n      return _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 235, in _run_py_ifelse\r\n      return true_fn(*true_args) if pred else false_fn(*false_args)\r\n    File \"/xxxxPaddleDetection-2.2.0/ppdet/modeling/architectures/meta_arch.py\", line 28, in forward\r\n      out = self.get_pred()\r\n    File \"/xxxx/PaddleDetection-2.2.0/ppdet/modeling/architectures/yolo.py\", line 124, in get_pred\r\n      return self._forward()\r\n    File \"/xxxx/PaddleDetection-2.2.0/ppdet/modeling/architectures/yolo.py\", line 79, in _forward\r\n      body_feats = self.backbone(self.inputs)\r\n    File \"/xxxxx/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/xxxx/paddle/PaddleDetection-2.2.0/ppdet/modeling/backbones/resnet.py\", line 582, in forward\r\n      conv1 = self.conv1(x)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/container.py\", line 98, in forward\r\n      input = layer(input)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/tmp/tmp59fdoqes.py\", line 22, in forward\r\n      (inputs, self), (out,))\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 210, in convert_ifelse\r\n      return _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 235, in _run_py_ifelse\r\n      return true_fn(*true_args) if pred else false_fn(*false_args)\r\n    File \"/xxxxx/paddle/PaddleDetection-2.2.0/ppdet/modeling/backbones/resnet.py\", line 122, in forward\r\n      out = self.conv(inputs)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/nn/layer/conv.py\", line 667, in forward\r\n      use_cudnn=self._use_cudnn)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/nn/functional/conv.py\", line 139, in _conv_nd\r\n      type=op_type, inputs=inputs, outputs=outputs, attrs=attrs)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 2905, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/root/anaconda3/envs/paddle_2.1.2_gpu/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 1977, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string > > const&, bool, bool)\r\n1   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n2   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n3   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CUDNNConvOpKernel<float>, paddle::operators::CUDNNConvOpKernel<double>, paddle::operators::CUDNNConvOpKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n7   paddle::operators::CUDNNConvOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const\r\n8   paddle::platform::TensorDescriptor::set(paddle::framework::Tensor const&, cudnnTensorFormat_t)\r\n9   paddle::platform::EnforceNotMet::EnforceNotMet(paddle::platform::ErrorSummary const&, char const*, int)\r\n10  paddle::platform::GetCurrentTraceBackString[abi:cxx11]()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nExternalError:  Cudnn error, CUDNN_STATUS_BAD_PARAM  (at /paddle/paddle/fluid/platform/cudnn_desc.h:163)\r\n  [operator < conv2d > error]\r\n\r\n**猜测**：会不会由于export_model.py导出模型的时候，detection inference模型的保存还是老版本的接口导致的。",
        "state": "closed",
        "user": "LiquorPerfect",
        "closed_by": "LiquorPerfect",
        "created_at": "2021-08-30T12:55:07+00:00",
        "updated_at": "2021-09-10T03:28:13+00:00",
        "closed_at": "2021-09-10T03:28:13+00:00",
        "comments_count": [
            "XGZhang11",
            "LiquorPerfect",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 890,
        "title": "量化模型时出错AttributeError: module 'paddle' has no attribute 'batch'",
        "body": "使用PaddleSlim量化模型，输出eval指令显示AttributeError: module 'paddle' has no attribute 'batch'，应该怎么修改，求指点",
        "state": "closed",
        "user": "bueredgirll",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-09-01T09:34:59+00:00",
        "updated_at": "2024-02-06T02:58:37+00:00",
        "closed_at": "2024-02-06T02:58:37+00:00",
        "comments_count": [
            "bueredgirll",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 899,
        "title": "训练模型剪枝时出错，出现数组越界错误",
        "body": "debug发现是在\r\n    def _visit_and_search(self, var, axis, transforms):\r\n        self._visit(var, axis)\r\n        pre_ops = var.inputs()\r\n        for op in pre_ops: \r\n这段代码循环到一个op，内容是{Out=['learning_rate']} = fill_constant(inputs={ShapeTensor=[], ShapeTensorList=[], ValueTensor=[]}, dtype = 5, force_cpu = False, op_device = , op_namescope = /, op_role = 16, op_role_var = [], place_type = -1, shape = [1], str_value = 0.001, value = 0.0010000000474974513)，这时候剪枝报错。",
        "state": "closed",
        "user": "yezechen",
        "closed_by": "XGZhang11",
        "created_at": "2021-09-26T02:56:26+00:00",
        "updated_at": "2024-02-06T03:43:16+00:00",
        "closed_at": "2024-02-06T03:43:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 900,
        "title": "对测试模型进行剪枝，剪枝完成之后将获得的program进行测试，报错",
        "body": "InvalidArgumentError: The number of input's channels should be equal to filter's channels * groups for Op(Conv). But received: the input's channels is 256, the input's shape is [32, 256, 125, 4]; the filter's channels is 1, the filter's shape is [256, 1, 3, 3]; the groups is 205, the data_format is NCHW. The error may come from wrong data_format setting.\r\n      [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:256 != filter_dims[1] * groups:205.] (at D:\\v2.0.1\\paddle\\paddle\\fluid\\operators\\conv_op.cc:96)\r\n      [operator < depthwise_conv2d > error]\r\n",
        "state": "closed",
        "user": "yezechen",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-09-26T02:59:36+00:00",
        "updated_at": "2024-02-06T02:58:38+00:00",
        "closed_at": "2024-02-06T02:58:38+00:00",
        "comments_count": [
            "Water2style",
            "wanghaoshuang",
            "wanghaoshuang",
            "Jiashuhao518"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 906,
        "title": "paddleslim如何压缩ernie-tiny",
        "body": "\r\n![2D7AB4F321E58CD5D511589B23C6B0F4](https://user-images.githubusercontent.com/29837553/137061304-e47544db-140c-4b72-b95c-2bf1c0f99e94.jpg)\r\n使用paddleslim对ernie-tiny压缩的，说可以达到1ms。这个有案例脚本？\r\n",
        "state": "closed",
        "user": "tianchiguaixia",
        "closed_by": "XGZhang11",
        "created_at": "2021-10-13T03:18:01+00:00",
        "updated_at": "2024-02-06T03:58:18+00:00",
        "closed_at": "2024-02-06T03:58:18+00:00",
        "comments_count": [
            "ceci3",
            "tianchiguaixia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 909,
        "title": "离线量化问题：",
        "body": "paddleDetection导出模型离线量化报错：\r\n![image](https://user-images.githubusercontent.com/63913709/137620820-7d5fb77c-998b-4230-b738-a754390aa1b1.png)\r\n好像是加载校准数据时出错了，使用如下方式加载的：\r\nimport paddle.fluid as fluid\r\nfrom paddleslim.quant import quant_post_static\r\nfrom ppdet.core.workspace import load_config, merge_config, create\r\nfrom ppdet.data.reader import create_reader\r\nfrom ppdet.utils.cli import ArgsParser\r\nfrom ppdet.utils.check import check_gpu, check_version, check_config, enable_static_mode\r\nimport logging\r\nFORMAT = '%(asctime)s-%(levelname)s: %(message)s'\r\nlogging.basicConfig(level=logging.INFO, format=FORMAT)\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\ndef main():\r\n    env = os.environ\r\n    cfg = load_config(FLAGS.config)\r\n    main_arch = cfg.architecture\r\n    model = create(main_arch)\r\n    inputs_def = cfg['EvalReader']['inputs_def']\r\n    feed_vars, eval_loader = model.build_inputs(**inputs_def)\r\n    eval_reader = create_reader(cfg.EvalReader, devices_num=1)\r\n    eval_dataset = eval_loader.set_sample_list_generator(eval_reader)\r\n    place = fluid.CUDAPlace(0)\r\n    exe = fluid.Executor(place)\r\n    model_dir = r'E:\\detection0.5bate\\output\\0910model\\cascade_rcnn_dcn_r101_vd_fpn_tiles_0910'\r\n    model_filename = '__model__'\r\n    params_filename = '__params__'\r\n    save_model_path = r'E:\\detection0.5bate\\output\\qua_out'\r\n    batch_generator = eval_dataset\r\n    batch_size = 2\r\n    batch_nums = None\r\n    algo = \"KL\"\r\n    quantizable_op_type = [\"conv2d\", \"depthwise_conv2d\", \"mul\"]\r\n    quant_post_static(executor=exe,\r\n                      model_dir=model_dir,\r\n                      model_filename=model_filename,\r\n                      params_filename=params_filename,\r\n                      quantize_model_path=save_model_path,\r\n                      batch_generator=batch_generator,\r\n                      batch_size=batch_size,\r\n                      batch_nums=batch_nums,\r\n                      algo=algo,\r\n                      quantizable_op_type=quantizable_op_type)\r\n\r\nif __name__ == '__main__':\r\n    enable_static_mode()\r\n    parser = ArgsParser()\r\n    FLAGS = parser.parse_args()\r\n    main()\r\n不知问题在哪里？另外有没有加载校准数据的DEMO供参考，谢谢！",
        "state": "closed",
        "user": "jackie8310",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-10-17T09:24:08+00:00",
        "updated_at": "2024-02-06T02:58:39+00:00",
        "closed_at": "2024-02-06T02:58:39+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 912,
        "title": "剪枝demo数据预处理未添加",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/b9e5730bf3f35fee2b08102ff23db1dbafe0d2d0/demo/prune/eval.py#L37\r\n\r\n对于mnist的数据，需要增加均值方差的预处理：\r\n        transform = T.Compose([T.Transpose(), T.Normalize([127.5], [127.5])])\r\n        val_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\r\n\r\n",
        "state": "closed",
        "user": "BraveLii",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-10-28T08:02:50+00:00",
        "updated_at": "2024-02-06T02:58:41+00:00",
        "closed_at": "2024-02-06T02:58:41+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 907,
        "title": "RuntimeError: propeller 0.2 requires paddle 1.7+, got 2.1.0",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/ofa/ernie#ofa%E5%8E%8B%E7%BC%A9ernie%E6%A8%A1%E5%9E%8B\r\n\r\n环境：paddlepaddle==2.1\r\n\r\n运行代码总是报错，难道2.1版本不是高于1.7？？？",
        "state": "closed",
        "user": "tianchiguaixia",
        "closed_by": "tianchiguaixia",
        "created_at": "2021-10-13T08:09:03+00:00",
        "updated_at": "2021-10-14T09:30:44+00:00",
        "closed_at": "2021-10-14T09:30:44+00:00",
        "comments_count": [
            "tianchiguaixia",
            "ceci3",
            "tianchiguaixia",
            "ceci3",
            "tianchiguaixia",
            "ceci3",
            "tianchiguaixia",
            "tianchiguaixia",
            "tianchiguaixia"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 911,
        "title": "Paddleseg 导出预测量化模型时报错。AttributeError: 'NoneType' object has no attribute 'state_dict'",
        "body": "paddlpaddle版本：paddlepaddle-gpu的nightly build版本\r\n![image](https://user-images.githubusercontent.com/71338215/138858742-f264d451-4e88-4cd5-96b4-fa2c6bf83ac0.png)\r\n\r\n\r\n报错：\r\n![image](https://user-images.githubusercontent.com/71338215/138858770-4971b85f-db6f-4399-bdcf-8107dcc98abd.png)\r\n",
        "state": "closed",
        "user": "huangwan-jiayi",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-10-26T10:17:00+00:00",
        "updated_at": "2024-02-06T02:58:40+00:00",
        "closed_at": "2024-02-06T02:58:40+00:00",
        "comments_count": [
            "huangwan-jiayi",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 914,
        "title": "Paddle2.1 动态图Embedding层怎么量化，急！",
        "body": "需要对Transformer进行量化，可以量化中间层，但是不知道怎么量化Embedding层，Embedding层和其他层一起量化应该怎么配置",
        "state": "closed",
        "user": "kismit",
        "closed_by": "XGZhang11",
        "created_at": "2021-11-02T03:24:32+00:00",
        "updated_at": "2024-02-06T03:58:29+00:00",
        "closed_at": "2024-02-06T03:58:29+00:00",
        "comments_count": [
            "ceci3",
            "kismit",
            "ceci3",
            "ceci3",
            "kismit",
            "ceci3",
            "kismit",
            "kismit",
            "kismit"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 915,
        "title": "slim剪裁识别模型错误输出：？",
        "body": "eval model:: 100%|?????????????????????????????????????????????????????????????????????????????????????????????| 160/160 [01:02<00:00,  2.57it/s]\r\n[2021/11/04 07:12:04] root INFO: metric['acc']: 0.0\r\neval model:: 100%|?????????????????????????????????????????????????????????????????????????????????????????????| 160/160 [01:00<00:00,  2.66it/s]\r\n[2021/11/04 07:13:04] root INFO: metric['acc']: 0.0\r\nTraceback (most recent call last):\r\n  File \"deploy/slim/prune/export_prune_model.py\", line 127, in <module>\r\n    main(config, device, logger, vdl_writer)\r\n  File \"deploy/slim/prune/export_prune_model.py\", line 73, in main\r\n    params_sensitive = pruner.sensitive(\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddleslim-1.0.0-py3.8.egg/paddleslim/dygraph/prune/filter_pruner.py\", line 118, in sensitive\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddleslim-1.0.0-py3.8.egg/paddleslim/dygraph/prune/filter_pruner.py\", line 264, in _cal_sensitive\r\nZeroDivisionError: float division by zero\r\n",
        "state": "closed",
        "user": "EricHuiK",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-11-04T07:23:07+00:00",
        "updated_at": "2024-02-06T02:58:42+00:00",
        "closed_at": "2024-02-06T02:58:42+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 923,
        "title": "在AIstudio多卡中，安装了Paddleslim在计算Flops的时候",
        "body": "`os.system(\"cd PaddleDetection-release-2.3 && pip install paddleslim -i https://mirror.baidu.com/pypi/simple\")`\r\n\r\n训练时候在计算Flops的时候却显示：\r\n\r\n`[11/21 10:15:40] ppdet.engine WARNING: Unable to calculate flops, please install paddleslim, for example: `pip install paddleslim``",
        "state": "closed",
        "user": "gaorui999",
        "closed_by": "gaorui999",
        "created_at": "2021-11-21T02:29:52+00:00",
        "updated_at": "2021-11-28T13:06:11+00:00",
        "closed_at": "2021-11-28T13:06:11+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 940,
        "title": "model_dir下的文件应该放什么文件",
        "body": "`model_dir = './pd_model'`\r\n`quant_post_static(executor=exe,\r\n                  model_dir=model_dir,\r\n                  model_filename=model_filename,\r\n                  params_filename=params_filename,\r\n                  quantize_model_path=save_model_path,\r\n                  sample_generator=sample_generator,\r\n                  batch_size=batch_size,\r\n                  batch_nums=batch_nums,\r\n                  algo=algo,\r\n                  quantizable_op_type=quantizable_op_type)\r\n`\r\n如上，作静态量化时，model_dir下应该放什么文件，我目前放的是x2paddle生成的model.pdiparams文件、model.pdmodel文件和model.pdiparams.info，运行时报错`[Errno 2] No such file or directory: 'pd_model/__model__'`",
        "state": "closed",
        "user": "LiLiLiam",
        "closed_by": "XGZhang11",
        "created_at": "2021-11-30T11:25:15+00:00",
        "updated_at": "2024-02-06T03:58:37+00:00",
        "closed_at": "2024-02-06T03:58:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 926,
        "title": "跟着教程做量化训练(静态图)，推理时报错，说reshape2的输入（label）没有初始化",
        "body": "教程里的量化训练能正常运行，最后能够保存静态图成功.\r\n但是推理模型的时候报错\r\n\r\n代码段1（教程里的代码，不报错）：\r\n“with paddle.static.program_guard(train_program, startup):\r\n    #data\r\n    image = paddle.static.data(\r\n        name='image', shape=[None, 1, 28, 28], dtype='float32')\r\n\r\n    #Bug exists here: label is not initialized 推理的时候说label没有初始化\r\n    label = paddle.static.data(name='label', shape=[None, 1], dtype='int64')\r\n    gt = paddle.reshape(label, [-1, 1])\r\n\r\n    out = model.net(input=image, class_dim=10)\r\n    cost = paddle.nn.functional.loss.cross_entropy(input=out, label=gt)\r\n    avg_cost = paddle.mean(x=cost)\r\n    acc_top1 = paddle.metric.accuracy(input=out, label=gt, k=1)\r\n    acc_top5 = paddle.metric.accuracy(input=out, label=gt, k=5)\r\n    opt = paddle.optimizer.Momentum(0.01, 0.9)\r\n    opt.minimize(avg_cost)”\r\n\r\n代码段2：\r\n1.自己写了一个load静态图模型，读取的是量化训练save下来的模型\r\n2.后来去使用了官方提供的save_quant_model.py转换这个静态模型，会生成很多op对用的weights，使用paddle_inferece推理会报同样的错误，都是 reshape2 的输入参数， label没有初始化\r\n\r\n“\r\nimport paddle\r\nimport numpy as np\r\npath_prefix = './quant_infer_model'\r\n\r\npaddle.enable_static()\r\nexe = paddle.static.Executor()\r\nstartup_prog = paddle.static.default_startup_program()\r\nexe.run(startup_prog)\r\n\r\n[inference_program, feed_target_names, fetch_targets] = (paddle.static.load_inference_model(path_prefix, exe))\r\n\r\ntensor_img = np.array(np.random.random((1,1,28,28)), dtype=np.float32)\r\n\r\nresults = exe.run(inference_program,\r\n                feed={feed_target_names[0]: tensor_img},\r\n                fetch_list=fetch_targets)\r\n”\r\n报错：\r\nxieyunyao@yoga:~/Desktop/MasterProject/MasterProject/Paddle/PaddleSlim/Static_graph$ python 2.2.static_infer.py \r\nYou are using Paddle compiled with TensorRT, but TensorRT dynamic library is not found. Ignore this if TensorRT is not needed.\r\n/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/executor.py:1150: UserWarning: There are no operators in the program to be executed. If you pass Program manually, please use fluid.program_guard to ensure the current Program is being used.\r\n  warnings.warn(error_info)\r\nW1122 11:53:52.169804 15521 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 11.1\r\nW1122 11:53:52.171689 15521 device_context.cc:422] device: 0, cuDNN Version: 8.2.\r\nTraceback (most recent call last):\r\n  File \"2.2.static_infer.py\", line 14, in <module>\r\n    results = exe.run(inference_program,\r\n  File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1110, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1098, in run\r\n    return self._run_impl(\r\n  File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1231, in _run_impl\r\n    return self._run_program(\r\n  File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1328, in _run_program\r\n    self._default_executor.run(program.desc, scope, 0, True, True,\r\nValueError: In user code:\r\n\r\n    File \"2.0.Quantization-Train.py\", line 26, in <module>\r\n      gt = paddle.reshape(label, [-1, 1])\r\n    File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/tensor/manipulation.py\", line 1575, in reshape\r\n      return paddle.fluid.layers.reshape(x=x, shape=shape, name=name)\r\n    File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/layers/nn.py\", line 6202, in reshape\r\n      helper.append_op(\r\n    File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 2899, in append_op\r\n      op = Operator(\r\n    File \"/home/xieyunyao/miniconda3/envs/tftorch/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 1977, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: The Tensor in the reshape2 Op's Input Variable X(label) is not initialized.\r\n      [Hint: Expected t->IsInitialized() == true, but received t->IsInitialized():0 != true:1.] (at /paddle/paddle/fluid/framework/operator.cc:1570)\r\n      [operator < reshape2 > error]\r\n",
        "state": "closed",
        "user": "Water2style",
        "closed_by": "wanghaoshuang",
        "created_at": "2021-11-22T11:00:54+00:00",
        "updated_at": "2021-11-25T09:56:10+00:00",
        "closed_at": "2021-11-25T09:56:10+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Water2style",
            "wanghaoshuang",
            "Water2style",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 937,
        "title": "量化模型格式解释",
        "body": "## 问题1\r\n\r\nfake_quant_xxx算子的InScale和OutScale，在计算下一个节点的输入Scale的时候，应该取InScale还是OutScale除((1 << (bit_length - 1)) - 1)\r\n\r\n## 问题2\r\n\r\n![image](https://user-images.githubusercontent.com/7534971/144013578-eb0205ee-95dd-441c-92de-2efab28ad24a.png)\r\n上面这张图里面的各种fake算子，是否有些是废弃掉的？\r\n\r\n\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-11-30T08:40:34+00:00",
        "updated_at": "2024-02-06T02:58:44+00:00",
        "closed_at": "2024-02-06T02:58:44+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang",
            "marsbzp",
            "wanghaoshuang",
            "mrshaoyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 938,
        "title": "flatten_contiguous_range op is unsupported in PTQ",
        "body": "<img width=\"1389\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/74164525/144019187-75971938-9a22-4999-a3ef-b1086ea62623.png\">\r\nmbv1离线量化报错如上图\r\n模型：paddle新版mbv1模型，新增了算子flatten_contiguous_range\r\n<img width=\"412\" alt=\"图片\" src=\"https://user-images.githubusercontent.com/74164525/144019428-e351f526-60c6-4342-aaca-33cbd4760ca9.png\">\r\n版本：paddle和slim版本均为11月29日最新develop",
        "state": "closed",
        "user": "yingshengBD",
        "closed_by": "yingshengBD",
        "created_at": "2021-11-30T09:20:06+00:00",
        "updated_at": "2021-11-30T12:09:33+00:00",
        "closed_at": "2021-11-30T12:09:33+00:00",
        "comments_count": [
            "yingshengBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 934,
        "title": "PaddleOCR 识别模型裁剪和量化问题",
        "body": "### 裁剪：\r\n```bash\r\ncd PaddleOCR\r\n\r\npython deploy/slim/prune/sensitivity_anal.py -c configs/rec_record/rec_r34_vd_none_bilstm_ctc_ccpd.yml -o Global.pretrained_model=output/rec/r34_vd_none_bilstm_ctc_ccpd/best_accuracy Global.save_model_dir=./output/prune_model_ccpd/\r\n\r\n```\r\n+ 裁剪错误日志\r\n\r\n```bash\r\nW1126 09:49:51.398372 46912 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.3, Runtime API Version: 11.0\r\nW1126 09:49:51.406190 46912 device_context.cc:465] device: 0, cuDNN Version: 8.0.\r\n<class 'paddle.nn.layer.pooling.AvgPool2D'>'s flops has been counted\r\n<class 'paddle.nn.layer.conv.Conv2D'>'s flops has been counted\r\n<class 'paddle.fluid.dygraph.nn.BatchNorm'>'s flops has been counted\r\nCannot find suitable count function for <class 'paddle.nn.layer.pooling.MaxPool2D'>. Treat it as zero FLOPs.\r\nCannot find suitable count function for <class 'ppocr.modeling.necks.rnn.Im2Seq'>. Treat it as zero FLOPs.\r\nCannot find suitable count function for <class 'paddle.nn.layer.rnn.LSTMCell'>. Treat it as zero FLOPs.\r\n<class 'paddle.nn.layer.common.Linear'>'s flops has been counted\r\nTraceback (most recent call last):\r\n  File \"deploy/slim/prune/sensitivity_anal.py\", line 147, in <module>\r\n    main(config, device, logger, vdl_writer)\r\n  File \"deploy/slim/prune/sensitivity_anal.py\", line 77, in main\r\n    flops = paddle.flops(model, [1, 3, 640, 640])\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\hapi\\dynamic_flops.py\", line 108, in flops\r\n    print_detail=print_detail)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\hapi\\dynamic_flops.py\", line 249, in dynamic_flops\r\n    model(inputs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"deploy/slim/prune\\..\\..\\..\\ppocr\\modeling\\architectures\\base_model.py\", line 78, in forward\r\n    x = self.neck(x)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"deploy/slim/prune\\..\\..\\..\\ppocr\\modeling\\necks\\rnn.py\", line 89, in forward\r\n    x = self.encoder_reshape(x)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\layers.py\", line 914, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"deploy/slim/prune\\..\\..\\..\\ppocr\\modeling\\necks\\rnn.py\", line 31, in forward\r\n    assert H == 1\r\nAssertionError\r\n```\r\n\r\n### 量化\r\n```bash\r\npython deploy/slim/quantization/quant.py -c configs/rec_record/rec_r34_vd_none_bilstm_ctc_ccpd.yml -o Global.pretrain_weights=./output/rec/r34_vd_none_bilstm_ctc_ccpd/best_accuracy   Global.save_model_dir=./output/quant_model_ccpd\r\n```\r\n\r\n+ 量化错误日志\r\n```bash\r\nW1126 10:49:18.884593  7304 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.3, Runtime API Version: 11.0\r\nW1126 10:49:18.900218  7304 device_context.cc:465] device: 0, cuDNN Version: 8.0.\r\nINFO:root:If regularizer of a Parameter has been set by 'paddle.ParamAttr' or 'static.WeightNormParamAttr' already. The weight_decay[L2Decay, regularization_coeff=0.000000] in Optimizer will not take effect, and it will only be applied to other Parameters!\r\nTraceback (most recent call last):\r\n  File \"deploy/slim/quantization/quant.py\", line 162, in <module>\r\n    main(config, device, logger, vdl_writer)\r\n  File \"deploy/slim/quantization/quant.py\", line 149, in main\r\n    pre_best_model_dict = init_model(config, model, logger, optimizer)\r\n  File \"E:\\Paddle\\PaddleOCR\\ppocr\\utils\\save_load.py\", line 65, in init_model\r\n    optimizer.set_state_dict(opti_dict)\r\nAttributeError: 'Logger' object has no attribute 'set_state_dict\r\n```\r\n\r\nPaddlePaddle版本 : paddlepaddle-gpu 2.2.0.post110\r\nPaddleSlim版本: 2.2.0、 2.0.0 拉取PaddleSlim ,执行 python setup.py install 安装版本 以上3个版本都测试\r\n\r\n这个问题怎么解决？？\r\n",
        "state": "closed",
        "user": "chccc1994",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-11-26T02:52:05+00:00",
        "updated_at": "2024-02-06T02:58:43+00:00",
        "closed_at": "2024-02-06T02:58:43+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 941,
        "title": "【LatencyPredictor】读取opt转换生成的pb模型，其中卷积的weight、output形状信息有误",
        "body": "使用关闭了内存复用的opt工具将inference模型转换为protobuf格式的模型，可以读取到模型的拓扑结构和各层op的参数信息、输入输出形状，用于延时预估，但在Ubuntu环境下，偶发卷积的weight、output的channels对应不上，如下所示：\r\n\r\n读取的conv信息：\r\nconv2d in=(1, 32, 56, 56) weight=(24, 32, 1, 1) out=(1, 72, 56, 56) \r\n\r\n但同样的inference模型放到mac环境下进行protobuf格式转换却没有发生类似的错误，初步判断是ubuntu环境下的opt工具本身的问题。",
        "state": "closed",
        "user": "zzjjay",
        "closed_by": "XGZhang11",
        "created_at": "2021-12-01T03:10:00+00:00",
        "updated_at": "2024-02-06T03:58:47+00:00",
        "closed_at": "2024-02-06T03:58:47+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 944,
        "title": "Transformer 动态图PTQ量化报错",
        "body": "\r\npaddle版本： 2.2.0\r\npaddleslim版本：2.2.0\r\n\r\n代码：\r\n```\r\nfrom paddleslim import PTQ\r\nfrom paddlenlp.transformers import InferTransformerModel\r\n\r\ntransformer = InferTransformerModel(\r\n        src_vocab_size=20000,\r\n        trg_vocab_size=20000,\r\n        max_length=128,\r\n        num_encoder_layers=6,\r\n        num_decoder_layers=2,\r\n        n_head=8,\r\n        d_model=256,\r\n        d_inner_hid=2048,\r\n        dropout=0.1,\r\n        weight_sharing=False,\r\n        bos_id=0,\r\n        eos_id=1,\r\n        beam_size=2,\r\n        max_out_len=128\r\n    )\r\n\r\n    transformer.eval()\r\n\r\n    ptq = PTQ()\r\n    quant_model = ptq.quantize(transformer, fuse=True, fuse_list=None)\r\n    \r\n    ptq.save_quantized_model(quant_model, 'models',\r\n                             paddle.static.InputSpec(\r\n                                 shape=[1, 128],\r\n                                 dtype='int64')\r\n                             )\r\n\r\n```\r\n\r\n报错:\r\n```\r\nTraceback (most recent call last):\r\n  File \"ptq.py\", line 153, in <module>\r\n    main(args)\r\n  File \"ptq.py\", line 142, in main\r\n    dtype='int64')\r\n  File \".../.conda/envs/paddle2/lib/python3.6/site-packages/paddleslim/dygraph/quant/ptq.py\", line 146, in save_quantized_model\r\n    model=model, path=path, input_spec=input_spec)\r\n  File \".../.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/contrib/slim/quantization/imperative/ptq.py\", line 139, in save_quantized_model\r\n    self._convert(model)\r\n  File \".../.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/contrib/slim/quantization/imperative/ptq.py\", line 203, in _convert\r\n    self._save_output_thresholds(sub_layer, sub_layer._quant_config)\r\n  File \".../.conda/envs/paddle2/lib/python3.6/site-packages/paddle/fluid/contrib/slim/quantization/imperative/ptq.py\", line 261, in _save_output_thresholds\r\n    assert len(output_thresholds) == 1\r\nAssertionError\r\n\r\n```",
        "state": "closed",
        "user": "kismit",
        "closed_by": "XGZhang11",
        "created_at": "2021-12-07T08:14:24+00:00",
        "updated_at": "2024-02-06T03:58:57+00:00",
        "closed_at": "2024-02-06T03:58:57+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "kismit",
            "kismit",
            "wanghaoshuang",
            "kismit"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 945,
        "title": "非结构化训练加载GMPUnstructuredPruner报错，使用的2.2.1版本",
        "body": "![image](https://user-images.githubusercontent.com/77316774/145350219-258d1b64-e4cb-4ea9-a720-cc3326aeb33c.png)\r\n",
        "state": "closed",
        "user": "gaorui999",
        "closed_by": "gaorui999",
        "created_at": "2021-12-09T07:09:36+00:00",
        "updated_at": "2021-12-10T11:59:24+00:00",
        "closed_at": "2021-12-10T11:59:24+00:00",
        "comments_count": [
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 946,
        "title": "希望尽快能把develop版本的发布一下，目前训练非结构化稀疏配路径太难了~~~",
        "body": null,
        "state": "closed",
        "user": "gaorui999",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-12-09T14:29:09+00:00",
        "updated_at": "2024-02-06T02:58:45+00:00",
        "closed_at": "2024-02-06T02:58:45+00:00",
        "comments_count": [
            "minghaoBD",
            "gaorui999",
            "minghaoBD",
            "gaorui999",
            "gaorui999",
            "minghaoBD",
            "gaorui999",
            "gaorui999",
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 948,
        "title": "可以对yolov5进行压缩和量化吗？",
        "body": "可以对yolov5进行压缩和量化吗？",
        "state": "closed",
        "user": "WEIZHIHONG720",
        "closed_by": "XGZhang11",
        "created_at": "2021-12-14T13:46:29+00:00",
        "updated_at": "2024-02-06T03:59:22+00:00",
        "closed_at": "2024-02-06T03:59:22+00:00",
        "comments_count": [
            "yghstill",
            "Eric-Zhang1990",
            "dium6i"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 949,
        "title": "uniform剪枝要如何操作?",
        "body": "直接获取所有卷积操作的变量名称API应该参考哪个？\r\nuniform 剪枝是步骤是指 获得了所有卷积变量名称后每个变量剪枝相同比例吗？",
        "state": "closed",
        "user": "sc0ttms",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-12-15T01:53:48+00:00",
        "updated_at": "2024-02-06T02:58:46+00:00",
        "closed_at": "2024-02-06T02:58:46+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 951,
        "title": "使用不同shape的校准数据量化模型，产生报错",
        "body": "假设一个由单个conv组成的简单模型，conv的输入是动态的【1，3，None，None】，使用quant_post_static量化，这个api的校准数据迭代器sample_generator产生不同shape的校准数据，量化过程中报错：\r\n源码：\r\n\r\n> \r\n     import paddle\r\n     from paddle.nn import Conv2D\r\n     from paddle.nn.initializer import Assign\r\n     import paddleslim\r\n     \r\n     \r\n     # 定义一个简单只有conv op的模型,其中weight_attr定义为全1数据\r\n    class conv_model(paddle.nn.Layer):\r\n        def __init__(self):\r\n            super(conv_model, self).__init__()\r\n            self.conv_2d = Conv2D(in_channels=3, \r\n                                out_channels=3, \r\n                                kernel_size=2, \r\n                                padding=\"SAME\", \r\n                                weight_attr = paddle.ParamAttr(initializer=Assign(np.ones([3,3,2,2]).astype(np.float32))\r\n                                ))\r\n\r\n        def forward(self, inputs):\r\n            y = self.conv_2d(inputs)\r\n            return y\r\n\r\n\r\n    from paddle.static import InputSpec\r\n    import numpy as np\r\n\r\n    paddle.disable_static()\r\n    conv_2d_model = conv_model()\r\n\r\n    # save\r\n    path = \"./example_conv_2d/conv2d\"\r\n    paddle.jit.save(\r\n        layer=conv_2d_model,\r\n        path=path,\r\n        input_spec=[InputSpec(shape=[1,3,None,None], dtype='float32')])\r\n\r\n    paddle.enable_static()\r\n    place = paddle.CPUPlace()\r\n    exe = paddle.static.Executor(place)\r\n\r\n    def reader():\r\n      for x in [5,6]:\r\n        for _ in range(100):\r\n            yield np.random.random([1,3,x,x]).astype(np.float32)\r\n\r\n    paddleslim.quant.quant_post_static(\r\n      executor=exe,\r\n      weight_bits=8,\r\n      model_dir=\"./example_conv_2d\",\r\n      quantize_model_path=\"./static_quantized_conv_2d\",\r\n      sample_generator=reader,\r\n      model_filename=\"./example_conv_2d/conv2d.pdmodel\",\r\n      params_filename=\"./example_conv_2d/conv2d.pdiparams\",\r\n      )\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n假如使用相同shape的校准数据，便不产生报错\r\n>\r\n    def reader():\r\n      for x in [5]:\r\n        for _ in range(100):\r\n            yield np.random.random([1,3,x,x]).astype(np.float32)\r\n\r\n",
        "state": "closed",
        "user": "weishengying",
        "closed_by": "weishengying",
        "created_at": "2021-12-15T08:16:05+00:00",
        "updated_at": "2023-07-25T02:27:38+00:00",
        "closed_at": "2023-07-25T02:27:38+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 952,
        "title": "QAT量化后执行eval()报错如下",
        "body": "ValueError: (InvalidArgument) Tensor holds the wrong type, it holds ::paddle::platform::float16, but desires to be float.\r\n  [Hint: Expected valid == true, but received valid:0 != true:1.] (at /paddle/paddle/fluid/framework/tensor_impl.h:33)\r\n  [operator < fake_quantize_dequantize_moving_average_abs_max > error]",
        "state": "closed",
        "user": "sc0ttms",
        "closed_by": "sc0ttms",
        "created_at": "2021-12-15T09:54:16+00:00",
        "updated_at": "2022-02-08T04:49:33+00:00",
        "closed_at": "2022-02-08T04:49:33+00:00",
        "comments_count": [
            "yghstill",
            "sc0ttms",
            "yghstill",
            "sc0ttms"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 950,
        "title": "AIDigest 无此公众号",
        "body": "AIDigest 无此公众号",
        "state": "closed",
        "user": "sc0ttms",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-12-15T01:58:31+00:00",
        "updated_at": "2024-02-06T02:58:46+00:00",
        "closed_at": "2024-02-06T02:58:46+00:00",
        "comments_count": [
            "liyuyuan6969"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 962,
        "title": "请问如何在动态图中离线量化",
        "body": "动态图离线量化教程\r\nhttps://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/quick_start/dygraph/dygraph_quant_post_tutorial.md\r\n中的代码似乎是静态图代码吧\r\n\r\npaddle.enable_static()\r\nplace = paddle.CPUPlace()\r\nexe = paddle.static.Executor(place)\r\npaddleslim.quant.quant_post_static(\r\n        executor=exe,\r\n        model_dir='./',\r\n        model_filename='fp32_inference_model.pdmodel',\r\n        params_filename='fp32_inference_model.pdiparams',\r\n        quantize_model_path='./quant_post_static_model',\r\n        sample_generator=paddle.dataset.cifar.test10(),\r\n        batch_nums=10)",
        "state": "closed",
        "user": "huilin16",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2021-12-27T02:29:07+00:00",
        "updated_at": "2024-02-06T02:58:47+00:00",
        "closed_at": "2024-02-06T02:58:47+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 959,
        "title": "EC-DARTS: Inducing Equalized and Consistent Optimization into DARTS",
        "body": "这篇文章啥时候开源",
        "state": "closed",
        "user": "fxwfzsxyq",
        "closed_by": "XGZhang11",
        "created_at": "2021-12-22T09:37:22+00:00",
        "updated_at": "2024-02-06T03:59:37+00:00",
        "closed_at": "2024-02-06T03:59:37+00:00",
        "comments_count": [
            "wanghaoshuang",
            "fxwfzsxyq"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 966,
        "title": "需求：静态量化后的FP32格式模型存为INT8(缩小体积），推理时再从INT8转为FP32推理.",
        "body": "需求：静态量化后的FP32格式模型存为INT8(缩小体积），推理时再从INT8转为FP32推理.\r\n\r\n\r\n目前做法：\r\nstep1. 用paddle.load,从.pdiparams和.pdmodel读取到模型的state_dict\r\nstep2. 修改 被量化的权重，把weights的数据格式改成int8. data.astype(np.int8). 并赋值给state_dict.\r\nstep3. 用paddle.save或者pickle.dump保存模型. 在这里可以观察到 体积缩小约4倍的小模型.\r\nstep4. 和第二步同理. 把INT8转为FP32并储存.\r\n\r\n问题所在：\r\n1.FP32-INT8-FP32， 最后这个FP32模型无法使用 load_inference_model进行读取.\r\n\r\n后经过排查：\r\n\r\n1.问题不是出在数据转换过程和量化过程.\r\n\r\n2.拿原版的，官网下载的inference模型进行实验. 再paddle.load之后，马上用paddle.save存下新的.pdiparams，搭配原版的 .pdmodel.  依然无法推理，报的错误和之前一样.\r\n\r\n3. 通过python自带的open和file.read()，读取原版的.pdiparmas和新的.pdiparams.发现两个二进制文件内部，内容不一样. 使用len()，读取文件长度, 新的.pdiparams的长度长了3000左右.\r\n\r\n4.所以怀疑问题出在 paddle.load和paddle.save中间. \r\n\r\n\r\n错误报告：\r\n\r\nload_inference_model出错主要在 反序列化参数这一步.即 deserialize_persistables(program, params_bytes, exe).\r\n\r\n\r\nFile \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/static/io.py\", line 848, in load_inference_model\r\ndeserialize_persistables(program, params_bytes, executor)\r\nFile \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\nreturn caller(func, *(extras + args), **kw)\r\nFile \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in impl\r\nreturn wrapped_func(*args, **kwargs)\r\nFile \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 238, in impl\r\nreturn func(*args, **kwargs)\r\nFile \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/static/io.py\", line 669, in deserialize_persistables\r\nload_block.append_op(\r\nFile \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3178, in append_op\r\nop = Operator(\r\nFile \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 2224, in init\r\nfor frame in traceback.extract_stack():\r\nInvalidArgumentError: Deserialize to tensor failed, maybe the loaded file is not a paddle model(expected file format: 0, but 4254401664 found).\r\n[Hint: Expected version == 0U, but received version:4254401664 != 0U:0.] (at /paddle/paddle/fluid/framework/lod_tensor.cc:329)\r\n[operator < load_combine > error]\r\n\r\n\r\n所以，这上面的错误有办法解决吗~~？\r\n或者是还有其他方法可以实现这个需求吗？\r\n谢谢！\r\n\r\n",
        "state": "closed",
        "user": "Water2style",
        "closed_by": "Water2style",
        "created_at": "2021-12-31T11:02:21+00:00",
        "updated_at": "2022-05-25T07:50:24+00:00",
        "closed_at": "2022-02-12T21:32:04+00:00",
        "comments_count": [
            "yghstill",
            "Water2style",
            "Water2style",
            "Eric-Zhang1990"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 970,
        "title": "剪枝敏感度分析报错.",
        "body": "需求: 对 存在本地的训练好的模型进行剪枝.\r\n\r\n过程：\r\n1.首先跟着文档做了一套流程，可以完成剪枝.\r\nhttps://paddleslim-readthedocs-io.translate.goog/zh_CN/latest/tutorials/pruning/static/image_classification_sensitivity_analysis_tutorial.html?_x_tr_sl=zh-CN&_x_tr_tl=en&_x_tr_hl=zh-CN&_x_tr_pto=nui,op,sc\r\n\r\n2.由于这个文档的模型，是要在脚本中训练的，所以我先把文档里的模型训练后，用 save_inference_model 保存在本地（train_program和val_program都保存了，出同样的错误）.\r\n\r\n3. 后来用 load_inference_model,（此模型能通过test函数测试）.  再结合文档后半部分代码，在敏感度分析处报错：\r\n\r\n\r\n\r\n=== begin to do sensitivity !!=======\r\nFinal eva - acc_top1: 0.9668469429016113; acc_top5: 0.9991987347602844\r\n2022-01-25 15:02:20,717-INFO: sensitive - param: conv5_4_sep_weights; ratios: 0.1\r\n2022-01-25 15:02:21,026-WARNING: Leaves ['batch_norm_4.tmp_0', 'batch_norm_15.tmp_0', 'cross_entropy2_0.tmp_1', 'batch_norm_9.tmp_1', 'accuracy_1.tmp_4', 'batch_norm_18.tmp_0', 'batch_norm_9.tmp_0', 'batch_norm_12.tmp_1', 'batch_norm_16.tmp_1', 'batch_norm_17.tmp_0', 'batch_norm_8.tmp_1', 'batch_norm_17.tmp_1', 'batch_norm_11.tmp_1', 'batch_norm_0.tmp_0', 'batch_norm_13.tmp_0', 'batch_norm_26.tmp_0', 'accuracy_1.tmp_3', 'batch_norm_10.tmp_1', 'batch_norm_24.tmp_0', 'batch_norm_22.tmp_1', 'batch_norm_20.tmp_0', 'batch_norm_6.tmp_0', 'batch_norm_22.tmp_0', 'batch_norm_24.tmp_1', 'batch_norm_1.tmp_1', 'batch_norm_5.tmp_0', 'batch_norm_1.tmp_0', 'batch_norm_7.tmp_0', 'batch_norm_23.tmp_0', 'batch_norm_2.tmp_0', 'accuracy_0.tmp_3', 'batch_norm_21.tmp_0', 'accuracy_0.tmp_4', 'batch_norm_3.tmp_1', 'batch_norm_16.tmp_0', 'batch_norm_7.tmp_1', 'batch_norm_14.tmp_0', 'batch_norm_6.tmp_1', 'cross_entropy2_0.tmp_2', 'batch_norm_5.tmp_1', 'batch_norm_13.tmp_1', 'batch_norm_2.tmp_1', 'batch_norm_4.tmp_1', 'batch_norm_8.tmp_0', 'batch_norm_15.tmp_1', 'batch_norm_25.tmp_0', 'batch_norm_26.tmp_1', 'batch_norm_3.tmp_0', 'batch_norm_18.tmp_1', 'batch_norm_10.tmp_0', 'batch_norm_12.tmp_0', 'batch_norm_19.tmp_1', 'batch_norm_23.tmp_1', 'fetch', 'batch_norm_11.tmp_0', 'batch_norm_0.tmp_1', 'batch_norm_20.tmp_1', 'batch_norm_21.tmp_1', 'batch_norm_25.tmp_1', 'batch_norm_14.tmp_1', 'batch_norm_19.tmp_0'] will be skipped when parsing graph.\r\n2022-01-25 15:02:21,072-INFO: change groups of depthwise_conv2d(conv5_5_dw_weights) from 512 to 461;\r\nTraceback (most recent call last):\r\n  File \"1.mobilenet_prune.py\", line 133, in <module>\r\n    sens_0 = slim.prune.sensitivity(\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddleslim/prune/sensitive.py\", line 99, in sensitivity\r\n    pruned_program, param_backup, _ = pruner.prune(\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddleslim/prune/pruner.py\", line 165, in prune\r\n    graph.infer_shape()\r\n  File \"/home/xieyunyao/miniconda3/envs/PP22/lib/python3.8/site-packages/paddleslim/core/graph_wrapper.py\", line 391, in infer_shape\r\n    op._op.desc.infer_shape(op._op.block.desc)\r\nRuntimeError: (NotFound) Operator feed's infer_shape is not registered.\r\n  [Hint: Expected static_cast<bool>(infer_shape) == true, but received static_cast<bool>(infer_shape):0 != true:1.] (at /paddle/paddle/fluid/framework/op_desc.cc:789)\r\n  [operator < feed > error]\r\n\r\n输入的 infer_shape没有注册？ 这个问题怎么解决呢",
        "state": "closed",
        "user": "Water2style",
        "closed_by": "Water2style",
        "created_at": "2022-01-25T11:51:11+00:00",
        "updated_at": "2022-02-03T09:29:34+00:00",
        "closed_at": "2022-02-03T09:29:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 972,
        "title": "静态图下,训练/预训练re-train, 相关问题.",
        "body": "新年快乐！\r\n你好，目前有如下几个问题想请教一下.\r\n\r\n由于在static模式下，有时候会通过re-train在剪枝后用来恢复acc. (剪枝教程里就re-train了)\r\n目前有下面几个问题想要请教一下.\r\n\r\n\r\n教程里是拿MNIST训了一下，但我要做的是ImageNet数据集，从新训练几乎不可能.\r\n官网上找的预训练模型，变量名字和 slim.models 里的模型网络对不上,无法通过 paddle.static.set_program_state来把预训练模型给加入program.\r\n目前像教程中那种 static风格来组建模型网络的资料也挺少.....\r\n\r\n所以,\r\n结合现状，后续会多多个分类模型做剪枝和量化，是否建议转动态图~? 大不了不去实现 那两个只支持静态图的剪枝算法.\r\n\r\n谢谢! \r\n\r\n ",
        "state": "closed",
        "user": "Water2style",
        "closed_by": "Water2style",
        "created_at": "2022-02-02T19:07:53+00:00",
        "updated_at": "2022-02-12T21:31:46+00:00",
        "closed_at": "2022-02-12T21:31:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 975,
        "title": "PaddleSlim/demo/imagenet_reader.py，  有bug.",
        "body": "你好，\r\n我在使用 https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/dygraph/quant 时，发现使用的PaddleSlim/demo/imagenet_reader.py有问题.\r\n\r\n1.#210和#217使用的data_path， 并不是 DATA_DIR/train 和 DATA_DIR/val.  读取图片时报错.\r\n\r\n2. 为什么 dygraph/quant和dygraph/pruning 两个demo中，使用的数据集方式不同？\r\nquant用的是io.Dataloader，然后自己写的训练函数； 然而pruning用的是DatasetFolder搭配高层API的model.fit\r\n\r\n为什么用了两种不同的方式来加载数据集呢？\r\n两种方式有什么区别呢？之前看到好像 model.fit(dataset)的方式，会比使用io.Dataloader的方式训练得快一些.\r\n谢谢！",
        "state": "closed",
        "user": "Water2style",
        "closed_by": "XGZhang11",
        "created_at": "2022-02-13T14:34:41+00:00",
        "updated_at": "2024-02-06T03:59:58+00:00",
        "closed_at": "2024-02-06T03:59:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 999,
        "title": "关于darts教程中的使用实例，没有构建cell",
        "body": "您好，我想研究下基于paddle怎么复现darts，但是这个[链接](https://github.com/PaddlePaddle/PaddleSlim/blob/release/2.0.0/docs/zh_cn/api_cn/dygraph/nas/darts.rst#%E5%8F%AF%E5%BE%AE%E5%88%86%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2darts)下的使用实例没有构建cell块吧，整个网络只有stem层和分类层。",
        "state": "closed",
        "user": "nick-zoo",
        "closed_by": "XGZhang11",
        "created_at": "2022-02-23T09:38:30+00:00",
        "updated_at": "2024-02-06T04:00:07+00:00",
        "closed_at": "2024-02-06T04:00:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1001,
        "title": "paddleslim进行量化和压缩是否对百度edgeboard硬件平台有提升？",
        "body": "目前没有这方面的教程或者说明。我想通过量化来提高原有的paddledetection模型在edgeboard上的表现，不知能否使用paddleslim",
        "state": "closed",
        "user": "imzongjian",
        "closed_by": "XGZhang11",
        "created_at": "2022-02-27T14:04:43+00:00",
        "updated_at": "2024-02-06T04:00:14+00:00",
        "closed_at": "2024-02-06T04:00:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 973,
        "title": "在ImageNet上做剪枝的敏感性分析...有必要把5万张val跑完吗",
        "body": "Hello\r\n今天发现做剪枝的敏感性分析，如果我一个模型可能对20个conv做剪枝\r\n我发现在敏感性分析的时候,可能就会跑 20次 eval.....\r\n请问有必要跑完吗？ 谢谢！\r\n",
        "state": "closed",
        "user": "Water2style",
        "closed_by": "Water2style",
        "created_at": "2022-02-06T16:44:16+00:00",
        "updated_at": "2022-02-08T07:04:31+00:00",
        "closed_at": "2022-02-08T07:04:31+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Water2style"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 976,
        "title": "ResNeXt101_vd_32x4d 参考PaddleClas 模板剪枝报错。",
        "body": "ResNeXt101_vd_32x4d 剪枝报错。 其中，版本：\r\nPaddleSlim 2.1.1\r\nPaddleClas 2.2\r\nPaddlePadddle 2.1.2\r\n\r\n2022-02-14 22:20:16,608-INFO: change groups from 32 to 22 for res5c_branch2b_weights.\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 31, in <module>\r\n    engine = Engine(config, mode=\"train\")\r\n  File \"/home/aistudio/PaddleClas/ppcls/engine/engine.py\", line 194, in __init__\r\n    self.pruner = get_pruner(self.config, self.model)\r\n  File \"/home/aistudio/PaddleClas/ppcls/engine/slim/prune.py\", line 35, in get_pruner\r\n    _prune_model(pruner, config, model)\r\n  File \"/home/aistudio/PaddleClas/ppcls/engine/slim/prune.py\", line 59, in _prune_model\r\n    flops(model, [1] + config[\"Global\"][\"image_shape\"]) / 1e9,\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/analysis/flops.py\", line 133, in dygraph_flops\r\n    program = dygraph2program(model, inputs)\r\n  File \"<decorator-gen-279>\", line 2, in dygraph2program\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 227, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/core/dygraph.py\", line 119, in dygraph2program\r\n    original_outputs = layer(*inputs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/aistudio/PaddleClas/ppcls/arch/backbone/model_zoo/resnext_vd.py\", line 246, in forward\r\n    y = block(y)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/aistudio/PaddleClas/ppcls/arch/backbone/model_zoo/resnext_vd.py\", line 141, in forward\r\n    conv1 = self.conv1(y)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/aistudio/PaddleClas/ppcls/arch/backbone/model_zoo/resnext_vd.py\", line 90, in forward\r\n    y = self._conv(inputs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/conv.py\", line 667, in forward\r\n    use_cudnn=self._use_cudnn)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/conv.py\", line 114, in _conv_nd\r\n    pre_bias = getattr(core.ops, op_type)(x, weight, *attrs)\r\nValueError: (InvalidArgument) The number of output's channels (filter's first dimension) of Op(Conv) should be divided by groups. But received: the output channels is 90, the filter's shape is [90, 4, 3, 3], the groups is 22.\r\n  [Hint: Expected filter_dims[0] % groups == 0, but received filter_dims[0] % groups:2 != 0:0.] (at /paddle/paddle/fluid/operators/conv_op.cc:108)\r\n  [operator < conv2d > error]",
        "state": "closed",
        "user": "ChrisMengxl",
        "closed_by": "ChrisMengxl",
        "created_at": "2022-02-14T14:28:35+00:00",
        "updated_at": "2022-03-07T02:32:49+00:00",
        "closed_at": "2022-03-07T02:32:49+00:00",
        "comments_count": [
            "ChrisMengxl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1002,
        "title": "paddleslim官方文档版本配置与实际不符",
        "body": "官方文档是paddleslim=2.1.0与paddlex=2.1.0,但实际却有冲突\r\n![image](https://user-images.githubusercontent.com/80373122/155956195-9e5fc803-e23f-4408-8c01-add3a96b2659.png)\r\n",
        "state": "closed",
        "user": "llt-Nancy",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-02-28T09:14:28+00:00",
        "updated_at": "2024-02-06T02:58:48+00:00",
        "closed_at": "2024-02-06T02:58:48+00:00",
        "comments_count": [
            "LLiuzui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1008,
        "title": "使用预测模型进行量化训练中的问题",
        "body": "我在参考 “使用预测模型进行量化训练示例” 这一篇中遇到一些问题，想请教一下.\r\nref: https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/quant/quant_aware_with_infermodel\r\n\r\n1.教程中是带有蒸馏功能的，我想问可以对动态图jit.save后的预测模型，在静态图中QAT训练吗？（也就是不要蒸馏部分）\r\n\r\n2.教程中有一个参数：distill_node_name_list，后面跟着大量的蒸馏节点，如果只做自蒸馏，不同的模型下，我想问这个蒸馏节点该怎么选呢？ 好像没有相关的资料说明该如何选择这些节点.\r\n\r\n谢谢！",
        "state": "closed",
        "user": "Water2style",
        "closed_by": "Water2style",
        "created_at": "2022-03-08T16:26:34+00:00",
        "updated_at": "2022-03-14T16:31:18+00:00",
        "closed_at": "2022-03-14T16:31:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1003,
        "title": "默认batch_size是16不太好吧",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/66168f6b957146fe46fd6d45dff7f4d1985e59ab/paddleslim/quant/quanter.py#L315\r\n\r\n默认batch_size的话，很多模型转换过来调用`slim.quant.quant_post_static()`会报错`InvalidArgumentError: The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape`，感觉默认是1比较好。",
        "state": "closed",
        "user": "vicwer",
        "closed_by": "yghstill",
        "created_at": "2022-03-03T07:37:29+00:00",
        "updated_at": "2022-03-07T05:34:56+00:00",
        "closed_at": "2022-03-07T05:34:56+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1007,
        "title": "关于使用slim做paddle模型的conv+bn合并",
        "body": "如果对于一个paddle模型，只想做conv+BN合并，不想做量化，该调用什么接口呢，现在看合并是在quant_opst_static调用的",
        "state": "closed",
        "user": "vicwer",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-03-07T03:11:31+00:00",
        "updated_at": "2024-02-06T02:58:49+00:00",
        "closed_at": "2024-02-06T02:58:49+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1017,
        "title": "剪枝与量化问题",
        "body": "使用paddledetection里的static静态图对预训练模型ssd_mobilenet_voc进行剪枝后是否能用static里的量化工具进行量化，还是需要离线量化",
        "state": "closed",
        "user": "TANSHOUTAO",
        "closed_by": "XGZhang11",
        "created_at": "2022-03-17T02:14:53+00:00",
        "updated_at": "2024-02-06T04:00:32+00:00",
        "closed_at": "2024-02-06T04:00:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1025,
        "title": "from work import reader错误",
        "body": "在论坛上也问了下！\r\n\r\n问题链接：https://aistudio.baidu.com/paddle/forum/topic/show/994140\r\n\r\n这个项目的ISSURE怎么像在都没人回了？论坛也没人回，xdm有其他的量化工具推荐吗？",
        "state": "closed",
        "user": "liyuyuan6969",
        "closed_by": "XGZhang11",
        "created_at": "2022-03-30T02:31:28+00:00",
        "updated_at": "2024-02-06T04:00:51+00:00",
        "closed_at": "2024-02-06T04:00:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1013,
        "title": "Quantization of paddleslim question!!!",
        "body": "hi，\r\n    为什么我pip install paddleslim后有fluid\\contrib\\slim\\quantization 这一组目录，但是我从repo上git clone下来的最新几个版本都没有这组目录哪怕一个子目录？\r\n     请问下为什么这两套代码不同步呢？还是我找的方式不对，请教下，多谢\r\n\r\nBR",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "XGZhang11",
        "created_at": "2022-03-09T11:02:45+00:00",
        "updated_at": "2024-02-06T04:00:22+00:00",
        "closed_at": "2024-02-06T04:00:22+00:00",
        "comments_count": [
            "2050airobert"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1016,
        "title": "请教一下 nas 有关模型 fc层输出的问题",
        "body": "您好， 我想使用paddleslim的nas功能为自己的研究搜索一个轻量级的深度哈希网络，希望模型可以输出指定长度的哈希编码，即需要用到模型最后一个fc层的输出，并且我想通过程序设置指定输出向量的长度。\r\n\r\n我认真研读了 https://github.com/PaddlePaddle/PaddleSlim/blob/develop/demo/nas/sanas_darts_space.py 的代码，包括https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/nas 还有 https://paddleslim.readthedocs.io/zh_CN/latest/api_cn/static/nas/search_space.html?highlight=output_size#id3 ，https://github.com/PaddlePaddle/PaddleSlim/blob/4d75cb9cecf5a02e789576b0c02ce7376615dafd/docs/zh_cn/api_cn/static/nas/nas_api.rst文档。  output_size 可以用来设置输出的feature map的大小。\r\n\r\n这是我找到的最接近的config选项，请问倘若我要生成128位的二进制编码，我是需要将 传入SANAS的configs可以指定为[(’MobileNetV2BlockSpace’, {’input_size’: 224, ‘output_size’: 128, ‘block_num’: 10})]吗？ \r\n\r\n预期结果： 此时网络运算结果为 128位的二进制编码 即一个128位的二进制分布，每一位为一个浮点数。 \r\n请问我理解的对吗？\r\n\r\n![截屏2022-03-14 20 28 24](https://user-images.githubusercontent.com/31544054/158172124-86135183-fabb-45b1-9b67-c69089e01d6d.png)\r\n",
        "state": "closed",
        "user": "zhiyuan1i",
        "closed_by": "zhiyuan1i",
        "created_at": "2022-03-14T12:54:13+00:00",
        "updated_at": "2022-03-15T15:23:41+00:00",
        "closed_at": "2022-03-15T15:23:41+00:00",
        "comments_count": [
            "zhiyuan1i",
            "RachelXu7",
            "zhiyuan1i"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1018,
        "title": "小白的剪枝问题",
        "body": "敏感度分析完后，怎么确定剪枝的层和剪枝率，因为介绍用python绘制的话该怎么做，那个网页404了",
        "state": "closed",
        "user": "TANSHOUTAO",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-03-17T02:16:59+00:00",
        "updated_at": "2024-02-06T02:58:50+00:00",
        "closed_at": "2024-02-06T02:58:50+00:00",
        "comments_count": [
            "bbilixzc",
            "TANSHOUTAO",
            "bbilixzc",
            "TANSHOUTAO",
            "SunYF-0729"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1027,
        "title": "在线量化得到模型如何转换为paddle-trt支持的模型呢",
        "body": "![image](https://user-images.githubusercontent.com/20138766/160821128-9f178c8c-3633-4b01-9d35-afd911b4b849.png)\r\n直接使用这个模型进行推理结果异常",
        "state": "closed",
        "user": "marsbzp",
        "closed_by": "XGZhang11",
        "created_at": "2022-03-30T11:08:18+00:00",
        "updated_at": "2024-02-06T04:01:11+00:00",
        "closed_at": "2024-02-06T04:01:11+00:00",
        "comments_count": [
            "yghstill",
            "marsbzp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1030,
        "title": "如何对已训练好的静态模型进行剪枝？",
        "body": "我现在有一个已经训练好的静态模型，其是使用PaddlePaddle2.1.2训练的，现在想对这个训练好的模型进行剪裁，看相关文档都是从模型训练开始的，但我模型已经训练好了。所以目前不知道使用什么API将模型导入进去以及是否还需要设置model.prepare参数？请帮忙解答下，如何操作可以将已经训练导出的静态模型进行剪枝",
        "state": "closed",
        "user": "dhbhf",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-04-02T03:25:55+00:00",
        "updated_at": "2024-02-06T02:58:51+00:00",
        "closed_at": "2024-02-06T02:58:51+00:00",
        "comments_count": [
            "smallhaozigithub"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1031,
        "title": "EfficientNet / RegNet等模型的量化效果",
        "body": "hi～请问下你们有没有在model_zoo上批量测试过当前大部分模型的量化效果，想了解下在EfficientNet / RegNet / MobileNetV3 等模型上的量化表现如何",
        "state": "closed",
        "user": "xingyueye",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-04-02T06:19:36+00:00",
        "updated_at": "2024-02-06T02:58:51+00:00",
        "closed_at": "2024-02-06T02:58:51+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1034,
        "title": "SLIM 量化新pose模型失败！",
        "body": "Hi，\r\n     1 请问是否有最新的关于调用cmd命令或者相关py文件的slim使用说明文档或者网页链接？\r\n      2 比如要int8量化一个新的模型tinypose 如何调用paddle slim工具实现呢？ \r\n      3 最新的可用版本是哪个？ 具体使用甚至包括编译说明step by step 可以分享下链接吗？ \r\n      4 PADDLE SLIM 离线量化跟paddle lite里面提供的opt 带量化选项的功能是不是一致，可以不用slim而直接用opt，离线uint8量化的结果也是一样的吗？\r\n BR",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "XGZhang11",
        "created_at": "2022-04-06T12:53:10+00:00",
        "updated_at": "2024-02-06T04:01:21+00:00",
        "closed_at": "2024-02-06T04:01:21+00:00",
        "comments_count": [
            "2050airobert",
            "yghstill",
            "2050airobert",
            "yghstill",
            "2050airobert",
            "2050airobert",
            "yghstill",
            "2050airobert",
            "2050airobert"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1037,
        "title": "模型结构化剪枝说明",
        "body": "在PaddlePaddle中，变量分为两种，可训练的Parameters和中间变量（即各层的输出，也叫做feature map）。\r\n剪枝操作只会对Parameters进行剪裁，比如将conv_weight_0从shape[32, 3, 5, 5]剪裁成shape[16, 3, 5, 5];\r\n在对Program剪枝之后，program中的Parameters的shape会改变，中间变量的shape暂时不会变化。在运行剪枝后的program时，中间变量会在infer_shape操作中，根据parameter的变化进行调整。\r\n\r\n以上，验证剪枝后模型是否变化，需要对比剪枝前后Parameters的shape变化，方法如下：\r\nhttps://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/static/Program_cn.html#all_parameters\r\n\r\n```\r\nfor param in program.all_parameters():\r\n    print(param)\r\n```\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2022-04-08T03:23:56+00:00",
        "updated_at": "2024-02-06T04:01:31+00:00",
        "closed_at": "2024-02-06T04:01:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1050,
        "title": "Yolofastest模型怎么利用paddleslim做模型压缩呢？",
        "body": "我是一个新手。 我想请教一下前辈们， 必须是基于paddle框架训练的模型才能用paddleslim吗？\r\n  \r\n像yolofastest的模型能利用paddleslim做模型压缩吗？\r\n\r\n如果可以的话， 应该怎么做呢？",
        "state": "closed",
        "user": "Dora1483",
        "closed_by": "qingqing01",
        "created_at": "2022-04-18T15:56:26+00:00",
        "updated_at": "2022-04-24T07:26:03+00:00",
        "closed_at": "2022-04-24T07:26:03+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1046,
        "title": "SANAS source code",
        "body": "How to obtain the source code of SANAS?",
        "state": "closed",
        "user": "Johnzhjw",
        "closed_by": "Johnzhjw",
        "created_at": "2022-04-13T04:28:29+00:00",
        "updated_at": "2022-04-17T14:47:01+00:00",
        "closed_at": "2022-04-17T14:47:00+00:00",
        "comments_count": [
            "Johnzhjw"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1052,
        "title": "TypeError: quant_post_static() got an unexpected keyword argument 'data_loader'",
        "body": "有人知道这个问题是什么引起的吗？",
        "state": "closed",
        "user": "Dora1483",
        "closed_by": "XGZhang11",
        "created_at": "2022-04-18T17:14:47+00:00",
        "updated_at": "2024-02-06T04:01:42+00:00",
        "closed_at": "2024-02-06T04:01:42+00:00",
        "comments_count": [
            "yghstill",
            "Dora1483",
            "Dora1483",
            "yghstill",
            "Dora1483",
            "yghstill",
            "yghstill",
            "Dora1483",
            "Dora1483",
            "Dora1483",
            "yghstill",
            "Dora1483",
            "Dora1483",
            "yghstill",
            "yghstill",
            "Dora1483",
            "Dora1483",
            "yghstill",
            "Dora1483",
            "yghstill",
            "Dora1483",
            "Dora1483",
            "Dora1483",
            "yghstill",
            "Dora1483",
            "Dora1483",
            "Dora1483"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1059,
        "title": "paddle slim快速开始 » 静态图 » 量化训练教程报错",
        "body": "跑 paddle slim官方给出的例程的时候，在保存量化后的模型的时候报错，错误如下\r\n![QQ截图20220420150421](https://user-images.githubusercontent.com/97490092/164170232-f66e15d5-d758-4474-a7d9-aec4177472d6.jpg)\r\n：",
        "state": "closed",
        "user": "fash120",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-04-20T07:05:45+00:00",
        "updated_at": "2024-02-06T02:58:52+00:00",
        "closed_at": "2024-02-06T02:58:52+00:00",
        "comments_count": [
            "yghstill",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1073,
        "title": "离线量化报错 ImportError: cannot import name 'quant_post_static' from 'paddleslim.quant' ",
        "body": "想做一下模型的离线量化，但是发现develop版的paddlepaddle无法兼容paddleslim，使用quant_post_static这个API就会报错\r\n```bash\r\n/usr/local/lib/python3.7/site-packages/paddle/fluid/framework.py:356: UserWarning: PaddlePaddle version 1.8.4 or higher is required, but 0.0.0 installed, Maybe you are using a develop version, please make sure the version is good with your code.\r\n  (min_version, fluid_version.full_version))\r\n2022-04-28 13:11:51,249-WARNING: type object 'QuantizationTransformPass' has no attribute '_supported_quantizable_op_type'\r\n2022-04-28 13:11:51,249-WARNING: If you want to use training-aware and post-training quantization, please use Paddle >= 1.8.4 or develop version\r\nTraceback (most recent call last):\r\n  File \"quant_post_static.py\", line 22, in <module>\r\n    from paddleslim.quant import quant_post_static\r\nImportError: cannot import name 'quant_post_static' from 'paddleslim.quant' (/usr/local/lib/python3.7/site-packages/paddleslim/quant/__init__.py)\r\n```\r\n然后怀疑是paddle版本号有问题，换到2.2.2居然就好了…………\r\n难道使用slim之前还得把paddle卸载一遍安装上稳定版的才行？",
        "state": "closed",
        "user": "HydrogenSulfate",
        "closed_by": "HydrogenSulfate",
        "created_at": "2022-04-28T13:19:20+00:00",
        "updated_at": "2023-01-12T05:42:15+00:00",
        "closed_at": "2023-01-12T05:42:15+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1060,
        "title": "Exception: 'feed_targets' does not have inputs variable",
        "body": "运行静态离线量化示例报上述错误。\r\n\r\n有大佬指导一下吗？",
        "state": "closed",
        "user": "Dora1483",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-04-20T14:26:50+00:00",
        "updated_at": "2024-02-06T02:58:53+00:00",
        "closed_at": "2024-02-06T02:58:53+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1075,
        "title": "模型导出以及Paddlelite部署",
        "body": "### PaddleSlim开发者你好，请问如何将经过PRUNE-QAT的模型进行保存并通过Paddlelite进行部署？\r\n因为PRUNE是动态图转为静态图(dygraphy to static)再进行保存，而QAT是直接从动态图(dygraphy)保存，因此请问经过PRUNE-QAT后的模型如何保存以及通过Paddlelite部署？\r\n五一快乐~。~   \r\n谢谢！\r\n\r\n",
        "state": "closed",
        "user": "WeizXy",
        "closed_by": "WeizXy",
        "created_at": "2022-04-30T11:33:47+00:00",
        "updated_at": "2022-05-28T02:25:15+00:00",
        "closed_at": "2022-05-10T08:58:21+00:00",
        "comments_count": [
            "yghstill",
            "WeizXy",
            "yghstill",
            "WeizXy",
            "Jiashuhao518"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1074,
        "title": "用Paddle对SSD模型剪枝的问题",
        "body": "![image](https://user-images.githubusercontent.com/104298741/166101578-9dd102a7-2bfb-46de-b841-90874148fdbd.png)\r\n为什么这个的pruned ratio 只有0.045左右啊，yolov3的这个都可以达到30%几。这个配置文件该怎么改呢？ @wanghaoshuang ",
        "state": "closed",
        "user": "malcolm-wang",
        "closed_by": "XGZhang11",
        "created_at": "2022-04-30T10:18:33+00:00",
        "updated_at": "2024-02-06T04:01:51+00:00",
        "closed_at": "2024-02-06T04:01:51+00:00",
        "comments_count": [
            "malcolm-wang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1084,
        "title": "如何自定义量化方法",
        "body": "如何自定义量化方法，例如dorefa 8bit量化，有没有这方面的案例参考?\r\n\r\n我看[\\dygraph\\quant\\qat.py](https://github.com/PaddlePaddle/paddleslim/blob/develop/paddleslim/dygraph/quant/qat.py#L158)里面的QAT对象留了自定义量化方法的接口，有没有实际例子？\r\n\r\n```\r\nclass QAT(object):\r\n    \"\"\"\r\n    Quant Aware Training(QAT): Add the fake quant logic for given quantizable layers, namely add the quant_dequant computational logic both for activation inputs and weight inputs.\r\n    \"\"\"\r\n\r\n    def __init__(self,\r\n                 config=None,\r\n                 weight_preprocess=None,\r\n                 act_preprocess=None,\r\n                 weight_quantize=None,\r\n                 act_quantize=None):\r\n        \"\"\"\r\n        Args:\r\n            model(nn.Layer)\r\n            config(dict, optional): configs for quantization. if None, will use default config. \r\n                    Default: None.\r\n            weight_quantize(class, optional): Defines how to quantize weight. Using this\r\n                    can quickly test if user's quantization method works or not. In this method, user should\r\n                    both define quantization function and dequantization function, that is, the function's input\r\n                    is non-quantized weight and function returns dequantized weight. If None, will use\r\n                    quantization op defined by 'weight_quantize_type'.\r\n                    Default is None.\r\n            act_quantize(class, optional): Defines how to quantize activation. Using this\r\n                    can quickly test if user's quantization method works or not. In this function, user should\r\n                    both define quantization and dequantization process, that is, the function's input\r\n                    is non-quantized activation and function returns dequantized activation. If None, will use \r\n                    quantization op defined by 'activation_quantize_type'.\r\n                    Default is None.\r\n            weight_preprocess(class, optional): Defines how to preprocess weight before quantization. Using this\r\n                    can quickly test if user's preprocess method works or not. The function's input\r\n                    is non-quantized weight and function returns processed weight to be quantized. If None, will\r\n                    use preprocess method defined by 'weight_preprocess_type'.\r\n                    Default is None.\r\n            act_preprocess(class, optional): Defines how to preprocess activation before quantization. Using this\r\n                    can quickly test if user's preprocess method works or not. The function's input\r\n                    is non-quantized activation and function returns processed activation to be quantized. If None,\r\n                    will use preprocess method defined by 'activation_preprocess_type'.\r\n                    Default is None.\r\n        \"\"\"\r\n```\r\n",
        "state": "closed",
        "user": "personqianduixue",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-05-08T12:52:49+00:00",
        "updated_at": "2024-02-06T02:58:54+00:00",
        "closed_at": "2024-02-06T02:58:54+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1088,
        "title": "量化时的数据集",
        "body": "请问我可以用VOC的验证集吗，格式是什么样的呢",
        "state": "closed",
        "user": "LLiuzui",
        "closed_by": "XGZhang11",
        "created_at": "2022-05-10T01:20:33+00:00",
        "updated_at": "2024-02-06T04:01:58+00:00",
        "closed_at": "2024-02-06T04:01:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1086,
        "title": "离线静态量化报错 paddleslim2.1.1 paddlepaddle2.1.1",
        "body": ".\\..\\imagenet_reader.py:119: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\r\n  img = img.transpose(Image.FLIP_LEFT_RIGHT)\r\nTraceback (most recent call last):\r\n  File \"quant_post.py\", line 67, in <module>\r\n    main()\r\nC:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\reader.py:1294: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\r\n  logging.warn('Your reader has raised an exception!')\r\n2022-05-09 12:53:53,398-WARNING: Your reader has raised an exception!\r\n  File \"quant_post.py\", line 62, in main\r\n    quantize(args)\r\n  File \"quant_post.py\", line 56, in quantize\r\n    bias_correction=args.bias_correction)\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddleslim-2.1.1-py3.7.egg\\paddleslim\\quant\\quanter.py\", line 417, in quant_post_static\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\data_feeder.py\", line 206, in done\r\n    arr = arr.reshape(self.shape)\r\nValueError: cannot reshape array of size 32 into shape (3,300,300)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\reader.py\", line 1295, in __thread_main__\r\n    six.reraise(*sys.exc_info())\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\six.py\", line 719, in reraise\r\n    raise value\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\reader.py\", line 1275, in __thread_main__\r\n    for tensors in self._tensor_reader():\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\data_feeder.py\", line 249, in __call__\r\n    yield self._done()\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\data_feeder.py\", line 237, in _done\r\n    return [c.done() for c in self.converters]\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\data_feeder.py\", line 237, in <listcomp>\r\n    return [c.done() for c in self.converters]\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\data_feeder.py\", line 210, in done\r\n    .format(self.shape, arr.shape))\r\nValueError: Reshape error. What is defined in data layer is (-1, 3, 300, 300), but receive (32,)\r\n\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\contrib\\slim\\quantization\\post_training_quantization.py\", line 365, in quantize\r\n    for data in self._data_loader():\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\PaddleSlim-2.1.1\\lib\\site-packages\\paddle\\fluid\\reader.py\", line 1251, in __next__\r\n    return self._reader.read_next()\r\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\r\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at C:\\home\\workspace\\Paddle_release2\\paddle/fluid/operators/reader/blocking_queue.h:166)\r\n\r\n\r\n",
        "state": "closed",
        "user": "LLiuzui",
        "closed_by": "LLiuzui",
        "created_at": "2022-05-09T04:58:16+00:00",
        "updated_at": "2022-05-09T06:14:10+00:00",
        "closed_at": "2022-05-09T06:14:10+00:00",
        "comments_count": [
            "LLiuzui",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1091,
        "title": "用途是在Paddle-Inference上使用，是否可以使用在线量化训练来压缩模型大小？",
        "body": "如同很多教程所说，在线量化训练导出的模型不会降低模型大小，使用paddle-lite opt后才能降低模型大小。\r\n我的用途是在Paddle-Inference上使用的压缩模型，是不是不能使用在线量化策略来完成？",
        "state": "closed",
        "user": "sun222",
        "closed_by": "sun222",
        "created_at": "2022-05-10T07:08:42+00:00",
        "updated_at": "2022-05-13T11:38:33+00:00",
        "closed_at": "2022-05-13T11:38:33+00:00",
        "comments_count": [
            "yghstill",
            "sun222"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1094,
        "title": "paddleslim在线量化demo train.py中引用的from utility import add_arguments, print_arguments报错",
        "body": "Traceback (most recent call last):\r\n  File \"train_ssd.py\", line 24, in <module>\r\n    from utility import add_arguments, print_arguments\r\nImportError: cannot import name 'add_arguments' from 'utility' (unknown location)\r\n\r\n请问这个utility包是什么，我直接pip安装了还是报错，且site-packages中只出现了utility-1.0.dist-info文件夹\r\n",
        "state": "closed",
        "user": "LLiuzui",
        "closed_by": "LLiuzui",
        "created_at": "2022-05-10T14:01:58+00:00",
        "updated_at": "2022-05-11T04:40:42+00:00",
        "closed_at": "2022-05-11T04:40:42+00:00",
        "comments_count": [
            "yghstill",
            "LLiuzui"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1093,
        "title": "PaddleSlim能对SSD_Mobilenet_v1进行静态图量化训练吗",
        "body": "我看到官方给出的model都是图像分类。不知道能否对图像识别进行量化训练",
        "state": "closed",
        "user": "fash120",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-05-10T11:32:58+00:00",
        "updated_at": "2024-02-06T02:58:55+00:00",
        "closed_at": "2024-02-06T02:58:55+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1095,
        "title": "已安装paddleslim ，运行 python tools/train.py -c configs/ssd/ssd_mobilenet_v1_300_120e_voc.yml --slim_config configs/ssd/ssd_mobilenet_v1_qat.yml  报错",
        "body": "C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddle\\tensor\\creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warni\r\nng, use `object` by itself. Doing this will not modify any behavior and is safe.\r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  if data.dtype == np.object:\r\nW0511 12:37:27.197337  5304 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.6, Runtime API Version: 10.2\r\nW0511 12:37:27.214337  5304 device_context.cc:422] device: 0, cuDNN Version: 7.6.\r\n[05/11 12:37:29] ppdet.utils.checkpoint INFO: Finish loading model weights: C:\\Users\\1/.cache/paddle/weights\\ssd_mobilenet_v1_300_120e_voc.pdparams\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddle\\utils\\lazy_import.py\", line 32, in try_import\r\n    mod = importlib.import_module(module_name)\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddleslim\\__init__.py\", line 22, in <module>\r\n    from paddleslim import dygraph\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddleslim\\dygraph\\__init__.py\", line 2, in <module>\r\n    from .quant import *\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddleslim\\dygraph\\quant\\__init__.py\", line 16, in <module>\r\n    from . import ptq\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddleslim\\dygraph\\quant\\ptq.py\", line 21, in <module>\r\n    from paddle.fluid.contrib.slim.quantization import AbsmaxQuantizer\r\nImportError: cannot import name 'AbsmaxQuantizer' from 'paddle.fluid.contrib.slim.quantization' (C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddle\\fluid\\contrib\\slim\\quantizat\r\nion\\__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 139, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 129, in main\r\n    cfg = build_slim_model(cfg, FLAGS.slim_config)\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddledet-2.1.0-py3.8.egg\\ppdet\\slim\\__init__.py\", line 57, in build_slim_model\r\n    cfg['model'] = slim(model)\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddledet-2.1.0-py3.8.egg\\ppdet\\slim\\quant.py\", line 35, in __call__\r\n    paddleslim = try_import('paddleslim')\r\n  File \"C:\\Users\\1\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddle\\utils\\lazy_import.py\", line 40, in try_import\r\n    raise ImportError(err_msg)\r\n\r\n**ImportError: Failed importing paddleslim. This likely means that some paddle modules require additional dependencies that have to be manually installed (usually with `pip install paddleslim`).\r\n",
        "state": "closed",
        "user": "LLiuzui",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-05-11T04:43:26+00:00",
        "updated_at": "2024-02-06T02:58:56+00:00",
        "closed_at": "2024-02-06T02:58:56+00:00",
        "comments_count": [
            "yghstill",
            "1190202328",
            "1190202328"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1100,
        "title": "剪枝后评估报错 InvalidArgumentError PaddleDetection2.1 PaddleSlim2.1.0",
        "body": "(paddle) jiash21@asic-u1:~/Desktop/PaddleDetection-release-2.1/static$ python slim/prune/eval.py -c configs/ssd/ssd_mobilenet_v1_voc.yml --pruned_params \"conv7_4_extra2_weights,conv7_1_extra2_weights,conv1_weights,conv5_5_sep_weights,conv2_1_sep_weights,conv7_2_extra1_weights,conv6_sep_weights,conv7_4_extra1_weights,conv7_3_extra1_weights,conv7_1_extra1_weights,conv7_2_extra2_weights,conv7_3_extra2_weights\" --pruned_ratios=\"0.3,0.9,0.2,0.7,0.1,0.4,0.6,0.6,0.2,0.2,0.9,0.2\" -o weights=output/ssd_mobilenet_v1_voc/model_final.pdparams\r\n/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddleslim/core/graph_wrapper.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  from collections import Iterable\r\nW0512 00:48:01.676729 48192 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.2\r\nW0512 00:48:01.680086 48192 device_context.cc:465] device: 0, cuDNN Version: 8.0.\r\n2022-05-12 00:48:17,315-INFO: pruned params: ['conv7_4_extra2_weights', 'conv7_1_extra2_weights', 'conv1_weights', 'conv5_5_sep_weights', 'conv2_1_sep_weights', 'conv7_2_extra1_weights', 'conv6_sep_weights', 'conv7_4_extra1_weights', 'conv7_3_extra1_weights', 'conv7_1_extra1_weights', 'conv7_2_extra2_weights', 'conv7_3_extra2_weights']\r\n2022-05-12 00:48:17,315-INFO: pruned ratios: [0.3, 0.9, 0.2, 0.7, 0.1, 0.4, 0.6, 0.6, 0.2, 0.2, 0.9, 0.2]\r\n2022-05-12 00:48:18,513-WARNING: Leaves ['batch_norm_21.tmp_0', 'batch_norm_6.tmp_0', 'batch_norm_24.tmp_2', 'batch_norm_5.tmp_2', 'batch_norm_7.tmp_1', 'batch_norm_11.tmp_0', 'batch_norm_20.tmp_0', 'batch_norm_29.tmp_2', 'batch_norm_12.tmp_2', 'batch_norm_3.tmp_2', 'transpose_6.tmp_1', 'batch_norm_10.tmp_1', 'batch_norm_32.tmp_0', 'batch_norm_28.tmp_1', 'batch_norm_15.tmp_2', 'batch_norm_17.tmp_1', 'transpose_4.tmp_1', 'batch_norm_19.tmp_1', 'flatten_16.tmp_1', 'transpose_1.tmp_1', 'transpose_5.tmp_1', 'batch_norm_16.tmp_1', 'flatten_15.tmp_1', 'flatten_4.tmp_1', 'reshape2_1.tmp_1', 'batch_norm_13.tmp_1', 'batch_norm_24.tmp_0', 'batch_norm_15.tmp_0', 'transpose_8.tmp_1', 'batch_norm_14.tmp_1', 'batch_norm_32.tmp_2', 'batch_norm_20.tmp_1', 'batch_norm_2.tmp_1', 'flatten_19.tmp_1', 'batch_norm_8.tmp_1', 'im_id', 'batch_norm_11.tmp_2', 'batch_norm_6.tmp_1', 'batch_norm_13.tmp_2', 'batch_norm_2.tmp_0', 'batch_norm_18.tmp_0', 'batch_norm_9.tmp_0', 'batch_norm_18.tmp_2', 'batch_norm_8.tmp_2', 'batch_norm_25.tmp_1', 'batch_norm_10.tmp_2', 'batch_norm_16.tmp_0', 'batch_norm_31.tmp_2', 'batch_norm_33.tmp_2', 'batch_norm_3.tmp_0', 'batch_norm_21.tmp_2', 'batch_norm_29.tmp_0', 'transpose_10.tmp_1', 'detection_output_0.tmp_0', 'flatten_7.tmp_1', 'batch_norm_19.tmp_0', 'batch_norm_22.tmp_2', 'flatten_17.tmp_1', 'batch_norm_7.tmp_2', 'batch_norm_33.tmp_0', 'batch_norm_23.tmp_1', 'batch_norm_22.tmp_0', 'flatten_5.tmp_1', 'flatten_21.tmp_1', 'batch_norm_25.tmp_2', 'batch_norm_10.tmp_0', 'batch_norm_27.tmp_1', 'flatten_10.tmp_1', 'batch_norm_19.tmp_2', 'batch_norm_4.tmp_0', 'batch_norm_25.tmp_0', 'flatten_2.tmp_1', 'batch_norm_24.tmp_1', 'batch_norm_31.tmp_1', 'batch_norm_6.tmp_2', 'flatten_12.tmp_1', 'im_shape', 'batch_norm_14.tmp_0', 'transpose_11.tmp_1', 'batch_norm_5.tmp_0', 'batch_norm_4.tmp_1', 'flatten_23.tmp_1', 'batch_norm_1.tmp_1', 'batch_norm_1.tmp_2', 'transpose_12.tmp_1', 'batch_norm_18.tmp_1', 'transpose_3.tmp_1', 'batch_norm_17.tmp_2', 'batch_norm_9.tmp_2', 'batch_norm_23.tmp_2', 'batch_norm_30.tmp_1', 'batch_norm_30.tmp_0', 'batch_norm_8.tmp_0', 'batch_norm_31.tmp_0', 'transpose_0.tmp_1', 'flatten_6.tmp_1', 'flatten_8.tmp_1', 'batch_norm_16.tmp_2', 'batch_norm_9.tmp_1', 'batch_norm_12.tmp_0', 'reshape2_0.tmp_1', 'batch_norm_4.tmp_2', 'flatten_9.tmp_1', 'batch_norm_27.tmp_2', 'transpose_7.tmp_1', 'batch_norm_21.tmp_1', 'flatten_13.tmp_1', 'batch_norm_34.tmp_1', 'flatten_11.tmp_1', 'batch_norm_13.tmp_0', 'transpose_9.tmp_1', 'batch_norm_7.tmp_0', 'flatten_18.tmp_1', 'batch_norm_33.tmp_1', 'flatten_3.tmp_1', 'batch_norm_26.tmp_1', 'flatten_0.tmp_1', 'batch_norm_30.tmp_2', 'batch_norm_26.tmp_0', 'batch_norm_34.tmp_0', 'batch_norm_26.tmp_2', 'batch_norm_28.tmp_2', 'batch_norm_0.tmp_1', 'batch_norm_27.tmp_0', 'batch_norm_29.tmp_1', 'batch_norm_23.tmp_0', 'batch_norm_32.tmp_1', 'batch_norm_3.tmp_1', 'batch_norm_28.tmp_0', 'batch_norm_22.tmp_1', 'batch_norm_20.tmp_2', 'batch_norm_0.tmp_0', 'batch_norm_34.tmp_2', 'transpose_2.tmp_1', 'batch_norm_11.tmp_1', 'batch_norm_17.tmp_0', 'batch_norm_12.tmp_1', 'flatten_14.tmp_1', 'batch_norm_1.tmp_0', 'flatten_22.tmp_1', 'gt_class', 'flatten_20.tmp_1', 'is_difficult', 'batch_norm_2.tmp_2', 'batch_norm_15.tmp_1', 'batch_norm_5.tmp_1', 'batch_norm_14.tmp_2', 'batch_norm_0.tmp_2', 'flatten_1.tmp_1', 'gt_bbox'] will be skipped when parsing graph. You can set skipped variables by option 'skip_vars'.\r\n2022-05-12 00:48:18,954-WARNING: ('Unsupported operator named prior_box',)\r\n2022-05-12 00:48:18,974-INFO: change groups of depthwise_conv2d(conv2_1_dw_weights) from 32 to 26;\r\n2022-05-12 00:48:18,981-INFO: change groups of depthwise_conv2d(conv2_2_dw_weights) from 64 to 58;\r\n2022-05-12 00:48:19,042-INFO: pruned FLOPS: 0.03032174633227653\r\n/home/jiash21/Desktop/PaddleDetection-release-2.1/static/ppdet/data/reader.py:90: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\r\n  if isinstance(item, collections.Sequence) and len(item) == 0:\r\nTraceback (most recent call last):\r\n  File \"slim/prune/eval.py\", line 244, in <module>\r\n    main()\r\n  File \"slim/prune/eval.py\", line 200, in main\r\n    resolution=resolution)\r\n  File \"/home/jiash21/Desktop/PaddleDetection-release-2.1/static/ppdet/utils/eval_utils.py\", line 148, in eval_run\r\n    return_numpy=False)\r\n  File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1262, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1260, in run\r\n    return_merged=return_merged)\r\n  File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1415, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1065, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\nValueError: In user code:\r\n\r\n    File \"slim/prune/eval.py\", line 244, in <module>\r\n      main()\r\n    File \"slim/prune/eval.py\", line 88, in main\r\n      fetches = model.eval(feed_vars)\r\n    File \"/home/jiash21/Desktop/PaddleDetection-release-2.1/static/ppdet/modeling/architectures/ssd.py\", line 135, in eval\r\n      return self.build(feed_vars, 'eval')\r\n    File \"/home/jiash21/Desktop/PaddleDetection-release-2.1/static/ppdet/modeling/architectures/ssd.py\", line 73, in build\r\n      body_feats = self.backbone(im)\r\n    File \"/home/jiash21/Desktop/PaddleDetection-release-2.1/static/ppdet/modeling/backbones/mobilenet.py\", line 168, in __call__\r\n      out, 32, 64, 32, 1, scale, name=self.prefix_name + \"conv2_1\")\r\n    File \"/home/jiash21/Desktop/PaddleDetection-release-2.1/static/ppdet/modeling/backbones/mobilenet.py\", line 121, in depthwise_separable\r\n      name=name + \"_dw\")\r\n    File \"/home/jiash21/Desktop/PaddleDetection-release-2.1/static/ppdet/modeling/backbones/mobilenet.py\", line 88, in _conv_norm\r\n      bias_attr=False)\r\n    File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 1651, in conv2d\r\n      \"data_format\": data_format,\r\n    File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3184, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/home/jiash21/.conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2224, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: The number of input's channels should be equal to filter's channels * groups for Op(Conv). But received: the input's channels is 32, the input's shape is [32, 32, 150, 150]; the filter's channels is 1, the filter's shape is [32, 1, 3, 3]; the groups is 26, the data_format is NCHW. The error may come from wrong data_format setting.\r\n      [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:32 != filter_dims[1] * groups:26.] (at /paddle/paddle/fluid/operators/conv_op.cc:119)\r\n      [operator < depthwise_conv2d > error]\r\n",
        "state": "closed",
        "user": "Jiashuhao518",
        "closed_by": "XGZhang11",
        "created_at": "2022-05-11T17:04:44+00:00",
        "updated_at": "2024-02-06T04:02:05+00:00",
        "closed_at": "2024-02-06T04:02:05+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Jiashuhao518"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1118,
        "title": "paddleslim目前最新的版本是2.2.2吗",
        "body": "在说明文档里面看到有自动压缩的示例，但是要求的paddleslim版本是2.3.0，产品动态里面写的5.23发布2.3.0，想确认一下是不是这样的",
        "state": "closed",
        "user": "susan-812",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-05-19T02:07:02+00:00",
        "updated_at": "2024-02-06T02:58:56+00:00",
        "closed_at": "2024-02-06T02:58:56+00:00",
        "comments_count": [
            "yghstill",
            "YiZhi-W813"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1119,
        "title": "没有相应模块",
        "body": "使用如下命令进行自动压缩时出现错误：\r\n\r\n```\r\n%cd /home/aistudio/work/PaddleSlim-develop/\r\n!python demo/auto_compression/detection/run.py --config_path=demo/auto_compression/detection//configs/ppyoloe_l_qat_dist.yaml --eval=True\r\n```\r\n\r\n报错为：\r\n\r\n```\r\n/home/aistudio/work/PaddleSlim-develop\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:130: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n  if data.dtype == np.object:\r\n[05-19 11:06:30 MainThread @logger.py:242] Argv: demo/auto_compression/detection/run.py --config_path=demo/auto_compression/detection//configs/ppyoloe_l_qat_dist.yaml --eval=True\r\n[05-19 11:06:30 MainThread @utils.py:79] WRN paddlepaddle version: 2.2.2. The dynamic graph version of PARL is under development, not fully tested and supported\r\nTraceback (most recent call last):\r\n  File \"demo/auto_compression/detection/run.py\", line 23, in <module>\r\n    from paddleslim.auto_compression.config_helpers import load_config as load_slim_config\r\nModuleNotFoundError: No module named 'paddleslim.auto_compression'\r\n\r\n```",
        "state": "closed",
        "user": "simon-sxx",
        "closed_by": "XGZhang11",
        "created_at": "2022-05-19T03:06:58+00:00",
        "updated_at": "2024-02-06T03:43:00+00:00",
        "closed_at": "2024-02-06T03:43:00+00:00",
        "comments_count": [
            "qingqing01",
            "tianv",
            "tongtongwyo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1126,
        "title": "自动压缩可用于压缩经过微调的ERNIE 1.0模型吗？",
        "body": "[https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/auto_compression/nlp#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B%E8%87%AA%E5%8A%A8%E5%8E%8B%E7%BC%A9%E7%A4%BA%E4%BE%8B](自然语言处理模型自动压缩示例)里面的例子是PP-MiniLM模型，可以套用在ERNIE 1.0模型上吗？",
        "state": "closed",
        "user": "wjddd",
        "closed_by": "wjddd",
        "created_at": "2022-05-20T02:43:52+00:00",
        "updated_at": "2022-06-16T02:22:37+00:00",
        "closed_at": "2022-06-16T02:22:37+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1130,
        "title": "自动压缩评估时报错, 最后map很低",
        "body": "使用下列命令评估时报错，评估出来map很低：\r\n\r\n```\r\n%cd /home/aistudio/work/PaddleSlim-develop/demo/auto_compression/detection/\r\n!python run.py --config_path=./configs/ppyoloe_l_qat_dis.yaml --eval=True\r\n\r\n```\r\n\r\n报错为：Exception in thread Thread-1:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 505, in _thread_loop\r\n    batch = self._get_data()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 634, in _get_data\r\n    batch.reraise()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/worker.py\", line 169, in reraise\r\n    raise self.exc_type(msg)\r\nValueError: DataLoader worker(2) caught ValueError with message:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/worker.py\", line 329, in _worker_loop\r\n    batch = fetcher.fetch(indices)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py\", line 134, in fetch\r\n    data = self.collate_fn(data)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddledet-2.3.0-py3.7.egg/ppdet/data/reader.py\", line 91, in __call__\r\n    batch_data = default_collate_fn(data)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/collate.py\", line 70, in default_collate_fn\r\n    for key in sample\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/collate.py\", line 70, in <dictcomp>\r\n    for key in sample\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/collate.py\", line 58, in default_collate_fn\r\n    batch = np.stack(batch, axis=0)\r\n  File \"<__array_function__ internals>\", line 6, in stack\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 427, in stack\r\n    raise ValueError('all input arrays must have the same shape')\r\nValueError: all input arrays must have the same shape\r\n\r\n```",
        "state": "closed",
        "user": "simon-sxx",
        "closed_by": "XGZhang11",
        "created_at": "2022-05-20T07:25:57+00:00",
        "updated_at": "2024-02-06T04:02:17+00:00",
        "closed_at": "2024-02-06T04:02:17+00:00",
        "comments_count": [
            "yghstill",
            "simon-sxx",
            "aiyodiulehuner",
            "LiquorPerfect",
            "Justin62628"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1131,
        "title": "模型蒸馏报错",
        "body": "报错信息：\r\n[05-21 17:39:33 MainThread @logger.py:242] Argv: PaddleSeg-develop/slim/distill/distill_train.py --teather_config PaddleSeg-develop/configs/quick_start/deeplabv3p_resnet50_os8_optic_disc_512x512_1k_teacher.yml --student_config PaddleSeg-develop/configs/quick_start/deeplabv3p_resnet18_os8_optic_disc_512x512_1k_student.yml --do_eval --use_vdl --save_interval 250 --num_workers 3 --seed 0 --save_dir output/deeplabv3p_resnet18_distill\r\n[05-21 17:39:33 MainThread @utils.py:79] WRN paddlepaddle version: 2.3.0. The dynamic graph version of PARL is under development, not fully tested and supported\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\r\n  context = pyarrow.default_serialization_context()\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import MutableMapping\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Iterable, Mapping\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Sized\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers_old.py:151: DeprecationWarning: invalid escape sequence \\_\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers_old.py:460: DeprecationWarning: invalid escape sequence \\s\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers_old.py:151: DeprecationWarning: invalid escape sequence \\_\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers_old.py:460: DeprecationWarning: invalid escape sequence \\s\r\nTraceback (most recent call last):\r\n  File \"PaddleSeg-develop/slim/distill/distill_train.py\", line 30, in <module>\r\n    from distill_config import prepare_distill_adaptor, prepare_distill_config\r\n  File \"/home/aistudio/PaddleSeg-develop/slim/distill/distill_config.py\", line 15, in <module>\r\n    from paddleslim.dygraph.dist import AdaptorBase\r\nImportError: cannot import name 'AdaptorBase' from 'paddleslim.dygraph.dist' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/dygraph/dist/__init__.py)\r\n用的paddle是2.3gpu版本，slim是2.3版本",
        "state": "closed",
        "user": "guoxuntao",
        "closed_by": "guoxuntao",
        "created_at": "2022-05-21T09:51:40+00:00",
        "updated_at": "2022-05-26T09:45:52+00:00",
        "closed_at": "2022-05-26T09:45:52+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1132,
        "title": "自动压缩后，用paddlelite 导出报错",
        "body": "测试自动压缩[demo](https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/auto_compression)后，用paddlelite导出后报错\r\n\r\n[F  5/21 18: 1: 6.617 ...optimizer/mir/static_kernel_pick_pass.cc:71 Apply] Check failed: !instruct.kernels().empty(): No kernels found for fake_quantize_abs_max",
        "state": "closed",
        "user": "renmada",
        "closed_by": "XGZhang11",
        "created_at": "2022-05-21T10:07:56+00:00",
        "updated_at": "2024-02-06T03:41:14+00:00",
        "closed_at": "2024-02-06T03:41:14+00:00",
        "comments_count": [
            "yghstill",
            "renmada"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1133,
        "title": "cannot import name 'AbsmaxQuantizer' from 'paddle.fluid.contrib.slim.quantization' ",
        "body": "![image](https://user-images.githubusercontent.com/59467994/169727333-27411560-e3e3-4307-b78d-8de5e11dd9dd.png)\r\n\r\n只是使用了这个命令， paddlepaddle =2.0 paddleslim=2.2.2 \r\n![image](https://user-images.githubusercontent.com/59467994/169727412-6f621205-c6ee-47fc-bbae-bbc7a7c42b17.png)\r\n请问怎么解决",
        "state": "closed",
        "user": "ljl86092297",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-05-23T01:38:40+00:00",
        "updated_at": "2024-02-06T02:58:57+00:00",
        "closed_at": "2024-02-06T02:58:57+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1135,
        "title": "tinypose and lite hrne QAT 训练失败！",
        "body": "Hi，\r\n1 参考https://github.com/PaddlePaddle/Paddle/issues/42341 这个picodet的在线训练量化，完全搭建不出来一套tinypose或者litehrnet的qat在线训练版本啊，什么时候可以发布一套类似picodet的 tinypose的正式在线量化版本，多谢！\r\n可以看到下面例子完全不能作为tinypos或者litehrnet的参考，必须paddle自己来做，这样失去了相当大的paddleslim这个框架研发的初衷\r\n![image](https://user-images.githubusercontent.com/8407513/169745437-ba1f2c11-b3c2-49c4-937c-0f3af74649fc.png)\r\n\r\n\r\n2 举个例子，pretrain_weights: https://paddledet.bj.bcebos.com/models/picodet_s_416_coco_lcnet.pdparams \r\n这个对于litehrnet 我的pretrain_weights 从哪里拿呢？不用也行？\r\n\r\n![image](https://user-images.githubusercontent.com/8407513/169747365-57c0aa29-6cba-477b-8a49-3c346d3647a2.png)\r\n\r\n\r\n3  #####data\r\nTrainDataset:\r\n  !KeypointTopDownCocoDataset\r\n    image_dir: \"\"\r\n    anno_path: aic_coco_train_cocoformat.json\r\n    dataset_dir: dataset\r\n\r\n这里的 dataset 数据集是哪个，具体子目录应该是啥样？aic_coco_train_cocoformat.json这个从哪里下载啊？\r\nBR ",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "yghstill",
        "created_at": "2022-05-23T04:51:18+00:00",
        "updated_at": "2022-05-24T06:33:17+00:00",
        "closed_at": "2022-05-24T06:33:17+00:00",
        "comments_count": [
            "2050airobert",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1140,
        "title": "AssertionError: feed_list should be set when return_list=False",
        "body": "# 场景描述\r\n我正在量化paddle里面的关键点检测模型，我参考的[量化文档](https://paddleslim.readthedocs.io/zh_CN/latest/api_cn/static/quant/quantization_api.html#quant-post-dynamic)，但是我还是不是很懂sample_generator这个参数要怎么传？然后我看代码里面的加载数据集的方式是先调用`self.dataset = cfg['{}Dataset'.format(self.mode.capitalize())]`来构造一个对象，然后使用`self.loader = create('{}Reader'.format(self.mode.capitalize()))(\r\n                self.dataset, cfg.worker_num)`来构造一个loader，\r\n最后推理的方式为\r\n```         \r\nfor step_id, data in enumerate(self.loader):\r\n        self.status['data_time'].update(time.time() - iter_tic)\r\n        self.status['step_id'] = step_id\r\n        profiler.add_profiler_step(profiler_options)\r\n        self._compose_callback.on_step_begin(self.status)\r\n        data['epoch_id'] = epoch_id\r\n        \r\n        if self.cfg.get('amp', False):\r\n            with amp.auto_cast(enable=self.cfg.use_gpu):\r\n                # model forward\r\n                outputs = model(data)\r\n                loss = outputs['loss']\r\n```\r\n我以为是把这个loader传到sample_generator参数就好了，于是我的量化代码就写成了下面的样子：\r\n```\r\nif __name__ == \"__main__\":\r\n    image_path = r\"./images/100\"\r\n    save_path = r\"./images/all_anns_100.json\"\r\n    if os.path.exists(save_path):\r\n        convert(image_path, save_path, image_path)\r\n    # gt_db = load_coco_keypoint_annotations(save_path, image_path)\r\n    cfg = load_config('/data/liyy/QuantPoseDemo/other/PaddleDetection/configs/keypoint/tiny_pose/tinypose_128x96.yml')\r\n    # 开启静态图模式\r\n    paddle.enable_static()\r\n    image = paddle.static.data(\r\n        name='image', shape=[None, 1, 128, 96], dtype='float32')\r\n    label = paddle.static.data(name='label', shape=[None, 1], dtype='int64')\r\n    dataset = cfg['{}Dataset'.format(\"eval\".capitalize())]\r\n    eval_reader = create('{}Reader'.format(\"eval\".capitalize()))\r\n    loader = eval_reader(dataset, cfg.worker_num)\r\n    slim.quant.quant_post_static(\r\n        executor=paddle.static.Executor(),\r\n        feed_list=[image, label],\r\n        model_dir='./inference_model',\r\n        quantize_model_path='./quant_post_static_model',\r\n        sample_generator=loader,\r\n        model_filename='fp32.pdmodel',\r\n        params_filename='fp32.pdiparams',\r\n        batch_nums=10)\r\n```\r\n于是就有下面的报错：\r\n![image](https://user-images.githubusercontent.com/53716679/169930263-6a984b25-6a19-4fea-a48a-e8651b0b034f.png)\r\n\r\n# 问题\r\n1. 请问我这里的sample_generator是直接传loader就行了吗？还是要把loader里面的data取出来，然后组成一个列表再传给sample_generator呢？\r\n2. 请问静态图中这个feed_list我这里应该怎么传呢？\r\n感谢帮忙解答一下哈！谢谢了！",
        "state": "closed",
        "user": "liyuyuan6969",
        "closed_by": "XGZhang11",
        "created_at": "2022-05-24T01:38:40+00:00",
        "updated_at": "2024-02-06T04:12:54+00:00",
        "closed_at": "2024-02-06T04:12:54+00:00",
        "comments_count": [
            "ceci3",
            "liyuyuan6969",
            "liyuyuan6969",
            "liyuyuan6969",
            "ceci3",
            "liyuyuan6969",
            "liyuyuan6969",
            "APeiZou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1137,
        "title": "请问模型库里有剪裁后的SSD-MobilenetV1的模型吗？",
        "body": null,
        "state": "closed",
        "user": "BergerQAQ",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-05-23T08:36:36+00:00",
        "updated_at": "2024-02-06T02:58:58+00:00",
        "closed_at": "2024-02-06T02:58:58+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1141,
        "title": "fairmot里的模型可以用paddleslim进行自动压缩吗",
        "body": "paddleslim自动压缩给出的demo是关于目标检测的，想请问一下fairmot里的模型可不可以用paddleslim进行自动压缩，如果可以的话有没有demo可以参考的",
        "state": "closed",
        "user": "susan-812",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-05-25T02:26:18+00:00",
        "updated_at": "2024-02-06T02:58:59+00:00",
        "closed_at": "2024-02-06T02:58:59+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1144,
        "title": "可不可以出一个fairmot里的模型的自动化压缩demo",
        "body": "跟着目标检测的demo试了一下fairmot里的fairmot_hrnetv2_w18_dlafpn_30e_576x320模型的自动化压缩，没弄出来，官方大大能不能出一个呀",
        "state": "closed",
        "user": "susan-812",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-05-27T01:32:22+00:00",
        "updated_at": "2024-02-06T02:59:00+00:00",
        "closed_at": "2024-02-06T02:59:00+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1148,
        "title": "可不可以出一个动态图的bert量化例子",
        "body": null,
        "state": "closed",
        "user": "kismit",
        "closed_by": "XGZhang11",
        "created_at": "2022-05-30T11:51:59+00:00",
        "updated_at": "2024-02-06T03:39:47+00:00",
        "closed_at": "2024-02-06T03:39:47+00:00",
        "comments_count": [
            "yghstill",
            "kismit"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1154,
        "title": "paddle slim可以对leakyRelu做量化处理吗？",
        "body": "请问下paddle slim可以对leakyRelu做量化处理吗？我看有些框架没法对leakyRelu量化，导致即使量化了，还是相当于跑float一样，不知道paddle在这方面做得怎么样？如果好的话，可以考虑入坑",
        "state": "closed",
        "user": "StrugglingForBetter",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-07T07:59:22+00:00",
        "updated_at": "2024-02-06T02:59:02+00:00",
        "closed_at": "2024-02-06T02:59:02+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1156,
        "title": "PaddleSlim 可以对BasicVSR++ 压缩吗？",
        "body": "请问一下PaddleSlim 可以对BasicVSR++ 压缩吗？有相关经验可以分享吗？",
        "state": "closed",
        "user": "eepeter",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-07T11:07:31+00:00",
        "updated_at": "2024-02-06T02:59:02+00:00",
        "closed_at": "2024-02-06T02:59:02+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1164,
        "title": "tinypose slim 量化训练版本缺失！",
        "body": null,
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "XGZhang11",
        "created_at": "2022-06-10T10:40:12+00:00",
        "updated_at": "2024-02-06T03:39:19+00:00",
        "closed_at": "2024-02-06T03:39:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1152,
        "title": "模型量化以后 精度直接没了",
        "body": "谷歌关键点模型经过离线量化后\r\n![image](https://user-images.githubusercontent.com/59467994/172144562-400c2852-3c6e-414a-9f77-ac0ed7c77665.png)\r\n经过上图函数量化以后精度直接消失了\r\n![image](https://user-images.githubusercontent.com/59467994/172144710-99fd231d-78a8-4f59-b80a-2951615aa07c.png)\r\n上图是未量化前的模型效果\r\n![image](https://user-images.githubusercontent.com/59467994/172144789-05c252d1-8558-44b3-939d-053efdcfe2bd.png)\r\n这是量化后的效果，-1代表骨骼点未检测到",
        "state": "closed",
        "user": "ljl86092297",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-06T10:34:48+00:00",
        "updated_at": "2024-02-06T02:59:01+00:00",
        "closed_at": "2024-02-06T02:59:01+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1168,
        "title": "tinypose量化训练版本效果很差！",
        "body": "\r\n请问下tinypose的量化训练版本 有发布吗？ \r\n\r\n",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-13T08:56:00+00:00",
        "updated_at": "2024-02-06T02:59:03+00:00",
        "closed_at": "2024-02-06T02:59:03+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1171,
        "title": "paddleslim运行报错没有AdaptorBase",
        "body": "求助，运行paddleslim提供的蒸馏训练时出现\r\n\r\n错误，paddlepaddle-gpu版本2.2.1，paddleslim版本2.2.0\r\n![image](https://user-images.githubusercontent.com/101849755/173539158-dcbf9357-a3f2-4574-8dbc-50b550f24bd1.png)\r\n",
        "state": "closed",
        "user": "fanxiaochen456",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-14T09:06:26+00:00",
        "updated_at": "2024-02-06T02:59:04+00:00",
        "closed_at": "2024-02-06T02:59:04+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1172,
        "title": "How quant is called!",
        "body": null,
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "XGZhang11",
        "created_at": "2022-06-14T10:55:45+00:00",
        "updated_at": "2024-02-06T03:39:05+00:00",
        "closed_at": "2024-02-06T03:39:05+00:00",
        "comments_count": [
            "wanghaoshuang",
            "2050airobert"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1177,
        "title": "PicoDet 量化训练模型发布问题！",
        "body": "hi，\r\n    1 请问下，picoDet 目前的量化训练精度调优ok了吗？ 下周是否有发布计划，多谢~\r\n    2 关于量化压缩，以下两个链接 有啥区别，还是完全可以合并为一个？\r\nhttps://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4/configs/slim\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/auto_compression/detection\r\n\r\nBR",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-17T03:39:07+00:00",
        "updated_at": "2024-02-06T02:59:05+00:00",
        "closed_at": "2024-02-06T02:59:05+00:00",
        "comments_count": [
            "2050airobert",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1195,
        "title": "PaddleSlim量化训练",
        "body": "您好，我使用PaddleSlim对PaddleSeg的模型进行量化训练\r\n![image](https://user-images.githubusercontent.com/101849755/175762682-fad57ff1-48e5-4555-80ab-a5a1f040c699.png)\r\n这是我的量化模型，我使用测试脚本测试效果很好，请问一下，我怎样可以输出量化之后模型的参数量Params和量化模型进行一次模型推理所需要的计算量Flops呢?",
        "state": "closed",
        "user": "fanxiaochen456",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-25T04:45:15+00:00",
        "updated_at": "2024-02-06T02:59:06+00:00",
        "closed_at": "2024-02-06T02:59:06+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1197,
        "title": "Missing Paddle slim tinypose 量化训练 quant8！",
        "body": "Hi，\r\n请问下，\r\npaddle slim tinypose 量化训练版本何时能够release啊？\r\n或者已经在主干了吗？多谢\r\nBR \r\n",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "XGZhang11",
        "created_at": "2022-06-27T02:06:31+00:00",
        "updated_at": "2024-02-06T03:38:49+00:00",
        "closed_at": "2024-02-06T03:38:49+00:00",
        "comments_count": [
            "wanghaoshuang",
            "2050airobert",
            "2050airobert"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1209,
        "title": "paddleslim=2.2.2无法兼容paddlepaddle=2.3",
        "body": "\r\n以下为 @levinzhangyd 提出的问题，辛苦 @yghstill 帮忙看下？\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSlim/pull/338#issuecomment-1169773627\r\n---------------------------------------------------\r\n最新的2.2版本的paddleslim，写代码都能自动关联到函数，结果运行找不到，这是有什么机关吗？\r\nTraceback (most recent call last): \r\n  File \"E:\\pythonProject\\testLaneDetect\\pytotch_2_pp_module.py\", line 94, in <module> \r\n    quant.quant_post_dynamic(\r\nAttributeError: module 'paddleslim.quant' has no attribute 'quant_post_dynamic'\r\n\r\n\r\n调用代码\r\nfrom paddleslim import quant\r\nfrom paddleslim.quant import quant_post_dynamic\r\n\r\n# 动态量化\r\nquant_post_dynamic(\r\n\r\n尝试1：重装。Not work\r\n尝试2：重装，并且换到2.0版本.Not work\r\n尝试3：部分帖子说quant_post_dynamic换成quant_post_only_weight，还是不行\r\n\r\n环境描述：\r\npaddle=2.3\r\npython=3.9\r\npaddlelite=2.10rc\r\npaddleslim=2.2.2",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2022-06-29T14:47:52+00:00",
        "updated_at": "2022-06-29T15:15:18+00:00",
        "closed_at": "2022-06-29T15:15:18+00:00",
        "comments_count": [
            "levinzhangyd",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1215,
        "title": "ernie+crf模型自动压缩问题",
        "body": "环境:AIStudio GPU\r\n模型结构：使用PaddleNLP/examples/information_extraction/waybill_ie模型，模型结构是ernie+crf。\r\n当前使用AutoCompression。\r\n问题：目前模型为静态图，最后一层为crf层，模型预测时走维特比算法，无法输入标签，无法计算loss，请问这个需要怎么处理呢？",
        "state": "closed",
        "user": "Macxy2018",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-30T09:31:45+00:00",
        "updated_at": "2024-02-06T02:59:07+00:00",
        "closed_at": "2024-02-06T02:59:07+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1213,
        "title": "目标检测模型的敏感度分析报错",
        "body": "报错信息：\r\nValueError: (InvalidArgument) Currently, Tensor.__indices__() only allows indexing by Integers, Slices, Ellipsis, None, tuples of these types and list of Bool and Integers, but received str in 1th slice item (at ..\\paddle\\fluid\\pybind\\imperative.cc:645)\r\n代码：\r\n    pruner = L2NormFilterPruner(trainer.model,[1,3,300,300])\r\n    pruner.sensitive(eval_func=eval_fn,sen_file=\"./sen.pickle\")\r\n改代码的模型到底应该传入怎样的参数才能使用，针对目标检测模型。\r\n目前的参考示例全是针对分类的模型，能否提供一下思路",
        "state": "closed",
        "user": "ZRS0326",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-06-30T08:18:41+00:00",
        "updated_at": "2025-02-11T06:41:25+00:00",
        "closed_at": "2025-02-11T06:41:25+00:00",
        "comments_count": [
            "ZRS0326",
            "liopos",
            "Rishi-NF",
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1258,
        "title": "swig failed when installing paddleslim on macOS or Windows with python>=3.9",
        "body": "## Solution\r\n\r\n### macOS\r\nPlease install swig with cmd as below:\r\n\r\n```\r\n#  set environment variables to skip updating of brew\r\nexport HOMEBREW_NO_AUTO_UPDATE=1\r\nexport HOMEBREW_UPDATE_PREINSTALL=0\r\nbrew install swig\r\n```\r\n\r\n### Windows\r\n\r\nPlease install swig from https://www.swig.org/download.html\r\n\r\n## Error log\r\n```\r\nBuilding wheels for collected packages: smac, pynisher, pyrfr\r\n  Building wheel for smac (PEP 517) ... done\r\n  Created wheel for smac: filename=smac-1.3.4-py3-none-any.whl size=218017 sha256=45271afe47f3457a6e77c2c53dd17b6605ff1ef69c68c0e5aacb75928c7aa779\r\n  Stored in directory: /Users/wanghaoshuang/Library/Caches/pip/wheels/d0/cb/62/62c54ef694e4cf3846fdbbf788de91c86458ac4044973e7473\r\n  Building wheel for pynisher (setup.py) ... done\r\n  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7043 sha256=349ecedf8ae6110e6342752b4712f007d3ad8dcd2fde1b68aacff7f3301fe2cd\r\n  Stored in directory: /Users/wanghaoshuang/Library/Caches/pip/wheels/1d/de/5e/d4947b76b76ba27581d1e09f395eca1583a802203a41c04873\r\n  Building wheel for pyrfr (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /Users/wanghaoshuang/miniconda3/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/qz/12m2q98n7kjdfn9mrtk2j1600000gn/T/pip-install-8qe9956_/pyrfr_29aadea9444645b08bc76c6003297fbc/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/qz/12m2q98n7kjdfn9mrtk2j1600000gn/T/pip-install-8qe9956_/pyrfr_29aadea9444645b08bc76c6003297fbc/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/qz/12m2q98n7kjdfn9mrtk2j1600000gn/T/pip-wheel-royxjobt\r\n       cwd: /private/var/folders/qz/12m2q98n7kjdfn9mrtk2j1600000gn/T/pip-install-8qe9956_/pyrfr_29aadea9444645b08bc76c6003297fbc/\r\n  Complete output (8 lines):\r\n  [<setuptools.extension.Extension('pyrfr._regression') at 0x7f9409620070>, <setuptools.extension.Extension('pyrfr._util') at 0x7f94096200d0>]\r\n  running bdist_wheel\r\n  running build\r\n  running build_ext\r\n  building 'pyrfr._regression' extension\r\n  swigging pyrfr/regression.i to pyrfr/regression_wrap.cpp\r\n  swig -python -c++ -modern -py3 -features nondynamic -I./include -o pyrfr/regression_wrap.cpp pyrfr/regression.i\r\n  error: command 'swig' failed: No such file or directory\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for pyrfr\r\n```",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2022-07-06T04:07:16+00:00",
        "updated_at": "2022-07-06T11:47:28+00:00",
        "closed_at": "2022-07-06T04:10:29+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1255,
        "title": "I need paddleslim-opt-tools for arm64",
        "body": "I work on arm64  centos， use paddle suit develop. I install or build PaddleSlim  but cannt find a paddleslim-opt-tools for arm64?\r\nWhere or how to do it?",
        "state": "closed",
        "user": "wayneck",
        "closed_by": "wayneck",
        "created_at": "2022-07-05T10:11:57+00:00",
        "updated_at": "2022-07-07T08:21:31+00:00",
        "closed_at": "2022-07-07T08:21:31+00:00",
        "comments_count": [
            "ceci3",
            "wayneck"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1270,
        "title": "Auto tuning the dynamic input shapes for PaddleTensorRT engine",
        "body": "https://github.com/PaddlePaddle/Paddle-Inference-Demo/blob/master/python/gpu/tuned_dynamic_shape/infer_tune.py",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2022-07-07T07:56:43+00:00",
        "updated_at": "2022-07-07T07:57:00+00:00",
        "closed_at": "2022-07-07T07:57:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1263,
        "title": "FirstRunCrashedException,这个什么啥原因，已经如何破解啊",
        "body": "FirstRunCrashedException: First run crashed, abort. Please check your setup -- we assume that your default configuration does not crashes. (To deactivate this exception, use the SMAC scenario option 'abort_on_first_run_crash'). Additional run info: {}",
        "state": "closed",
        "user": "tianv",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-07-06T10:22:58+00:00",
        "updated_at": "2024-02-06T02:59:08+00:00",
        "closed_at": "2024-02-06T02:59:07+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1269,
        "title": "Exception: 'feed_targets' does not have x variable",
        "body": "在运行demo_yolofastest.py时， 将eval参数中的False改为True, 报上述错误。",
        "state": "closed",
        "user": "Dora1483",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-07-07T07:06:14+00:00",
        "updated_at": "2024-02-06T02:59:08+00:00",
        "closed_at": "2024-02-06T02:59:08+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Dora1483",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1288,
        "title": "TinyPose qat全量化版本bug！",
        "body": "Hi，\r\n1 请问下 TinyPose模型的自动化压缩代码无bug版本的整理好了吗？ \r\n2 是否有文档，确保过程无误？\r\n3 coco数据集qat全量化后掉点多少，业务最终掉点多少呢？\r\n多谢",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "XGZhang11",
        "created_at": "2022-07-11T10:33:24+00:00",
        "updated_at": "2024-02-06T04:14:37+00:00",
        "closed_at": "2024-02-06T04:14:37+00:00",
        "comments_count": [
            "2050airobert",
            "yghstill",
            "2050airobert",
            "2050airobert",
            "2050airobert",
            "yghstill",
            "2050airobert",
            "2050airobert",
            "2050airobert",
            "yghstill",
            "2050airobert",
            "2050airobert",
            "leiqing1",
            "2050airobert",
            "leiqing1",
            "2050airobert",
            "2050airobert",
            "2050airobert",
            "Syunraii",
            "APeiZou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1279,
        "title": "paddleslim动态量化结果不如预期",
        "body": "hi,\r\n  初学深度学习，从github上拿了一个pytorch模型文件（大概170M），转换成paddle模型后，大小差不多。\r\n使用动态图量化后，权重文件减小并不明显,减小到137M。模型使用resnet-18,和文档介绍的1/4相差较多。\r\n\r\n目前来看，没有达到预期的优化结果，我是想把模型往移动端进行移植，但是目前的大小无法进行移动端的开发\r\n1.想咨询下是我优化方法不对，还是本身的动态图离线量化就只能做到这种程度？\r\n2.看到释放了最新的paddleslim,但是还是无法安装成功（2.2安装ok）\r\n",
        "state": "closed",
        "user": "levinzhangyd",
        "closed_by": "XGZhang11",
        "created_at": "2022-07-08T06:46:34+00:00",
        "updated_at": "2024-02-06T03:37:57+00:00",
        "closed_at": "2024-02-06T03:37:57+00:00",
        "comments_count": [
            "yghstill",
            "levinzhangyd",
            "yghstill",
            "levinzhangyd",
            "yghstill",
            "levinzhangyd",
            "ceci3",
            "levinzhangyd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1282,
        "title": "Do not reply, just some pics",
        "body": "![image](https://user-images.githubusercontent.com/23690325/178102488-9f09e991-bfd6-4827-8641-849d9c3fa83c.png)\r\n",
        "state": "closed",
        "user": "D-DanielYang",
        "closed_by": "D-DanielYang",
        "created_at": "2022-07-09T10:48:28+00:00",
        "updated_at": "2022-07-11T03:04:28+00:00",
        "closed_at": "2022-07-11T02:11:30+00:00",
        "comments_count": [
            "D-DanielYang",
            "leiqing1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1289,
        "title": "paddleslim量化int8模型，paddle-inference部署推理报错",
        "body": "按照离线动态量化教程https://paddle-inference.readthedocs.io/en/latest/guides/x86_cpu_infer/paddle_x86_cpu_int8.html#id1 ，用quant_post_static保存量化模型，再用脚本转成int8模型。教程里的paddle.models.mobilenetv1没有问题，量化、部署都ok，但是换UNet就会在inference推理时报错（转int8始终没有问题），看起来是和concat有关。\r\n\r\n```\r\nInvalidArgumentError: Tensor holds the wrong type, it holds int8_t, but desires to be uint8_t.\r\n  [Hint: Expected valid == true, but received valid:0 != true:1.] (at /home/wangye19/Paddle/paddle/fluid/framework/tensor_impl.h:33)\r\n  [operator < concat > error]\r\n```\r\n\r\n通过反复实验最后抽取出下面这个有问题的小模型，不理解的是只要去掉relu或interpolate就没问题，不知道原因\r\n```\r\nclass FooNet(nn.Layer):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.conv = nn.Conv2D(3, 1, 1)\r\n        self.bn = nn.BatchNorm2D(1)\r\n        self.relu = nn.ReLU()\r\n        self.conv2 = nn.Conv2D(2, 1, 1)\r\n\r\n    def forward(self, x):\r\n        x = self.conv(x)\r\n        x = self.bn(x)\r\n        x = self.relu(x)\r\n        x2 = F.interpolate(\r\n            x,\r\n            scale_factor=1,\r\n            mode='bilinear',\r\n            align_corners=True)\r\n        y = paddle.concat([x, x2], axis=1)\r\n        out = self.conv2(y)\r\n        return out\r\n```\r\n\r\n我用的版本是paddle2.2.1+paddleslim2.2.2+paddle-inference2.1.1，在cpu上推理",
        "state": "closed",
        "user": "Memoriaaa",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-07-11T11:24:16+00:00",
        "updated_at": "2024-02-06T02:59:09+00:00",
        "closed_at": "2024-02-06T02:59:09+00:00",
        "comments_count": [
            "Memoriaaa",
            "yeliang2258",
            "yeliang2258",
            "Memoriaaa",
            "yeliang2258"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1292,
        "title": " 经过静态量化后性能却由150ms变为250m",
        "body": "使用Android nnapi方式，硬件为mtk设备。经过将自己的yolov3模型，经过x2paddle转换后，在经过静态离线量化，最后经过动态量化后，性能对比不经过静态量化有150ms变为了250ms。具体见文件：\r\n[apu_question.zip](https://github.com/PaddlePaddle/PaddleSlim/files/9098525/apu_question.zip)\r\n![2022-07-13 10-45-21 的屏幕截图](https://user-images.githubusercontent.com/82625719/178639877-9a563e7e-45c7-495e-acd2-4b2d0626c91c.png)\r\n\r\n",
        "state": "closed",
        "user": "yangguangda-hub",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-07-13T02:46:28+00:00",
        "updated_at": "2024-02-06T02:59:10+00:00",
        "closed_at": "2024-02-06T02:59:10+00:00",
        "comments_count": [
            "wanghaoshuang",
            "yingshengBD",
            "yangguangda-hub",
            "SunYF-0729"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1297,
        "title": "example/auto_compression/semantic_segmentation运行错误",
        "body": "Traceback (most recent call last):\r\n  File \"run.py\", line 167, in <module>\r\n    main(args)\r\n  File \"run.py\", line 149, in main\r\n    ac = AutoCompression(\r\n  File \"/home/hongyang/codebase/paddle_code/PaddleSlim/paddleslim/auto_compression/compressor.py\", line 153, in __init__\r\n    self.train_dataloader = wrap_dataloader(train_dataloader,\r\n  File \"/home/hongyang/codebase/paddle_code/PaddleSlim/paddleslim/auto_compression/utils/dataloader.py\", line 37, in wrap_dataloader\r\n    data = next(dataloader())\r\n  File \"run.py\", line 114, in gen\r\n    imgs = np.array(data[0])\r\nKeyError: 0",
        "state": "closed",
        "user": "hyaihjq",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-07-14T08:41:19+00:00",
        "updated_at": "2024-02-06T02:59:11+00:00",
        "closed_at": "2024-02-06T02:59:11+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1304,
        "title": "qat failed！",
        "body": "TinyPose qat全量化版本bug！ #1288\r\n问题和log描述非常详细，请帮忙检查下为啥 无法export出paddledet提供的模型呢？(具体在1288这个issue最开始的帖子里)\r\n建议您仔细看下\r\n[tinypose_128x96-lcl.zip](https://github.com/PaddlePaddle/PaddleSlim/files/9108898/tinypose_128x96-lcl.zip)\r\n[tinypose_128x96-yml-lcl.zip](https://github.com/PaddlePaddle/PaddleSlim/files/9108922/tinypose_128x96-yml-lcl.zip)\r\n这是两个包，你要的都在，对吗？\r\nBR",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-07-18T13:11:17+00:00",
        "updated_at": "2024-02-06T02:59:12+00:00",
        "closed_at": "2024-02-06T02:59:12+00:00",
        "comments_count": [
            "2050airobert",
            "leiqing1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1305,
        "title": "paddleslim对ssd_mobilenet_v1进行剪裁出现的推理速度等相关问题",
        "body": "版本：\r\n![image](https://user-images.githubusercontent.com/109390344/179612740-420eba0b-4375-4faf-b733-887f6d0455ea.png)\r\n问题：\r\n剪裁0.3%后，flops减少，在验证集上预测速度变快，但量化后部署到arm和intel fpga上推理速度反而变慢\r\n剪裁前：\r\n![R_WVA%XZC3NDRTVXQ4P9H D](https://user-images.githubusercontent.com/109390344/179614192-e3bd9e85-4bb6-40a7-b8b6-b07773c5b9ba.png)\r\n![7YY8_C (KVDCBFS DWECHWG](https://user-images.githubusercontent.com/109390344/179614209-4426b589-f1e2-4c0c-bf40-95f792814977.png)\r\n剪裁后：\r\n![{A_HX5YEMZ{CW6X}_F7QTYJ](https://user-images.githubusercontent.com/109390344/179614241-f99a2bf9-6ad4-470f-9a7f-1c919908e6b6.png)\r\n![5_6DQ}QV06@A@X)V1`({BGQ](https://user-images.githubusercontent.com/109390344/179614261-644a7b0b-1207-41df-8d13-e71c6eec8017.png)\r\n以下是我的训练过程：\r\n![image](https://user-images.githubusercontent.com/109390344/179612808-25b4e690-a3d0-4b1d-9ca0-becac42be2bf.png)\r\n我参照量化的congfig的设置方式加了个prune的congfig，在train中加入slim_config_prune,config如下：\r\n![image](https://user-images.githubusercontent.com/109390344/179613085-b03bda03-e408-469f-a21e-b8a86ea8f865.png)\r\n这里训练的时候我其实设的全为0.3。这里的参数名称我不清楚该裁剪哪个，不让剪裁的系统会自己跳过，所以都写上去。\r\n剪裁后导出的静态模型从23.4M变为14.7M，但是部署到板子上推理照片的速度从350ms变为了610ms，求大佬解答！！！\r\n",
        "state": "closed",
        "user": "SunYF-0729",
        "closed_by": "XGZhang11",
        "created_at": "2022-07-18T20:50:29+00:00",
        "updated_at": "2024-02-06T04:15:09+00:00",
        "closed_at": "2024-02-06T04:15:09+00:00",
        "comments_count": [
            "yghstill",
            "SunYF-0729",
            "SunYF-0729",
            "SunYF-0729",
            "zzjjay",
            "SunYF-0729",
            "zzjjay",
            "SunYF-0729",
            "yu0802chao",
            "SunYF-0729",
            "yu0802chao",
            "SunYF-0729",
            "yu0802chao",
            "SunYF-0729",
            "wangplin",
            "SunYF-0729",
            "wangplin",
            "personqianduixue",
            "liopos"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1306,
        "title": "AssertionError: (h, w) of target size should be greater than (im_h, im_w)",
        "body": "[https://s3.bmp.ovh/imgs/2022/07/19/18967221eeac0752.png](url)\r\n就是在数据dataset.yml中， target_size的尺寸一定要比原始的图片大吗？",
        "state": "closed",
        "user": "Dora1483",
        "closed_by": "RachelXu7",
        "created_at": "2022-07-19T07:07:38+00:00",
        "updated_at": "2022-07-19T12:25:41+00:00",
        "closed_at": "2022-07-19T12:25:41+00:00",
        "comments_count": [
            "RachelXu7"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1314,
        "title": "动态qat量化后用netron查看模型的 pdparams参数含义不明晰",
        "body": null,
        "state": "closed",
        "user": "fpjnice",
        "closed_by": "yghstill",
        "created_at": "2022-07-26T13:26:05+00:00",
        "updated_at": "2022-07-29T10:37:06+00:00",
        "closed_at": "2022-07-29T10:37:06+00:00",
        "comments_count": [
            "yghstill",
            "fpjnice",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1310,
        "title": "run `example/auto_compression/semantic_segmentation` get NaN",
        "body": "Hi, I run [`run.py`](https://github.com/PaddlePaddle/PaddleSlim/blob/develop/example/auto_compression/semantic_segmentation/run.py) as follow in `PaddleSlim/example/auto_compression/semantic_segmentation`:\r\n\r\n```python\r\nargs.config_path = \"configs/pp_liteseg/pp_liteseg_mine.yaml\"\r\nargs.save_dir = './save_sparse_model'\r\n```\r\n\r\nbut I got:\r\n```python\r\n2022-07-22 12:59:49,955-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul', 'matmul', 'matmul_v2'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'name': 'Distillation', 'loss': 'l2', 'node': [], 'alpha': 1.0, 'teacher_model_dir': '../../../../714/save/output', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\n2022-07-22 13:00:36,223-INFO: Total iter: 0, epoch: 0, batch: 0, loss: [0.02632807]\r\n2022-07-22 13:00:36,593-INFO: Total iter: 1, epoch: 0, batch: 1, loss: [0.0527272]\r\n2022-07-22 13:00:36,777-INFO: Total iter: 2, epoch: 0, batch: 2, loss: [0.1315988]\r\n2022-07-22 13:00:37,332-INFO: Total iter: 3, epoch: 0, batch: 3, loss: [0.3486606]\r\n2022-07-22 13:00:37,476-INFO: Total iter: 4, epoch: 0, batch: 4, loss: [9.675454]\r\n2022-07-22 13:00:37,607-INFO: Total iter: 5, epoch: 0, batch: 5, loss: [61.659126]\r\n2022-07-22 13:00:37,731-INFO: Total iter: 6, epoch: 0, batch: 6, loss: [4.6202196e+27]\r\n2022-07-22 13:00:37,859-INFO: Total iter: 7, epoch: 0, batch: 7, loss: [nan]\r\n2022-07-22 13:00:37,979-INFO: Total iter: 8, epoch: 0, batch: 8, loss: [nan]\r\n2022-07-22 13:00:38,101-INFO: Total iter: 9, epoch: 0, batch: 9, loss: [nan]\r\n.....\r\n2022-07-22 13:00:42,007-INFO: Total iter: 41, epoch: 0, batch: 41, loss: [nan]\r\n```\r\n\r\n\r\n`configs/pp_liteseg/pp_liteseg_mine.yaml`:\r\n```yaml\r\nGlobal:\r\n  reader_config: ../../../../714/save/config_paddleslim.yml\r\n  model_dir: ../../../../714/save/output\r\n  model_filename: model.pdmodel\r\n  params_filename: model.pdiparams\r\n\r\nTrainConfig:\r\n epochs: 14\r\n logging_iter: 1\r\n eval_iter: 90\r\n learning_rate: \r\n   type: PiecewiseDecay\r\n   boundaries: [900]\r\n   values: [0.001, 0.0005]\r\n optimizer_builder:\r\n   optimizer: \r\n     type: SGD\r\n   weight_decay: 0.0005  \r\n```\r\n\r\n`config_paddleslim.yml`:\r\n```yaml\r\ntrain_dataset:\r\n  type: Dataset\r\n  # dataset_root: /root/share/program/save/data/portraint\r\n  # val_path: /root/share/program/save/data/portraint/txtfiles/test.txt\r\n  dataset_root: ../../../..\r\n  train_path:  ../../../../test/test.txt\r\n  num_classes: 2\r\n  transforms:\r\n    - type: Resize\r\n      target_size: [224, 224]\r\n    - type: Normalize\r\n  mode: train\r\n\r\nval_dataset:\r\n  type: Dataset\r\n  # dataset_root: /root/share/program/save/data/portraint\r\n  # val_path: /root/share/program/save/data/portraint/txtfiles/test.txt\r\n  dataset_root: ../../../..\r\n  val_path: ../../../../test/test.txt\r\n  num_classes: 2\r\n  transforms:\r\n    - type: Resize\r\n      target_size: [224, 224]\r\n    - type: Normalize\r\n  mode: val\r\n\r\nexport:\r\n  transforms:\r\n    - type: Resize\r\n      target_size: [224, 224]\r\n    - type: Normalize\r\n\r\n# optimizer:\r\n#   type: sgd\r\n#   momentum: 0.9\r\n#   weight_decay: 5.0e-4\r\n\r\n# lr_scheduler:\r\n#   type: PolynomialDecay\r\n#   learning_rate: 0.02  #finetune 0.02\r\n#   end_lr: 0\r\n#   power: 0.9\r\n#   warmup_iters: 100\r\n#   warmup_start_lr: 1.0e-5\r\n\r\n# loss:\r\n#   types:\r\n#     - type: CrossEntropyLoss\r\n#       #min_kept: 1254400   # batch_size * 224 * 224 // 16\r\n#     - type: CrossEntropyLoss\r\n#       #min_kept: 1254400\r\n#     - type: CrossEntropyLoss\r\n#       #min_kept: 1254400\r\n#     - type: CrossEntropyLoss\r\n#   coef: [1, 1, 1, 1]\r\n\r\nmodel:\r\n  type: PPLiteSeg\r\n  backbone:\r\n    type: STDC2\r\n  backbone_indices: [0, 1, 2, 3]\r\n  arm_out_chs: [16, 32, 32, 64]\r\n  seg_head_inter_chs: [8, 16, 16, 32]\r\n  # pretrained: output/pp_liteseg_stdc2_myhumanseg_modify_1_syntheses/iter_4200/model.pdparams\r\n```\r\n\r\nCould you please tell me the possible reason? Thanks!!",
        "state": "closed",
        "user": "DrRyanHuang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-07-22T05:06:32+00:00",
        "updated_at": "2024-02-06T02:59:13+00:00",
        "closed_at": "2024-02-06T02:59:13+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1318,
        "title": "使用Inference模型恢复训练",
        "body": "在paddleslim中的recover_inference_program貌似提供了推理模型转训练模型的功能，但是没有找到具体的应用实例，可以给一个简单的demo演示一下该功能如何使用并进行训练吗？",
        "state": "closed",
        "user": "moonlightian",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-01T07:50:18+00:00",
        "updated_at": "2024-02-06T02:59:14+00:00",
        "closed_at": "2024-02-06T02:59:14+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1323,
        "title": "Please check the py_verion variable",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/8b156124638caf851e728f49cf46afb9ebf7ed4e/paddleslim/analysis/latency_predictor.py#L98",
        "state": "closed",
        "user": "colorjam",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-02T07:25:32+00:00",
        "updated_at": "2024-02-06T02:59:15+00:00",
        "closed_at": "2024-02-06T02:59:15+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1325,
        "title": "量化模型转TensorRT",
        "body": "请问如何把链接中yolov6的量化模型转成对应的TensorRT模型\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression/pytorch_yolov6",
        "state": "closed",
        "user": "xingyueye",
        "closed_by": "yghstill",
        "created_at": "2022-08-04T08:28:58+00:00",
        "updated_at": "2022-08-10T06:41:41+00:00",
        "closed_at": "2022-08-10T03:05:38+00:00",
        "comments_count": [
            "xingyueye",
            "yghstill",
            "yghstill",
            "xingyueye",
            "yghstill",
            "xingyueye",
            "yghstill",
            "yghstill",
            "xingyueye"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1330,
        "title": "为什么ACT的目标检测示例均为量化蒸馏?",
        "body": "是不是剪枝等方法加速效果不好",
        "state": "closed",
        "user": "eshoyuan",
        "closed_by": "eshoyuan",
        "created_at": "2022-08-10T03:14:36+00:00",
        "updated_at": "2022-08-10T05:44:38+00:00",
        "closed_at": "2022-08-10T05:44:37+00:00",
        "comments_count": [
            "yghstill",
            "eshoyuan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1331,
        "title": "新出的自动压缩支持PPYOLO系列吗？比如PPYOLO-mbv3_small",
        "body": "请问新出的自动压缩支持PPYOLO系列吗？比如PPYOLO-mbv3_small模型。",
        "state": "closed",
        "user": "jo-dean",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-10T07:39:15+00:00",
        "updated_at": "2024-02-06T02:59:16+00:00",
        "closed_at": "2024-02-06T02:59:16+00:00",
        "comments_count": [
            "yghstill",
            "jo-dean",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1333,
        "title": "模型静态离线量化报错",
        "body": "模型静态离线量化时，收到一个报错，请帮忙看下，谢谢！\r\n\r\n模型为det模型，使用的inference为PaddleOCR/tools中export_model.py导出，该模型转为onnx是可以正常推理的，目前想将该模型量化后再转为onnx，但量化时报错如下：\r\n\r\n\r\n使用MobileNetV1_infer.tar中的模型则没有这个问题。\r\n\r\n\r\n/usr/local/lib/python3.8/dist-packages/paddle/fluid/executor.py:990: UserWarning: The variable inputs is not found in program. It is not declared or is pruned.\r\nTraceback (most recent call last):\r\n  File \"quant_post.py\", line 97, in <module>\r\n    main()\r\n  File \"quant_post.py\", line 92, in main\r\n    quantize(args)\r\n  File \"quant_post.py\", line 71, in quantize\r\n    quant_post_static(\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddleslim/quant/quanter.py\", line 506, in quant_post_static\r\n    post_training_quantization.quantize()\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 360, in quantize\r\n    self._executor.run(program=self._program,\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/executor.py\", line 1299, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python3.8/dist-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/executor.py\", line 1285, in run\r\n    res = self._run_impl(\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/executor.py\", line 1431, in _run_impl\r\n    program = self._add_feed_fetch_ops(\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/executor.py\", line 788, in _add_feed_fetch_ops\r\n    if not has_feed_operators(global_block, feed, feed_var_name):\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddle/fluid/executor.py\", line 281, in has_feed_operators\r\n    raise Exception(\"'feed_targets' does not have {} variable\".\r\nException: 'feed_targets' does not have x variable\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "maximli",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-11T08:53:05+00:00",
        "updated_at": "2024-12-26T09:28:49+00:00",
        "closed_at": "2024-02-06T02:59:16+00:00",
        "comments_count": [
            "maximli",
            "yghstill",
            "maximli",
            "yghstill",
            "Zhang-O",
            "mandylyin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1337,
        "title": "提个建议",
        "body": "我相信你们的技术很强，但是你们的文档实在是太差了，对于初学者根本无法下手。\r\n举个例子，你们的自动压缩ACT，在readme 里面只有量化的选项，我照搬这个例子去运行，可以正常运行，但是如果我需要剪枝呢，该怎么设置，没有例子，没有文档说明，我去看源代码，看到了相关设置，结果还是报错，按照报错提示修改了还是没用。后来发现你们有个文档网站https://paddleslim.readthedocs.io/zh_CN/develop/cv/detection/static/paddledetection_slim_pruing_tutorial.html， 结果根本就没有详细说明和例子，跳来跳去又跳到github上。微软的nni做的很好，跟着例子就能照猫画虎，你们的这个，我摸索了半天了，还是不行",
        "state": "closed",
        "user": "ly0303521",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-12T06:38:12+00:00",
        "updated_at": "2024-02-06T02:59:17+00:00",
        "closed_at": "2024-02-06T02:59:17+00:00",
        "comments_count": [
            "ly0303521",
            "ly0303521",
            "ceci3",
            "ceci3",
            "ceci3",
            "ly0303521",
            "ly0303521",
            "ceci3",
            "shituo123456",
            "leiqing1",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1345,
        "title": "Error compressing picodet_xs model using nas",
        "body": "1、env\r\n-----------------------------------------------------------------------\r\nsystem：Ubuntu 20\r\npaddle version：paddlepaddle-gpu 2.3.1.post116\r\npaddleslim  version：2.3.2\r\nPython verison: 3.7.13\r\n\r\n\r\n2、run code\r\n--------------------------------------------------------------------------\r\ncd PaddleSlim-develop/example/auto_compression/detection\r\n\r\npython run.py --config_path=./configs/picodet_s_qat_dis.yaml  --save_dir='./output/'\r\n\r\n\r\n\r\n\r\n\r\n\r\n3、result\r\n-----------  Running Arguments -----------\r\n Distillation:\r\n         alpha: 1.0\r\n         loss: l2\r\n Global:\r\n         Evaluation: True\r\n         input_list: ['image', 'scale_factor']\r\n         model_dir: ./picodet_s_288_coco_lcnet/\r\n         model_filename: model.pdmodel\r\n         params_filename: model.pdiparams\r\n         reader_config: ./configs/picodet_reader.yml      \r\n Quantization:\r\n         activation_bits: 8\r\n         activation_quantize_type: moving_average_abs_max \r\n         quantize_op_types: ['conv2d', 'depthwise_conv2d']\r\n         use_pact: True\r\n         weight_bits: 8\r\n TrainConfig:\r\n         eval_iter: 1000\r\n         learning_rate:\r\n                 T_max: 8000\r\n                 learning_rate: 1e-05\r\n                 type: CosineAnnealingDecay\r\n         optimizer_builder:\r\n                 optimizer:\r\n                         type: SGD\r\n                 weight_decay: 4e-05\r\n         train_iter: 8000\r\n------------------------------------------\r\n[08/15 23:15:15] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/12--Group_12_Group_Large_Group_12_Group_Large_Group_12_424_0.xml, x1: 572.0, y1: 561.0, x2: 571.0, y2: 571.0.\r\n[08/15 23:15:16] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/10--People_Marching_10_People_Marching_People_Marching_10_People_Marching_People_Marching_10_People_Marching_People_Marching_10_543_0.xml, x1: 572.0, y1: 459.0, x2: 571.0, y2: 470.0.\r\n[08/15 23:17:05] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Political_Rally_2_201_0.xml, x1: 572.0, y1: 497.0, x2: 571.0, y2: 507.0.\r\n[08/15 23:17:36] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_485_0.xml, x1: 572.0, y1: 588.0, x2: 571.0, y2: 596.0.\r\n[08/15 23:17:46] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_465_0.xml, x1: 572.0, y1: 408.0, x2: 571.0, y2: 414.0.\r\n[08/15 23:18:11] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_502_0.xml, x1: 572.0, y1: 442.0, x2: 571.0, y2: 457.0.\r\n[08/15 23:21:53] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/15--Stock_Market_15_Stock_Market_Stock_Market_15_194_0.xml, x1: 572.0, y1: 439.0, x2: 571.0, y2: 444.0.\r\n[08/15 23:22:49] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_189_0.xml, x1: 572.0, y1: 308.0, x2: 571.0, y2: 316.0.\r\n[08/15 23:22:56] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_Parade_0_391_0.xml, x1: 572.0, y1: 300.0, x2: 571.0, y2: 311.0.\r\n[08/15 23:24:29] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/44--Aerobics_44_Aerobics_Aerobics_44_926_0.xml, x1: 572.0, y1: 299.0, x2: 571.0, y2: 316.0.\r\n[08/15 23:25:10] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Political_Rally_2_330_0.xml, x1: 572.0, y1: 579.0, x2: 571.0, y2: 588.0.\r\n[08/15 23:26:27] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/10--People_Marching_10_People_Marching_People_Marching_10_People_Marching_People_Marching_10_88_0.xml, x1: 754.0, y1: 534.0, x2: 754.0, y2: 547.0.\r\n[08/15 23:26:46] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/14--Traffic_14_Traffic_Traffic_14_338_0.xml, x1: 572.0, y1: 569.0, x2: 571.0, y2: 581.0.\r\n[08/15 23:26:48] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/9--Press_Conference_9_Press_Conference_Press_Conference_9_392_0.xml, x1: 572.0, y1: 255.0, x2: 571.0, y2: 269.0.\r\n[08/15 23:26:58] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/12--Group_12_Group_Team_Organized_Group_12_Group_Team_Organized_Group_12_639_0.xml, x1: 572.0, y1: 426.0, x2: 571.0, y2: 431.0.\r\n[08/15 23:27:24] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/39--Ice_Skating_39_Ice_Skating_iceskiing_39_325_0.xml, x1: 572.0, y1: 463.0, x2: 571.0, y2: 471.0.\r\n[08/15 23:27:49] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/47--Matador_Bullfighter_47_Matador_Bullfighter_matadorbullfighting_47_376_0.xml, x1: 572.0, y1: 360.0, x2: 571.0, y2: 368.0.\r\n[08/15 23:28:19] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_339_0.xml, x1: 572.0, y1: 580.0, x2: 571.0, y2: 593.0.\r\n[08/15 23:28:35] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_120_0.xml, x1: 572.0, y1: 458.0, x2: 571.0, y2: 466.0.\r\n[08/15 23:28:35] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_235_0.xml, x1: 572.0, y1: 313.0, x2: 571.0, y2: 321.0.\r\n[08/15 23:31:27] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/16--Award_Ceremony_16_Award_Ceremony_Awards_Ceremony_16_46_0.xml, x1: 572.0, y1: 354.0, x2: 571.0, y2: 362.0.\r\n[08/15 23:31:27] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/16--Award_Ceremony_16_Award_Ceremony_Awards_Ceremony_16_46_0.xml, x1: 572.0, y1: 404.0, x2: 571.0, y2: 414.0.\r\n[08/15 23:31:43] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/35--Basketball_35_Basketball_basketballgame_ball_35_375_0.xml, x1: 572.0, y1: 258.0, x2: 571.0, y2: 266.0.\r\n[08/15 23:33:34] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/17--Ceremony_17_Ceremony_Ceremony_17_717_0.xml, x1: 572.0, y1: 240.0, x2: 571.0, y2: 248.0.\r\n[08/15 23:34:01] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/21--Festival_21_Festival_Festival_21_54_0.xml, x1: 572.0, y1: 638.0, x2: 571.0, y2: 648.0.\r\n[08/15 23:35:35] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/6--Funeral_6_Funeral_Funeral_6_214_0.xml, x1: 572.0, y1: 280.0, x2: 571.0, y2: 285.0.\r\n[08/15 23:37:17] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/mda-kk1vbjriwnkqgu3d__735___0.xml, x1: 486.0, y1: 231.0, x2: 486.0, y2: 250.0.\r\n[08/15 23:37:26] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_476_0.xml, x1: 572.0, y1: 225.0, x2: 571.0, y2: 234.0.\r\n\r\n[08/15 23:37:47] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstrators_2_559_0.xml, x1: 572.0, y1: 354.0, x2: 571.0, y2: 366.0.\r\n[08/15 23:38:06] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_Parade_0_514_0.xml, x1: 572.0, y1: 626.0, x2: 571.0, y2: 635.0.\r\n[08/15 23:38:15] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/35--Basketball_35_Basketball_basketballgame_ball_35_49_0.xml, x1: 572.0, y1: 690.0, x2: 571.0, y2: 699.0.\r\n[08/15 23:38:21] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/mda-mmw9jrdqaiv6iy32__1710___0.xml, x1: 486.0, y1: 181.0, x2: 486.0, y2: 199.0.\r\n[08/15 23:39:29] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/46--Jockey_46_Jockey_Jockey_46_182_0.xml, x1: 572.0, y1: 253.0, x2: 571.0, y2: 266.0.\r\n[08/15 23:41:31] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_881_0.xml, x1: 572.0, y1: 337.0, x2: 571.0, y2: 347.0.\r\n[08/15 23:41:37] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/7--Cheering_7_Cheering_Cheering_7_548_0.xml, x1: 572.0, y1: 490.0, x2: 571.0, y2: 498.0.\r\n[08/15 23:42:58] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/52--Photographers_52_Photographers_photographertakingphoto_52_818_0.xml, x1: 829.0, y1: 591.0, x2: 829.0, y2: 602.0.\r\n[08/15 23:43:32] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/9--Press_Conference_9_Press_Conference_Press_Conference_9_28_0.xml, x1: 572.0, y1: 366.0, x2: 571.0, y2: 371.0.\r\n[08/15 23:43:39] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/21--Festival_21_Festival_Festival_21_943_0.xml, x1: 572.0, y1: 324.0, x2: 571.0, y2: 333.0.\r\n[08/15 23:43:43] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_465_0.xml, x1: 572.0, y1: 311.0, x2: 571.0, y2: 315.0.\r\n[08/15 23:44:17] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/7--Cheering_7_Cheering_Cheering_7_171_0.xml, x1: 572.0, y1: 304.0, x2: 571.0, y2: 321.0.\r\n[08/15 23:44:54] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Political_Rally_2_231_0.xml, x1: 830.0, y1: 392.0, x2: 830.0, y2: 415.0.\r\n[08/15 23:45:00] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_455_0.xml, x1: 572.0, y1: 110.0, x2: 571.0, y2: 124.0.\r\n[08/15 23:45:13] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/mda-mmj5a2z2pkxwumw9__5550___0.xml, x1: 486.0, y1: 274.0, x2: 486.0, y2: 292.0.\r\n[08/15 23:45:27] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_Parade_0_188_0.xml, x1: 572.0, y1: 428.0, x2: 571.0, y2: 438.0.\r\n[08/15 23:46:17] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/21--Festival_21_Festival_Festival_21_833_0.xml, x1: 572.0, y1: 546.0, x2: 571.0, y2: 557.0.\r\n[08/15 23:46:36] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Protesters_2_441_0.xml, x1: 572.0, y1: 232.0, x2: 571.0, y2: 249.0.\r\n[08/15 23:46:53] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_193_0.xml, x1: 572.0, y1: 340.0, x2: 571.0, y2: 350.0.\r\n[08/15 23:46:53] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_193_0.xml, x1: 572.0, y1: 284.0, x2: 571.0, y2: 289.0.\r\n[08/15 23:47:14] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/8--Election_Campain_8_Election_Campain_Election_Campaign_8_349_0.xml, x1: 572.0, y1: 300.0, x2: 571.0, y2: 314.0.\r\n[08/15 23:48:14] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Political_Rally_2_609_0.xml, x1: 572.0, y1: 519.0, x2: 571.0, y2: 532.0.\r\n[08/15 23:48:29] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_843_0.xml, x1: 572.0, y1: 357.0, x2: 571.0, y2: 368.0.\r\n[08/15 23:48:31] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Political_Rally_2_60_0.xml, x1: 572.0, y1: 476.0, x2: 571.0, y2: 487.0.\r\n[08/15 23:48:32] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/18--Concerts_18_Concerts_Concerts_18_989_0.xml, x1: 572.0, y1: 623.0, x2: 571.0, y2: 639.0.\r\n[08/15 23:48:32] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/18--Concerts_18_Concerts_Concerts_18_989_0.xml, x1: 572.0, y1: 270.0, x2: 571.0, y2: 281.0.\r\n[08/15 23:48:44] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_691_0.xml, x1: 572.0, y1: 529.0, x2: 571.0, y2: 533.0.\r\n[08/15 23:48:45] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/21--Festival_21_Festival_Festival_21_130_0.xml, x1: 572.0, y1: 598.0, x2: 571.0, y2: 607.0.\r\n[08/15 23:48:49] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Protesters_2_545_0.xml, x1: 572.0, y1: 516.0, x2: 571.0, y2: 523.0.\r\n[08/15 23:48:54] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_140_0.xml, x1: 572.0, y1: 479.0, x2: 571.0, y2: 485.0.\r\n[08/15 23:48:57] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_500_0.xml, x1: 572.0, y1: 345.0, x2: 571.0, y2: 357.0.\r\n[08/15 23:49:07] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/44_Aerobics_Aerobics_44_926_0.xml, x1: 572.0, y1: 75.0, x2: 571.0, y2: 91.0.\r\n[08/15 23:49:40] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/35--Basketball_35_Basketball_basketballgame_ball_35_479_0.xml, x1: 572.0, y1: 499.0, x2: 571.0, y2: 506.0.\r\n[08/15 23:49:40] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/35--Basketball_35_Basketball_basketballgame_ball_35_479_0.xml, x1: 572.0, y1: 458.0, x2: 571.0, y2: 464.0.\r\n[08/15 23:49:40] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/35--Basketball_35_Basketball_basketballgame_ball_35_479_0.xml, x1: 572.0, y1: 449.0, x2: 571.0, y2: 453.0.\r\n[08/15 23:49:41] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstrators_2_594_0.xml, x1: 572.0, y1: 346.0, x2: 571.0, y2: 360.0.\r\n[08/15 23:51:49] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_337_0.xml, x1: 572.0, y1: 367.0, x2: 571.0, y2: 382.0.\r\n[08/15 23:52:21] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_Parade_0_856_0.xml, x1: 572.0, y1: 797.0, x2: 571.0, y2: 805.0.\r\n[08/15 23:52:32] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_17_0.xml, x1: 572.0, y1: 480.0, x2: 571.0, y2: 493.0.\r\n\r\n\r\n\r\n\r\n[08/15 23:53:23] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/35--Basketball_35_Basketball_basketballgame_ball_35_82_0.xml, x1: 572.0, y1: 221.0, x2: 571.0, y2: 235.0.\r\n[08/15 23:53:33] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Protesters_2_166_0.xml, x1: 572.0, y1: 358.0, x2: 571.0, y2: 374.0.\r\n[08/15 23:54:05] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_Parade_0_68_0.xml, x1: 572.0, y1: 559.0, x2: 571.0, y2: 570.0.\r\n[08/15 23:54:48] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/46--Jockey_46_Jockey_Jockey_46_877_0.xml, x1: 572.0, y1: 503.0, x2: 571.0, y2: 517.0.\r\n[08/15 23:55:00] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_593_0.xml, x1: 572.0, y1: 528.0, x2: 571.0, y2: 535.0.\r\n[08/15 23:55:10] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/000404__3__6420___0.xml, x1: 1019.0, y1: 742.0, x2: 1019.0, y2: 751.0.\r\n[08/15 23:55:26] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/14--Traffic_14_Traffic_Traffic_14_9_0.xml, x1: 792.0, y1: 310.0, x2: 792.0, y2: 317.0.\r\n[08/15 23:56:13] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/13--Interview_13_Interview_Interview_2_People_Visible_13_69_0.xml, x1: 572.0, y1: 470.0, x2: 571.0, y2: 483.0.\r\n[08/15 23:56:33] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Political_Rally_2_509_0.xml, x1: 572.0, y1: 606.0, x2: 571.0, y2: 615.0.\r\n[08/15 23:56:46] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_665_0.xml, x1: 572.0, y1: 376.0, x2: 571.0, y2: 396.0.\r\n[08/15 23:57:12] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/12--Group_12_Group_Large_Group_12_Group_Large_Group_12_4_0.xml, x1: 572.0, y1: 367.0, x2: 571.0, y2: 388.0.\r\n[08/15 23:59:37] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/PartA_00053_1.xml, x1: 1.0, y1: 105.0, x2: 1.0, y2: 117.0.\r\n[08/15 23:59:44] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/test_00003674_0.xml, x1: 392.0, y1: 280.0, x2: 392.0, y2: 317.0.\r\n[08/16 00:00:06] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/12--Group_12_Group_Large_Group_12_Group_Large_Group_12_31_0.xml, x1: 572.0, y1: 200.0, x2: 571.0, y2: 211.0.\r\n[08/16 00:00:06] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/12--Group_12_Group_Large_Group_12_Group_Large_Group_12_31_0.xml, x1: 572.0, y1: 507.0, x2: 571.0, y2: 520.0.\r\n[08/16 00:00:06] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/12--Group_12_Group_Large_Group_12_Group_Large_Group_12_31_0.xml, x1: 572.0, y1: 183.0, x2: 571.0, y2: 189.0.\r\n[08/16 00:00:39] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstrators_2_270_0.xml, x1: 572.0, y1: 539.0, x2: 571.0, y2: 561.0.\r\n[08/16 00:00:45] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/35--Basketball_35_Basketball_basketballgame_ball_35_250_0.xml, x1: 572.0, y1: 302.0, x2: 571.0, y2: 312.0.\r\n[08/16 00:02:40] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_258_0.xml, x1: 572.0, y1: 489.0, x2: 571.0, y2: 495.0.\r\n[08/16 00:02:40] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstration_Or_Protest_2_258_0.xml, x1: 572.0, y1: 503.0, x2: 571.0, y2: 508.0.\r\n[08/16 00:04:13] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_Parade_0_71_0.xml, x1: 572.0, y1: 540.0, x2: 571.0, y2: 554.0.\r\n[08/16 00:06:03] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/2--Demonstration_2_Demonstration_Demonstrators_2_40_0.xml, x1: 572.0, y1: 482.0, x2: 571.0, y2: 493.0.\r\n[08/16 00:06:39] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/PartA_00053_0.xml, x1: 493.0, y1: 82.0, x2: 493.0, y2: 96.0.\r\n[08/16 00:07:07] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/21--Festival_21_Festival_Festival_21_287_0.xml, x1: 572.0, y1: 620.0, x2: 571.0, y2: 633.0.\r\n[08/16 00:08:35] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/35--Basketball_35_Basketball_basketballgame_ball_35_526_0.xml, x1: 572.0, y1: 423.0, x2: 571.0, y2: 433.0.\r\n[08/16 00:08:56] ppdet.data.source.voc WARNING: Found an invalid bbox in annotations: xml_file: /home/guest/projects/xiaohuan/data_cut/cut_images_all_0802_xml/0--Parade_0_Parade_marchingband_1_541_0.xml, x1: 572.0, y1: 596.0, x2: 571.0, y2: 602.0.\r\nW0816 00:09:09.955559 52598 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.2\r\nW0816 00:09:10.153280 52598 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\r\nTue Aug 16 00:09:17-WARNING: The old way to load inference model is deprecated. model path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdmodel, params path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdiparams   \r\n2022-08-16 00:09:18,419-INFO: devices: gpu\r\nTue Aug 16 00:09:18-WARNING: The old way to load inference model is deprecated. model path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdmodel, params path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdiparams   \r\n2022-08-16 00:09:21,587-INFO: Detect model type: None\r\nTue Aug 16 00:09:21-WARNING: The old way to load inference model is deprecated. model path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdmodel, params path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdiparams   \r\n2022-08-16 00:09:21,701-INFO: Selected strategies: ['qat_dis']\r\nTue Aug 16 00:09:21-WARNING: The old way to load inference model is deprecated. model path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdmodel, params path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdiparams   \r\nTue Aug 16 00:09:24-WARNING: The old way to load inference model is deprecated. model path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdmodel, params path: /home/guest/projects/PaddleSlim-develop/example/auto_compression/detection/picodet_s_288_coco_lcnet/model.pdiparams   \r\n2022-08-16 00:09:27,435-INFO: train config.distill_node_pair: ['teacher_conv2d_129.tmp_1', 'conv2d_129.tmp_1', 'teacher_conv2d_130.tmp_1', 'conv2d_130.tmp_1', 'teacher_batch_norm_60.tmp_2', 'batch_norm_60.tmp_2', 'teacher_linear_0.tmp_0', 'linear_0.tmp_0', 'teacher_conv2d_137.tmp_1', 'conv2d_137.tmp_1', 'teacher_conv2d_138.tmp_1', 'conv2d_138.tmp_1', 'teacher_batch_norm_67.tmp_2', 'batch_norm_67.tmp_2', 'teacher_linear_1.tmp_0', 'linear_1.tmp_0', 'teacher_conv2d_145.tmp_1', 'conv2d_145.tmp_1', 'teacher_conv2d_146.tmp_1', 'conv2d_146.tmp_1', 'teacher_batch_norm_74.tmp_2', 'batch_norm_74.tmp_2', 'teacher_linear_2.tmp_0', 'linear_2.tmp_0', 'teacher_conv2d_153.tmp_1', 'conv2d_153.tmp_1', 'teacher_conv2d_154.tmp_1', 'conv2d_154.tmp_1', 'teacher_batch_norm_81.tmp_2', 'batch_norm_81.tmp_2', 'teacher_linear_3.tmp_0', 'linear_3.tmp_0']       \r\n2022-08-16 00:09:28,168-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'name': 'Distillation', 'loss': 'l2', 'node': [], 'alpha': 1.0, 'teacher_model_dir': './picodet_s_288_coco_lcnet', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\nAdding quant op with weight:|██████████████████████████████████████████| 347/347\r\nAdding OutScale op:|███████████████████████████████████████████████████| 337/337\r\n2022-08-16 00:09:32,929-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'name': 'Distillation', 'loss': 'l2', 'node': [], 'alpha': 1.0, 'teacher_model_dir': './picodet_s_288_coco_lcnet', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\nAdding quant op with weight:|████████████████████████████████████████| 1966/1966\r\nAdding OutScale op:|█████████████████████████████████████████████████| 1249/1249\r\n2022-08-16 00:13:18,124-INFO: When a preprocess_func is used in quant_aware, Need to save a mapping table to match variable names in the convert phase.\r\n2022-08-16 00:13:18,124-INFO: The mapping table is saved as './mapping_table_for_saving_inference_model'.\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 188, in <module>\r\n    main()\r\n  File \"run.py\", line 178, in main\r\n    ac.compress()\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 575, in compress\r\n    train_config)\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 702, in single_strategy_compress\r\n    train_program_info, test_program_info, strategy, train_config)\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 714, in _start_train\r\n    fetch_list=train_program_info.fetch_targets)\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1299, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1295, in run\r\n    return_merged=return_merged)\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1531, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1049, in _run_parallel\r\n    var = global_block.var(feed_name) if need_check_feed else None\r\n  File \"/root/miniconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3358, in var\r\n    raise ValueError(\"var %s not in this block\" % name)\r\nValueError: var scale_factor not in this block",
        "state": "closed",
        "user": "hurun",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-16T07:41:55+00:00",
        "updated_at": "2024-02-06T02:59:18+00:00",
        "closed_at": "2024-02-06T02:59:18+00:00",
        "comments_count": [
            "hurun",
            "yghstill",
            "hurun",
            "jo-dean",
            "yghstill",
            "jo-dean"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1346,
        "title": "不支持windows https://pypi.org/simple/paddleslim-opt-tools/",
        "body": "不支持windows ，也找不到windows的包：  \r\n\r\nAdding paddleslim 2.3.0 to easy-install.pth file\r\n\r\nInstalled c:\\programdata\\anaconda3\\envs\\paddlegpu\\lib\\site-packages\\paddleslim-2.3.0-py3.7.egg\r\nProcessing dependencies for paddleslim==2.3.0\r\nSearching for paddleslim-opt-tools\r\nReading https://pypi.org/simple/paddleslim-opt-tools/\r\nNo local packages or working download links found for paddleslim-opt-tools\r\nerror: Could not find suitable distribution for Requirement.parse('paddleslim-opt-tools')\r\n\r\n![微信图片_20220816165838](https://user-images.githubusercontent.com/6648329/184841649-792525ed-1325-49de-a5eb-664fd5c2f690.png)\r\n\r\n",
        "state": "closed",
        "user": "gg22mm",
        "closed_by": "gg22mm",
        "created_at": "2022-08-16T09:05:39+00:00",
        "updated_at": "2022-08-23T06:21:07+00:00",
        "closed_at": "2022-08-17T03:52:49+00:00",
        "comments_count": [
            "yghstill",
            "gg22mm",
            "yghstill",
            "gg22mm",
            "yghstill",
            "gg22mm",
            "iamWHTWD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1350,
        "title": "离线KL量化 使用 Paddle2ONNX转换模型",
        "body": "[Paddle2ONNX] Oops, there are some operators not supported yet, including linspace",
        "state": "closed",
        "user": "Linaom1214",
        "closed_by": "Linaom1214",
        "created_at": "2022-08-17T01:39:10+00:00",
        "updated_at": "2022-08-22T08:29:29+00:00",
        "closed_at": "2022-08-22T08:29:29+00:00",
        "comments_count": [
            "yghstill",
            "Linaom1214",
            "yghstill",
            "Linaom1214",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1351,
        "title": "图片分割例子不能运行",
        "body": "cd PaddleSlim/example/auto_compression/semantic_segmentation/\r\npython run.py\r\n\r\nrun.py 如下：\r\n`\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser(description='Model training')\r\n    parser.add_argument(\r\n        '--model_dir',\r\n        type=str,\r\n        default='./models/ppseg_lite_portrait_398x224_with_softmax',  #模型目录\r\n        help=\"inference model directory.\")\r\n    parser.add_argument(\r\n        '--model_filename',\r\n        type=str,\r\n        default='model.pdmodel',                                       #模型名\r\n        help=\"inference model filename.\")\r\n    parser.add_argument(\r\n        '--params_filename',\r\n        type=str,\r\n        default='model.pdiparams',                                     #模型参数\r\n        help=\"inference params filename.\")\r\n    parser.add_argument(\r\n        '--save_dir',\r\n        type=str,\r\n        default='./save_compressed_model',                             #自动压缩后的模型保存目录\r\n        help=\"directory to save compressed model.\")\r\n    parser.add_argument(\r\n        '--strategy_config',\r\n        type=str,\r\n        default=None,\r\n        help=\"path of compression strategy config.\")\r\n    parser.add_argument(\r\n        '--dataset_config',\r\n        type=str,\r\n        default='./configs/dataset/humanseg_dataset.yaml',              #数据集配置 \r\n        help=\"path of dataset config.\")\r\n    parser.add_argument(\r\n        '--deploy_hardware',\r\n        type=str,\r\n        default='deploy_hardware',                                      #传入 deploy_hardware 字段时，将自动搜索压缩策略进行压缩\r\n        help=\"The hardware you want to deploy.\")\r\n    return parser.parse_args()\r\n\r\n`\r\n\r\n\r\n![11](https://user-images.githubusercontent.com/6648329/185053456-0776984d-0d32-4c9b-9407-7f77691b89e8.png)\r\n![33](https://user-images.githubusercontent.com/6648329/185053530-810b68d7-ec64-4b31-80b8-e0b8abc3065b.png)\r\n\r\n\r\n报错：\r\n\r\n(paddleGpu) D:\\dzkj\\PaddleSlim\\example\\auto_compression\\semantic_segmentation>python run.py\r\n2022-08-17 14:46:42,134-WARNING: post-quant-hpo is not support in system other than linux\r\nC:\\ProgramData\\Anaconda3\\envs\\paddleGpu\\lib\\site-packages\\paddle\\fluid\\reader.py:485: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\r\nWed Aug 17 14:46:42-WARNING: The old way to load inference model is deprecated. model path: D:\\dzkj\\PaddleSlim\\example\\auto_compression\\semantic_segmentation\\models\\ppseg_lite_portrait_398x224_with_softmax\\model.pdmodel, params path: D:\\dzkj\\PaddleSlim\\example\\auto_compression\\semantic_segmentation\\models\\ppseg_lite_portrait_398x224_with_softmax\\model.pdiparams\r\nW0817 14:46:42.415777  2076 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 3.7, Driver API Version: 10.2, Runtime API Version: 10.2\r\nW0817 14:46:42.431401  2076 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 181, in <module>\r\n    deploy_hardware=args.deploy_hardware)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddleGpu\\lib\\site-packages\\paddleslim-2.3.0-py3.7.egg\\paddleslim\\auto_compression\\compressor.py\", line 152, in __init__\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\paddleGpu\\lib\\site-packages\\paddleslim-2.3.0-py3.7.egg\\paddleslim\\auto_compression\\utils\\dataloader.py\", line 37, in wrap_dataloader\r\n  File \"run.py\", line 138, in gen\r\n    imgs = np.array(data[0])\r\nKeyError: 0\r\n![55](https://user-images.githubusercontent.com/6648329/185053814-0cc3466f-f8b6-4bce-abb7-d89e04c6c3fc.png)\r\n\r\n我138行打印：print(data) 返回的是这样的：\r\n{'trans_info': [[['padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding'], [<paddle.fluid.core_avx.Tensor object at 0x00000182DF1AFAB0>, <paddle.fluid.core_avx.Tensor object at 0x00000182DF05CE30>]], [['resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize', 'resize'], [<paddle.fluid.core_avx.Tensor object at 0x00000182DEE8AF30>, <paddle.fluid.core_avx.Tensor object at 0x00000182F9843430>]]], 'img': <paddle.fluid.core_avx.Tensor object at 0x00000182DF069B30>, 'label': <paddle.fluid.core_avx.Tensor object at 0x00000182DF2AF2B0>, 'gt_fields': [['label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label', 'label']]}\r\n\r\n------------------------\r\n\r\n还有另一个问题，不知道是不是这个问题导致一连串问题，就是：--config_path 没有这个参数，\r\n所以并不能用： python run.py --config_path='./configs/pp_humanseg/pp_humanseg_auto.yaml'  ，只能： python run.py\r\n![6666](https://user-images.githubusercontent.com/6648329/185057607-c9c34de6-c8b6-4852-a458-e1b789fcc751.jpg)\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "gg22mm",
        "closed_by": "gg22mm",
        "created_at": "2022-08-17T03:42:15+00:00",
        "updated_at": "2022-08-17T09:51:07+00:00",
        "closed_at": "2022-08-17T09:51:07+00:00",
        "comments_count": [
            "zzjjay",
            "gg22mm",
            "zzjjay",
            "gg22mm",
            "zzjjay",
            "gg22mm",
            "zzjjay",
            "gg22mm",
            "zzjjay",
            "gg22mm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1352,
        "title": "ImportError: cannot import name 'load_config' from 'paddleslim.common'",
        "body": "\r\n![image](https://user-images.githubusercontent.com/38728358/185031220-32e068ec-68fa-4fd7-a4e7-58567236a384.png)\r\n\r\n\r\nimport 失败\r\n安装了paddleslim 以及paddlepaddle 推理版本\r\n![image](https://user-images.githubusercontent.com/38728358/185031315-b405cb25-d599-4e7f-8c68-a9a5b76e424f.png)\r\n\r\n",
        "state": "closed",
        "user": "jo-dean",
        "closed_by": "jo-dean",
        "created_at": "2022-08-17T03:54:52+00:00",
        "updated_at": "2022-08-22T01:25:26+00:00",
        "closed_at": "2022-08-22T01:25:26+00:00",
        "comments_count": [
            "yghstill",
            "jo-dean",
            "yghstill",
            "jo-dean",
            "yghstill",
            "jo-dean",
            "jo-dean",
            "yghstill",
            "jo-dean"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1355,
        "title": "请问支持YOLOX么？",
        "body": null,
        "state": "closed",
        "user": "lixiangMindSpore",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-17T07:09:20+00:00",
        "updated_at": "2024-02-06T02:59:19+00:00",
        "closed_at": "2024-02-06T02:59:19+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1357,
        "title": "YOLOV7-tiny单卡和多卡训练，都按照默认的学习率么？",
        "body": "![image](https://user-images.githubusercontent.com/78945582/185080532-936ccea2-8207-43f0-ac32-f6355dad583f.png)\r\nYOLOV7-tiny单卡和多卡训练，都按照默认的学习率么？\r\n",
        "state": "closed",
        "user": "lixiangMindSpore",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-17T09:08:16+00:00",
        "updated_at": "2024-02-06T02:59:20+00:00",
        "closed_at": "2024-02-06T02:59:20+00:00",
        "comments_count": [
            "yghstill",
            "gutao0315",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1363,
        "title": "./configs/pp_liteseg/pp_liteseg_auto.yaml 模型配置没有运行成功",
        "body": "测试了下：有没模型配置没有运行成功\r\n\r\n#这个可以成功\r\npython run.py --config_path='./configs/pp_humanseg/pp_humanseg_auto.yaml' --save_dir='./save_compressed_model'\t  \r\n\r\n#这个没有成功 - NameError: name 'post_quant_hpo' is not defined\r\npython run.py --config_path='./configs/pp_liteseg/pp_liteseg_auto.yaml' --save_dir='./save_compressed_model'\t\r\n\r\n   \r\n![11111](https://user-images.githubusercontent.com/6648329/185360098-bd0bbfdf-6e3c-414c-8837-ef3764fb1e45.jpg)\r\n",
        "state": "closed",
        "user": "gg22mm",
        "closed_by": "gg22mm",
        "created_at": "2022-08-18T09:22:26+00:00",
        "updated_at": "2022-08-19T08:47:25+00:00",
        "closed_at": "2022-08-19T08:47:25+00:00",
        "comments_count": [
            "wanghaoshuang",
            "gg22mm",
            "wanghaoshuang",
            "gg22mm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1360,
        "title": "做分割模型图像抠图压缩遇到的问题",
        "body": "图片抠图用的是： https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.6/Matting    生成的模型25MB， 但是有点慢大概4秒时间，想通过压缩加速好提升速度，于似呼开始爬坑......\r\n\r\n1、看了语义分割模型自动压缩示例没找到关于“Matting ”的\r\n\thttps://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression/semantic_segmentation\r\n    打算自己添加一个：    \r\n          cd PaddleSlim/example/auto_compression/semantic_segmentation\r\n         \r\n![8888](https://user-images.githubusercontent.com/6648329/185308004-a9962957-0ee8-4478-8187-bdf8a11b6f6e.png)\r\n![99999](https://user-images.githubusercontent.com/6648329/185309187-f14b0b3a-66d5-4d2f-aaec-ef9f2a616292.png)\r\n\r\n其中自己添加配置：\r\n       configs/modnet/modnet-mobilenetv2_auto.yaml\r\n模型来自：\r\n            /models/modnet-mobilenetv2/    \r\n            生成模型是通过Matting  生成如下：\r\n                    cd PaddleSeg-release-2.6/Matting/\r\n                    python train.py --config configs/modnet/modnet-mobilenetv2.yml --do_eval --use_vdl --save_interval 30 --num_workers 0 --save_dir output\r\n                   python export.py --config configs/quick_start/modnet-mobilenetv2.yml --model_path ./weigth/modnet-mobilenetv2.pdparams  --save_dir ./inference_model\r\n                    \r\n2、模型压缩\r\n    因为与现有例子的语义分割数据格式是： \r\n               图片： JPEGImages\\1.png          蒙版：Annotations\\1.png  是这样种格式\r\n     而Matting只是这种格式： \r\n               图片data/tongue/val/fg/1.jpg     蒙版：没有在train.txt中，只需要把 fg 改成： alpha 就是蒙版图，所以下载：https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.6/paddleseg  目录放到 example/auto_compression/semantic_segmentation 目录下，并修改example/auto_compression/semantic_segmentation/paddleseg/datasets/dataset.py\r\n               修改如下图：\r\n\r\n![777777](https://user-images.githubusercontent.com/6648329/185310370-87f15a99-0de6-47bc-9578-9e8fbed46cbe.png)\r\n\r\n\r\n3、执行压缩\r\n  python run.py --config_path='./configs/modnet/modnet-mobilenetv2_auto.yaml' --save_dir='./save_compressed_model'\r\n\r\n报如下错：不知道怎么回事？ \r\n    \r\n![666666](https://user-images.githubusercontent.com/6648329/185313573-69de644e-dbb3-4ce2-b6d9-282571e7f825.png)\r\n\r\n\r\n建议官方用：Matting   做个例子 ，  太需要了....",
        "state": "closed",
        "user": "gg22mm",
        "closed_by": "gg22mm",
        "created_at": "2022-08-18T06:39:50+00:00",
        "updated_at": "2022-08-18T07:52:00+00:00",
        "closed_at": "2022-08-18T07:52:00+00:00",
        "comments_count": [
            "zzjjay",
            "gg22mm"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1389
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1385,
        "title": "8月22日-YOLO系列模型-自动压缩及部署 直播活动交流问题",
        "body": "YOLOv5、YOLOv6、YOLOv7、PP-YOLOE的自动压缩及部署\r\n1.直播视频回放链接：https://www.bilibili.com/video/BV11Y4y1F751?spm_id_from=333.337.search-card.all.click\r\n2.自动压缩工具：https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression\r\n3.量化分析工具：https://github.com/PaddlePaddle/PaddleSlim/blob/develop/example/post_training_quantization/analysis.md\r\n4.直播过程YOLOv7手把手教程：https://aistudio.baidu.com/aistudio/projectdetail/4443717\r\n\r\n- 【问题一】add和concat量化不？需要保证不同分支量化参数统一不？\r\nadd和concat不做量化，默认对conv和fc做量化。模型如果有多个分支，需要统一量化参数。\r\n\r\n- 【问题二】如何理解大量值为0是不利于scale统计；只是大量接近0，大量接近0+较多离群点=量化不友好\r\n0附近的数据太多，这个范围内的数值映射范围是固定的，所以数值越多，精度损失越大。量化分析工作还在探索中，会持续总结更多影响量化的因素。\r\n\r\n- 【问题三】Paddle TensorRT\r\npaddle trt子图接了trt，可以直接读Paddle模型。\r\n\r\n- 【问提四】量化后的模型，在电脑上跑速度提升了，在手机上速度反而慢了，怎么回事呀\r\n具体需要看使用的预测库对量化的支持情况，因为量化是部分层量化（conv、fc），量化后多出了数据类型转换操作，导致预测速度不降反升。\r\n\r\n更多问题，欢迎issue交流。",
        "state": "closed",
        "user": "leiqing1",
        "closed_by": "XGZhang11",
        "created_at": "2022-08-22T12:25:59+00:00",
        "updated_at": "2024-02-06T03:30:46+00:00",
        "closed_at": "2024-02-06T03:30:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1367,
        "title": "在windows上安装PaddleSlim失败，报swig error",
        "body": "  Attempting uninstall: tornado\r\n    Found existing installation: tornado 6.2\r\n    Uninstalling tornado-6.2:\r\n      Successfully uninstalled tornado-6.2\r\n  Running setup.py install for pyrfr ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  × Running setup.py install for pyrfr did not run successfully.\r\n  │ exit code: 1\r\n  ╰─> [9 lines of output]\r\n      [<setuptools.extension.Extension('pyrfr._regression') at 0x2854db53400>, <setuptools.extension.Extension('pyrfr._util') at 0x2854dcf2220>]\r\n      running install\r\n      C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n        warnings.warn(\r\n      running build_ext\r\n      building 'pyrfr._regression' extension\r\n      swigging pyrfr/regression.i to pyrfr/regression_wrap.cpp\r\n      swig.exe -python -c++ -modern -py3 -features nondynamic -I./include -o pyrfr/regression_wrap.cpp pyrfr/regression.i\r\n      error: command 'swig.exe' failed: None\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: legacy-install-failure\r\n\r\n× Encountered error while trying to install package.\r\n╰─> pyrfr\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for output from the failure.\r\n\r\n\r\n使用pip install PaddleSlim安装,结果报错,上面是错误提示.使用PaddleSlim官方的安装教程安装,依然报错,也是同样的报错提示.\r\npaddlegpu是2.3.2,cuda10.2版本,970显卡,windows11系统,64位.",
        "state": "closed",
        "user": "yuwoyizhan",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-18T13:21:06+00:00",
        "updated_at": "2024-02-06T02:59:21+00:00",
        "closed_at": "2024-02-06T02:59:21+00:00",
        "comments_count": [
            "wanghaoshuang",
            "yuwoyizhan",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1366,
        "title": "关于直接修改源码获得train_loader 并自动压缩问题",
        "body": "1、通过文档：https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression 我们知道 只要传入相应该的train_loader 即可\"运行自动化压缩\" 如图：\r\n![1](https://user-images.githubusercontent.com/6648329/185398649-66a6cadd-5087-49b6-8c82-fc23736fd339.png)\r\n\r\n2、实战：\r\n     下载：https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.6/Matting\r\n      修改：  PaddleSeg/Matting/core/train.py  ， 可以直接下载：[PaddleSeg/Matting/core/tarin.py](http://ztg.diyyq.com/train.txt)\r\n      \r\n      顶部引入：\r\n            # 快速压缩模型 - 运行自动化压缩\r\n            from paddleslim.auto_compression import AutoCompression\r\n           # paddle.enable_static()\r\n\r\n     添加如下图：\r\n![2](https://user-images.githubusercontent.com/6648329/185399639-18520241-4ff8-4471-91ef-6b7234fc7e97.png)\r\n\r\n3、运行\r\npython train.py --config configs/modnet/modnet-mobilenetv2.yml --do_eval --use_vdl --save_interval 30 --num_workers 0 --save_dir output\r\n\r\n\r\n报如下错是怎么回事？：\r\n\r\n![3](https://user-images.githubusercontent.com/6648329/185400278-cbb64da6-b5fd-46d4-93bf-b9e2c174d594.png)\r\n\r\nAutoCompression   是不是要传固定样式的 dataloader  ?\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "gg22mm",
        "closed_by": "gg22mm",
        "created_at": "2022-08-18T12:57:48+00:00",
        "updated_at": "2022-08-19T08:24:28+00:00",
        "closed_at": "2022-08-19T08:18:21+00:00",
        "comments_count": [
            "wanghaoshuang",
            "gg22mm",
            "wanghaoshuang",
            "gg22mm",
            "wanghaoshuang",
            "gg22mm",
            "wanghaoshuang",
            "gg22mm"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1382,
        "title": "使用 paddledetection train出来的yolox auto_compression 发现有问题",
        "body": "<img width=\"989\" alt=\"截屏2022-08-22 17 44 11\" src=\"https://user-images.githubusercontent.com/15171817/185891820-4a9fcc99-d31f-4074-b13b-d2c48b26d8f7.png\">\r\n命令: usr/bin/python -u /PaddleSlim/example/auto_compression/pytorch_yolo_series/run.py --config_path=./configs/yolov5s_qat_dis.yaml --save_dir='./output/'\r\n<img width=\"774\" alt=\"截屏2022-08-22 17 45 39\" src=\"https://user-images.githubusercontent.com/15171817/185892104-316542a8-2ee9-413a-9054-9598552576d5.png\">\r\n\r\n",
        "state": "closed",
        "user": "JackYang825",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-22T09:44:01+00:00",
        "updated_at": "2024-02-06T02:59:22+00:00",
        "closed_at": "2024-02-06T02:59:22+00:00",
        "comments_count": [
            "yghstill",
            "lyuwenyu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1386,
        "title": "如何用自己训练的模型进行量化。",
        "body": "我用的是芯原的产品，在学习PaddleSlim-quant-demo.tar.gz  这个demo 时，model里的模型跟paddledection 里训练好的模型(如pdmodel 和pdiparams) 格式似乎不一样，去运行自己训练好的模型作量化时就报错了，运行demo里的mobilenet_v1 和 resnet50时是正确的，用自己的训练 好的模型做静态量化时还需要注意什么？  谢谢 ",
        "state": "closed",
        "user": "Genlk",
        "closed_by": "Genlk",
        "created_at": "2022-08-22T13:35:55+00:00",
        "updated_at": "2022-08-24T02:48:18+00:00",
        "closed_at": "2022-08-24T02:48:18+00:00",
        "comments_count": [
            "Genlk",
            "yghstill",
            "Genlk",
            "Genlk",
            "yghstill",
            "yghstill",
            "Genlk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1401,
        "title": "如何量化LSTM层",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/issues/937\r\n在这个issue中说到静态模型的静态量化支持LSTM层\r\n但是在静态模型中LSTM被转换成了如下图所示的rnn等op操作，量化时并没有lstm这个op，导致最终lstm层并没有量化\r\n而rnn这个op又不支持量化，如果想要量化lstm的话该如何量化呢\r\n![image](https://user-images.githubusercontent.com/75289802/187362533-955e7fe9-e983-471c-b37a-b63a7ff547ff.png)\r\n",
        "state": "closed",
        "user": "qiuming-93",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-30T06:11:15+00:00",
        "updated_at": "2024-02-06T02:59:23+00:00",
        "closed_at": "2024-02-06T02:59:23+00:00",
        "comments_count": [
            "yghstill",
            "qiuming-93",
            "yghstill",
            "leiqing1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1395,
        "title": "Does paddleslim support generating task models? ",
        "body": "Does paddleslim support generating task models?  Prepare to compress the translation model trained by fairseq, such as distillation and pruning. Can you give me some advice?\r\nThank U.",
        "state": "closed",
        "user": "AIikai",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-08-26T01:24:13+00:00",
        "updated_at": "2024-02-06T02:59:23+00:00",
        "closed_at": "2024-02-06T02:59:22+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1402,
        "title": "paddle.static.Executor执行channel-wise量化模型速度异常",
        "body": "## 问题\r\n\r\n### [paddle.static.Executor](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/static/Executor_cn.html#executor)执行量化模型，在channel-wise模式下，速度异常慢。\r\n\r\n解决方法：优化fake dequant kernel\r\n\r\n### 复现方式\r\n根据自动化压缩示例: https://github.com/PaddlePaddle/PaddleSlim/tree/v2.3.4/example/auto_compression/nlp\r\n将配置文件./configs/pp-minilm/auto/afqmc.yaml修改为如下，只执行量化训练，产出量化 模型：\r\n```\r\nGlobal:\r\n  model_dir: ./afqmc/\r\n  model_filename: inference.pdmodel\r\n  params_filename: inference.pdiparams\r\n  task_name: afqmc\r\n  dataset: clue\r\n  batch_size: 16\r\n  max_seq_length: 128\r\nQuantization:\r\nDistillation:\r\nTrainConfig:\r\n  epochs: 1\r\n  eval_iter: 1070\r\n  learning_rate: 2.0e-5\r\n  optimizer_builder:\r\n    optimizer: \r\n      type: AdamW\r\n    weight_decay: 0.01\r\n  origin_metric: 0.7403\r\n```\r\n执行eval, 发现速度很慢：\r\n```\r\nexport CUDA_VISIBLE_DEVICES=0\r\npython run.py --config_path='./configs/pp-minilm/auto/afqmc.yaml'  --eval True\r\n```\r\n\r\n## 分析\r\n基于上述自动化压缩示例，通过[profiler工具](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/profiler/Profiler_cn.html#profiler)分析结果如下：\r\n![image](https://user-images.githubusercontent.com/7534971/187627030-292b0e3f-7c07-4566-910b-ad3c511bd5e2.png)\r\n\r\n**其中，DequantizeTwoScale执行时间明显异常**\r\n\r\n## 解决方案\r\n优化[DequantizeTwoScale](https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/fake_dequantize_op.cu.h#L154)\r\n建议参考：https://github.com/PaddlePaddle/Paddle/pull/40772\r\n\r\n在PR#40772中，只优化了channel-wise量化训练的速度，对fake量化推理不生效。\r\n因为，在[freeze pass](https://github.com/PaddlePaddle/Paddle/blob/v2.3.2/python/paddle/fluid/contrib/slim/quantization/quantization_pass.py#L930)之前，量化训练网络中的dequant op的scale是一个输入，在freeze pass之后，推理网络中的dequant op的scale设置成了两个输入。先后两种情况，命中的kernel不同。\r\n\r\n## 补充\r\n\r\n如下图所示，fake_channel_wise_dequantize_max_abs的scales有两个输入，应该分别是weights的scales和input scale.\r\n1. 为什么不能将两个scale乘在一起？是为了推理库的pass更方便的获取到weights scales?\r\n2. 设置这两个scales的代码在哪里？\r\n- 在这里：[_insert_post_channel_dequant_op(](https://github.com/PaddlePaddle/Paddle/blob/1b0b253d58bc4fb7989ddde4b8761d2dd671085b/python/paddle/fluid/contrib/slim/quantization/quantization_pass.py#L1110)\r\n\r\n![image](https://user-images.githubusercontent.com/7534971/187620126-ad119495-80a4-40ac-b866-7cf53f0deb86.png)\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2022-08-31T07:41:49+00:00",
        "updated_at": "2022-09-06T05:40:19+00:00",
        "closed_at": "2022-09-06T05:40:19+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1403,
        "title": "机器翻译模型压缩优化问题",
        "body": "你好！\r\n我用paddlenlp/examples/machine_translator/transformer的train.py程序训练了一个翻译模型，想压缩优化下，请问\r\npaddleslim哪种工具可以有效优化transformer模型（压缩，提速等）？",
        "state": "closed",
        "user": "dlkht",
        "closed_by": "XGZhang11",
        "created_at": "2022-09-01T05:59:24+00:00",
        "updated_at": "2024-02-06T03:30:14+00:00",
        "closed_at": "2024-02-06T03:30:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1405,
        "title": "auto_compression/pytorch_yolo_serie环境配置不成功，一直run不成功 ",
        "body": "/PaddleSlim/example/auto_compression/pytorch_yolo_series\r\n\r\n2022-09-02 10:39:31,795-INFO: Now translating model from onnx to paddle.\r\n2022-09-02 10:39:31,795-WARNING: __init__() missing 1 required positional argument: 'enable_onnx_checker'\r\n2022-09-02 10:39:31,795-ERROR: x2paddle threw an exception, you can ask for help at: https://github.com/PaddlePaddle/X2Paddle/issues\r\n\r\n您好  使用slim中的自动压缩模块做yolo蒸馏，第一次使用，环境总是配置不好。重新安装了paddle和git 最新的X2Paddle安装。还是报这个错。\r\n请问怎么解决 谢谢",
        "state": "closed",
        "user": "shituo123456",
        "closed_by": "shituo123456",
        "created_at": "2022-09-02T02:42:27+00:00",
        "updated_at": "2022-09-02T02:43:52+00:00",
        "closed_at": "2022-09-02T02:43:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1406,
        "title": "auto_compression/pytorch_yolo_series 无法run成功",
        "body": "       \r\n按照官方教程配置好环境后，报如下错：\r\n\r\nNow, onnx2paddle support convert onnx model opset_verison [9],opset_verison of your onnx model is 12, automatically treated as op_set: 9.\r\nTotal nodes: 248\r\nNodes converting ...\r\nConverting node 327 ...     2022-09-02 10:36:26,643-WARNING: convert failed node:onnx__Concat_271, op_type is Resize\r\n2022-09-02 10:36:26,643-ERROR: x2paddle threw an exception, you can ask for help \r\n\r\n按照 https://github.com/PaddlePaddle/X2Paddle/issues/494 的方法重新配置x2paddle后，又报如下错：\r\n\r\n2022-09-02 10:39:31,795-INFO: Now translating model from onnx to paddle.\r\n2022-09-02 10:39:31,795-WARNING: __init__() missing 1 required positional argument: 'enable_onnx_checker'\r\n2022-09-02 10:39:31,795-ERROR: x2paddle threw an exception, you can ask for help at: https://github.com/PaddlePaddle/X2Paddle/issues\r\n\r\n目前这个问题找不到解决方法。麻烦看一下 谢谢\r\n",
        "state": "closed",
        "user": "shituo123456",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-09-02T02:46:14+00:00",
        "updated_at": "2024-02-06T02:59:24+00:00",
        "closed_at": "2024-02-06T02:59:24+00:00",
        "comments_count": [
            "leiqing1",
            "yghstill",
            "shituo123456",
            "ginalee828",
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1418,
        "title": "paddlelite 支持int8预测吗？",
        "body": "paddlelite 支持int8预测吗？",
        "state": "closed",
        "user": "wchuan163",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-09-11T05:55:46+00:00",
        "updated_at": "2024-02-06T02:59:25+00:00",
        "closed_at": "2024-02-06T02:59:25+00:00",
        "comments_count": [
            "yghstill",
            "wchuan163",
            "yghstill",
            "leiqing1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1422,
        "title": "solov2自动压缩失败",
        "body": "环境:\r\nPaddleDetection 2.5\r\nPaddleSlim 2.3.4\r\nubuntu 20.04\r\ncuda 11.1\r\n用PaddleDetection训练solov2，之后导出模型，导出命令如下\r\npython tools/export_model.py -c configs/solov2/solov2_r50_enhance_symhua_coco.yml --output_dir=./inference_model\r\n -o weights=resume/best_model\r\n然后根据部署的auto_compression的文档说明，配置了相关的文件，之后执行\r\npython run.py --config_path=./configs/solov2_qat_dis.yaml --save_dir='./output/'\r\n报错\r\n(PPSolov2) root@hof-System-Product-Name:/mnt/myDisk/deepLearn/PaddleDetection/PaddleDetection/deploy/auto_compression# python run.py --config_path=./configs/solov2_qat_dis.yaml --save_dir='./output/'\r\n-----------  Running Arguments -----------\r\n Distillation:\r\n\t alpha: 1.0\r\n\t loss: soft_label\r\n Global:\r\n\t Evaluation: True\r\n\t input_list: ['image', 'scale_factor']\r\n\t model_dir: ./solov2_r50_enhance_symhua_coco\r\n\t model_filename: model.pdmodel\r\n\t params_filename: model.pdiparams\r\n\t reader_config: configs/solov2_reader.yml\r\n Quantization:\r\n\t activation_quantize_type: moving_average_abs_max\r\n\t quantize_op_types: ['conv2d', 'depthwise_conv2d']\r\n\t use_pact: True\r\n TrainConfig:\r\n\t eval_iter: 1000\r\n\t learning_rate:\r\n\t\t T_max: 6000\r\n\t\t learning_rate: 0.00125\r\n\t\t type: CosineAnnealingDecay\r\n\t optimizer_builder:\r\n\t\t optimizer:\r\n\t\t\t type: SGD\r\n\t\t weight_decay: 4e-05\r\n\t train_iter: 5000\r\n------------------------------------------\r\nloading annotations into memory...\r\nDone (t=0.01s)\r\ncreating index...\r\nindex created!\r\nW0917 10:08:10.872013 3000434 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.1\r\nW0917 10:08:10.875550 3000434 gpu_resources.cc:91] device: 0, cuDNN Version: 8.0.\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\n2022-09-17 10:08:14,268-INFO: devices: gpu\r\n2022-09-17 10:08:30,781-INFO: Detect model type: None\r\n2022-09-17 10:08:31,491-INFO: Selected strategies: ['qat_dis']\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 183, in <module>\r\n    main()\r\n  File \"run.py\", line 173, in main\r\n    ac.compress()\r\n  File \"/root/anaconda3/envs/PPSolov2/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 569, in compress\r\n    train_config)\r\n  File \"/root/anaconda3/envs/PPSolov2/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 704, in single_strategy_compress\r\n    default_distill_node_pair, strategy, config, train_config)\r\n  File \"/root/anaconda3/envs/PPSolov2/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 493, in _prepare_program\r\n    default_distill_node_pair=default_distill_node_pair)\r\n  File \"/root/anaconda3/envs/PPSolov2/lib/python3.7/site-packages/paddleslim/auto_compression/create_compressed_program.py\", line 273, in build_distill_program\r\n    feed_target_names=feed_target_names)\r\n  File \"/root/anaconda3/envs/PPSolov2/lib/python3.7/site-packages/paddleslim/auto_compression/create_compressed_program.py\", line 197, in _load_program_and_merge\r\n    merge_feed=merge_feed)\r\n  File \"/root/anaconda3/envs/PPSolov2/lib/python3.7/site-packages/paddleslim/dist/single_distiller.py\", line 73, in merge\r\n    teacher_var.name, new_name)\r\n  File \"/root/anaconda3/envs/PPSolov2/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3456, in _rename_var\r\n    raise ValueError(\"var %s is not in current block\" % name)\r\nValueError: var top_k_v2_0.tmp_1 is not in current block\r\n\r\nsolov2_qat_dis.yaml的配置如下\r\n\r\nGlobal:\r\n  reader_config: configs/solov2_reader.yml\r\n  input_list: ['image', 'scale_factor']\r\n  Evaluation: True\r\n  model_dir: ./solov2_r50_enhance_symhua_coco\r\n  model_filename: model.pdmodel\r\n  params_filename: model.pdiparams\r\n\r\nDistillation:\r\n  alpha: 1.0\r\n  loss: soft_label\r\n\r\nQuantization:\r\n  use_pact: true\r\n  activation_quantize_type: 'moving_average_abs_max'\r\n  quantize_op_types:\r\n  - conv2d\r\n  - depthwise_conv2d\r\n\r\nTrainConfig:\r\n  train_iter: 5000\r\n  eval_iter: 1000\r\n  learning_rate:  \r\n    type: CosineAnnealingDecay\r\n    learning_rate: 0.00125\r\n    T_max: 6000\r\n  optimizer_builder:\r\n    optimizer: \r\n      type: SGD\r\n    weight_decay: 4.0e-05\r\n\r\nsolov2_reader.yml的配置如下\r\nmetric: COCO\r\nnum_classes: 7\r\n\r\n# Datset configuration\r\nTrainDataset:\r\n  !COCODataSet\r\n    image_dir: train2017\r\n    anno_path: annotations/instances_train2017.json\r\n    dataset_dir: data/coco/\r\n\r\nEvalDataset:\r\n  !COCODataSet\r\n    image_dir: val2017\r\n    anno_path: annotations/instances_val2017.json\r\n    dataset_dir: data/coco/\r\n\r\nworker_num: 2\r\n\r\n# preprocess reader in test\r\nEvalReader:\r\n  sample_transforms:\r\n    - Decode: {}\r\n    - Resize: {target_size: [640, 640], keep_ratio: False, interp: 2}\r\n    - NormalizeImage: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225], is_scale: True}\r\n    - Permute: {}\r\n  batch_size: 4\r\n帮忙看一下是什么原因造成的",
        "state": "closed",
        "user": "hf62580",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-09-17T02:19:42+00:00",
        "updated_at": "2024-02-06T02:59:26+00:00",
        "closed_at": "2024-02-06T02:59:26+00:00",
        "comments_count": [
            "ceci3",
            "hf62580",
            "ceci3",
            "hf62580",
            "ceci3",
            "hf62580",
            "yghstill",
            "dijiupianhai9",
            "dijiupianhai9"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1429,
        "title": "自动化压缩处理完之后 可以部署到tf serving中使用吗",
        "body": null,
        "state": "closed",
        "user": "qiu-pinggaizi",
        "closed_by": "XGZhang11",
        "created_at": "2022-09-21T11:05:37+00:00",
        "updated_at": "2024-02-06T03:29:51+00:00",
        "closed_at": "2024-02-06T03:29:51+00:00",
        "comments_count": [
            "leiqing1",
            "qiu-pinggaizi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1431,
        "title": "cannot import quant_post function",
        "body": ">请问 用了paddleslim2.3.0以上，name 'post_quant_hpo' is not defined 提示 cannot import name 'quant_post' from 'paddleslim.quant' (/opt/python37/lib/python3.7/site-packages/paddleslim/quant/__init__.py)\r\n\r\n以上问题的一个原因是：\r\n\r\nPaddleSlim >= 2.3.0版本，需要依赖 PaddlePaddle >= 2.3.0。相关代码在这里：[code](https://github.com/PaddlePaddle/PaddleSlim/blob/v2.3.4/paddleslim/quant/__init__.py#L25)\r\nPaddlePaddle 2.3.0rc0不符合以上依赖要求。\r\n建议升级PaddlePaddle  [安装教程](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/linux-pip.html)",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2022-09-23T01:27:51+00:00",
        "updated_at": "2024-02-06T03:29:01+00:00",
        "closed_at": "2024-02-06T03:29:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1444,
        "title": "tensor is not found error in plot_activation_distribution of AnalysisQuant",
        "body": "## 问题\r\n\r\n如上图所示，在调用`plot_activation_distribution`方式，在scope未找到变量。\r\n\r\n<img width=\"1191\" alt=\"image\" src=\"https://user-images.githubusercontent.com/7534971/193178392-89bc7421-0eb5-4213-b1d0-42a7351d502c.png\">\r\n\r\n## 原因\r\n\r\n初步猜测，原因是在AnalysisQuant的初始化方法中注释掉了eval_function的调用逻辑，导致模型没有被执行，某些变量没有在scope中构造。注释掉eval_function的代码如下：\r\n```\r\n# create data_loader\r\n        self.data_loader = wrap_dataloader(data_loader, self.feed_list)\r\n\r\n        # evaluate before quant \r\n        # TODO: self.eval_function can be None\r\n        # if self.eval_function is not None:\r\n        #     self.base_metric = self.eval_function(\r\n        #         executor, program, self.feed_list, self.fetch_list)\r\n        #     _logger.info('Before quantized, the accuracy of the model is: {}'.\r\n        #                  format(self.base_metric))\r\n\r\n        # quant and evaluate after quant (skip_list = None)\r\n        post_training_quantization = PostTrainingQuantization(\r\n            executor=executor,\r\n            data_loader=self.data_loader,\r\n            model_dir=self.model_dir,\r\n            model_filename=self.model_filename,\r\n            params_filename=self.params_filename,\r\n            skip_tensor_list=None,\r\n            algo='avg',  #fastest\r\n            **self.ptq_config)\r\n        program = post_training_quantization.quantize()\r\n        # self.quant_metric = self.eval_function(executor, program,\r\n        #                                        self.feed_list, self.fetch_list)\r\n        # _logger.info('After quantized, the accuracy of the model is: {}'.format(\r\n        #     self.quant_metric))\r\n\r\n        # get quantized weight and act var name\r\n        self.quantized_weight_var_name = post_training_quantization._quantized_weight_var_name\r\n        self.quantized_act_var_name = post_training_quantization._quantized_act_var_name\r\n        executor.close()\r\n```\r\n\r\n## 解决办法\r\n\r\n给AnalysisQuant传递eval_function.\r\n\r\n## 本质问题\r\n\r\n当前AnalysisQuant的实现有问题：\r\n- 没有对eval_function=None做检查，需要及时抛出异常，并给出可读的错误提示和建议\r\n- 单测覆盖不够\r\n- AnalysisQuant功能设计和代码组织不够简洁清晰",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2022-09-30T02:51:01+00:00",
        "updated_at": "2024-02-06T03:27:42+00:00",
        "closed_at": "2024-02-06T03:27:42+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1445,
        "title": "AnalysisQuant设计问题",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/fe33833a6009ad1f2414a310039406c5366b80da/paddleslim/quant/analysis.py\r\n\r\n这个功能能再简化一下么？\r\n\r\n1. 初始化方法里调用离线量化+eval_function，合适么？\r\n2. plot_activation_distribution、calculate_histogram等方法是不是可以拆到common package? 这和量化也不是强相关吧？\r\n\r\n总之，AnalysisQuant定位不太清晰，主要是做Analysis，还是Quant?",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2022-09-30T03:04:04+00:00",
        "updated_at": "2024-02-06T03:27:25+00:00",
        "closed_at": "2024-02-06T03:27:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1434,
        "title": "PaddleX训练的模型使用paddleslim量化报错",
        "body": "我在使用paddlex训练完成我自己的mobilenetv1模型后，参考https://paddle-lite.readthedocs.io/zh/develop/demo_guides/verisilicon_timvx.html\r\n这个文档进行模型量化，是基于npu的模型量化，遇到了如下问题\r\n![image](https://user-images.githubusercontent.com/74920047/192414646-d0886a52-78a9-48d9-81b6-d67e90ab6115.png)\r\n看了原先其他人的讲法是paddleslim的版本过旧，那基于这个paddlelite npusoc的paddleslim量化方式建议同步改进，或者能否告诉我如何使用现有的模型进行转化",
        "state": "closed",
        "user": "Hyperpepe",
        "closed_by": "XGZhang11",
        "created_at": "2022-09-27T02:08:48+00:00",
        "updated_at": "2024-02-06T03:28:32+00:00",
        "closed_at": "2024-02-06T03:28:32+00:00",
        "comments_count": [
            "yghstill",
            "Hyperpepe"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1442,
        "title": "采用paddleslim静态离线量化api ，quant_post_static(), 量化之后，送入paddlelite进行推理，出现op_info->Hasinputscale（） check failed",
        "body": "具体问题如图所示\r\n\r\n<img width=\"796\" alt=\"截屏2022-09-28 下午9 33 15\" src=\"https://user-images.githubusercontent.com/55530624/192961586-71f615aa-6470-41ab-ae5d-ca59ea3bf75c.png\">\r\n\r\n",
        "state": "closed",
        "user": "tomtcy",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-09-29T06:59:06+00:00",
        "updated_at": "2024-02-06T02:59:27+00:00",
        "closed_at": "2024-02-06T02:59:27+00:00",
        "comments_count": [
            "wanghaoshuang",
            "tomtcy",
            "wanghaoshuang",
            "jiangjiajun",
            "wanghaoshuang",
            "yeliang2258",
            "hong19860320"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1446,
        "title": "mul 剪枝过程中不支持的情况",
        "body": "#  mul 稀疏化（剪枝）问题汇总\r\n\r\n## Case 1\r\n假设矩阵X的形状为[a, b, c], 矩阵 Y的shape为[d, e, f]\r\n当矩阵X的num_col_dims=1时，意思是将X平铺为shape为[a, b*c]的矩阵X'\r\n当矩阵X的num_col_dims=2时，意思是将Y平铺为shape为[d*e, f]]的矩阵Y'\r\n\r\n当前对矩阵乘X' * Y'的Y’进行剪枝时：\r\n- 在f维度上剪枝，即剪裁column，则X'不受影响\r\n- 在d或e维度上剪枝，即剪裁rows，则需要调整X'的column。如上，X'的column为b*c。此时，不好判断如何调整b或c，故跳过该情况，不与支持。\r\n\r\n检查以上逻辑的代码如下：\r\nhttps://github.com/PaddlePaddle/PaddleSlim/blob/4d75cb9cecf5a02e789576b0c02ce7376615dafd/paddleslim/prune/prune_worker.py#L612-L613",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2022-10-08T06:50:23+00:00",
        "updated_at": "2024-02-06T03:27:14+00:00",
        "closed_at": "2024-02-06T03:27:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1453,
        "title": "Compress ERNIE model from paddlepaddle1.8 with ACT ",
        "body": "![f68026f85972966f2acbb9d94d0aa5cb](https://user-images.githubusercontent.com/7534971/194797611-5d0e178e-27bd-4afe-9079-82899e8f62b7.png)\r\n\r\n![3e26d3a6eec9a3a7e3aa36dec6ff66a9](https://user-images.githubusercontent.com/7534971/194797627-b9f6ff19-dc28-4c90-9f36-ec46303a6a10.png)\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2022-10-10T04:00:49+00:00",
        "updated_at": "2024-02-06T03:26:53+00:00",
        "closed_at": "2024-02-06T03:26:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1448,
        "title": "示例代码运行错误及修改",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression\r\n快速开始\r\n* 3\r\n\r\nCUDA_VISIBLE_DEVICES=0 python ./image_classification/eval.py\r\n中使用了Global传参，但是eval.yaml中没有该参数，会直接报错。建议修改。\r\n\r\n还有这里并没有git clone仓库 切换目录的过程，按照该流程无法直接运行得到eval结果。建议添加。\r\n",
        "state": "closed",
        "user": "xu-peng-7",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-10-09T02:41:22+00:00",
        "updated_at": "2024-02-06T02:59:28+00:00",
        "closed_at": "2024-02-06T02:59:28+00:00",
        "comments_count": [
            "leiqing1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1456,
        "title": "Error when prune: __init__() missing 1 required positional argument: 'out_channels_list'",
        "body": "[2022/10/11 09:10:12] ppocr INFO: Architecture : \r\n[2022/10/11 09:10:12] ppocr INFO:     Backbone : \r\n[2022/10/11 09:10:12] ppocr INFO:         last_conv_stride : [1, 2]\r\n[2022/10/11 09:10:12] ppocr INFO:         last_pool_type : avg\r\n[2022/10/11 09:10:12] ppocr INFO:         name : MobileNetV1Enhance\r\n[2022/10/11 09:10:12] ppocr INFO:         scale : 0.5\r\n[2022/10/11 09:10:12] ppocr INFO:     Head :\r\n[2022/10/11 09:10:12] ppocr INFO:         head_list :\r\n[2022/10/11 09:10:12] ppocr INFO:             CTCHead :\r\n[2022/10/11 09:10:12] ppocr INFO:                 Head :\r\n[2022/10/11 09:10:12] ppocr INFO:                     fc_decay : 1e-05\r\n[2022/10/11 09:10:12] ppocr INFO:                 Neck :\r\n[2022/10/11 09:10:12] ppocr INFO:                     depth : 2\r\n[2022/10/11 09:10:12] ppocr INFO:                     dims : 64\r\n[2022/10/11 09:10:12] ppocr INFO:                     hidden_dims : 120\r\n[2022/10/11 09:10:12] ppocr INFO:                     name : svtr\r\n[2022/10/11 09:10:12] ppocr INFO:                     use_guide : True\r\n[2022/10/11 09:10:12] ppocr INFO:             SARHead :\r\n[2022/10/11 09:10:12] ppocr INFO:                 enc_dim : 512\r\n[2022/10/11 09:10:12] ppocr INFO:                 max_text_length : 25\r\n[2022/10/11 09:10:12] ppocr INFO:         name : MultiHead\r\n[2022/10/11 09:10:12] ppocr INFO:     Transform : None\r\n[2022/10/11 09:10:12] ppocr INFO:     algorithm : SVTR\r\n[2022/10/11 09:10:12] ppocr INFO:     model_type : rec\r\n[2022/10/11 09:10:12] ppocr INFO: Eval :\r\n[2022/10/11 09:10:12] ppocr INFO:     dataset :\r\n[2022/10/11 09:10:12] ppocr INFO:         data_dir : ./project\r\n[2022/10/11 09:10:12] ppocr INFO:         label_file_list : ['./project/train_data/rec/val.txt']\r\n[2022/10/11 09:10:12] ppocr INFO:         name : SimpleDataSet\r\n[2022/10/11 09:10:12] ppocr INFO:         transforms :\r\n[2022/10/11 09:10:12] ppocr INFO:             DecodeImage :\r\n[2022/10/11 09:10:12] ppocr INFO:                 channel_first : False\r\n[2022/10/11 09:10:12] ppocr INFO:                 img_mode : BGR\r\n[2022/10/11 09:10:12] ppocr INFO:             MultiLabelEncode : None\r\n[2022/10/11 09:10:12] ppocr INFO:             RecResizeImg :\r\n[2022/10/11 09:10:12] ppocr INFO:                 image_shape : [3, 48, 160]\r\n[2022/10/11 09:10:12] ppocr INFO:             KeepKeys :\r\n[2022/10/11 09:10:12] ppocr INFO:                 keep_keys : ['image', 'label_ctc', 'label_sar', 'length', 'valid_ratio']\r\n[2022/10/11 09:10:12] ppocr INFO:     loader :\r\n[2022/10/11 09:10:12] ppocr INFO:         batch_size_per_card : 32\r\n[2022/10/11 09:10:12] ppocr INFO:         drop_last : False\r\n[2022/10/11 09:10:12] ppocr INFO:         num_workers : 4\r\n[2022/10/11 09:10:12] ppocr INFO:         shuffle : False\r\n[2022/10/11 09:10:12] ppocr INFO: Global :\r\n[2022/10/11 09:10:12] ppocr INFO:     cal_metric_during_train : True\r\n[2022/10/11 09:10:12] ppocr INFO:     character_dict_path : project/dict.txt\r\n[2022/10/11 09:10:12] ppocr INFO:     checkpoints : project/rec_model/best_accuracy\r\n[2022/10/11 09:10:12] ppocr INFO:     debug : False\r\n[2022/10/11 09:10:12] ppocr INFO:     distributed : False\r\n[2022/10/11 09:10:12] ppocr INFO:     epoch_num : 500\r\n[2022/10/11 09:10:12] ppocr INFO:     eval_batch_step : [0, 2000]\r\n[2022/10/11 09:10:12] ppocr INFO:     infer_img : doc/imgs_words/ch/word_1.jpg\r\n[2022/10/11 09:10:12] ppocr INFO:     infer_mode : False\r\n[2022/10/11 09:10:12] ppocr INFO:     log_smooth_window : 20\r\n[2022/10/11 09:10:12] ppocr INFO:     max_text_length : 25\r\n[2022/10/11 09:10:12] ppocr INFO:     pretrained_model : project/rec_model/best_accuracy\r\n[2022/10/11 09:10:12] ppocr INFO:     print_batch_step : 10\r\n[2022/10/11 09:10:12] ppocr INFO:     save_epoch_step : 100\r\n[2022/10/11 09:10:12] ppocr INFO:     save_inference_dir : project/rec_model/inference\r\n[2022/10/11 09:10:12] ppocr INFO:     save_model_dir : ./project/rec_model/prune_model/\r\n[2022/10/11 09:10:12] ppocr INFO:     save_res_path : ./output/rec1/predicts_ppocrv3_en.txt\r\n[2022/10/11 09:10:12] ppocr INFO:     use_gpu : True\r\n[2022/10/11 09:10:12] ppocr INFO:     use_space_char : True\r\n[2022/10/11 09:10:12] ppocr INFO:     use_visualdl : False\r\n[2022/10/11 09:10:12] ppocr INFO: Loss :\r\n[2022/10/11 09:10:12] ppocr INFO:     loss_config_list :\r\n[2022/10/11 09:10:12] ppocr INFO:         CTCLoss : None\r\n[2022/10/11 09:10:12] ppocr INFO:         SARLoss : None\r\n[2022/10/11 09:10:12] ppocr INFO:     name : MultiLoss\r\n[2022/10/11 09:10:12] ppocr INFO: Metric :\r\n[2022/10/11 09:10:12] ppocr INFO:     ignore_space : False\r\n[2022/10/11 09:10:12] ppocr INFO:     main_indicator : acc\r\n[2022/10/11 09:10:12] ppocr INFO:     name : RecMetric\r\n[2022/10/11 09:10:12] ppocr INFO: Optimizer :\r\n[2022/10/11 09:10:12] ppocr INFO:     beta1 : 0.9\r\n[2022/10/11 09:10:12] ppocr INFO:     beta2 : 0.999\r\n[2022/10/11 09:10:12] ppocr INFO:     lr :\r\n[2022/10/11 09:10:12] ppocr INFO:         learning_rate : 0.001\r\n[2022/10/11 09:10:12] ppocr INFO:         name : Cosine\r\n[2022/10/11 09:10:12] ppocr INFO:         warmup_epoch : 5\r\n[2022/10/11 09:10:12] ppocr INFO:     name : Adam\r\n[2022/10/11 09:10:12] ppocr INFO:     regularizer :\r\n[2022/10/11 09:10:12] ppocr INFO:         factor : 3e-05\r\n[2022/10/11 09:10:12] ppocr INFO:         name : L2\r\n[2022/10/11 09:10:12] ppocr INFO: PostProcess :\r\n[2022/10/11 09:10:12] ppocr INFO:     name : CTCLabelDecode\r\n[2022/10/11 09:10:12] ppocr INFO: Train :\r\n[2022/10/11 09:10:12] ppocr INFO:     dataset :\r\n[2022/10/11 09:10:12] ppocr INFO:         data_dir : ./project\r\n[2022/10/11 09:10:12] ppocr INFO:         ext_op_transform_idx : 1\r\n[2022/10/11 09:10:12] ppocr INFO:         label_file_list : ['./project/train_data/rec/train.txt']\r\n[2022/10/11 09:10:12] ppocr INFO:         name : SimpleDataSet\r\n[2022/10/11 09:10:12] ppocr INFO:         transforms :\r\n[2022/10/11 09:10:12] ppocr INFO:             DecodeImage :\r\n[2022/10/11 09:10:12] ppocr INFO:                 channel_first : False\r\n[2022/10/11 09:10:12] ppocr INFO:                 img_mode : BGR\r\n[2022/10/11 09:10:12] ppocr INFO:             RecConAug :\r\n[2022/10/11 09:10:12] ppocr INFO:                 ext_data_num : 2\r\n[2022/10/11 09:10:12] ppocr INFO:                 image_shape : [48, 160, 3]\r\n[2022/10/11 09:10:12] ppocr INFO:                 prob : 0.5\r\n[2022/10/11 09:10:12] ppocr INFO:             RecAug : None\r\n[2022/10/11 09:10:12] ppocr INFO:             MultiLabelEncode : None\r\n[2022/10/11 09:10:12] ppocr INFO:             RecResizeImg :\r\n[2022/10/11 09:10:12] ppocr INFO:                 image_shape : [3, 48, 160]\r\n[2022/10/11 09:10:12] ppocr INFO:             KeepKeys :\r\n[2022/10/11 09:10:12] ppocr INFO:                 keep_keys : ['image', 'label_ctc', 'label_sar', 'length', 'valid_ratio']\r\n[2022/10/11 09:10:12] ppocr INFO:     loader :\r\n[2022/10/11 09:10:12] ppocr INFO:         batch_size_per_card : 64\r\n[2022/10/11 09:10:12] ppocr INFO:         drop_last : True\r\n[2022/10/11 09:10:12] ppocr INFO:         num_workers : 4\r\n[2022/10/11 09:10:12] ppocr INFO:         shuffle : True\r\n[2022/10/11 09:10:12] ppocr INFO: profiler_options : None\r\n[2022/10/11 09:10:12] ppocr INFO: train with paddle 2.3.1 and device Place(gpu:0)\r\n[2022/10/11 09:10:12] ppocr INFO: Initialize indexs of datasets:['./project/train_data/rec/train.txt']\r\n[2022/10/11 09:10:12] ppocr INFO: Initialize indexs of datasets:['./project/train_data/rec/val.txt']\r\nW1011 09:10:12.918350 23436 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.6, Runtime API Version: 11.6\r\nW1011 09:10:12.923333 23436 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.\r\nTraceback (most recent call last):\r\n  File \"deploy/slim/prune/sensitivity_anal.py\", line 175, in <module>\r\n    main(config, device, logger, vdl_writer)\r\n  File \"deploy/slim/prune/sensitivity_anal.py\", line 75, in main\r\n    model = build_model(config['Architecture'])\r\n  File \"E:\\WorkPower\\Project\\px\\PaddleOCR\\deploy/slim/prune\\..\\..\\..\\ppocr\\modeling\\architectures\\__init__.py\", line 27, in build_model\r\n    arch = BaseModel(config)\r\n  File \"E:\\WorkPower\\Project\\px\\PaddleOCR\\deploy/slim/prune\\..\\..\\..\\ppocr\\modeling\\architectures\\base_model.py\", line 71, in __init__\r\n    self.head = build_head(config[\"Head\"])\r\n  File \"E:\\WorkPower\\Project\\px\\PaddleOCR\\deploy/slim/prune\\..\\..\\..\\ppocr\\modeling\\heads\\__init__.py\", line 57, in build_head\r\n    module_class = eval(module_name)(**config)\r\nTypeError: __init__() missing 1 required positional argument: 'out_channels_list'",
        "state": "closed",
        "user": "yearzhengcheng",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-10-11T01:27:12+00:00",
        "updated_at": "2024-02-06T02:59:29+00:00",
        "closed_at": "2024-02-06T02:59:28+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1465,
        "title": "[question]RuntimeError: Can't load tokenizer for './afqmc'.",
        "body": "![b8c25b40fe9bade47aa736b38b5b3fc](https://user-images.githubusercontent.com/75259281/195900771-25ac2dda-11aa-4bae-a8f5-cf5ba709a13e.png)\r\n",
        "state": "closed",
        "user": "buhanyunfei",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-10-14T16:54:49+00:00",
        "updated_at": "2024-02-06T02:59:29+00:00",
        "closed_at": "2024-02-06T02:59:29+00:00",
        "comments_count": [
            "buhanyunfei",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1467,
        "title": "win11 报错“NameError: name 'platform' is not defined”",
        "body": "## win11 报错“NameError: name 'platform' is not defined”\r\n\r\n如题，跑 PaddleSlim-develop\\example\\auto_compression\\semantic_segmentation 的 例子，报错\r\n```bash\r\n加载个人及系统配置文件用了 939 毫秒。\r\n(p2) PS C:\\Users\\Administrator> cd C:\\Users\\Administrator\\Desktop\\PaddleSlim-develop\\example\\auto_compression\\semantic_segmentation\r\n(p2) PS C:\\Users\\Administrator\\Desktop\\PaddleSlim-develop\\example\\auto_compression\\semantic_segmentation> python run.py --config_path='./configs/pp_humanseg/pp_humanseg_auto.yaml' --save_dir='./save_compressed_model'\r\nC:\\miniconda3\\envs\\p2\\lib\\site-packages\\paddleseg\\models\\losses\\decoupledsegnet_relax_boundary_loss.py:19: DeprecationWarning: Please use `shift` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.  from scipy.ndimage.interpolation import shift\r\nC:\\miniconda3\\envs\\p2\\lib\\site-packages\\paddleseg\\transforms\\functional.py:18: DeprecationWarning: Please use `distance_transform_edt` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\r\n  from scipy.ndimage.morphology import distance_transform_edt\r\nC:\\miniconda3\\envs\\p2\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n2022-10-16 20:06:17,416-WARNING: post-quant-hpo is not support in system other than linux\r\n-----------  Running Arguments -----------\r\n Global:\r\n         deploy_hardware: SD710\r\n         model_dir: ./ppseg_lite_portrait_398x224_with_softmax\r\n         model_filename: model.pdmodel\r\n         params_filename: model.pdiparams\r\n         reader_config: configs/dataset/humanseg_dataset.yaml\r\n TrainConfig:\r\n         epochs: 14\r\n         eval_iter: 400\r\n         learning_rate: 0.005\r\n         optimizer_builder:\r\n                 optimizer:\r\n                         type: SGD\r\n                 weight_decay: 0.0005\r\n------------------------------------------\r\nW1016 20:06:17.537575  3000 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.2\r\nW1016 20:06:17.587304  3000 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\r\n[<paddle.fluid.core_avx.Tensor object at 0x0000024DC775BFB0>, <paddle.fluid.core_avx.Tensor object at 0x0000024DC73A1930>]\r\n2022-10-16 20:06:26,207-INFO: devices: gpu\r\n2022-10-16 20:06:27,841-INFO: Detect model type: None\r\nTraceback (most recent call last):\r\n  File \"C:\\miniconda3\\envs\\p2\\lib\\site-packages\\paddleslim\\auto_compression\\utils\\predict.py\", line 66, in predict_compressed_model\r\n    predictor = TableLatencyPredictor(hardware)\r\n  File \"C:\\miniconda3\\envs\\p2\\lib\\site-packages\\paddleslim\\analysis\\latency_predictor.py\", line 80, in __init__\r\n    self._check_opt_model()\r\n  File \"C:\\miniconda3\\envs\\p2\\lib\\site-packages\\paddleslim\\analysis\\latency_predictor.py\", line 95, in _check_opt_model\r\n    raise NotImplementedError(\r\nNotImplementedError: latency predictor does NOT support running on Windows.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\Desktop\\PaddleSlim-develop\\example\\auto_compression\\semantic_segmentation\\run.py\", line 168, in <module>\r\n    main(args)\r\n  File \"C:\\Users\\Administrator\\Desktop\\PaddleSlim-develop\\example\\auto_compression\\semantic_segmentation\\run.py\", line 150, in main\r\n    ac = AutoCompression(\r\n  File \"C:\\miniconda3\\envs\\p2\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 178, in __init__\r\n    strategy_config = prepare_strategy(\r\n  File \"C:\\miniconda3\\envs\\p2\\lib\\site-packages\\paddleslim\\auto_compression\\auto_strategy.py\", line 169, in prepare_strategy\r\n    compressed_time_dict = predict_compressed_model(\r\n  File \"C:\\miniconda3\\envs\\p2\\lib\\site-packages\\paddleslim\\auto_compression\\utils\\predict.py\", line 70, in predict_compressed_model\r\n    format(platform.system()))\r\nNameError: name 'platform' is not defined\r\n```",
        "state": "closed",
        "user": "livingbody",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-10-16T12:09:19+00:00",
        "updated_at": "2024-02-06T02:59:30+00:00",
        "closed_at": "2024-02-06T02:59:30+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1471,
        "title": "请问支持什么权重和激活函数的量化类型 and 什么类型的预处理方法",
        "body": "我好像只在QAT源码中看到了有type 但是config中没有说明 还有请问在paddlelite上进行推理支持什么量化类型进行量化产生的量化模型呢",
        "state": "closed",
        "user": "Yamabukiss",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-10-19T03:38:52+00:00",
        "updated_at": "2024-02-06T02:59:31+00:00",
        "closed_at": "2024-02-06T02:59:31+00:00",
        "comments_count": [
            "yghstill",
            "Yamabukiss",
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1475,
        "title": "run.sh中没有dataset的字段",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression/nlp\r\n![image](https://user-images.githubusercontent.com/75259281/196904565-0afe1394-ad1d-469f-a8d5-15e567fc3feb.png)\r\n![image](https://user-images.githubusercontent.com/75259281/196904626-da291ec0-43f6-422e-b6d5-c8f1b6ab6fa0.png)\r\n",
        "state": "closed",
        "user": "buhanyunfei",
        "closed_by": "XGZhang11",
        "created_at": "2022-10-20T08:59:47+00:00",
        "updated_at": "2024-02-06T03:26:33+00:00",
        "closed_at": "2024-02-06T03:26:33+00:00",
        "comments_count": [
            "buhanyunfei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1487,
        "title": "PaddleSlim安装情况时的一些问题",
        "body": "### 环境\r\nsystem：win11+WSL2【Ubuntu20.04】\r\npaddle：develop\r\nPaddleSlim：git version\r\nconda环境：python3.6\r\n### 问题\r\n在新建的conda环境中安装好paddle的develop版本后，在根据文档提示安装paddleslim时发生了报错\r\n安装文件如下\r\n![image](https://user-images.githubusercontent.com/74920047/198971112-f2949348-a525-4404-b191-7e0ca74ac962.png)\r\n报错环节为最后一行命令\r\n下面是报错\r\n```\r\n(paddlepaddle) lxh@Y9000P:/mnt/d/data/PaddleSlim-quant-demo/PaddleSlim-quant-demo/image_classification_demo/quant_post/PaddleSlim$ python3 ./setup.py install\r\n/home/lxh/anaconda3/envs/paddlepaddle/lib/python3.6/site-packages/setuptools/dist.py:505: UserWarning: The version specified ('Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).') is an invalid version, this may not work as expected with newer versions of setuptools, pip, and PyPI. Please see PEP 440 for more details.\r\n  \"details.\" % version\r\nrunning install\r\nrunning bdist_egg\r\nrunning egg_info\r\nwriting paddleslim.egg-info/PKG-INFO\r\nwriting dependency_links to paddleslim.egg-info/dependency_links.txt\r\nwriting requirements to paddleslim.egg-info/requires.txt\r\nwriting top-level names to paddleslim.egg-info/top_level.txt\r\nreading manifest file 'paddleslim.egg-info/SOURCES.txt'\r\nadding license file 'LICENSE'\r\nwriting manifest file 'paddleslim.egg-info/SOURCES.txt'\r\ninstalling library code to build/bdist.linux-x86_64/egg\r\nrunning install_lib\r\nrunning build_py\r\ncreating build/bdist.linux-x86_64/egg\r\ncreating build/bdist.linux-x86_64/egg/paddleslim\r\ncreating build/bdist.linux-x86_64/egg/paddleslim/analysis\r\ncopying build/lib/paddleslim/analysis/extract_features.py -> build/bdist.linux-x86_64/egg/paddleslim/analysis\r\nerror: [Errno 1] Operation not permitted\r\n```\r\n这是使用sudo su命令获取到权限后执行的setup命令结果，\r\n[log.txt](https://github.com/PaddlePaddle/PaddleSlim/files/9899660/log.txt)\r\n太长了所以直接上传文件了。\r\n最终的需求是在paddlepaddle conda环境中使用paddle和paddleslim，实现对模型的全量化，跑通一个自己训练的模型。\r\n正在尝试在root环境中安装一个paddle，但是最好能够在cconda环境中使用paddleslim\r\n![Snipaste_2022-10-31_17-18-08](https://user-images.githubusercontent.com/74920047/198974072-e2598e45-3713-4ab5-ba94-55e0d65550f4.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "Hyperpepe",
        "closed_by": "XGZhang11",
        "created_at": "2022-10-31T09:19:59+00:00",
        "updated_at": "2024-02-06T03:26:17+00:00",
        "closed_at": "2024-02-06T03:26:17+00:00",
        "comments_count": [
            "iamWHTWD",
            "Hyperpepe",
            "Hyperpepe"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1488,
        "title": "tinypose qat demo missing！",
        "body": "hi，\r\n      https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression/detection 请问下啥时候会有tinypose的qat全量化的demo呢？ 目前看来，用不起来，训练的时候loss都是nan，ru如下图所示:\r\n![image](https://user-images.githubusercontent.com/8407513/199145264-04520186-34a1-40d4-8bc6-7ef7c72fe845.png)\r\n\r\nBR ",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-01T02:27:16+00:00",
        "updated_at": "2024-02-06T02:59:32+00:00",
        "closed_at": "2024-02-06T02:59:32+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1491,
        "title": "技术交流微信群 二维码过期了，谁可以给一个新的群 或者交流渠道",
        "body": "百度飞桨 如流群",
        "state": "closed",
        "user": "huyuanchao",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-01T09:37:20+00:00",
        "updated_at": "2024-02-06T03:25:07+00:00",
        "closed_at": "2024-02-06T03:25:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1490,
        "title": "num_workers 是怎么设置",
        "body": "train_loader = paddle.io.DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True, num_workers=4)\r\n         \r\nval_loader = paddle.io.DataLoader(dataset, batch_size=32, shuffle=False, drop_last=True, num_workers=4)\r\n\r\n我用同服务器的8张卡训练和验证，是否需要指定num_workers，需要设置成多少？",
        "state": "closed",
        "user": "huyuanchao",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-01T06:01:07+00:00",
        "updated_at": "2024-02-06T02:59:33+00:00",
        "closed_at": "2024-02-06T02:59:33+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1492,
        "title": "picodet 全量化版本bug！",
        "body": "hi，\r\n  按照下述的链接，复现后结果跟文档不符\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/v2.4rc/example/full_quantization/picodet\r\n 具体如下图所示:\r\n![image](https://user-images.githubusercontent.com/8407513/199220355-8c34bc31-c852-4cb4-80d8-fdf5673baa23.png)\r\n也就是说量化训练过程是有bug的，我的版本完全按照该文档所示的都是最新release版本具体如下\r\n![image](https://user-images.githubusercontent.com/8407513/199220499-e2d08ab1-727c-40c6-b589-9affa1e3ab83.png)\r\n期待pp大佬的支持，多谢\r\nBR",
        "state": "closed",
        "user": "2050airobert",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-01T11:11:44+00:00",
        "updated_at": "2024-02-06T03:24:39+00:00",
        "closed_at": "2024-02-06T03:24:39+00:00",
        "comments_count": [
            "leiqing1",
            "2050airobert"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1493,
        "title": "yolov5 v6.1自动压缩失败",
        "body": "参考[`YOLO`系列模型自动压缩示例#自动压缩流程](https://github.com/PaddlePaddle/PaddleSlim/blob/develop/example/auto_compression/pytorch_yolo_series/README.md#自动压缩流程)\r\n```bash\r\npython -m pip install paddlepaddle-gpu==2.3.2.post112 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\r\npip install paddleslim==2.3.3\r\n```\r\n运行`run.py`报以下错误\r\n```bash\r\ncore_avx.so: undefined symbol: _dl_sym, version GLIBC_PRIVATE\r\n```\r\n参考[`Paddle issues 44571`](https://github.com/PaddlePaddle/Paddle/issues/44571#issuecomment-1268797171)\r\n```bash\r\npython -m pip install paddlepaddle-gpu==2.4.0rc0 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\r\n```\r\n再运行`run.py`报以下错误\r\n```bash\r\n2022-11-01 19:22:11,370-INFO: Now translating model from onnx to paddle.\r\n2022-11-01 19:22:11,370-WARNING: ONNXDecoder.__init__() missing 1 required positional argument: 'enable_onnx_checker'\r\n```\r\n参考[`X2Paddle issues 901`](https://github.com/PaddlePaddle/X2Paddle/issues/901#issuecomment-1266561146)，此时`x2paddle`版本是`1.3.9`，降到`1.3.8`\r\n```bash\r\npip install x2paddle==1.3.8\r\n```\r\n再运行`run.py`报以下错误\r\n```bash\r\n···\r\n\r\n!!!!!!!!!!\r\nshape inferenced.\r\nNow, onnx2paddle support convert onnx model opset_verison [9],opset_verison of your onnx model is 12, automatically treated as op_set: 9.\r\nTotal nodes: 248\r\nNodes converting ...\r\nConverting node 327 ...     2022-11-01 19:13:57,583-WARNING: convert failed node:onnx__Concat_271, op_type is Resize\r\n2022-11-01 19:13:57,583-ERROR: x2paddle threw an exception, you can ask for help at: https://github.com/PaddlePaddle/X2Paddle/issues\r\n```",
        "state": "closed",
        "user": "hhxdestiny",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-01T11:31:36+00:00",
        "updated_at": "2024-02-06T04:15:32+00:00",
        "closed_at": "2024-02-06T04:15:32+00:00",
        "comments_count": [
            "Hap-Zhang",
            "yghstill",
            "Hap-Zhang",
            "hhxdestiny",
            "liumingzhu6060",
            "hhxdestiny"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1515,
        "title": "不同版本的yapf行为不一致",
        "body": "1. 在PaddleSlim中，是从github安装的yapf，https://github.com/PaddlePaddle/PaddleSlim/blob/develop/.pre-commit-config.yaml#L11\r\n版本为[yapf==0.13.2](https://github.com/PaddlePaddle/mirrors-yapf/blob/paddle_customize_version/setup.py#L7)， \r\n\r\n2. CI server用的应该不是yapf==0.13.2，或者，配置文件.style.yapf没生效\r\n\r\n## yapf==0.13.2 与 yapf==0.32.0  结果不一致\r\n可以通过pip install yapf==0.13.2 安装\r\n\r\n### yapf==0.13.2 结果\r\n\r\n无diff\r\n\r\n### yapf==0.32.0 结果\r\n\r\n```\r\n--- paddleslim/nas/darts/architect.py   (original)\r\n+++ paddleslim/nas/darts/architect.py   (reformatted)\r\n@@ -21,6 +21,7 @@\r\n \r\n \r\n class Architect(object):\r\n+\r\n     def __init__(self, model, eta, arch_learning_rate, unrolled, parallel):\r\n         self.network_momentum = 0.9\r\n         self.network_weight_decay = 3e-4\r\n@@ -37,8 +38,7 @@\r\n         if self.unrolled:\r\n             self.unrolled_model = self.model.new()\r\n             self.unrolled_model_params = [\r\n-                p for p in self.unrolled_model.parameters()\r\n-                if p.name not in\r\n+                p for p in self.unrolled_model.parameters() if p.name not in\r\n                 [a.name\r\n                  for a in self.unrolled_model.arch_parameters()] and p.trainable\r\n             ]\r\n@@ -62,8 +62,10 @@\r\n \r\n     def step(self, input_train, target_train, input_valid, target_valid):\r\n         if self.unrolled:\r\n-            params_grads = self._backward_step_unrolled(\r\n-                input_train, target_train, input_valid, target_valid)\r\n+            params_grads = self._backward_step_unrolled(input_train,\r\n+                                                        target_train,\r\n+                                                        input_valid,\r\n+                                                        target_valid)\r\n             self.optimizer.apply_gradients(params_grads)\r\n         else:\r\n             loss = self._backward_step(input_valid, target_valid)\r\n@@ -134,8 +136,8 @@\r\n \r\n         model_params = [\r\n             p for p in self.model.parameters()\r\n-            if p.name not in [a.name for a in self.model.arch_parameters()] and\r\n-            p.trainable\r\n+            if p.name not in [a.name for a in self.model.arch_parameters()]\r\n+            and p.trainable\r\n         ]\r\n         for param, grad in zip(model_params, vector):\r\n             param_p = param + grad * R\r\n```\r\n\r\n## CI server 结果\r\n\r\n```\r\n - files were modified by this hook\r\n2022-11-10 10:44:29 Check for added large files..............................................Passed\r\n2022-11-10 10:44:29 Check for merge conflicts................................................Passed\r\n2022-11-10 10:44:30 Check for broken symlinks................................................Passed\r\n2022-11-10 10:44:30 Detect Private Key...................................(no files to check)Skipped\r\n2022-11-10 10:44:30 Fix End of Files.....................................(no files to check)Skipped\r\n2022-11-10 10:44:30 Trim Trailing Whitespace.............................(no files to check)Skipped\r\n2022-11-10 10:44:30 pylint...................................................................Passed\r\n2022-11-10 10:44:30 copyright_checker....................................(no files to check)Skipped\r\n2022-11-10 10:44:30 \u001b[31m ---- check fail file_name: paddleslim/nas/darts/architect.py \u001b[0m\r\n2022-11-10 10:44:30 diff --git a/paddleslim/nas/darts/architect.py b/paddleslim/nas/darts/architect.py\r\n2022-11-10 10:44:30 index 1a1bba6..873ad67 100644\r\n2022-11-10 10:44:30 --- a/paddleslim/nas/darts/architect.py\r\n2022-11-10 10:44:30 +++ b/paddleslim/nas/darts/architect.py\r\n2022-11-10 10:44:30 @@ -37,8 +37,7 @@ class Architect(object):\r\n2022-11-10 10:44:30          if self.unrolled:\r\n2022-11-10 10:44:30              self.unrolled_model = self.model.new()\r\n2022-11-10 10:44:30              self.unrolled_model_params = [\r\n2022-11-10 10:44:30 -                p for p in self.unrolled_model.parameters()\r\n2022-11-10 10:44:30 -                if p.name not in\r\n2022-11-10 10:44:30 +                p for p in self.unrolled_model.parameters() if p.name not in\r\n2022-11-10 10:44:30                  [a.name\r\n2022-11-10 10:44:30                   for a in self.unrolled_model.arch_parameters()] and p.trainable\r\n2022-11-10 10:44:30              ]\r\n2022-11-10 10:44:30 @@ -97,11 +96,10 @@ class Architect(object):\r\n2022-11-10 10:44:30              to_variable(param._grad_ivar().numpy())\r\n2022-11-10 10:44:30              for param in self.unrolled_model_params\r\n2022-11-10 10:44:30          ]\r\n2022-11-10 10:44:30 -        arch_params_grads = [\r\n2022-11-10 10:44:30 -            (alpha, to_variable(ualpha._grad_ivar().numpy()))\r\n2022-11-10 10:44:30 -            for alpha, ualpha in zip(self.model.arch_parameters(),\r\n2022-11-10 10:44:30 -                                     self.unrolled_model.arch_parameters())\r\n2022-11-10 10:44:30 -        ]\r\n2022-11-10 10:44:30 +        arch_params_grads = [(alpha, to_variable(ualpha._grad_ivar().numpy()))\r\n2022-11-10 10:44:30 +                             for alpha, ualpha in\r\n2022-11-10 10:44:30 +                             zip(self.model.arch_parameters(),\r\n2022-11-10 10:44:30 +                                 self.unrolled_model.arch_parameters())]\r\n2022-11-10 10:44:30          self.unrolled_model.clear_gradients()\r\n2022-11-10 10:44:30  \r\n2022-11-10 10:44:30          implicit_grads = self._hessian_vector_product(vector, input_train,\r\n```\r\n\r\n## yapf配置\r\n\r\n```\r\n[style]\r\nbased_on_style = pep8\r\ncolumn_limit = 80\r\n```\r\n\r\n\r\n## 代码\r\npaddleslim/nas/darts/architect.py\r\n```python\r\n# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport paddle.fluid as fluid\r\nfrom paddle.fluid.dygraph.base import to_variable\r\n\r\n\r\nclass Architect(object):\r\n    def __init__(self, model, eta, arch_learning_rate, unrolled, parallel):\r\n        self.network_momentum = 0.9\r\n        self.network_weight_decay = 3e-4\r\n        self.eta = eta\r\n        self.model = model\r\n        self.optimizer = fluid.optimizer.Adam(\r\n            arch_learning_rate,\r\n            0.5,\r\n            0.999,\r\n            regularization=fluid.regularizer.L2Decay(1e-3),\r\n            parameter_list=self.model.arch_parameters())\r\n        self.unrolled = unrolled\r\n        self.parallel = parallel\r\n        if self.unrolled:\r\n            self.unrolled_model = self.model.new()\r\n            self.unrolled_model_params = [\r\n                p for p in self.unrolled_model.parameters()\r\n                if p.name not in\r\n                [a.name\r\n                 for a in self.unrolled_model.arch_parameters()] and p.trainable\r\n            ]\r\n            self.unrolled_optimizer = paddle.optimizer.Momentum(\r\n                self.eta,\r\n                self.network_momentum,\r\n                regularization=fluid.regularizer.L2DecayRegularizer(\r\n                    self.network_weight_decay),\r\n                parameter_list=self.unrolled_model_params)\r\n\r\n        if self.parallel:\r\n            strategy = fluid.dygraph.parallel.prepare_context()\r\n            self.parallel_model = fluid.dygraph.parallel.DataParallel(\r\n                self.model, strategy)\r\n            if self.unrolled:\r\n                self.parallel_unrolled_model = fluid.dygraph.parallel.DataParallel(\r\n                    self.unrolled_model, strategy)\r\n\r\n    def get_model(self):\r\n        return self.parallel_model if self.parallel else self.model\r\n\r\n    def step(self, input_train, target_train, input_valid, target_valid):\r\n        if self.unrolled:\r\n            params_grads = self._backward_step_unrolled(\r\n                input_train, target_train, input_valid, target_valid)\r\n            self.optimizer.apply_gradients(params_grads)\r\n        else:\r\n            loss = self._backward_step(input_valid, target_valid)\r\n            self.optimizer.minimize(loss)\r\n        self.optimizer.clear_gradients()\r\n\r\n    def _backward_step(self, input_valid, target_valid):\r\n        loss = self.model._loss(input_valid, target_valid)\r\n        if self.parallel:\r\n            loss = self.parallel_model.scale_loss(loss)\r\n            loss.backward()\r\n            self.parallel_model.apply_collective_grads()\r\n        else:\r\n            loss.backward()\r\n        return loss\r\n\r\n    def _backward_step_unrolled(self, input_train, target_train, input_valid,\r\n                                target_valid):\r\n        self._compute_unrolled_model(input_train, target_train)\r\n        unrolled_loss = self.unrolled_model._loss(input_valid, target_valid)\r\n\r\n        if self.parallel:\r\n            unrolled_loss = self.parallel_unrolled_model.scale_loss(\r\n                unrolled_loss)\r\n            unrolled_loss.backward()\r\n            self.parallel_unrolled_model.apply_collective_grads()\r\n        else:\r\n            unrolled_loss.backward()\r\n\r\n        vector = [\r\n            to_variable(param._grad_ivar().numpy())\r\n            for param in self.unrolled_model_params\r\n        ]\r\n        arch_params_grads = [\r\n            (alpha, to_variable(ualpha._grad_ivar().numpy()))\r\n            for alpha, ualpha in zip(self.model.arch_parameters(),\r\n                                     self.unrolled_model.arch_parameters())\r\n        ]\r\n        self.unrolled_model.clear_gradients()\r\n\r\n        implicit_grads = self._hessian_vector_product(vector, input_train,\r\n                                                      target_train)\r\n        for (p, g), ig in zip(arch_params_grads, implicit_grads):\r\n            new_g = g - (ig * self.unrolled_optimizer.current_step_lr())\r\n            fluid.layers.assign(new_g.detach(), g)\r\n        return arch_params_grads\r\n\r\n    def _compute_unrolled_model(self, input, target):\r\n        for x, y in zip(self.unrolled_model.parameters(),\r\n                        self.model.parameters()):\r\n            fluid.layers.assign(y.detach(), x)\r\n\r\n        loss = self.unrolled_model._loss(input, target)\r\n        if self.parallel:\r\n            loss = self.parallel_unrolled_model.scale_loss(loss)\r\n            loss.backward()\r\n            self.parallel_unrolled_model.apply_collective_grads()\r\n        else:\r\n            loss.backward()\r\n\r\n        self.unrolled_optimizer.minimize(loss)\r\n        self.unrolled_model.clear_gradients()\r\n\r\n    def _hessian_vector_product(self, vector, input, target, r=1e-2):\r\n        R = r * fluid.layers.rsqrt(\r\n            fluid.layers.sum(\r\n                [fluid.layers.reduce_sum(paddle.square(v)) for v in vector]))\r\n\r\n        model_params = [\r\n            p for p in self.model.parameters()\r\n            if p.name not in [a.name for a in self.model.arch_parameters()] and\r\n            p.trainable\r\n        ]\r\n        for param, grad in zip(model_params, vector):\r\n            param_p = param + grad * R\r\n            fluid.layers.assign(param_p.detach(), param)\r\n        loss = self.model._loss(input, target)\r\n        if self.parallel:\r\n            loss = self.parallel_model.scale_loss(loss)\r\n            loss.backward()\r\n            self.parallel_model.apply_collective_grads()\r\n        else:\r\n            loss.backward()\r\n\r\n        grads_p = [\r\n            to_variable(param._grad_ivar().numpy())\r\n            for param in self.model.arch_parameters()\r\n        ]\r\n\r\n        for param, grad in zip(model_params, vector):\r\n            param_n = param - grad * R * 2\r\n            fluid.layers.assign(param_n.detach(), param)\r\n        self.model.clear_gradients()\r\n\r\n        loss = self.model._loss(input, target)\r\n        if self.parallel:\r\n            loss = self.parallel_model.scale_loss(loss)\r\n            loss.backward()\r\n            self.parallel_model.apply_collective_grads()\r\n        else:\r\n            loss.backward()\r\n\r\n        grads_n = [\r\n            to_variable(param._grad_ivar().numpy())\r\n            for param in self.model.arch_parameters()\r\n        ]\r\n        for param, grad in zip(model_params, vector):\r\n            param_o = param + grad * R\r\n            fluid.layers.assign(param_o.detach(), param)\r\n        self.model.clear_gradients()\r\n        arch_grad = [(p - n) / (2 * R) for p, n in zip(grads_p, grads_n)]\r\n        return arch_grad\r\n```",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-11T02:36:52+00:00",
        "updated_at": "2024-02-06T04:15:55+00:00",
        "closed_at": "2024-02-06T04:15:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1500,
        "title": "ImportError: cannot import name '_legacy_C_ops' from 'paddle' (/home/ubuntu/anaconda3/envs/xl_paddleslim/lib/python3.8/site-packages/paddle/__init__.py)",
        "body": "环境问题。 找不到对应的包。",
        "state": "closed",
        "user": "Dora1483",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-03T09:45:39+00:00",
        "updated_at": "2024-02-06T02:59:34+00:00",
        "closed_at": "2024-02-06T02:59:34+00:00",
        "comments_count": [
            "wanghaoshuang",
            "wanghaoshuang",
            "Richard-mei",
            "Richard-mei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1505,
        "title": "IndexError: tuple index out of range",
        "body": "/home/aistudio/work/PaddleSlim-release-2.4/example/auto_compression/detection\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import imp\r\n[11-07 22:19:51 MainThread @logger.py:242] Argv: run.py --config_path=./configs/ppyoloe_s_qat_dis.yaml --save_dir=./output/ --devices=cpu\r\n[11-07 22:19:51 MainThread @utils.py:79] WRN paddlepaddle version: 2.4.0-rc0. The dynamic graph version of PARL is under development, not fully tested and supported\r\nWARNING:root:cannot import name 'layers' from 'parl' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/__init__.py)\r\n2022-11-07 22:19:52,278-WARNING: Some functions fail to import, please update PaddlePaddle version to 2.4+\r\n-----------  Running Arguments -----------\r\n Distillation:\r\n\t alpha: 1.0\r\n\t loss: soft_label\r\n Global:\r\n\t Evaluation: True\r\n\t arch: PPYOLOE\r\n\t model_dir: /home/aistudio/work/PaddleDetection/output_inference/ppyoloe_plus_crn_s_80e_coco\r\n\t model_filename: model.pdmodel\r\n\t params_filename: model.pdiparams\r\n\t reader_config: configs/yolo_reader.yml\r\n Quantization:\r\n\t activation_quantize_type: moving_average_abs_max\r\n\t onnx_format: True\r\n\t quantize_op_types: ['conv2d', 'depthwise_conv2d']\r\n\t use_pact: True\r\n TrainConfig:\r\n\t eval_iter: 10\r\n\t learning_rate:\r\n\t\t T_max: 20\r\n\t\t learning_rate: 3e-05\r\n\t\t type: CosineAnnealingDecay\r\n\t optimizer_builder:\r\n\t\t optimizer:\r\n\t\t\t type: SGD\r\n\t\t weight_decay: 4e-05\r\n\t train_iter: 10\r\n------------------------------------------\r\nloading annotations into memory...\r\nDone (t=0.04s)\r\ncreating index...\r\nindex created!\r\nloading annotations into memory...\r\nDone (t=0.09s)\r\ncreating index...\r\nindex created!\r\n2022-11-07 22:19:54,727-INFO: devices: cpu\r\n2022-11-07 22:21:07,319-INFO: Detect model type: None\r\n2022-11-07 22:21:08,289-INFO: Selected strategies: ['qat_dis']\r\n2022-11-07 22:22:26,271-INFO: train config.distill_node_pair: ['teacher_conv2d_173.tmp_1', 'conv2d_173.tmp_1', 'teacher_conv2d_177.tmp_0', 'conv2d_177.tmp_0', 'teacher_conv2d_180.tmp_1', 'conv2d_180.tmp_1', 'teacher_conv2d_184.tmp_0', 'conv2d_184.tmp_0', 'teacher_conv2d_187.tmp_1', 'conv2d_187.tmp_1', 'teacher_conv2d_191.tmp_0', 'conv2d_191.tmp_0']\r\n2022-11-07 22:22:27,218-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'quant_post_first': False, 'scale_trainable': True, 'name': 'Distillation', 'loss': 'soft_label', 'node': [], 'alpha': 1.0, 'teacher_model_dir': '/home/aistudio/work/PaddleDetection/output_inference/ppyoloe_plus_crn_s_80e_coco', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\nAdding quant op with weight:|██████████████████████████████████████████| 397/397\r\nAdding OutScale op:|███████████████████████████████████████████████████| 382/382\r\n2022-11-07 22:22:37,079-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'quant_post_first': False, 'scale_trainable': True, 'name': 'Distillation', 'loss': 'soft_label', 'node': [], 'alpha': 1.0, 'teacher_model_dir': '/home/aistudio/work/PaddleDetection/output_inference/ppyoloe_plus_crn_s_80e_coco', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\nAdding quant op with weight:|████████████████████████████████████████| 2005/2005\r\nAdding OutScale op:|█████████████████████████████████████████████████| 1233/1233\r\n2022-11-07 22:30:34,936-INFO: When a preprocess_func is used in quant_aware, Need to save a mapping table to match variable names in the convert phase.\r\n2022-11-07 22:30:34,936-INFO: The mapping table is saved as './mapping_table_for_saving_inference_model'.\r\n!!! The CPU_NUM is not specified, you should set CPU_NUM in the environment variable list.\r\nCPU_NUM indicates that how many CPUPlace are used in the current task.\r\nAnd if this parameter are set as N (equal to the number of physical CPU core) the program may be faster.\r\n\r\nexport CPU_NUM=64 # for example, set CPU_NUM as number of physical CPU core which is 64.\r\n\r\n!!! The default number of CPU_NUM=1.\r\n2022-11-07 22:30:54,660-INFO: Total iter: 0, epoch: 0, batch: 0, loss: [15.1287]\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 193, in <module>\r\n    main()\r\n  File \"run.py\", line 183, in main\r\n    ac.compress()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-Stopping.at.filesystem.boundary._GIT_DISCOVERY_ACROSS_FILESYSTEM.not.set_.-py3.7.egg/paddleslim/auto_compression/compressor.py\", line 569, in compress\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-Stopping.at.filesystem.boundary._GIT_DISCOVERY_ACROSS_FILESYSTEM.not.set_.-py3.7.egg/paddleslim/auto_compression/compressor.py\", line 715, in single_strategy_compress\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-Stopping.at.filesystem.boundary._GIT_DISCOVERY_ACROSS_FILESYSTEM.not.set_.-py3.7.egg/paddleslim/auto_compression/compressor.py\", line 757, in _start_train\r\n  File \"run.py\", line 106, in eval_function\r\n    res = postprocess(np.array(outs[0]), data_all['scale_factor'])\r\n  File \"/home/aistudio/work/PaddleSlim-release-2.4/example/auto_compression/detection/post_process.py\", line 156, in __call__\r\n    scale_factor)\r\n  File \"/home/aistudio/work/PaddleSlim-release-2.4/example/auto_compression/detection/post_process.py\", line 108, in _non_max_suppression\r\n    for class_index in range(0, confidences.shape[1]):\r\nIndexError: tuple index out of range\r\n\r\npaddle2.4，paddleslim也是2.4",
        "state": "closed",
        "user": "weijingsu",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-07T15:09:06+00:00",
        "updated_at": "2024-02-06T04:15:43+00:00",
        "closed_at": "2024-02-06T04:15:43+00:00",
        "comments_count": [
            "weijingsu",
            "yghstill",
            "yghstill",
            "weijingsu",
            "weijingsu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1506,
        "title": "RuntimeError: (NotFound) Attribute op_role is not found.",
        "body": "执行如下命令：\r\nCUDA_VISIBLE_DEVICES=0,1,2,3 python -m paddle.distributed.launch --log_dir=log --gpus 0,1,2,3 run.py \\\r\n          --config_path=./configs/yolov7_tiny_qat_dis.yaml --save_dir='./output/'\r\n报下面的错误：\r\n2022-11-08 15:06:05,044-INFO: Total iter: 970, epoch: 0, batch: 970, loss: [9.762854]\r\n2022-11-08 15:06:06,677-INFO: Total iter: 980, epoch: 0, batch: 980, loss: [9.984757]\r\n2022-11-08 15:06:08,339-INFO: Total iter: 990, epoch: 0, batch: 990, loss: [10.013017]\r\n\r\nEvaluation stage, Run batch:|                                          | 0/40137\r\nEvaluation stage, Run batch:|                                          | 0/40137\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 148, in <module>\r\n    main()\r\n  File \"run.py\", line 136, in main\r\n    ac.compress()\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 568, in compress\r\n    self.single_strategy_compress(strategy, config, strategy_idx,\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 708, in single_strategy_compress\r\n    test_program_info = self._start_train(\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 748, in _start_train\r\n    metric = self.eval_function(\r\n  File \"run.py\", line 70, in eval_function\r\n    outs = exe.run(compiled_test_program,\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1299, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1285, in run\r\n    res = self._run_impl(\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1520, in _run_impl\r\n    program._compile(scope, self.place)\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/compiler.py\", line 480, in _compile\r\n    self._executor = self._compile_data_parallel(\r\n  File \"/home/liuhongyuan/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/compiler.py\", line 427, in _compile_data_parallel\r\n    return core.ParallelExecutor(\r\nRuntimeError: (NotFound) Attribute op_role is not found.\r\n  [Hint: Expected it != attrs_.end(), but received it == attrs_.end().] (at /paddle/paddle/fluid/framework/op_desc.cc:590)\r\n\r\nINFO 2022-11-08 15:06:24,893 launch_utils.py:322] terminate process group gid:5867\r\nINFO 2022-11-08 15:06:24,893 launch_utils.py:322] terminate process group gid:5867\r\nINFO 2022-11-08 15:06:24,894 launch_utils.py:322] terminate process group gid:5870\r\nINFO 2022-11-08 15:06:24,894 launch_utils.py:322] terminate process group gid:5870\r\nINFO 2022-11-08 15:06:24,894 launch_utils.py:322] terminate process group gid:5874\r\nINFO 2022-11-08 15:06:24,894 launch_utils.py:322] terminate process group gid:5874\r\nINFO 2022-11-08 15:06:28,899 launch_utils.py:343] terminate all the procs\r\nINFO 2022-11-08 15:06:28,899 launch_utils.py:343] terminate all the procs\r\nERROR 2022-11-08 15:06:28,899 launch_utils.py:640] ABORT!!! Out of all 4 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nERROR 2022-11-08 15:06:28,899 launch_utils.py:640] ABORT!!! Out of all 4 trainers, the trainer process with rank=[0] was aborted. Please check its log.\r\nINFO 2022-11-08 15:06:32,903 launch_utils.py:343] terminate all the procs\r\nINFO 2022-11-08 15:06:32,903 launch_utils.py:343] terminate all the procs\r\nINFO 2022-11-08 15:06:32,904 launch.py:402] Local processes completed.\r\nINFO 2022-11-08 15:06:32,904 launch.py:402] Local processes completed.",
        "state": "closed",
        "user": "Hongyuan-Liu",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-08T07:16:01+00:00",
        "updated_at": "2024-02-06T02:59:35+00:00",
        "closed_at": "2024-02-06T02:59:35+00:00",
        "comments_count": [
            "yghstill",
            "linxid"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1507,
        "title": "AttributeError: 'MAOutputScaleLayer' object has no attribute 'gold_score'",
        "body": "在使用QAT进行模型量化的过程中，训练报错，AttributeError: 'MAOutputScaleLayer' object has no attribute 'gold_score'。\r\n![image](https://user-images.githubusercontent.com/12699033/200506533-3fdf3fdd-1ba9-4f69-962d-7ae284305b4d.png)\r\n报错layer为自定义layer。可以麻烦帮忙看一下如何解决这个问题嘛。",
        "state": "closed",
        "user": "Fordacre",
        "closed_by": "Fordacre",
        "created_at": "2022-11-08T07:57:19+00:00",
        "updated_at": "2022-11-11T02:07:47+00:00",
        "closed_at": "2022-11-11T02:07:46+00:00",
        "comments_count": [
            "yghstill",
            "Fordacre",
            "yghstill",
            "Fordacre"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1511,
        "title": "请问有没有针对语音识别的模型压缩方案或规划？？",
        "body": "- 如题；有没有针对语音识别的模型压缩方案、或规划？？\r\n- 语音识别框架，例如wenet，kaldi等；",
        "state": "closed",
        "user": "lvchigo",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-10T03:18:28+00:00",
        "updated_at": "2024-02-06T02:59:35+00:00",
        "closed_at": "2024-02-06T02:59:35+00:00",
        "comments_count": [
            "ceci3",
            "leiqing1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1516,
        "title": "Can yolov7 be pruned?",
        "body": "from yolov7.yaml，have no pruning.\r\nCan yolov7 be pruned?",
        "state": "closed",
        "user": "lucy3589",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-11T03:19:04+00:00",
        "updated_at": "2024-02-06T04:16:07+00:00",
        "closed_at": "2024-02-06T04:16:07+00:00",
        "comments_count": [
            "yghstill",
            "lucy3589"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1521,
        "title": "调用autocompress的非结构化剪枝工具后模型参数文件大小不发生变化",
        "body": "请问autocompress的非结构化剪枝是只对模型的参数做置零处理，其实并不改变模型结构吗？发现剪枝前后的模型参数文件model.pdiparams并未发生改变",
        "state": "closed",
        "user": "moonlightian",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-16T06:59:49+00:00",
        "updated_at": "2024-02-06T02:59:36+00:00",
        "closed_at": "2024-02-06T02:59:36+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1526,
        "title": "yolov5s自动压缩后的pdparems权重能保存成动态的batch吗",
        "body": "我用ylov5s onnx自动压缩生成pdprarms文件，但是netron打开是1x3x640x640怎么保存成动态的batch -1x3x640x640",
        "state": "closed",
        "user": "futureflsl",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-18T01:54:29+00:00",
        "updated_at": "2024-02-06T02:59:39+00:00",
        "closed_at": "2024-02-06T02:59:39+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1522,
        "title": "请问paddleslim支持对onnx的量化吗？",
        "body": null,
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-17T02:23:42+00:00",
        "updated_at": "2024-02-06T02:59:37+00:00",
        "closed_at": "2024-02-06T02:59:37+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1525,
        "title": "pdiparams转换成动态batch",
        "body": "pdiparams权重看了是1 3 640 640怎么转成动态batch-1 3 640 640",
        "state": "closed",
        "user": "futureflsl",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-18T01:46:44+00:00",
        "updated_at": "2024-02-06T02:59:38+00:00",
        "closed_at": "2024-02-06T02:59:38+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1529,
        "title": "PaddleSlim 自动压缩压缩paddleX训练的picodet模型失败",
        "body": "使用的是刚发布的fastdeploy的历程。\r\n需要重训和全量化训练picodet或者其他模型，但是目前只有一种可用\r\n于是使用了paddlex训练了一个基于自己训练集的picodet模型。\r\n下面是参考链接。\r\n[https://github.com/PaddlePaddle/FastDeploy/tree/develop/examples/vision/detection/paddledetection/rk1126/picodet_detection](url)\r\n\r\n[https://github.com/PaddlePaddle/PaddleDetection/blob/develop/configs/picodet/FULL_QUANTIZATION.md](url)\r\n\r\n基本未改动config文件，只是规定了模型位置等关键信息。\r\n不知道发生了什么错误导致一直报错。\r\n\r\n报错信息\r\n\r\n```\r\n(paddle) lxh@lxh-Y9000P:~/amlspace/PaddleSlim-develop/example/auto_compression/detection$ python run.py --config_path=./configs/picodet_s_qat_dis.yaml --save_dir='./output/'\r\n[11-21 15:52:05 MainThread @logger.py:242] Argv: run.py --config_path=./configs/picodet_s_qat_dis.yaml --save_dir=./output/\r\n[11-21 15:52:05 MainThread @utils.py:73] paddlepaddle version: 2.3.2.\r\n-----------  Running Arguments -----------\r\n Distillation:\r\n\t alpha: 1.0\r\n\t loss: l2\r\n\t node: ['conv2d_138.tmp_1', 'tmp_2', 'conv2d_146.tmp_1', 'tmp_5', 'conv2d_162.tmp_1', 'tmp_11', 'conv2d_154.tmp_1', 'tmp_8']\r\n Global:\r\n\t Evaluation: True\r\n\t model_dir: ./model/\r\n\t model_filename: model.pdmodel\r\n\t params_filename: model.pdiparams\r\n\t reader_config: ./configs/picodet_reader.yml\r\n Quantization:\r\n\t activation_bits: 8\r\n\t activation_quantize_type: moving_average_abs_max\r\n\t quantize_op_types: ['conv2d', 'depthwise_conv2d']\r\n\t use_pact: True\r\n\t weight_bits: 8\r\n TrainConfig:\r\n\t eval_iter: 1000\r\n\t learning_rate:\r\n\t\t T_max: 8000\r\n\t\t learning_rate: 1e-05\r\n\t\t type: CosineAnnealingDecay\r\n\t optimizer_builder:\r\n\t\t optimizer:\r\n\t\t\t type: SGD\r\n\t\t weight_decay: 4e-05\r\n\t train_iter: 8000\r\n------------------------------------------\r\n[11/21 15:52:06] ppdet.utils.download WARNING: Config dataset_dir dataset/coco is not exits, dataset config is not valid\r\n[11/21 15:52:06] ppdet.utils.download INFO: Dataset /home/lxh/amlspace/PaddleSlim-develop/example/auto_compression/detection/dataset/coco is not valid for reason above, try searching /home/lxh/.cache/paddle/dataset or downloading dataset...\r\nloading annotations into memory...\r\nDone (t=7.32s)\r\ncreating index...\r\nindex created!\r\n[11/21 15:52:17] ppdet.data.source.coco WARNING: Found an invalid bbox in annotations: im_id: 200365, area: 0.0 x1: 296.65, y1: 388.33, x2: 297.67999999999995, y2: 388.33.\r\n[11/21 15:52:21] ppdet.data.source.coco WARNING: Found an invalid bbox in annotations: im_id: 550395, area: 0.0 x1: 9.98, y1: 188.56, x2: 15.52, y2: 188.56.\r\nW1121 15:52:23.563212 70729 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.8, Runtime API Version: 11.6\r\nW1121 15:52:23.566123 70729 gpu_resources.cc:91] device: 0, cuDNN Version: 8.5.\r\n[11/21 15:52:24] ppdet.utils.download WARNING: Config dataset_dir dataset/coco is not exits, dataset config is not valid\r\n[11/21 15:52:24] ppdet.utils.download INFO: Dataset /home/lxh/amlspace/PaddleSlim-develop/example/auto_compression/detection/dataset/coco is not valid for reason above, try searching /home/lxh/.cache/paddle/dataset or downloading dataset...\r\nloading annotations into memory...\r\nDone (t=0.23s)\r\ncreating index...\r\nindex created!\r\n2022-11-21 15:52:24,774-INFO: devices: gpu\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 193, in <module>\r\n    main()\r\n  File \"run.py\", line 182, in main\r\n    eval_callback=eval_func)\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/auto_compression/compressor.py\", line 158, in __init__\r\n    self.model_type = self._get_model_type()\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/auto_compression/compressor.py\", line 310, in _get_model_type\r\n    _, _, model_type = get_patterns(inference_program)\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/common/patterns.py\", line 146, in get_patterns\r\n    final_weight_node = find_final_nodes(program)\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/common/patterns.py\", line 33, in find_final_nodes\r\n    if op.type() in ALL_WEIGHT_OP and is_output_weight_ops(op, graph):\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/common/patterns_common.py\", line 74, in is_output_weight_ops\r\n    return is_output_weight_ops(next_op, graph)\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/common/patterns_common.py\", line 74, in is_output_weight_ops\r\n    return is_output_weight_ops(next_op, graph)\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/common/patterns_common.py\", line 74, in is_output_weight_ops\r\n    return is_output_weight_ops(next_op, graph)\r\n  [Previous line repeated 979 more times]\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/common/patterns_common.py\", line 70, in is_output_weight_ops\r\n    next_ops = sorted(graph.next_ops(op))\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/core/graph_wrapper.py\", line 359, in next_ops\r\n    for out_var in op.all_outputs():\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/core/graph_wrapper.py\", line 136, in all_outputs\r\n    self._graph.var(var_name) for var_name in self._op.output_arg_names\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/core/graph_wrapper.py\", line 136, in <listcomp>\r\n    self._graph.var(var_name) for var_name in self._op.output_arg_names\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/core/graph_wrapper.py\", line 309, in var\r\n    return VarWrapper(block.var(name), self)\r\n  File \"/home/lxh/.conda/envs/paddle/lib/python3.6/site-packages/paddleslim/core/graph_wrapper.py\", line 40, in __init__\r\n    assert isinstance(var, (Variable, Parameter))\r\n\r\n```\r\n补充报错\r\n```\r\nRecursionError: maximum recursion depth exceeded in __instancecheck__\r\n```",
        "state": "closed",
        "user": "Hyperpepe",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-21T08:04:29+00:00",
        "updated_at": "2024-02-06T04:16:25+00:00",
        "closed_at": "2024-02-06T04:16:25+00:00",
        "comments_count": [
            "yghstill",
            "Hyperpepe",
            "ceci3",
            "Hyperpepe",
            "ceci3",
            "Hyperpepe",
            "lrp123456"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1531,
        "title": "自动压缩ppyoloe训练过程中马上变成nan调整学习率无用",
        "body": "降低学习率很多个级别都不行\r\npython run.py --config_path configs/ppyoloe_s_qat_dis.yaml\r\n-----------  Running Arguments -----------\r\n Distillation:\r\n         alpha: 1.0\r\n         loss: soft_label\r\n Global:\r\n         Evaluation: True\r\n         arch: PPYOLOE\r\n         model_dir: ./ppyoloe_crn_s_300e_coco\r\n         model_filename: model.pdmodel\r\n         params_filename: model.pdiparams\r\n         reader_config: configs/yolo_reader.yml\r\n Quantization:\r\n         activation_quantize_type: moving_average_abs_max\r\n         onnx_format: True\r\n         quantize_op_types: ['conv2d', 'depthwise_conv2d']\r\n         use_pact: True\r\n TrainConfig:\r\n         eval_iter: 1000\r\n         learning_rate:\r\n                 T_max: 6000\r\n                 learning_rate: 3e-08\r\n                 type: CosineAnnealingDecay\r\n         optimizer_builder:\r\n                 optimizer:\r\n                         type: SGD\r\n                 weight_decay: 4e-05\r\n         train_iter: 5000\r\n------------------------------------------\r\nloading annotations into memory...\r\nDone (t=0.01s)\r\ncreating index...\r\nindex created!\r\nW1122 10:26:51.865729 55936 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.4, Runtime API Version: 11.1\r\nW1122 10:26:51.868434 55936 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\n2022-11-22 10:26:54,445-INFO: devices: gpu\r\n2022-11-22 10:26:57,593-INFO: Detect model type: None\r\n2022-11-22 10:26:57,716-INFO: Selected strategies: ['qat_dis']\r\n2022-11-22 10:27:02,829-INFO: train config.distill_node_pair: ['teacher_conv2d_173.tmp_1', 'conv2d_173.tmp_1', 'teacher_conv2d_177.tmp_0', 'conv2d_177.tmp_0', 'teacher_conv2d_180.tmp_1', 'conv2d_180.tmp_1', 'teacher_conv2d_184.tmp_0', 'conv2d_184.tmp_0', 'teacher_conv2d_187.tmp_1', 'conv2d_187.tmp_1', 'teacher_conv2d_191.tmp_0', 'conv2d_191.tmp_0']\r\n2022-11-22 10:27:03,251-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'name': 'Distillation', 'loss': 'soft_label', 'node': [], 'alpha': 1.0, 'teacher_model_dir': './ppyoloe_crn_s_300e_coco', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\nAdding quant op with weight:|██████████████████████████████████████████| 324/324\r\nAdding OutScale op:|███████████████████████████████████████████████████| 319/319\r\n2022-11-22 10:27:07,641-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'name': 'Distillation', 'loss': 'soft_label', 'node': [], 'alpha': 1.0, 'teacher_model_dir': './ppyoloe_crn_s_300e_coco', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\nAdding quant op with weight:|████████████████████████████████████████| 1725/1725\r\nAdding OutScale op:|█████████████████████████████████████████████████| 1107/1107\r\n2022-11-22 10:29:53,033-INFO: When a preprocess_func is used in quant_aware, Need to save a mapping table to match variable names in the convert phase.\r\n2022-11-22 10:29:53,033-INFO: The mapping table is saved as './mapping_table_for_saving_inference_model'.\r\n2022-11-22 10:30:11,829-INFO: Total iter: 0, epoch: 0, batch: 0, loss: [13.393167 13.291335]\r\n2022-11-22 10:30:15,995-INFO: Total iter: 10, epoch: 0, batch: 10, loss: [12.573825 12.857247]\r\n2022-11-22 10:30:20,154-INFO: Total iter: 20, epoch: 0, batch: 20, loss: [12.493932 12.663242]\r\n2022-11-22 10:30:24,307-INFO: Total iter: 30, epoch: 0, batch: 30, loss: [nan nan]\r\n2022-11-22 10:30:28,446-INFO: Total iter: 40, epoch: 0, batch: 40, loss: [nan nan]\r\n2022-11-22 10:30:32,589-INFO: Total iter: 50, epoch: 0, batch: 50, loss: [nan nan]\r\n",
        "state": "closed",
        "user": "futureflsl",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-22T02:44:21+00:00",
        "updated_at": "2024-02-06T04:16:36+00:00",
        "closed_at": "2024-02-06T04:16:36+00:00",
        "comments_count": [
            "yghstill",
            "futureflsl"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1539,
        "title": "使用自动压缩工具prune_dis对模型进行减枝模型参数变大",
        "body": "padddleslim使用的develop版本\r\npaddle版本是paddle2.4rc0\r\n自动化压缩使用的是PaddleSlim-develop/example/auto_compression/image_classification/run.py\r\n配置文件是PaddleSlim-develop/example/auto_compression/image_classification/configs/MobileNetV3_large_x1_0/prune_dis.yaml\r\n\r\n对分类模型的减枝，执行命令python run.py后，**模型参数大小变大了**。\r\n\r\n原始模型参数：\r\n![image](https://user-images.githubusercontent.com/36955510/203250784-258fbfaf-1d50-4f7e-8624-21041cae5b77.png)\r\n模型减枝后模型参数：\r\n![image](https://user-images.githubusercontent.com/36955510/203250890-bb05fead-5def-446b-a5e7-1ce2bb01cbda.png)\r\n",
        "state": "closed",
        "user": "LiquorPerfect",
        "closed_by": "ceci3",
        "created_at": "2022-11-22T07:20:24+00:00",
        "updated_at": "2022-11-25T09:52:58+00:00",
        "closed_at": "2022-11-24T06:27:26+00:00",
        "comments_count": [
            "ceci3",
            "LiquorPerfect",
            "ceci3",
            "ceci3",
            "LiquorPerfect",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1541,
        "title": "采用官方提供的量化后模型，精度很低",
        "body": "从这里下载的模型\r\n![选区_159](https://user-images.githubusercontent.com/38750407/203253602-0ea75165-e5b4-41d7-8733-d58cf0f05196.jpg)\r\n在post_training_quantization/pytorcho_series目录下执行 python eval.py --config=./configs/yolov7_ptq.yaml命令\r\n配置文件为：\r\n![选区_161](https://user-images.githubusercontent.com/38750407/203254262-77e76b5f-d804-4251-bf30-0fc414cc482a.jpg)\r\n\r\n得到精度如下\r\n![选区_160](https://user-images.githubusercontent.com/38750407/203253803-0b9f95e9-868c-4a67-9b48-ee022ae05f4d.jpg)\r\n",
        "state": "closed",
        "user": "jiaerwang0328",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-22T07:42:13+00:00",
        "updated_at": "2024-02-06T02:59:40+00:00",
        "closed_at": "2024-02-06T02:59:40+00:00",
        "comments_count": [
            "ceci3",
            "jiaerwang0328",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1554,
        "title": "量化训练不生成calibration_file",
        "body": "自动压缩量化训练后只生成onnx模型，没有生成calibration.cache",
        "state": "closed",
        "user": "wuminjie12",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-25T06:03:16+00:00",
        "updated_at": "2024-02-06T02:59:40+00:00",
        "closed_at": "2024-02-06T02:59:40+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1558,
        "title": "ch_PP-OCRv3_rec_slim_infer int8量化问题",
        "body": "python3.7 tools/save_quant_model.py --quant_model_path=./ch_PP-OCRv3_rec_slim_infer --quant_model_filename=inference.pdmodel --quant_params_filename=inference.pdiparams --int8_model_save_path=./ch_PP-OCRv3_rec_slim_infer/int8\r\n\r\n--- Fused 0 subgraphs into layer_norm op.\r\n--- fused 0 pairs of fc lstm patterns\r\n--- fused 0 pairs of fc gru patterns\r\n--- fused 0 pairs of concatenated multi_gru ops\r\n--- fused 0 sequences of two multi_gru ops\r\nI1125 11:40:53.991871 16871 fuse_pass_base.cc:57] --- detected 9 subgraphs\r\nI1125 11:40:53.998540 16871 fuse_pass_base.cc:57] --- detected 4 subgraphs\r\nI1125 11:40:54.034428 16871 fuse_pass_base.cc:57] --- detected 13 subgraphs\r\nI1125 11:40:54.091616 16871 fuse_pass_base.cc:57] --- detected 32 subgraphs\r\nI1125 11:40:54.115307 16871 fuse_pass_base.cc:57] --- detected 4 subgraphs\r\n--- Fused 0 projection conv (as y) + elementwise_add patterns\r\n--- Fused 0 conv (as x) + elementwise_add patterns\r\n--- Fused 0 conv (as y) + elementwise_add patterns\r\nI1125 11:40:54.141652 16871 fuse_pass_base.cc:57] --- detected 2 subgraphs\r\nW1125 11:40:54.157826 16871 op_compat_sensible_pass.cc:207] Attribute(beta) of Op(swish) is not defined in opProto or is in extra set!The compatable check for this attribute is not use. Please remove it from the precondition of pass: conv_swish_mkldnn_fuse_pass\r\nI1125 11:40:54.158461 16871 fuse_pass_base.cc:57] --- detected 5 subgraphs\r\nI1125 11:40:54.169867 16871 fuse_pass_base.cc:57] --- detected 27 subgraphs\r\nI1125 11:40:54.179919 16871 fuse_pass_base.cc:57] --- detected 2 subgraphs\r\nI1125 11:40:54.191304 16871 fuse_pass_base.cc:57] --- detected 9 subgraphs\r\nI1125 11:40:54.201628 16871 fuse_pass_base.cc:57] --- detected 9 subgraphs\r\n--- fused 0 fc with gelu activation\r\n--- fused 0 fc with tanh activation\r\n--- fused 0 fc with sigmoid activation\r\n--- fused 0 fc with mish activation\r\n--- fused 0 fc with hard_swish activation\r\nI1125 11:40:54.209825 16871 fuse_pass_base.cc:57] --- detected 2 subgraphs\r\n--- Fused 2 MatmulTransposeReshape patterns for matmul Op\r\n--- Fused 0 MatmulTransposeReshape patterns for matmul_v2 Op\r\n--- fused 0 batch norm with relu activation\r\n--- fused 0 softplus with relu activation\r\n--- fused 0 softplus with tanh activation\r\n--- fused 0 softplus with leaky_relu activation\r\n--- fused 0 softplus with swish activation\r\n--- fused 0 softplus with hardswish activation\r\n--- fused 0 softplus with sqrt activation\r\n--- fused 0 softplus with abs activation\r\n--- fused 0 softplus with clip activation\r\n--- fused 0 softplus with gelu activation\r\n--- fused 0 softplus with relu6 activation\r\n--- fused 0 softplus with sigmoid activation\r\n/root/anaconda3/envs/paddlex/lib/python3.7/site-packages/paddle/fluid/contrib/slim/quantization/quant2_int8_mkldnn_pass.py:524: RuntimeWarning: divide by zero encountered in true_divide\r\naxis=axis)\r\nI1125 11:40:54.283635 16871 fuse_pass_base.cc:57] --- detected 2 subgraphs\r\n--- fused 2 scale with matmul\r\n--- Fused 0 ReshapeTransposeMatmul patterns for matmul Op\r\n--- Fused 0 ReshapeTransposeMatmul patterns for matmul Op with transpose's xshape\r\n--- Fused 0 ReshapeTransposeMatmul patterns for matmul Op with reshape's xshape\r\n--- Fused 0 ReshapeTransposeMatmul patterns for matmul Op with reshape's xshape with transpose's xshape\r\n--- Fused 0 ReshapeTransposeMatmul patterns for matmul_v2 Op\r\n--- Fused 0 ReshapeTransposeMatmul patterns for matmul_v2 Op with transpose's xshape\r\n--- Fused 0 ReshapeTransposeMatmul patterns for matmul_v2 Op with reshape's xshape\r\n--- Fused 0 ReshapeTransposeMatmul patterns for matmul_v2 Op with reshape's xshape with transpose's xshape\r\nI1125 11:40:54.311667 16871 fuse_pass_base.cc:57] --- detected 36 subgraphs\r\n--- quantized 36 conv2d ops\r\n--- quantized 0 conv2d ops with residual connection\r\n--- quantized 0 pool2d ops\r\nI1125 11:40:54.314494 16871 fuse_pass_base.cc:57] --- detected 1 subgraphs\r\n--- quantized 1 concat ops\r\n--- quantized 0 prior_box ops\r\nI1125 11:40:54.317961 16871 fuse_pass_base.cc:57] --- detected 6 subgraphs\r\n--- quantized 6 transpose2 ops\r\nI1125 11:40:54.319792 16871 fuse_pass_base.cc:57] --- detected 9 subgraphs\r\n--- quantized 9 fc ops\r\nI1125 11:40:54.322600 16871 fuse_pass_base.cc:57] --- detected 3 subgraphs\r\n--- quantized 3 reshape2 ops\r\nI1125 11:40:54.328544 16871 fuse_pass_base.cc:57] --- detected 2 subgraphs\r\n--- quantized 2 matmul ops\r\n--- quantized 0 elementwise_add ops\r\n--- quantized 0 elementwise_mul ops\r\n--- quantized 0 fusion_gru ops\r\n--- quantized 0 multi_gru ops\r\n--- quantized 0 fusion_lstm ops\r\nI1125 11:40:54.332952 16871 fuse_pass_base.cc:57] --- detected 6 subgraphs\r\n--- quantized 6 slice ops\r\n--- quantized 0 nearest_interp ops\r\n--- squashed 0 scale with dequantize op\r\n--- squashed 0 scale with quantize op\r\nI1125 11:40:54.350023 16871 fuse_pass_base.cc:57] --- detected 65 subgraphs\r\nI1125 11:40:54.373798 16871 fuse_pass_base.cc:57] --- detected 49 subgraphs\r\n--- squashed 49 dequantize-quantize pairs\r\nI1125 11:40:54.374718 16871 fuse_pass_base.cc:57] --- detected 1 subgraphs\r\n--- squashed 1 requantize ops\r\n--- squashed 0 requantize ops\r\nI1125 11:40:54.377631 16871 fuse_pass_base.cc:57] --- detected 12 subgraphs\r\n--- squashed 12 dequant with ops\r\nI1125 11:40:54.377813 16871 fuse_pass_base.cc:57] --- detected 1 subgraphs\r\n--- squashed 0 quantize op\r\n--- squashed 0 quantize with bfloat16 conv2d op\r\nTraceback (most recent call last):\r\nFile \"tools/save_quant_model.py\", line 155, in\r\ntest_args.save_model_filename, test_args.save_params_filename)\r\nFile \"tools/save_quant_model.py\", line 142, in transform_and_save_int8_model\r\nparams_filename=save_params_filename)\r\nFile \"</root/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-123>\", line 2, in save_inference_model\r\nFile \"/root/anaconda3/envs/paddlex/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in impl\r\nreturn wrapped_func(*args, **kwargs)\r\nFile \"/root/anaconda3/envs/paddlex/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 443, in impl\r\nreturn func(*args, **kwargs)\r\nFile \"/root/anaconda3/envs/paddlex/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1432, in save_inference_model\r\nprepend_feed_ops(main_program, feeded_var_names)\r\nFile \"/root/anaconda3/envs/paddlex/lib/python3.7/site-packages/paddle/fluid/io.py\", line 1218, in prepend_feed_ops\r\ni=i, name=name))\r\nValueError: The feeded_var_names[0]: 'x' doesn't exist in pruned inference program. Please check whether 'x' is a valid feed_var name, or remove it from feeded_var_names if 'x' is not involved in the target_vars calculation.\r\n\r\n请问是哪里的问题没能转换成功呢",
        "state": "closed",
        "user": "maiquanshen",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-28T02:06:17+00:00",
        "updated_at": "2025-02-11T06:41:26+00:00",
        "closed_at": "2025-02-11T06:41:26+00:00",
        "comments_count": [
            "yghstill",
            "maiquanshen",
            "maiquanshen",
            "mysteriousHerb",
            "XGZhang11",
            "lizexu123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1557,
        "title": "yoloe是否支持自动压缩？对精度速度的影响如何？",
        "body": null,
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-25T06:18:25+00:00",
        "updated_at": "2024-02-06T02:59:41+00:00",
        "closed_at": "2024-02-06T02:59:41+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1561,
        "title": "请问，语音合成声学模型，能否paddleslim进行量化呢？模型fastspeech2",
        "body": null,
        "state": "closed",
        "user": "liroda",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-28T08:27:51+00:00",
        "updated_at": "2024-02-06T02:59:42+00:00",
        "closed_at": "2024-02-06T02:59:42+00:00",
        "comments_count": [
            "yghstill",
            "liroda",
            "leiqing1",
            "yghstill",
            "liroda",
            "yt605155624",
            "yt605155624"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1562,
        "title": "自动压缩c++部署，trt_run不管用哪个run_mode速度都都一样？",
        "body": null,
        "state": "closed",
        "user": "alfheim1993",
        "closed_by": "XGZhang11",
        "created_at": "2022-11-28T08:42:49+00:00",
        "updated_at": "2024-02-06T04:18:33+00:00",
        "closed_at": "2024-02-06T04:18:33+00:00",
        "comments_count": [
            "alfheim1993",
            "yghstill",
            "alfheim1993"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1565,
        "title": "YOLOv5s量化后转换会onnx报错",
        "body": "在用paddleslim对YOLOv5s进行ACT压缩后，转换回ONNX时报错如下：\r\n![image](https://user-images.githubusercontent.com/76981650/204718870-fbb00552-1486-49bd-8579-3737bdbdcb1e.png)\r\n报错上看，是paddle2onnx不支持量化后的模型，是这样吗？",
        "state": "closed",
        "user": "litao-zhx",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-11-30T05:57:07+00:00",
        "updated_at": "2024-02-06T02:59:43+00:00",
        "closed_at": "2024-02-06T02:59:43+00:00",
        "comments_count": [
            "www7890",
            "yghstill",
            "www7890"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1568,
        "title": "量化模型转onnx报错",
        "body": "paddleslim 版本是2.4.0RC，paddlepaddle版本也是2.4.0RC，paddleslim版本是1.0.0RC，下图是export模型时配置的参数\r\n![image](https://user-images.githubusercontent.com/29878249/205034219-ed4a8a3e-3fff-40de-a010-f10b26215d97.png)\r\n设置了onnx_format=True，但是paddle2onnx时还是报错，如下图\r\n![image](https://user-images.githubusercontent.com/29878249/205034438-fda4b2f0-2b58-4079-adff-83fcb6fc930e.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "backtime92",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-01T10:53:34+00:00",
        "updated_at": "2024-02-06T02:59:44+00:00",
        "closed_at": "2024-02-06T02:59:44+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1569,
        "title": "使用官方demo对yoloe模型进行离线量化失败",
        "body": "![image](https://user-images.githubusercontent.com/102579571/205203907-8d740a37-2de1-45d3-8626-1178dd81c47c.png)\r\n![image](https://user-images.githubusercontent.com/102579571/205204002-e8d5b462-1167-44a1-bd39-e392fbfad74f.png)\r\n命令如下\r\n![image](https://user-images.githubusercontent.com/102579571/205204071-e604d565-22e6-4795-80d2-fc302a85d4af.png)\r\n",
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-02T02:51:05+00:00",
        "updated_at": "2024-02-06T02:59:45+00:00",
        "closed_at": "2024-02-06T02:59:45+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1570,
        "title": "离线量化yoloe模型速度不增反降",
        "body": "量化前\r\n![image](https://user-images.githubusercontent.com/102579571/205223420-64a2db8f-06f1-4b7d-87c3-89595eb76068.png)\r\n量化后\r\n![image](https://user-images.githubusercontent.com/102579571/205223455-9dedbf9a-06fd-4144-9607-872d2002f0e5.png)\r\n\r\n\r\n\r\n使用的是这个demo\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/post_training_quantization/detection#%E7%A6%BB%E7%BA%BF%E9%87%8F%E5%8C%96%E6%B5%81%E7%A8%8B",
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-02T05:44:44+00:00",
        "updated_at": "2024-02-06T02:59:46+00:00",
        "closed_at": "2024-02-06T02:59:46+00:00",
        "comments_count": [
            "yghstill",
            "lilianjie111111",
            "L-lei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1572,
        "title": "yoloe静态离线量化问题，使用demo如下所示。",
        "body": "![image](https://user-images.githubusercontent.com/102579571/205232923-400c4310-df05-4722-9eaa-5cfbf4c7b37b.png)\r\n配置文件如下所示\r\n![image](https://user-images.githubusercontent.com/102579571/205233110-5204561c-89f7-4103-b97b-a909c9d616a5.png)\r\n\r\n",
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-02T06:51:59+00:00",
        "updated_at": "2024-02-06T02:59:46+00:00",
        "closed_at": "2024-02-06T02:59:46+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1577,
        "title": "paddleslim支持mbart模型量化吗？",
        "body": null,
        "state": "closed",
        "user": "Amy234543",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-06T08:45:28+00:00",
        "updated_at": "2024-02-06T02:59:47+00:00",
        "closed_at": "2024-02-06T02:59:47+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1579,
        "title": "离线量化后模型转MKLDNN模型推理报错",
        "body": "模型为：paddleocr开源的字符方向分类器模型，https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar。\r\n经过离线量化，在c++ paddle inference（版本为2.3.2）上进行MKLDNN，GPU上推理没有问题。\r\n将量化好的模型使用脚本save_quant_model.py转换为mkldnn 量化模型（python环境为paddle2.4），进行c++ paddle inference推理报错，使用本工程提供的sample_tester_fake_data.cc可执行文件报错类型一样。麻烦排查一下。\r\n\r\nWARNING: Logging before InitGoogleLogging() is written to STDERR\r\nW1207 22:04:49.230881 109754 analysis_predictor.cc:1694] Deprecated. Please use CreatePredictor instead.\r\nI1207 22:04:49.680517 109754 analysis_predictor.cc:937] MKLDNN is enabled\r\n--- Running analysis [ir_graph_build_pass]\r\n--- Running analysis [ir_graph_clean_pass]\r\n--- Running analysis [ir_analysis_pass]\r\n--- Running IR pass [mkldnn_placement_pass]\r\n--- Running IR pass [simplify_with_basic_ops_pass]\r\n--- Running IR pass [layer_norm_fuse_pass]\r\n---    Fused 0 subgraphs into layer_norm op.\r\n--- Running IR pass [attention_lstm_fuse_pass]\r\n--- Running IR pass [seqconv_eltadd_relu_fuse_pass]\r\n--- Running IR pass [seqpool_cvm_concat_fuse_pass]\r\n--- Running IR pass [mul_lstm_fuse_pass]\r\n--- Running IR pass [fc_gru_fuse_pass]\r\n---    fused 0 pairs of fc gru patterns\r\n--- Running IR pass [mul_gru_fuse_pass]\r\n--- Running IR pass [seq_concat_fc_fuse_pass]\r\n--- Running IR pass [gpu_cpu_squeeze2_matmul_fuse_pass]\r\n--- Running IR pass [gpu_cpu_reshape2_matmul_fuse_pass]\r\n--- Running IR pass [gpu_cpu_flatten2_matmul_fuse_pass]\r\n--- Running IR pass [matmul_v2_scale_fuse_pass]\r\n--- Running IR pass [gpu_cpu_map_matmul_v2_to_mul_pass]\r\n--- Running IR pass [gpu_cpu_map_matmul_v2_to_matmul_pass]\r\n--- Running IR pass [matmul_scale_fuse_pass]\r\n--- Running IR pass [gpu_cpu_map_matmul_to_mul_pass]\r\n--- Running IR pass [fc_fuse_pass]\r\n--- Running IR pass [repeated_fc_relu_fuse_pass]\r\n--- Running IR pass [squared_mat_sub_fuse_pass]\r\n--- Running IR pass [conv_bn_fuse_pass]\r\n--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\r\n--- Running IR pass [conv_transpose_bn_fuse_pass]\r\n--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]\r\n--- Running IR pass [is_test_pass]\r\n--- Running IR pass [runtime_context_cache_pass]\r\n--- Running IR pass [depthwise_conv_mkldnn_pass]\r\n--- Running IR pass [conv_bn_fuse_pass]\r\n--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\r\n--- Running IR pass [conv_transpose_bn_fuse_pass]\r\n--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]\r\n--- Running IR pass [conv_bias_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_transpose_bias_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_mkldnn_fuse_pass]\r\n---    Fused 0 projection conv (as y) + elementwise_add patterns\r\n---    Fused 0 conv (as x) + elementwise_add patterns\r\n---    Fused 0 conv (as y) + elementwise_add patterns\r\n--- Running IR pass [conv_concat_relu_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_relu_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_leaky_relu_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_relu6_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_swish_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_hard_swish_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_mish_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_hard_sigmoid_mkldnn_fuse_pass]\r\n--- Running IR pass [conv_gelu_mkldnn_fuse_pass]\r\n--- Running IR pass [scale_matmul_fuse_pass]\r\n---    fused 0 scale with matmul\r\n--- Running IR pass [reshape_transpose_matmul_mkldnn_fuse_pass]\r\n---    Fused 0 ReshapeTransposeMatmul patterns for matmul Op\r\n---    Fused 0 ReshapeTransposeMatmul patterns for matmul Op with transpose's xshape\r\n---    Fused 0 ReshapeTransposeMatmul patterns for matmul Op with reshape's xshape\r\n---    Fused 0 ReshapeTransposeMatmul patterns for matmul Op with reshape's xshape with transpose's xshape\r\n--- Running IR pass [reshape_transpose_matmul_v2_mkldnn_fuse_pass]\r\n---    Fused 0 ReshapeTransposeMatmul patterns for matmul_v2 Op\r\n---    Fused 0 ReshapeTransposeMatmul patterns for matmul_v2 Op with transpose's xshape\r\n---    Fused 0 ReshapeTransposeMatmul patterns for matmul_v2 Op with reshape's xshape\r\n---    Fused 0 ReshapeTransposeMatmul patterns for matmul_v2 Op with reshape's xshape with transpose's xshape\r\n--- Running IR pass [matmul_transpose_reshape_fuse_pass]\r\n---    Fused 0 MatmulTransposeReshape patterns for matmul Op\r\n--- Running IR pass [matmul_v2_transpose_reshape_fuse_pass]\r\n---    Fused 0 MatmulTransposeReshape patterns for matmul_v2 Op\r\n--- Running IR pass [batch_norm_act_fuse_pass]\r\n---    fused 0 batch norm with relu activation\r\n--- Running IR pass [softplus_activation_mkldnn_fuse_pass]\r\n---    fused 0 softplus with relu activation\r\n---    fused 0 softplus with tanh activation\r\n---    fused 0 softplus with leaky_relu activation\r\n---    fused 0 softplus with swish activation\r\n---    fused 0 softplus with hardswish activation\r\n---    fused 0 softplus with sqrt activation\r\n---    fused 0 softplus with abs activation\r\n---    fused 0 softplus with clip activation\r\n---    fused 0 softplus with gelu activation\r\n---    fused 0 softplus with relu6 activation\r\n---    fused 0 softplus with sigmoid activation\r\n--- Running IR pass [elt_act_mkldnn_fuse_pass]\r\n---    fused 0 elementwise_add with relu activation\r\n---    fused 0 elementwise_add with tanh activation\r\n---    fused 0 elementwise_add with leaky_relu activation\r\n---    fused 0 elementwise_add with swish activation\r\n---    fused 0 elementwise_add with hardswish activation\r\n---    fused 0 elementwise_add with sqrt activation\r\n---    fused 0 elementwise_add with abs activation\r\n---    fused 0 elementwise_add with clip activation\r\n---    fused 0 elementwise_add with gelu activation\r\n---    fused 0 elementwise_add with relu6 activation\r\n---    fused 0 elementwise_add with sigmoid activation\r\n---    fused 0 elementwise_sub with relu activation\r\n---    fused 0 elementwise_sub with tanh activation\r\n---    fused 0 elementwise_sub with leaky_relu activation\r\n---    fused 0 elementwise_sub with swish activation\r\n---    fused 0 elementwise_sub with hardswish activation\r\n---    fused 0 elementwise_sub with sqrt activation\r\n---    fused 0 elementwise_sub with abs activation\r\n---    fused 0 elementwise_sub with clip activation\r\n---    fused 0 elementwise_sub with gelu activation\r\n---    fused 0 elementwise_sub with relu6 activation\r\n---    fused 0 elementwise_sub with sigmoid activation\r\n---    fused 0 elementwise_mul with relu activation\r\n---    fused 0 elementwise_mul with tanh activation\r\n---    fused 0 elementwise_mul with leaky_relu activation\r\n---    fused 0 elementwise_mul with swish activation\r\n---    fused 0 elementwise_mul with hardswish activation\r\n---    fused 0 elementwise_mul with sqrt activation\r\n---    fused 0 elementwise_mul with abs activation\r\n---    fused 0 elementwise_mul with clip activation\r\n---    fused 0 elementwise_mul with gelu activation\r\n---    fused 0 elementwise_mul with relu6 activation\r\n---    fused 0 elementwise_mul with sigmoid activation\r\n--- Running analysis [ir_params_sync_among_devices_pass]\r\n--- Running analysis [adjust_cudnn_workspace_size_pass]\r\n--- Running analysis [inference_op_replace_pass]\r\n--- Running analysis [ir_graph_to_program_pass]\r\nI1207 22:04:50.040491 109754 analysis_predictor.cc:1007] ======= optimize end =======\r\nI1207 22:04:50.042610 109754 naive_executor.cc:102] ---  skip [feed], feed -> x\r\nI1207 22:04:50.044800 109754 naive_executor.cc:102] ---  skip [save_infer_model/scale_0.tmp_0], fetch -> fetch\r\nBatch size 1\r\nI1207 22:04:50.051362 109754 device_context.cc:737] oneDNN v2.5.4\r\nterminate called after throwing an instance of 'phi::enforce::EnforceNotMet'\r\n  what():  \r\n\r\n  Compile Traceback (most recent call last):\r\n    File \"/Applications/PyCharm CE 2022.2 EAP.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\", line 2195, in <module>\r\n      main()\r\n    File \"/Applications/PyCharm CE 2022.2 EAP.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\", line 2177, in main\r\n      globals = debugger.run(setup['file'], None, None, is_module)\r\n    File \"/Applications/PyCharm CE 2022.2 EAP.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\", line 1489, in run\r\n      return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)\r\n    File \"/Applications/PyCharm CE 2022.2 EAP.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py\", line 1496, in _exec\r\n      pydev_imports.execfile(file, globals, locals)  # execute the script\r\n    File \"/Applications/PyCharm CE 2022.2 EAP.app/Contents/plugins/python-ce/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n      exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n    File \"/Users/zhoujun20/Desktop/工作相关/table/PaddleOCR/tools/export_model.py\", line 255, in <module>\r\n      main()\r\n    File \"/Users/zhoujun20/Desktop/工作相关/table/PaddleOCR/tools/export_model.py\", line 250, in main\r\n      export_single_model(\r\n    File \"/Users/zhoujun20/Desktop/工作相关/table/PaddleOCR/tools/export_model.py\", line 171, in export_single_model\r\n      paddle.jit.save(model, save_path)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/jit.py\", line 631, in wrapper\r\n      func(layer, path, input_spec, **configs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/jit.py\", line 860, in save\r\n      concrete_program = static_func.concrete_program_specify_input_spec(\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 527, in concrete_program_specify_input_spec\r\n      concrete_program, _ = self.get_concrete_program(\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 436, in get_concrete_program\r\n      concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 801, in __getitem__\r\n      self._caches[item_id] = self._build_once(item)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 785, in _build_once\r\n      concrete_program = ConcreteProgram.from_func_spec(\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 733, in from_func_spec\r\n      outputs = static_func(*inputs)\r\n    File \"/var/folders/9_/fj3gl_0x7mx4_bp7wx1q6z6h0000gp/T/tmp_owozyrl.py\", line 27, in forward\r\n      x = paddle.jit.dy2static.convert_ifelse(self.use_backbone, true_fn_1,\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 211, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py\", line 257, in _run_py_ifelse\r\n      return true_fn(*true_args) if pred else false_fn(*false_args)\r\n    File \"/Users/zhoujun20/Desktop/工作相关/table/PaddleOCR/ppocr/modeling/architectures/base_model.py\", line 86, in forward\r\n      x = self.backbone(x)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/Users/zhoujun20/Desktop/工作相关/table/PaddleOCR/ppocr/modeling/backbones/rec_mobilenet_v3.py\", line 134, in forward\r\n      x = self.conv1(x)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/Users/zhoujun20/Desktop/工作相关/table/PaddleOCR/ppocr/modeling/backbones/det_mobilenet_v3.py\", line 179, in forward\r\n      x = self.conv(x)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/nn/layer/conv.py\", line 666, in forward\r\n      out = F.conv._conv_nd(\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/nn/functional/conv.py\", line 168, in _conv_nd\r\n      helper.append_op(\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/layer_helper.py\", line 44, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3615, in append_op\r\n      op = Operator(\r\n    File \"/Users/zhoujun20/opt/anaconda3/envs/py38/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 2635, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::AnalysisPredictor::ZeroCopyRun()\r\n1   paddle::framework::NaiveExecutor::Run()\r\n2   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, phi::Place const&)\r\n3   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, phi::Place const&) const\r\n4   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, phi::Place const&, paddle::framework::RuntimeContext*) const\r\n5   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<phi::CPUPlace, false, 0ul, paddle::operators::ConvMKLDNNOpKernel<signed char, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n6   paddle::operators::ConvMKLDNNOpKernel<signed char, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The type of data we are trying to retrieve does not match the type of data currently contained in the container.\r\n  [Hint: Expected dtype() == paddle::experimental::CppTypeToDataType<T>::Type(), but received dtype():2 != paddle::experimental::CppTypeToDataType<T>::Type():12.] (at /paddle/paddle/phi/core/dense_tensor.cc:137)\r\n  [operator < conv2d > error]\r\nrun.sh: line 43: 109754 Aborted                 GLOG_logtostderr=1 ./build/sample_tester_fake_data --infer_model=${MODEL_DIR} --batch_size=1 --num_threads=${num_threads} --iterations=${ITERATIONS} --with_accuracy_layer=${with_accuracy_layer} --use_analysis=${with_analysis}\r\n",
        "state": "closed",
        "user": "LiquorPerfect",
        "closed_by": "LiquorPerfect",
        "created_at": "2022-12-07T06:27:41+00:00",
        "updated_at": "2024-01-16T12:09:20+00:00",
        "closed_at": "2024-01-16T12:09:20+00:00",
        "comments_count": [
            "yghstill",
            "LiquorPerfect",
            "LiquorPerfect"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1581,
        "title": "请问paddleslim实现的SANAS原理出自哪篇paper？",
        "body": null,
        "state": "closed",
        "user": "grapefruitL",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-08T08:26:55+00:00",
        "updated_at": "2024-02-06T02:59:48+00:00",
        "closed_at": "2024-02-06T02:59:48+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1582,
        "title": "loss为nan",
        "body": "为什么程序第一次运行的时候loss还是一个数，后面再一次运行，loss就变成nan了\r\n\r\n2022-12-08 17:57:31,371-INFO: Total iter: 0, epoch: 0, batch: 0, loss: [10.000229]\r\n2022-12-08 17:57:32,672-INFO: Total iter: 10, epoch: 0, batch: 10, loss: [nan]\r\n2022-12-08 17:57:33,992-INFO: Total iter: 20, epoch: 0, batch: 20, loss: [nan]\r\n2022-12-08 17:57:35,326-INFO: Total iter: 30, epoch: 0, batch: 30, loss: [nan]\r\n2022-12-08 17:57:36,653-INFO: Total iter: 40, epoch: 0, batch: 40, loss: [nan]\r\n2022-12-08 17:57:37,973-INFO: Total iter: 50, epoch: 0, batch: 50, loss: [nan]\r\n\r\n是不是哪里有缓存文件没有删掉？\r\n\r\n\r\n ",
        "state": "closed",
        "user": "liumingzhu6060",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-08T10:00:07+00:00",
        "updated_at": "2024-02-06T02:59:49+00:00",
        "closed_at": "2024-02-06T02:59:49+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1583,
        "title": "带lstm的crnn模型是不支持int8量化吗",
        "body": "在语音增强方向上这个网络效果还可以，也有很多变种，但是基本结构如下：\r\n![image](https://user-images.githubusercontent.com/3354428/206599922-29ef13ce-1576-49ac-8582-e572704b4f70.png)\r\n![image](https://user-images.githubusercontent.com/3354428/206600323-8d0e51f6-a909-4475-9c4d-1dfba0d30019.png)\r\n\r\n",
        "state": "closed",
        "user": "zuowanbushiwo",
        "closed_by": "zuowanbushiwo",
        "created_at": "2022-12-09T01:12:17+00:00",
        "updated_at": "2022-12-19T01:42:58+00:00",
        "closed_at": "2022-12-19T01:42:58+00:00",
        "comments_count": [
            "ceci3",
            "zuowanbushiwo",
            "ceci3",
            "zuowanbushiwo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1584,
        "title": "ACT tools onnx output with different opset version",
        "body": "Hi, \r\nI did success to use ACT tools for model pruning and quantization. \r\nAnd I want to output  model with different opset version onnx model, because I need to deploy model on different platform\r\nIs there anyway to do it? Thanks\r\n",
        "state": "closed",
        "user": "www7890",
        "closed_by": "www7890",
        "created_at": "2022-12-09T09:23:43+00:00",
        "updated_at": "2022-12-13T05:41:34+00:00",
        "closed_at": "2022-12-13T05:41:34+00:00",
        "comments_count": [
            "zzjjay",
            "www7890"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1588,
        "title": "使用auto_compress的结构化剪枝如何指定参数名",
        "body": "我想对模型使用诸如：\r\npruner = slim.prune.Pruner()\r\npruned_program, _, _ = pruner.prune(\r\n        train_program,\r\n        fluid.global_scope(),\r\n        params=[\"conv2_1_sep_weights\", \"conv2_2_sep_weights\"],\r\n        ratios=[0.33] * 2,\r\n        place=fluid.CPUPlace())\r\n的结构化剪枝功能，但是params的信息我并不清楚，我是否能通过一定的API调用，或者加入一些代码，分析出当前模型可以进行剪枝操作的参数列表？",
        "state": "closed",
        "user": "moonlightian",
        "closed_by": "XGZhang11",
        "created_at": "2022-12-13T08:32:25+00:00",
        "updated_at": "2024-02-06T04:18:53+00:00",
        "closed_at": "2024-02-06T04:18:53+00:00",
        "comments_count": [
            "ceci3",
            "moonlightian",
            "moonlightian",
            "moonlightian",
            "ceci3",
            "moonlightian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1589,
        "title": "压缩模型训练报错",
        "body": "使用这样的命令：\r\n![image](https://user-images.githubusercontent.com/99952437/207415833-0e7a4396-09f3-4e28-8144-6463c53a585a.png)\r\n\r\n会报这样的错误：\r\n![image](https://user-images.githubusercontent.com/99952437/207415750-4c76a5ac-2ec2-4c38-9369-df4bb3a904c6.png)\r\n\r\n如果install会：\r\n![image](https://user-images.githubusercontent.com/99952437/207415709-d641ba18-0c75-4e10-af98-a162ba6abd5e.png)\r\n\r\n请问该怎么解决？",
        "state": "closed",
        "user": "NwTbbetter",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-13T18:30:39+00:00",
        "updated_at": "2024-02-06T02:59:50+00:00",
        "closed_at": "2024-02-06T02:59:50+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1591,
        "title": "./paddleslim/dist/single_distiller.py 文件内变量重命名和变量clone代码矛盾",
        "body": "版本：\r\n```\r\npaddlepaddle-gpu          2.4.1.post117          \r\npaddleslim                2.4.0\r\n```\r\n\r\nin ./paddleslim/dist/single_distiller.py \r\n\r\n55行开始这部分，取`teacher_var`使用的是`teacher_program.list_vars()`，但后续\r\n`renamed_var = teacher_program.global_block()._rename_var(teacher_var.name, new_name)`\r\n的`global_block()`仅能返回`blocks[0]`，\r\n**若teacher_program包含多block这里会报错：**\r\n\r\n```python\r\n    for teacher_var in teacher_program.list_vars():\r\n        skip_rename = False\r\n        if teacher_var.name != 'fetch' and (not merge_feed or\r\n                                            teacher_var.name != 'feed'):\r\n            if teacher_var.name in data_name_map.keys():\r\n                new_name = data_name_map[teacher_var.name]\r\n                if new_name == teacher_var.name:\r\n                    skip_rename = True\r\n            else:\r\n                new_name = name_prefix + teacher_var.name\r\n            if not skip_rename:\r\n                # scope var rename\r\n                old_var = teacher_scope.var(teacher_var.name).get_tensor()\r\n                renamed_var = scope.var(new_name).get_tensor()\r\n                renamed_var.set(np.array(old_var), place)\r\n\r\n                # program var rename\r\n                renamed_var = teacher_program.global_block()._rename_var(\r\n                    teacher_var.name, new_name)\r\n\r\n    for teacher_var in teacher_program.list_vars():\r\n        if teacher_var.name != 'fetch' and (not merge_feed or\r\n                                            teacher_var.name != 'feed'):\r\n            # student program add var\r\n            new_var = student_program.global_block()._clone_variable(\r\n                teacher_var, force_persistable=False)\r\n            new_var.stop_gradient = True\r\n```\r\n\r\n建议修改为如下方式正确遍历：\r\n\r\n```python\r\n    for teacher_block in teacher_program.blocks:\r\n        for teacher_var in list(teacher_block.vars.values()):\r\n            skip_rename = False\r\n            if teacher_var.name != 'fetch' and (not merge_feed or\r\n                                                teacher_var.name != 'feed'):\r\n                if teacher_var.name in data_name_map.keys():\r\n                    new_name = data_name_map[teacher_var.name]\r\n                    if new_name == teacher_var.name:\r\n                        skip_rename = True\r\n                else:\r\n                    new_name = name_prefix + teacher_var.name\r\n                if not skip_rename:\r\n                    # scope var rename\r\n                    old_var = teacher_scope.var(teacher_var.name).get_tensor()\r\n                    renamed_var = scope.var(new_name).get_tensor()\r\n                    renamed_var.set(np.array(old_var), place)\r\n\r\n                    # program var rename\r\n                    renamed_var = teacher_block._rename_var(\r\n                        teacher_var.name, new_name)\r\n\r\n    idx = 0\r\n    for teacher_block in teacher_program.blocks:\r\n        for teacher_var in list(teacher_block.vars.values()):\r\n            if teacher_var.name != 'fetch' and (not merge_feed or\r\n                                                teacher_var.name != 'feed'):\r\n                # student program add var\r\n                new_var = student_program.blocks[idx]._clone_variable(\r\n                    teacher_var, force_persistable=False)\r\n                new_var.stop_gradient = True\r\n        idx += 1\r\n\r\n    idx = 0\r\n    for block in teacher_program.blocks:\r\n        for op in block.ops:\r\n            if (not merge_feed or op.type != 'feed') and op.type != 'fetch':\r\n                inputs = {}\r\n                outputs = {}\r\n                attrs = {}\r\n                for input_name in op.input_names:\r\n                    inputs[input_name] = [\r\n                        block.var(in_var_name)\r\n                        for in_var_name in op.input(input_name)\r\n                    ]\r\n\r\n                for output_name in op.output_names:\r\n                    outputs[output_name] = [\r\n                        block.var(out_var_name)\r\n                        for out_var_name in op.output(output_name)\r\n                    ]\r\n                for attr_name in op.attr_names:\r\n                    attrs[attr_name] = op.attr(attr_name)\r\n                student_program.blocks[idx].append_op(\r\n                    type=op.type, inputs=inputs, outputs=outputs, attrs=attrs)\r\n        idx += 1\r\n```\r\n\r\n",
        "state": "closed",
        "user": "hzkzTech",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-14T06:47:31+00:00",
        "updated_at": "2024-02-06T02:59:51+00:00",
        "closed_at": "2024-02-06T02:59:51+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1596,
        "title": "离线量化超参搜索不支持输出含有LoDTensor的模型",
        "body": null,
        "state": "closed",
        "user": "ceci3",
        "closed_by": "XGZhang11",
        "created_at": "2022-12-20T02:51:45+00:00",
        "updated_at": "2024-02-06T04:19:01+00:00",
        "closed_at": "2024-02-06T04:19:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1593,
        "title": "自动压缩工具报错",
        "body": "报错如下：\r\n![image](https://user-images.githubusercontent.com/102579571/207583801-31225b68-47eb-44bb-82a0-99fde4b69fe2.png)\r\n\r\n![image](https://user-images.githubusercontent.com/102579571/207583501-03cfbd45-09b8-48eb-bc6d-884b3f69c5ec.png)\r\n数据集如下：\r\n![image](https://user-images.githubusercontent.com/102579571/207583575-f15891d6-b293-489e-98c9-8207dde471da.png)\r\ndemo如下：\r\n![image](https://user-images.githubusercontent.com/102579571/207583727-aa600b60-9e86-439e-9071-af06eb37cae4.png)\r\n",
        "state": "closed",
        "user": "lilianjie111111",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-14T11:30:49+00:00",
        "updated_at": "2024-02-06T02:59:51+00:00",
        "closed_at": "2024-02-06T02:59:51+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1600,
        "title": "X2Paddle转换ONNX模型使用paddleSlim中ACT一直报错",
        "body": "paddleSlim:2.3.3\r\nX2Paddle:2.3.1\r\n模型：yolo5 lite\r\n\r\n使用X2Paddle将pytorch导出的ONNX模型转换为paddle的inference模型，然后使用paddleSlim中的ACT进行量化，然后一直报如下错误：\r\nKeyError: 'x2paddle_images'（通过netron工具查看模型的输入节点名称就是x2paddle_images）\r\n\r\n注：\r\n1.ACT配置项参考的是picodet_s_qat_dis.yaml文件\r\n2.数据路径没有问题\r\n\r\n![image](https://user-images.githubusercontent.com/36984088/208800253-d0253760-bf6f-45d4-80a2-d6d21c7d1179.png)\r\n",
        "state": "closed",
        "user": "fengyanWang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-21T01:40:21+00:00",
        "updated_at": "2024-02-06T02:59:52+00:00",
        "closed_at": "2024-02-06T02:59:52+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1595,
        "title": "剪枝错误：(NotFound) Cannot find attribute (use_mkldnn)",
        "body": "`RuntimeError                              Traceback (most recent call last)\r\n/tmp/ipykernel_9478/3276394805.py in <module>\r\n      9     train_dataloader=val_data_loader,\r\n     10     eval_dataloader=val_data_loader)\r\n---> 11 ac.compress()\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.0.0.dev0-py3.7.egg/paddleslim/auto_compression/compressor.py in compress(self)\r\n    594         ) in enumerate(zip(self._strategy, self._config, self.train_config)):\r\n    595             self.single_strategy_compress(strategy, config, strategy_idx,\r\n--> 596                                           train_config)\r\n    597 \r\n    598         if strategy == 'ptq_hpo' and config.max_quant_count == 1 and platform.system(\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.0.0.dev0-py3.7.egg/paddleslim/auto_compression/compressor.py in single_strategy_compress(self, strategy, config, strategy_idx, train_config)\r\n    771             train_program_info, test_program_info = self._prepare_program(\r\n    772                 inference_program, feed_target_names, fetch_targets, patterns,\r\n--> 773                 strategy, config, train_config)\r\n    774             if 'unstructure' in strategy:\r\n    775                 test_program_info.program._program = remove_unused_var_nodes(\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.0.0.dev0-py3.7.egg/paddleslim/auto_compression/compressor.py in _prepare_program(self, program, feed_target_names, fetch_targets, patterns, strategy, config, train_config)\r\n    500             self._pruner, train_program_info = build_prune_program(\r\n    501                 self._exe, self._places, config_dict, train_program_info,\r\n--> 502                 strategy, patterns, self.eval_dataloader)\r\n    503 \r\n    504         if train_config.use_fleet:\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.0.0.dev0-py3.7.egg/paddleslim/auto_compression/create_compressed_program.py in build_prune_program(executor, place, config, train_program_info, strategy, patterns, eval_dataloader)\r\n    521             width_mult=(1.0 - config['pruned_ratio']),\r\n    522             dataloader=eval_dataloader,\r\n--> 523             fetch_targets=train_program_info.fetch_targets)\r\n    524         pruned_program = pruner.prune()\r\n    525         train_program_info.program = pruned_program\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.0.0.dev0-py3.7.egg/paddleslim/auto_compression/transformer_pruner.py in __init__(self, exe, places, inference_program, patterns, label_info, width_mult, fetch_targets, dataloader)\r\n    284         _logger.info(\"start to reorder weight in program\")\r\n    285         self.scope = self.reorder(inference_program, self.scope, patterns,\r\n--> 286                                   layer_num, head_num, mha_weight, ffn_weight)\r\n    287 \r\n    288     def _preprocess_patterns(self, patterns, graph):\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.0.0.dev0-py3.7.egg/paddleslim/auto_compression/transformer_pruner.py in reorder(self, inference_program, scope, patterns, layer_num, head_num, mha_weight, ffn_weight)\r\n    491         compute_program, head_importance, neuron_importance = self.compute_importance(\r\n    492             self.exe, compute_program, patterns, ffn_weight, layer_num,\r\n--> 493             head_num, self.label_info, self.fetch_targets, self.dataloader)\r\n    494 \r\n    495         ###############################     REORDER    ##################################\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.0.0.dev0-py3.7.egg/paddleslim/auto_compression/transformer_pruner.py in compute_importance(self, exe, program, patterns, ffn_weight, layer_num, head_num, label_info, fetch_targets, dataloader)\r\n    366             Compute head importance according gradients of head_mask\"\"\"\r\n    367         program = self._program_add_mask(program, patterns, layer_num, head_num,\r\n--> 368                                          label_info, fetch_targets)\r\n    369 \r\n    370         ### define importance matrix\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim-0.0.0.dev0-py3.7.egg/paddleslim/auto_compression/transformer_pruner.py in _program_add_mask(self, program, patterns, layer_num, head_num, label_info, fetch_targets)\r\n    357 \r\n    358         program._sync_with_cpp()\r\n--> 359         paddle.static.append_backward(loss)\r\n    360         program._sync_with_cpp()\r\n    361         return program\r\n\r\n<decorator-gen-155> in append_backward(loss, parameter_list, no_grad_set, callbacks, checkpoints, distop_context)\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py in __impl__(func, *args, **kwargs)\r\n     24     def __impl__(func, *args, **kwargs):\r\n     25         wrapped_func = decorator_func(func)\r\n---> 26         return wrapped_func(*args, **kwargs)\r\n     27 \r\n     28     return __impl__\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py in __impl__(*args, **kwargs)\r\n    556             % func.__name__\r\n    557         )\r\n--> 558         return func(*args, **kwargs)\r\n    559 \r\n    560     return __impl__\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/backward.py in append_backward(loss, parameter_list, no_grad_set, callbacks, checkpoints, distop_context)\r\n   1798                 op_path_dict=op_path_dict,\r\n   1799                 distop_context=distop_context,\r\n-> 1800                 grad_op_id_to_fwd_op=grad_op_id_to_fwd_op)\r\n   1801 \r\n   1802     grad_info_map = dict()\r\n\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/backward.py in _append_backward_ops_(block, ops, target_vars, target_block, no_grad_dict, grad_to_var, callbacks, input_grad_names_set, op_path_dict, distop_context, rename_var_map, grad_op_id_to_fwd_op)\r\n   1241         # Getting op's corresponding grad_op\r\n   1242         grad_op_desc, op_grad_to_var = core.get_grad_op_desc(\r\n-> 1243             op.desc, cpt.to_text(no_grad_dict[block.idx]), grad_sub_block_list)\r\n   1244 \r\n   1245         # record the mapping between fwd and bwd\r\n\r\nRuntimeError: (NotFound) Cannot find attribute (use_mkldnn).\r\n  [Hint: Expected it != map.end(), but received it == map.end().] (at /paddle/paddle/fluid/framework/grad_op_desc_maker.h:174)\r\n  [operator < cast > error]`\r\n\r\n在使用AutoCompression时出现这个报错，请问应该怎么解决呢",
        "state": "closed",
        "user": "Rayman96",
        "closed_by": "Rayman96",
        "created_at": "2022-12-19T09:39:37+00:00",
        "updated_at": "2022-12-20T09:02:43+00:00",
        "closed_at": "2022-12-20T09:02:42+00:00",
        "comments_count": [
            "ceci3",
            "Rayman96",
            "Rayman96",
            "ceci3",
            "Rayman96",
            "Rayman96"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1602,
        "title": "ptq和qat量化的详细流程和demo能规范解释一下嘛，咱感觉好多的demo呢？",
        "body": null,
        "state": "closed",
        "user": "laoda1112222",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-21T06:25:50+00:00",
        "updated_at": "2024-02-06T02:59:53+00:00",
        "closed_at": "2024-02-06T02:59:53+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1604,
        "title": "AutoCompression压缩后，推理变慢很多",
        "body": "做了ERNIE 3.0 的medium和xbase版本的压缩，速度都变慢很多(10倍以上那种)，paddle 2.3.1   paddleslim 2.3.0",
        "state": "closed",
        "user": "cold-eye",
        "closed_by": "XGZhang11",
        "created_at": "2022-12-22T09:38:38+00:00",
        "updated_at": "2024-02-06T04:19:14+00:00",
        "closed_at": "2024-02-06T04:19:14+00:00",
        "comments_count": [
            "ceci3",
            "cold-eye",
            "ceci3",
            "cold-eye",
            "ceci3",
            "cold-eye",
            "cold-eye"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1607,
        "title": "AutoCompression的Distillation教师模型和学生模型可以是不同模型吗",
        "body": "我使用微调好的ernie-3.0-xbase-zh，给微调好的ernie-3.0-medium-zh进行蒸馏，报错block名不一致",
        "state": "closed",
        "user": "cold-eye",
        "closed_by": "cold-eye",
        "created_at": "2022-12-24T02:50:23+00:00",
        "updated_at": "2022-12-27T02:27:33+00:00",
        "closed_at": "2022-12-27T02:27:23+00:00",
        "comments_count": [
            "cold-eye",
            "cold-eye",
            "ceci3",
            "cold-eye"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1614,
        "title": "yolov5量化时报错",
        "body": "Traceback (most recent call last):\r\n  File \"run.py\", line 148, in <module>\r\n    main()\r\n  File \"run.py\", line 136, in main\r\n    ac.compress()\r\n  File \"D:\\Software\\anaconda3\\envs\\paddleslim_new\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 594, in compress\r\n    train_config)\r\n  File \"D:\\Software\\anaconda3\\envs\\paddleslim_new\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 776, in single_strategy_compress\r\n    train_program_info, test_program_info, strategy, train_config)\r\n  File \"D:\\Software\\anaconda3\\envs\\paddleslim_new\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 819, in _start_train\r\n    test_program_info.fetch_targets)\r\n  File \"run.py\", line 79, in eval_function\r\n    map_res = coco_metric(anno_file, bboxes_list, bbox_nums_list, image_id_list)\r\n  File \"E:\\MyProject\\pytorch_yolo_series\\post_process.py\", line 202, in coco_metric\r\n    coco_dt = coco_gt.loadRes(output)\r\n  File \"D:\\Software\\anaconda3\\envs\\paddleslim_new\\lib\\site-packages\\pycocotools\\coco.py\", line 328, in loadRes\r\n    if 'caption' in anns[0]:\r\nIndexError: list index out of range\r\n请问这个原因是为什么，我按照coco的格式整理了我的数据集",
        "state": "closed",
        "user": "liumingzhu6060",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2022-12-29T08:27:43+00:00",
        "updated_at": "2024-02-06T02:59:54+00:00",
        "closed_at": "2024-02-06T02:59:54+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1619,
        "title": "报：could not load library libcudnn_cnn_train.so.8. ",
        "body": "版本：\r\ncuda :11.3 cudnn:8.6.0 (对应cuda11.x)   python :3.8  paddlepaddle-gpu: 2.4.1.post112  paddleslim:2.4.1\r\n系统：linux\r\n\r\n**运行run.py过程中报如下错误：**\r\nCould not load library libcudnn_cnn_train.so.8.     Error: /home/zjl/anaconda3/envs/paddle/bin/../lib/libcudnn_ops_train.so.8 :undefined symbol: _ZN5cudnn3ops26JoinInternalPriorityStreamEP12cudnnContexti , version libcudnn_ops_infer.so.8\r\n\r\nt Error Message Summary:\r\nFatalError:`Process abort signal' is detected by the operating system.\r\n[TimeInfo: *** Aborted at 1672813800 (unix time)try \"date -d @1672813000\"  if you are using SNU date *][SignalInfo:*** SIGABRT (@Bx3e8000018c5)received by PID 6341 (TID 0x7f0f11fff780) from PID 6341 ***]\r\n已放弃〔核心已转储）",
        "state": "closed",
        "user": "Ledgero",
        "closed_by": "XGZhang11",
        "created_at": "2023-01-04T08:09:15+00:00",
        "updated_at": "2024-02-06T04:19:36+00:00",
        "closed_at": "2024-02-06T04:19:36+00:00",
        "comments_count": [
            "wanghaoshuang",
            "Ledgero",
            "Beau-Chen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1620,
        "title": "uie自动压缩示例执行报错",
        "body": "版本环境如下：\r\npaddlenlp          2.4.8\r\npaddlepaddle-gpu   2.4.1.post112\r\npaddleslim         2.4.1\r\n报错如下：\r\n```python\r\nAdding quant op with weight:|████████████████████████████████████████| 1510/1510\r\nAdding OutScale op:|███████████████████████████████████████████████████| 818/818\r\nTraceback (most recent call last):\r\n  File \"src/compress.py\", line 382, in <module>\r\n    main()\r\n  File \"src/compress.py\", line 375, in main\r\n    ac.compress()\r\n  File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 593, in compress\r\n    self.single_strategy_compress(strategy, config, strategy_idx,\r\n  File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 775, in single_strategy_compress\r\n    test_program_info = self._start_train(\r\n  File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 794, in _start_train\r\n    loss = self._exe.run(train_program_info.program, \\\r\n  File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1463, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1450, in run\r\n    res = self._run_impl(program=program,\r\n  File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1720, in _run_impl\r\n    return self._run_parallel(program,\r\n  File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1254, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\nNotImplementedError: In user code:\r\n\r\n    File \"src/compress.py\", line 382, in <module>\r\n      main()\r\n    File \"src/compress.py\", line 375, in main\r\n      ac.compress()\r\n    File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 593, in compress\r\n      self.single_strategy_compress(strategy, config, strategy_idx,\r\n    File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 769, in single_strategy_compress\r\n      train_program_info, test_program_info = self._prepare_program(\r\n    File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 509, in _prepare_program\r\n      train_program_info, test_program_info = build_distill_program(\r\n    File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/auto_compression/create_compressed_program.py\", line 266, in build_distill_program\r\n      train_program, test_program, data_name_map = _load_program_and_merge(\r\n    File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/auto_compression/create_compressed_program.py\", line 192, in _load_program_and_merge\r\n      merge(\r\n    File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddleslim/dist/single_distiller.py\", line 103, in merge\r\n      student_program.global_block().append_op(\r\n    File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 4017, in append_op\r\n      op = Operator(\r\n    File \"/home/xtl/anaconda3/envs/pp_com/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 2858, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    UnimplementedError: emebdding input only support int16, int32 and int64 (at /paddle/paddle/phi/kernels/gpu/embedding_kernel.cu:116)\r\n      [operator < lookup_table_v2 > error]\r\n```\r\nuie模型是通过export导出的inference模型，一直报上述错误不知道如何排查。",
        "state": "closed",
        "user": "noobexplore",
        "closed_by": "wanghaoshuang",
        "created_at": "2023-01-04T11:47:47+00:00",
        "updated_at": "2023-05-09T10:00:15+00:00",
        "closed_at": "2023-01-06T04:03:59+00:00",
        "comments_count": [
            "noobexplore",
            "wanghaoshuang",
            "xiu86"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1621,
        "title": "yolov5量化报错",
        "body": "\r\n2023-01-05 09:26:07,247-INFO: ==> The ACT comp2023-01-05 09:26:07,247-INFO: ==> The ACT compression has been completed and the final model is saved in `output`\r\n\r\n[Paddle2ONNX] Model file path: output\\model.pdmodel\r\n[Paddle2ONNX] Paramters file path: output\\model.pdiparams\r\n[Paddle2ONNX] Start to parsing Paddle model...\r\n[Paddle2ONNX] Use opset_version = 13 for ONNX export.\r\n[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\r\n2023-01-05 09:26:07,645-INFO: Convert model to ONNX: output\\ONNX\\quant_model.onnx\r\n\r\n为什么yolov5量化完成后没有输出calibration.cache文件",
        "state": "closed",
        "user": "liumingzhu6060",
        "closed_by": "yghstill",
        "created_at": "2023-01-05T01:28:59+00:00",
        "updated_at": "2023-01-05T11:01:04+00:00",
        "closed_at": "2023-01-05T11:01:04+00:00",
        "comments_count": [
            "liumingzhu6060",
            "liumingzhu6060"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1623,
        "title": "PTQ模型压缩后，怎么看模型压缩了多少呢",
        "body": null,
        "state": "closed",
        "user": "lip111",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-01-08T08:27:56+00:00",
        "updated_at": "2024-02-06T02:59:55+00:00",
        "closed_at": "2024-02-06T02:59:55+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1624,
        "title": "目前有LSTM量化的demo吗？",
        "body": "在repo中没有找到lstm量化相关的demo，想问下目前paddleslim支持lstm量化吗？",
        "state": "closed",
        "user": "littletomatodonkey",
        "closed_by": "XGZhang11",
        "created_at": "2023-01-09T13:49:20+00:00",
        "updated_at": "2024-02-06T04:19:56+00:00",
        "closed_at": "2024-02-06T04:19:56+00:00",
        "comments_count": [
            "ceci3",
            "littletomatodonkey"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1627,
        "title": "PPYOLOE+  auto_compression 训练时eval精度0.92 预测验证时eval只有0.82 ？",
        "body": "在BML上跑 PPYOLOE+ 的auto_compression实验：\r\n```\r\nGlobal:\r\n  reader_config: configs/ppyoloe_plus_640_reader.yml\r\n  arch: PPYOLOE\r\n  include_nms: False\r\n  Evaluation: True\r\n  model_dir: output_inference/ppyoloe_plus_crn_s_80e_coco_1500_noNMS\r\n  model_filename: model.pdmodel\r\n  params_filename: model.pdiparams\r\n\r\nDistillation:\r\n  alpha: 1.0\r\n  loss: soft_label\r\n\r\nQuantAware:\r\n  onnx_format: true\r\n  use_pact: true\r\n  activation_quantize_type: 'moving_average_abs_max'\r\n  quantize_op_types:\r\n  - conv2d\r\n  - depthwise_conv2d\r\n\r\nTrainConfig:\r\n  train_iter: 5000\r\n  eval_iter: 1000\r\n  learning_rate:  \r\n    type: CosineAnnealingDecay\r\n    learning_rate: 0.00003\r\n    T_max: 6000\r\n  optimizer_builder:\r\n    optimizer: \r\n      type: SGD\r\n    weight_decay: 4.0e-05\r\n```\r\n```\r\n! export CUDA_VISIBLE_DEVICES=0\r\n! cd work/PaddleDetection && python run.py --config_path=./configs/ppyoloe_plus_s_qat_dis_1500.yaml --save_dir='./output_slim/'\r\n```\r\n```\r\nDONE (t=1.60s).\r\nAccumulating evaluation results...\r\nDONE (t=0.63s).\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.927\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.799\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.494\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.687\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.486\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.778\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.582\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.849\r\n2023-01-10 13:55:44,387-INFO: epoch: 13 metric of compressed model is: 0.710378, best metric of compressed model is 0.716277\r\n2023-01-10 13:55:46,655-INFO: Total iter: 4009, epoch: 13, batch: 110, loss: [13.291732]soft_label: [13.291732] \r\n2023-01-10 13:55:48,821-INFO: Total iter: 4019, epoch: 13, batch: 120, loss: [13.326349]soft_label: [13.326349] \r\n2023-01-10 13:55:51,086-INFO: Total iter: 4029, epoch: 13, batch: 130, loss: [13.304006]soft_label: [13.304006] \r\n```\r\n\r\n这里边训练边eval，精度还是0.92。\r\n\r\n后面预测时：\r\nyaml文件中model_dir:改为了output_slim。执行命令：\r\n```# TensorRT预测：\r\n# 环境配置：如果使用 TesorRT 预测引擎，需安装 WITH_TRT=ON 的Paddle，下载地址：Python预测库\r\n! cd work/PaddleDetection && python eval.py \\\r\n      --config_path=configs/ppyoloe_plus_s_qat_dis_1500.yaml\r\n```\r\n```\r\nWarning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly\r\n[01-11 21:30:50 MainThread @logger.py:242] Argv: eval.py --config_path=configs/ppyoloe_plus_s_qat_dis_1500.yaml\r\n[01-11 21:30:50 MainThread @utils.py:79] WRN paddlepaddle version: 2.4.0. The dynamic graph version of PARL is under development, not fully tested and supported\r\nWARNING:root:cannot import name 'layers' from 'parl' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/__init__.py)\r\n-----------  Running Arguments -----------\r\n Distillation:\r\n\t alpha: 1.0\r\n\t loss: soft_label\r\n Global:\r\n\t Evaluation: True\r\n\t arch: PPYOLOE\r\n\t include_nms: False\r\n\t model_dir: output_slim\r\n\t model_filename: model.pdmodel\r\n\t params_filename: model.pdiparams\r\n\t reader_config: configs/ppyoloe_plus_640_reader.yml\r\n QuantAware:\r\n\t activation_quantize_type: moving_average_abs_max\r\n\t onnx_format: True\r\n\t quantize_op_types: ['conv2d', 'depthwise_conv2d']\r\n\t use_pact: True\r\n TrainConfig:\r\n\t eval_iter: 1000\r\n\t learning_rate:\r\n\t\t T_max: 6000\r\n\t\t learning_rate: 3e-05\r\n\t\t type: CosineAnnealingDecay\r\n\t optimizer_builder:\r\n\t\t optimizer:\r\n\t\t\t type: SGD\r\n\t\t weight_decay: 4e-05\r\n\t train_iter: 5000\r\n------------------------------------------\r\nloading annotations into memory...\r\nDone (t=0.01s)\r\ncreating index...\r\nindex created!\r\nW0111 21:30:51.066249  3547 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\nW0111 21:30:51.070571  3547 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\nWed Jan 11 21:30:52-WARNING: The old way to load inference model is deprecated. model path: /home/aistudio/work/PaddleDetection/output_slim/model.pdmodel, params path: /home/aistudio/work/PaddleDetection/output_slim/model.pdiparams\r\nLoaded model from: output_slim\r\n[01/11 21:30:57] ppdet.data.transform.operators WARNING: The actual image height: 663 is not equal to the height: 0.0 in annotation, and update sample['h'] by actual image height.\r\n[01/11 21:30:57] ppdet.data.transform.operators WARNING: The actual image width: 949 is not equal to the width: 0.0 in annotation, and update sample['w'] by actual image width.\r\nEval iter: 0\r\n[01/11 21:31:10] ppdet.data.transform.operators WARNING: The actual image height: 663 is not equal to the height: 0.0 in annotation, and update sample['h'] by actual image height.\r\n[01/11 21:31:10] ppdet.data.transform.operators WARNING: The actual image width: 949 is not equal to the width: 0.0 in annotation, and update sample['w'] by actual image width.\r\n[01/11 21:31:16] ppdet.metrics.metrics INFO: The bbox result is saved to bbox.json.\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\n[01/11 21:31:16] ppdet.metrics.coco_utils INFO: Start evaluate...\r\nLoading and preparing results...\r\nDONE (t=0.60s)\r\ncreating index...\r\nindex created!\r\nRunning per image evaluation...\r\nEvaluate annotation type *bbox*\r\nDONE (t=1.90s).\r\nAccumulating evaluation results...\r\nDONE (t=0.60s).\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.829\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.419\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.590\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.494\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.509\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708\r\n```\r\n这时精度就下降到0.82了。\r\n尝试按照[https://gitee.com/paddlepaddle/PaddleSlim/tree/develop/example/auto_compression/detection](https://gitee.com/paddlepaddle/PaddleSlim/tree/develop/example/auto_compression/detection)，使用paddle_inference_eval.py来eval时，出错：\r\n```\r\n! cd work/PaddleDetection && python paddle_inference_eval.py \\\r\n      --model_path=output_slim \\\r\n      --reader_config=configs/ppyoloe_plus_640_reader.yml\r\n```\r\n```\r\n--- Running analysis [ir_graph_to_program_pass]\r\nI0111 21:15:42.338825  1254 analysis_predictor.cc:1314] ======= optimize end =======\r\nI0111 21:15:42.351177  1254 naive_executor.cc:110] ---  skip [feed], feed -> image\r\nI0111 21:15:42.358578  1254 naive_executor.cc:110] ---  skip [save_infer_model/scale_0.tmp_0], fetch -> fetch\r\nloading annotations into memory...\r\nDone (t=0.00s)\r\ncreating index...\r\nindex created!\r\noutput_names= ['save_infer_model/scale_0.tmp_0']\r\noutput_names[0]= save_infer_model/scale_0.tmp_0\r\nTraceback (most recent call last):\r\n  File \"paddle_inference_eval.py\", line 501, in <module>\r\n    main()\r\n  File \"paddle_inference_eval.py\", line 485, in main\r\n    eval(predictor, val_loader, metric, rerun_flag=rerun_flag)\r\n  File \"paddle_inference_eval.py\", line 405, in eval\r\n    boxes_num = predictor.get_output_handle(output_names[1])\r\nIndexError: list index out of range\r\n```\r\n请各位大佬答疑解惑，感谢！",
        "state": "closed",
        "user": "yuanjim",
        "closed_by": "XGZhang11",
        "created_at": "2023-01-11T13:50:44+00:00",
        "updated_at": "2024-02-06T04:20:31+00:00",
        "closed_at": "2024-02-06T04:20:31+00:00",
        "comments_count": [
            "zzjjay",
            "yuanjim",
            "yuanjim",
            "yghstill",
            "yuanjim",
            "yghstill",
            "yuanjim",
            "yghstill",
            "yuanjim",
            "yuanjim"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1631,
        "title": "AssertionError: distill_node_pair config wrong, the length needs to be an even number",
        "body": "# 一. Environment\r\n\r\nOS: Ubuntu20.04\r\nGPU: RTX 3090\r\nRAM: 48GB\r\nCPU: AMD 5800x\r\npaddle-gpu 2.4.0\r\npaddleslim 2.4.0\r\npaddlex2.1.0\r\n# 二. Problem\r\n当执行ACT的压缩代码\r\n`export CUDA_VISIBLE_DEVICES=0\r\npython run.py --save_dir='/home/geek/Project/cloth_check/ACT/PPLCNet_quant' --config_path='/home/geek/Project/cloth_check/PaddleSlim/PaddleSlim-develop/example/auto_compression/image_classification/configs/PPLCNet_x1_0/qat_dis.yaml'`\r\n时，出现如下报错：\r\n\r\n![image](https://user-images.githubusercontent.com/62006079/212520529-23e0dbfe-50b2-468c-9921-4440b031c397.png)\r\n\r\n\r\n`AssertionError: distill_node_pair config wrong, the length needs to be an even number`\r\n请问这是怎么回事，该怎么解决？",
        "state": "closed",
        "user": "dongyangli-del",
        "closed_by": "zzjjay",
        "created_at": "2023-01-15T02:56:36+00:00",
        "updated_at": "2023-01-17T01:26:30+00:00",
        "closed_at": "2023-01-17T01:26:30+00:00",
        "comments_count": [
            "zzjjay",
            "dongyangli-del"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1628,
        "title": "量化训练以后导出int8模型，推理时报错：Operator (quantize) does not have kernel for {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}.",
        "body": "# 环境：\r\n- Tesla V100 [NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2]\r\n- paddle: paddlepaddle-gpu               2.4.0.post112\r\n- paddleslim: 2.4.0\r\n- paddleocr:2.6.0\r\n\r\n# 问题重现步骤\r\n1. 采用ppocr提供的pgnet算法，使用自己的标注数据进行训练，训练脚本: [quant.py](https://github.com/PaddlePaddle/PaddleOCR/blob/303e81b0b44b092ee0d7c7765d46a0952a76d71c/deploy/slim/quantization/quant.py)\r\n2. 训练完成后，导出成inference模型，导出用的脚本：[export_model.py](https://github.com/PaddlePaddle/PaddleOCR/blob/303e81b0b44b092ee0d7c7765d46a0952a76d71c/deploy/slim/quantization/export_model.py)，得到了inference.pdiparams、inference.pdiparams.info、inference.pdmodel 3个文件\r\n3. 再转换成int8类型，转换用的脚本：[save_quant_model.py](https://github.com/PaddlePaddle/Paddle/blob/3fa7a736e32508e797616b6344d97814c37d3ff8/python/paddle/fluid/contrib/slim/tests/save_quant_model.py)，得到了inference.pdiparams、inference.pdmodel两个文件（指定了save_model_filename和save_params_filename参数，不然会是一堆分散的文件）\r\n4. 推理时报错，推理代码：[predict_e2e.py](https://github.com/PaddlePaddle/PaddleOCR/blob/303e81b0b44b092ee0d7c7765d46a0952a76d71c/tools/infer/predict_e2e.py)\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"tools/infer/predict_e2e.py\", line 157, in <module>\r\n    points, strs, elapse = text_detector(img)\r\n  File \"tools/infer/predict_e2e.py\", line 120, in __call__\r\n    self.predictor.run()\r\nRuntimeError: (NotFound) Operator (quantize) does not have kernel for {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}.\r\n  [Hint: Expected kernel_iter != kernels.end(), but received kernel_iter == kernels.end().] (at /paddle/paddle/fluid/framework/operator.cc:2019)\r\n  [operator < quantize > error]\r\n```\r\n",
        "state": "closed",
        "user": "before31",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-01-12T09:34:12+00:00",
        "updated_at": "2024-02-06T02:59:55+00:00",
        "closed_at": "2024-02-06T02:59:55+00:00",
        "comments_count": [
            "minghaoBD",
            "before31",
            "dongyangli-del",
            "before31",
            "dongyangli-del",
            "minghaoBD",
            "minghaoBD",
            "minghaoBD",
            "before31",
            "zzjjay",
            "before31",
            "before31",
            "before31",
            "yghstill"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1647
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1637,
        "title": "PPYOLOE模型auto_compression后，use_static=True，但是推理过程有几百条notice和warning，导致推理时长10分钟？",
        "body": "github样例 环境要求：PP-YOLOE-s模型在Tesla T4，TensorRT 8.4.1，CUDA 11.2，batch_size=1，不包含NMS\r\n\r\naistudio环境：TensorRT8.2.5.1，CUDA 11.2\r\nPPYOLOE模型不包含NMS，auto_compression后，use_static=True，执行：\r\n```\r\n! cd work/PaddleDetection && python paddle_inference_eval.py \\\r\n      --model_path=output_slim \\\r\n      --reader_config=configs/ppyoloe_plus_640_reader.yml \\\r\n      --device=GPU \\\r\n      --benchmark=True \\\r\n      --include_nms=False \\\r\n      --use_trt=True \\\r\n      --precision=fp16\r\n```\r\n可以eval出结果，但是推理过程打印信息繁多，推理时长有10分钟，predict_time=1573ms：\r\n```\r\n[notice] To update, run: pip install --upgrade pip\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nRequirement already satisfied: GPUtil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.4.0)\r\n\r\n[notice] A new release of pip available: 22.1.2 -> 22.3.1\r\n[notice] To update, run: pip install --upgrade pip\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nRequirement already satisfied: pynvml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (8.0.4)\r\n\r\n[notice] A new release of pip available: 22.1.2 -> 22.3.1\r\n[notice] To update, run: pip install --upgrade pip\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nRequirement already satisfied: psutil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (5.7.2)\r\n\r\n[notice] A new release of pip available: 22.1.2 -> 22.3.1\r\n[notice] To update, run: pip install --upgrade pip\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nRequirement already satisfied: GPUtil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.4.0)\r\n\r\n[notice] A new release of pip available: 22.1.2 -> 22.3.1\r\n[notice] To update, run: pip install --upgrade pip\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nRequirement already satisfied: pynvml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (8.0.4)\r\n\r\n[notice] A new release of pip available: 22.1.2 -> 22.3.1\r\n[notice] To update, run: pip install --upgrade pip\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nRequirement already satisfied: psutil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (5.7.2)\r\n\r\n[notice] A new release of pip available: 22.1.2 -> 22.3.1\r\n[notice] To update, run: pip install --upgrade pip\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nRequirement already satisfied: GPUtil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.4.0)\r\n```\r\n\r\n本地GPU设备： TensorRT 8.4.2.4，CUDA 11.7\r\n```\r\n! cd work/PaddleDetection && python paddle_inference_eval.py \\\r\n      --model_path=output_slim \\\r\n      --reader_config=configs/ppyoloe_plus_640_reader.yml \\\r\n      --device=GPU \\\r\n      --benchmark=True \\\r\n      --include_nms=False \\\r\n      --use_trt=True \\\r\n      --precision=fp16\r\n```\r\n相同的问题，几百条notice和warning，推理过程打印信息：\r\n![image](https://user-images.githubusercontent.com/46877936/212820603-f67e7c39-ac79-4b01-a895-83f50df90b80.png)\r\n望大佬答疑解惑！",
        "state": "closed",
        "user": "yuanjim",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-01-17T05:56:02+00:00",
        "updated_at": "2024-02-06T03:00:17+00:00",
        "closed_at": "2024-02-06T02:59:56+00:00",
        "comments_count": [
            "yghstill",
            "yuanjim",
            "yghstill",
            "yuanjim",
            "yghstill",
            "yuanjim"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1638,
        "title": "自动压缩工具启动报错：",
        "body": "# 环境\r\n- Tesla V100 [NVIDIA-SMI 460.32.03 Driver Version: 460.32.03 CUDA Version: 11.2]\r\n- paddle: paddlepaddle-gpu 2.4.0.post112\r\n- paddleslim: 2.4.0\r\n- paddleocr:2.6.0\r\n\r\n# 问题重现步骤\r\n1. 采用ppocr提供的pgnet算法，使用自己的标注数据进行训练，训练脚本: [train.py](https://github.com/PaddlePaddle/PaddleOCR/blob/303e81b0b44b092ee0d7c7765d46a0952a76d71c/tools/train.py)\r\n2. 训练完成后，导出成inference模型，导出用的脚本：[export_model.py](https://github.com/PaddlePaddle/PaddleOCR/blob/303e81b0b44b092ee0d7c7765d46a0952a76d71c/tools/export_model.py)，得到了inference.pdiparams、inference.pdiparams.info、inference.pdmodel 3个文件\r\n3. 使用ACT自动压缩时报错：\r\n\r\n```\r\nlen(data) == len(names), but got len(data): 9 and len(names): 1\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddleslim/common/dataloader.py\", line 45, in wrap_dataloader\r\n    ), f\"len(data) == len(names), but got len(data): {len(data)} and len(names): {len(names)}\"\r\n  File \"/usr/local/lib/python3.7/dist-packages/paddleslim/auto_compression/compressor.py\", line 149, in __init__\r\n    self.feed_vars)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/30918844/212832748-e1d69962-94ab-44a8-aec2-b68e3c180ec4.png)\r\n\r\n自动压缩代码：\r\n```\r\ntrain_loader = xxxxx...\r\nac = AutoCompression(\r\n    model_dir=\"/paddle/model/e2e_sm/inference\",\r\n    model_filename=\"inference.pdmodel\",\r\n    params_filename=\"inference.pdiparams\",\r\n    save_dir=\"/paddle/model/e2e_sm/act\",\r\n    config={\"QuantPost\": {}, \"HyperParameterOptimization\": {'ptq_algo': ['avg'], 'max_quant_count': 3}},\r\n    ### config={\"QuantAware\": {}, \"Distillation\": {}}, ### 如果您的系统为Windows系统, 请使用当前这一行配置\r\n    train_dataloader=train_loader)\r\nac.compress()\r\n```\r\n\r\n请问应如何进一步排查问题？",
        "state": "closed",
        "user": "before31",
        "closed_by": "XGZhang11",
        "created_at": "2023-01-17T07:19:32+00:00",
        "updated_at": "2024-02-06T04:21:01+00:00",
        "closed_at": "2024-02-06T04:21:01+00:00",
        "comments_count": [
            "zzjjay",
            "before31",
            "zzjjay",
            "before31"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1642,
        "title": "predictor = create_predictor(config) 报错：RuntimeError: (NotFound) Cannot find  in scope. ",
        "body": "运行的代码和报错信息如下\r\n![image](https://user-images.githubusercontent.com/89114157/213338538-782e7c4f-dbce-4fff-a3c2-8257fcbc1235.png)\r\n其中，model.pdmodel和model.pdiparams都存在的\r\n![image](https://user-images.githubusercontent.com/89114157/213338957-bec33254-30f4-40b2-9985-79f35eba6c2d.png)\r\n",
        "state": "closed",
        "user": "xiuxiuxius",
        "closed_by": "XGZhang11",
        "created_at": "2023-01-19T02:09:48+00:00",
        "updated_at": "2024-02-06T04:21:21+00:00",
        "closed_at": "2024-02-06T04:21:21+00:00",
        "comments_count": [
            "xiuxiuxius",
            "yghstill",
            "xiuxiuxius"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1643,
        "title": "自动化压缩报错",
        "body": "![_6L}T~5WK(}$~WK%~ 6HG89](https://user-images.githubusercontent.com/99952437/215256453-1316b9e5-08b0-43ea-bf28-e8681e75bd83.png)\r\npppyoloe+自动化压缩到997轮报这个错误是什么原因？",
        "state": "closed",
        "user": "NwTbbetter",
        "closed_by": "XGZhang11",
        "created_at": "2023-01-28T08:46:00+00:00",
        "updated_at": "2024-02-06T04:21:59+00:00",
        "closed_at": "2024-02-06T04:21:59+00:00",
        "comments_count": [
            "yghstill",
            "shuaigeeed",
            "shuaigeeed",
            "truthsun22"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1648,
        "title": "AttributeError: module 'paddle.nn.quant' has no attribute 'matmul'",
        "body": "cudu版本为11.7，安装的paddlepaddle-gpu==0.0.0.post116，是否因为版本不匹配造成该错误。但是官网上安装cudu11.7版本的paddle命令”python -m pip install paddlepaddle-gpu==0.0.0.post117 -f https://www.paddlepaddle.org.cn/whl/windows/gpu/develop.html”无法使用，安装时提示paddlepaddle-gpu==0.0.0.post117。请问如何解决这两个问题？",
        "state": "closed",
        "user": "Hongyao98",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-07T02:10:45+00:00",
        "updated_at": "2024-02-06T04:22:41+00:00",
        "closed_at": "2024-02-06T04:22:41+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1646,
        "title": "auto_compression/pytorch_yolo_series压缩得到的模型大小没有变化",
        "body": "版本：\r\ncuda :11.3 cudnn:8.6.0 (对应cuda11.x) python :3.8 paddlepaddle-gpu: 2.4.1.post112 paddleslim:2.4.1\r\n系统：linux\r\n\r\n**问题：**\r\n运行run.py压缩yolov7-tiny , 原模型大小是24.9，压缩后导出的onnx模型大小还是24.9.同时精度没有发生改变。\r\n\r\n运行参数：\r\n`Global:\r\n  model_dir: ./yolov7-tiny.onnx\r\n  image_path: None      # If image_path is set, it will be trained directly based on unlabeled images, no need to set the COCO dataset path.\r\n  coco_dataset_dir: dataset/coco/\r\n  coco_train_image_dir: train2017\r\n  coco_train_anno_path: annotations/instances_train2017.json\r\n  coco_val_image_dir: val2017\r\n  coco_val_anno_path: annotations/instances_val2017.json\r\n  arch: YOLOv7\r\n\r\nDistillation:\r\n  alpha: 1.0\r\n  loss: soft_label\r\n\r\nQuantization:\r\n  onnx_format: True\r\n  activation_quantize_type: 'moving_average_abs_max'\r\n  quantize_op_types:\r\n  - conv2d\r\n  - depthwise_conv2d\r\n\r\nTrainConfig:\r\n  train_iter: 5000\r\n  eval_iter: 1000\r\n  learning_rate:\r\n    type: CosineAnnealingDecay \r\n    learning_rate: 0.00003\r\n    T_max: 8000\r\n  optimizer_builder:\r\n    optimizer:\r\n      type: SGD\r\n    weight_decay: 0.00004`\r\n运行中仅报以下warming：\r\n**WARMING:root:canot import name 'layers' from 'parl'(/home/zjJl/anaconda3/envs/paddLe/Llib/python3.8/site-packages/parl/..init...py)\r\n/hone/zj]l ancondas/envs/pettle/Lib/python5.8/site-packagesl_tistutils_hackl ..init ..py.83: Userlanning: Setuptools is replacing distutils.warnings.warn(\"Setuptools is replacing distutils.\")**\r\n",
        "state": "closed",
        "user": "Ledgero",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-03T11:14:56+00:00",
        "updated_at": "2024-02-06T04:22:24+00:00",
        "closed_at": "2024-02-06T04:22:24+00:00",
        "comments_count": [
            "zzjjay",
            "Ledgero"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1655,
        "title": "yolov7压缩报错，in loadRes  if 'caption' in anns[0]: IndexError: list index out of range",
        "body": "按照参考文档\r\n![image](https://user-images.githubusercontent.com/124556509/217734377-ccefe29d-c42d-4ab9-b223-0296265535b3.png)\r\n准备好自定义数据集，然后通过example/auto_compression/pytorch_yolo_series/run.py进行yolov7模型压缩。结果出现以下错误\r\n![image](https://user-images.githubusercontent.com/124556509/217734604-15dfd94b-0c2e-4702-a798-f34d27eda4a8.png)\r\n经过查询issues，得到类似问题的建议 ：\r\n1.首先可以确认环境是否正确，直接跑官方demo看能否复现readme结果。\r\n2.其次排查下你的模型、验证集是否有问题。直接用eval.py测试下量化前的模型精度。\r\n3.还可以只设置image_path进行量化，不评估。 然后产出的模型直接预测图片看看符合预期吗？\r\n由于coco数据集过大未进行步骤1，但使用eval.py同样出现类似问题\r\n![image](https://user-images.githubusercontent.com/124556509/217735151-964fe376-7d47-4cc8-8576-7cc97a1c5b99.png)\r\n只设置image_path，则run.py可以正常运行。求帮助，谢谢。\r\n",
        "state": "closed",
        "user": "Hongyao98",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-09T06:30:54+00:00",
        "updated_at": "2024-02-06T04:23:02+00:00",
        "closed_at": "2024-02-06T04:23:02+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1656,
        "title": "自动化压缩报错",
        "body": "请问使用自动化压缩工具对ppyoloe+模型进行压缩时，这样的报错是什么原因？\r\n![image](https://user-images.githubusercontent.com/99952437/218299379-68dbbb4d-611b-4752-958a-1506a7a1bdb3.png)\r\n![image](https://user-images.githubusercontent.com/99952437/218299389-50472201-bfee-499e-b44e-1ea4bfd61c90.png)\r\n",
        "state": "closed",
        "user": "NwTbbetter",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-12T07:53:10+00:00",
        "updated_at": "2024-02-06T04:23:12+00:00",
        "closed_at": "2024-02-06T04:23:12+00:00",
        "comments_count": [
            "yghstill"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1657,
        "title": "怎么使用ACT自动压缩工具对pp-yoloe-s 只检测行人的模型进行压缩？",
        "body": null,
        "state": "closed",
        "user": "lw-2017",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-13T08:36:04+00:00",
        "updated_at": "2024-02-06T04:23:29+00:00",
        "closed_at": "2024-02-06T04:23:29+00:00",
        "comments_count": [
            "yghstill",
            "lw-2017"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1661,
        "title": "使用ACT自动压缩YOLOv8报错",
        "body": "使用自己的数据集训练了一个YOLOv8的模型，然后用x2paddle转成了pd模型，在运行slim时报错了如下错误\r\n![错误](https://user-images.githubusercontent.com/68136766/218961499-b02440e9-dc48-470d-8d3f-f452ddfa9d93.png)\r\n",
        "state": "closed",
        "user": "pyftxdy",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-02-15T07:32:30+00:00",
        "updated_at": "2025-02-11T06:41:27+00:00",
        "closed_at": "2025-02-11T06:41:27+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1662,
        "title": "网络结构搜索tutorial疑问",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/release/2.0.0/docs/zh_cn/quick_start/static/nas_tutorial.md\r\n在8.完整示例中\r\n`archs = sanas.next_archs()[0]`\r\n我理解的是一组archs代表唯一生成对结构，为什么生成的一组archs列表只取第一个[0]做后续的训练和评估？其他部分怎么办",
        "state": "closed",
        "user": "Michael-Fuu",
        "closed_by": "Michael-Fuu",
        "created_at": "2023-02-16T07:32:16+00:00",
        "updated_at": "2023-02-17T03:13:44+00:00",
        "closed_at": "2023-02-17T03:13:43+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1663,
        "title": "RLNAS搜索后怎么拿到token？",
        "body": "https://paddleslim.readthedocs.io/zh_CN/latest/api_cn/static/nas/nas_api.html#rlnas\r\nSANAS 有save_checkpoint(str|None) - 保存checkpoint的文件目录 这个参数，能够从保存的json中拿到最优模型的token；RLNAS 没有save_checkpoint参数，取而代之的是save_controller(str|None|False) ，怎么获得最优模型的token呢",
        "state": "closed",
        "user": "Michael-Fuu",
        "closed_by": "Michael-Fuu",
        "created_at": "2023-02-16T08:49:38+00:00",
        "updated_at": "2023-02-20T11:18:50+00:00",
        "closed_at": "2023-02-20T11:18:50+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1664,
        "title": "DARTS",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/release/2.0.0/docs/zh_cn/api_cn/dygraph/nas/darts.rst#%E5%8F%AF%E5%BE%AE%E5%88%86%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2darts\r\ndarts可微分搜索产出一堆模型参数文件（默认会产生50个），他们有什么意义，怎么拿到最优搜索模型结构呢",
        "state": "closed",
        "user": "Michael-Fuu",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-02-17T03:13:18+00:00",
        "updated_at": "2025-02-11T06:41:28+00:00",
        "closed_at": "2025-02-11T06:41:28+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1665,
        "title": "自动压缩报错",
        "body": "我下载了“快速体验YOLOv8-s导出模型”来跑示例，运行run.py后出现了如下错误\r\n![image](https://user-images.githubusercontent.com/68136766/220039486-932d48a2-59e6-4ccc-80b3-8a4926c296e8.png)\r\n",
        "state": "closed",
        "user": "pyftxdy",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-02-20T07:31:45+00:00",
        "updated_at": "2025-02-11T06:41:29+00:00",
        "closed_at": "2025-02-11T06:41:29+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1668,
        "title": "Images used in tutorial of what is constraints",
        "body": "![image](https://user-images.githubusercontent.com/7534971/221735515-24a31167-6dd0-43c2-a1ac-26e3bab86e42.png)\r\n![image](https://user-images.githubusercontent.com/7534971/221735552-4c2df9e2-2a5f-4e25-a700-ad501be759f5.png)\r\n![image](https://user-images.githubusercontent.com/7534971/221735606-9820464d-797b-4437-bc7c-fbfc5bc3a0d3.png)\r\n![image](https://user-images.githubusercontent.com/7534971/221735648-f6fd3db2-1ec3-4253-a989-f68180169d6b.png)\r\n![image](https://user-images.githubusercontent.com/7534971/221735683-68bdde29-6b00-4943-98b1-ea8cda946dc2.png)\r\n![image](https://user-images.githubusercontent.com/7534971/221735696-f78fdaff-2067-4a76-bb92-c99ae4740f2f.png)\r\n\r\n\r\n",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-28T02:15:38+00:00",
        "updated_at": "2024-02-06T04:04:53+00:00",
        "closed_at": "2024-02-06T04:04:53+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1670,
        "title": "linux环境下运行官方量化推理demo编译报错 OrtGetApiBase",
        "body": "你好，我在测试https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/mkldnn_quant中的Intel CPU量化部署，\r\n在最后的编译环节中，我遇到了如下问题：（python版本会说卷积算子不支持int8量化，估计是没有mkldnn支持）\r\n\r\n```bash\r\ncd /PATH/TO/PaddleSlim\r\ncd demo/mkldnn_quant/\r\nmkdir build && cd build\r\ncmake -DPADDLE_LIB=path/to/paddle_inference_install_dir ..\r\nmake -j\r\n```\r\n\r\nld过程产生了onnxruntime相关的报错，\r\n![image](https://user-images.githubusercontent.com/96160062/221822904-9514638f-13a7-486c-abfc-fe0009e2d481.png)\r\n![image](https://user-images.githubusercontent.com/96160062/221822936-12534395-51a9-4bd9-b740-b41d39f28f01.png)\r\n\r\n请问我该如何排查问题？我用的预编译推离库是：\r\nhttps://paddleinference.paddlepaddle.org.cn/user_guides/download_lib.html\r\n\r\n\r\n版本说明\t预测库(2.3.2版本)\r\nmanylinux_cpu_avx_mkl_gcc8.2\t[paddle_inference.tgz](https://paddle-inference-lib.bj.bcebos.com/2.3.2/cxx_c/Linux/CPU/gcc8.2_avx_mkl/paddle_inference.tgz)\r\n\r\n\r\n谢谢你的回复。",
        "state": "closed",
        "user": "sanbuphy",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-28T10:09:40+00:00",
        "updated_at": "2024-02-06T04:04:38+00:00",
        "closed_at": "2024-02-06T04:04:38+00:00",
        "comments_count": [
            "sanbuphy",
            "sanbuphy",
            "sanbuphy",
            "wanghaoshuang",
            "sanbuphy",
            "sanbuphy",
            "sanbuphy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1671,
        "title": "cannot import name 'in_dygraph_mode' from 'paddle.framework' ",
        "body": "![image](https://user-images.githubusercontent.com/102586285/221823130-9c2e0acf-f207-49e8-9e35-45aed8422f05.png)这里怎么解决",
        "state": "closed",
        "user": "shuaigeeed",
        "closed_by": "shuaigeeed",
        "created_at": "2023-02-28T10:10:05+00:00",
        "updated_at": "2023-03-02T02:29:54+00:00",
        "closed_at": "2023-03-02T02:29:45+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1675,
        "title": "ppyoloe+  l    自动压缩报错",
        "body": "![image](https://user-images.githubusercontent.com/102586285/222471039-8fe3755f-2541-4144-9de9-5ae3bdce2fcc.png)\r\n你好请问这个情况怎么解决，感谢您的回复",
        "state": "closed",
        "user": "shuaigeeed",
        "closed_by": "shuaigeeed",
        "created_at": "2023-03-02T15:22:00+00:00",
        "updated_at": "2023-03-02T15:28:32+00:00",
        "closed_at": "2023-03-02T15:28:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1672,
        "title": "intel cpu量化部署问题",
        "body": "尝试如下这个demo的复现，但是出现了如下的错误。\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/mkldnn_quant/\r\n![image](https://user-images.githubusercontent.com/126534866/221836012-4735838b-962b-4df3-88f4-8b70f890569c.png)\r\n![image](https://user-images.githubusercontent.com/126534866/221836169-d175269b-4714-460a-95cc-907b547f057c.png)\r\n![image](https://user-images.githubusercontent.com/126534866/221836393-5f57fe88-c8a2-4ec7-b761-86bb4dfcdac5.png)\r\n这边尝试使用参数将对应id去除以及源码中的注释但没有什么用\r\n还是如上错误，望大佬解答！谢谢！\r\n",
        "state": "closed",
        "user": "luguanren",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-28T11:07:43+00:00",
        "updated_at": "2024-02-06T04:25:04+00:00",
        "closed_at": "2024-02-06T04:25:04+00:00",
        "comments_count": [
            "wanghaoshuang",
            "luguanren"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1674,
        "title": "训练压缩报错",
        "body": "![image](https://user-images.githubusercontent.com/102586285/222394118-06e2136f-284e-482c-9395-6a9bc375e84c.png)你好为什么会出现这种情况\r\n/home/aistudio/work/PaddleDetection\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import MutableMapping\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Iterable, Mapping\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n  from collections import Sized\r\nW0302 17:52:47.317415  6479 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\nW0302 17:52:47.322274  6479 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n[03/02 17:52:50] ppdet.utils.checkpoint INFO: The shape [365] in pretrained weight yolo_head.pred_cls.0.bias is unmatched with the shape [8] in model yolo_head.pred_cls.0.bias. And the weight yolo_head.pred_cls.0.bias will not be loaded\r\n[03/02 17:52:50] ppdet.utils.checkpoint INFO: The shape [365, 768, 3, 3] in pretrained weight yolo_head.pred_cls.0.weight is unmatched with the shape [8, 768, 3, 3] in model yolo_head.pred_cls.0.weight. And the weight yolo_head.pred_cls.0.weight will not be loaded\r\n[03/02 17:52:50] ppdet.utils.checkpoint INFO: The shape [365] in pretrained weight yolo_head.pred_cls.1.bias is unmatched with the shape [8] in model yolo_head.pred_cls.1.bias. And the weight yolo_head.pred_cls.1.bias will not be loaded\r\n[03/02 17:52:50] ppdet.utils.checkpoint INFO: The shape [365, 384, 3, 3] in pretrained weight yolo_head.pred_cls.1.weight is unmatched with the shape [8, 384, 3, 3] in model yolo_head.pred_cls.1.weight. And the weight yolo_head.pred_cls.1.weight will not be loaded\r\n[03/02 17:52:50] ppdet.utils.checkpoint INFO: The shape [365] in pretrained weight yolo_head.pred_cls.2.bias is unmatched with the shape [8] in model yolo_head.pred_cls.2.bias. And the weight yolo_head.pred_cls.2.bias will not be loaded\r\n[03/02 17:52:50] ppdet.utils.checkpoint INFO: The shape [365, 192, 3, 3] in pretrained weight yolo_head.pred_cls.2.weight is unmatched with the shape [8, 192, 3, 3] in model yolo_head.pred_cls.2.weight. And the weight yolo_head.pred_cls.2.weight will not be loaded\r\n[03/02 17:52:50] ppdet.utils.checkpoint INFO: Finish loading model weights: /home/aistudio/.cache/paddle/weights/ppyoloe_crn_l_obj365_pretrained.pdparams\r\n[03/02 17:52:50] ppdet.slim.distill_model INFO: Student model has loaded pretrain weights!\r\n[03/02 17:52:51] ppdet.utils.checkpoint INFO: The shape [80] in pretrained weight yolo_head.pred_cls.0.bias is unmatched with the shape [8] in model yolo_head.pred_cls.0.bias. And the weight yolo_head.pred_cls.0.bias will not be loaded\r\n[03/02 17:52:51] ppdet.utils.checkpoint INFO: The shape [80, 768, 3, 3] in pretrained weight yolo_head.pred_cls.0.weight is unmatched with the shape [8, 768, 3, 3] in model yolo_head.pred_cls.0.weight. And the weight yolo_head.pred_cls.0.weight will not be loaded\r\n[03/02 17:52:51] ppdet.utils.checkpoint INFO: The shape [80] in pretrained weight yolo_head.pred_cls.1.bias is unmatched with the shape [8] in model yolo_head.pred_cls.1.bias. And the weight yolo_head.pred_cls.1.bias will not be loaded\r\n[03/02 17:52:51] ppdet.utils.checkpoint INFO: The shape [80, 384, 3, 3] in pretrained weight yolo_head.pred_cls.1.weight is unmatched with the shape [8, 384, 3, 3] in model yolo_head.pred_cls.1.weight. And the weight yolo_head.pred_cls.1.weight will not be loaded\r\n[03/02 17:52:51] ppdet.utils.checkpoint INFO: The shape [80] in pretrained weight yolo_head.pred_cls.2.bias is unmatched with the shape [8] in model yolo_head.pred_cls.2.bias. And the weight yolo_head.pred_cls.2.bias will not be loaded\r\n[03/02 17:52:51] ppdet.utils.checkpoint INFO: The shape [80, 192, 3, 3] in pretrained weight yolo_head.pred_cls.2.weight is unmatched with the shape [8, 192, 3, 3] in model yolo_head.pred_cls.2.weight. And the weight yolo_head.pred_cls.2.weight will not be loaded\r\n[03/02 17:52:51] ppdet.utils.checkpoint INFO: Finish loading model weights: /home/aistudio/.cache/paddle/weights/ppyoloe_plus_crn_l_80e_coco.pdparams\r\n[03/02 17:52:51] ppdet.slim.distill_model INFO: Teacher model has loaded pretrain weights!\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 202, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 187, in main\r\n    cfg = build_slim_model(cfg, FLAGS.slim_config)\r\n  File \"/home/aistudio/work/PaddleDetection/ppdet/slim/__init__.py\", line 53, in build_slim_model\r\n    model = PPYOLOEDistillModel(cfg, slim_cfg)\r\n  File \"/home/aistudio/work/PaddleDetection/ppdet/slim/distill_model.py\", line 328, in __init__\r\n    self.arch)\r\nAssertionError: Unsupported arch: YOLOv3",
        "state": "closed",
        "user": "shuaigeeed",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-03-02T09:54:55+00:00",
        "updated_at": "2025-02-11T06:41:30+00:00",
        "closed_at": "2025-02-11T06:41:30+00:00",
        "comments_count": [
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1673,
        "title": "ImportError: cannot import name duplicates_everseen",
        "body": "报错：ImportError: cannot import name duplicates_everseen，请问怎么解决呀？\r\n![image](https://user-images.githubusercontent.com/109976361/221851411-c2b3f599-2fd8-4c44-b720-3d363d933594.png)\r\n![image](https://user-images.githubusercontent.com/109976361/221851509-612500e4-d749-4ef5-8434-6f110d9c1f5e.png)\r\n",
        "state": "closed",
        "user": "z5406",
        "closed_by": "XGZhang11",
        "created_at": "2023-02-28T12:13:55+00:00",
        "updated_at": "2024-02-06T05:37:19+00:00",
        "closed_at": "2024-02-06T05:37:19+00:00",
        "comments_count": [
            "wanghaoshuang",
            "z5406",
            "railgun-zyy",
            "Hooccee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1676,
        "title": "关于PPYOLOE_S使用自动压缩方法在训练过程中的loss值的问题",
        "body": "实验通过[官方示例](https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression/detection)进行，\r\n相关配置设置如下：\r\n```\r\nGlobal:\r\n  exclude_nms: True\r\n  arch: PPYOLOE    \r\n\r\nDistillation:\r\n  alpha: 1.0\r\n  loss: soft_label\r\n\r\nQuantAware:\r\n  onnx_format: true\r\n  use_pact: true\r\n  activation_quantize_type: 'moving_average_abs_max'\r\n  quantize_op_types:\r\n  - conv2d\r\n  - depthwise_conv2d\r\n\r\nTrainConfig:\r\n  train_iter: 5000\r\n  eval_iter: 1000\r\n  learning_rate:  \r\n    type: CosineAnnealingDecay\r\n    learning_rate: 0.00003\r\n    T_max: 6000\r\n  optimizer_builder:\r\n    optimizer: \r\n      type: SGD\r\n    weight_decay: 4.0e-05\r\n```\r\n\r\n模型训练时的loss如下，请问这种大小的loss数值是正常的吗\r\n```\r\n2023-03-04 15:22:00,387-INFO: Total iter: 0, epoch: 0, batch: 0, loss: [13.207467]soft_label: [13.207467] \r\n2023-03-04 15:22:03,056-INFO: Total iter: 10, epoch: 0, batch: 10, loss: [12.428257]soft_label: [12.428257] \r\n2023-03-04 15:22:05,751-INFO: Total iter: 20, epoch: 0, batch: 20, loss: [12.663028]soft_label: [12.663028] \r\n2023-03-04 15:22:08,447-INFO: Total iter: 30, epoch: 0, batch: 30, loss: [14.896362]soft_label: [14.896362] \r\n2023-03-04 15:22:11,144-INFO: Total iter: 40, epoch: 0, batch: 40, loss: [12.247461]soft_label: [12.247461] \r\n2023-03-04 15:22:13,840-INFO: Total iter: 50, epoch: 0, batch: 50, loss: [12.451904]soft_label: [12.451904] \r\n2023-03-04 15:22:16,536-INFO: Total iter: 60, epoch: 0, batch: 60, loss: [12.284585]soft_label: [12.284585] \r\n2023-03-04 15:22:19,237-INFO: Total iter: 70, epoch: 0, batch: 70, loss: [12.151497]soft_label: [12.151497] \r\n2023-03-04 15:22:21,940-INFO: Total iter: 80, epoch: 0, batch: 80, loss: [12.264659]soft_label: [12.264659] \r\n2023-03-04 15:22:24,642-INFO: Total iter: 90, epoch: 0, batch: 90, loss: [12.188266]soft_label: [12.188266] \r\n...\r\n2023-03-04 15:45:20,086-INFO: Total iter: 4959, epoch: 10, batch: 280, loss: [12.240063]soft_label: [12.240063] \r\n2023-03-04 15:45:22,784-INFO: Total iter: 4969, epoch: 10, batch: 290, loss: [12.523859]soft_label: [12.523859] \r\n2023-03-04 15:45:25,482-INFO: Total iter: 4979, epoch: 10, batch: 300, loss: [12.421528]soft_label: [12.421528] \r\n2023-03-04 15:45:28,180-INFO: Total iter: 4989, epoch: 10, batch: 310, loss: [11.971611]soft_label: [11.971611] \r\n2023-03-04 15:45:30,950-INFO: Total iter: 4999, epoch: 10, batch: 320, loss: [12.2105465]soft_label: [12.2105465] \r\n```",
        "state": "closed",
        "user": "Nirvana93",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-04T06:07:56+00:00",
        "updated_at": "2024-02-06T05:40:27+00:00",
        "closed_at": "2024-02-06T05:40:27+00:00",
        "comments_count": [
            "zzjjay",
            "Nirvana93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1677,
        "title": "PaddleSlim离线量化数据集格式问题",
        "body": "您好，请问PaddleSlim离线量化以及其他压缩方式所需要的数据集格式均必须为COCO格式的吗？如果用VOC格式，则会报错：\r\n\r\n![image](https://user-images.githubusercontent.com/71055342/222896873-591ec53a-89fb-448e-9cfc-f8e95f287728.png)\r\n\r\n，但是我自己的VOC格式数据集，转成COCO格式，精度下降很多（40-50百分点），是否还有其他解决办法？\r\n",
        "state": "closed",
        "user": "fan-min-97",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-03-04T11:16:46+00:00",
        "updated_at": "2025-02-11T06:41:31+00:00",
        "closed_at": "2025-02-11T06:41:31+00:00",
        "comments_count": [
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1693
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1678,
        "title": "求教：量化后模型转 paddlelite 失败 “Can't find a 'calib' kernel to trans“",
        "body": "先量化，然后使用opt 将paddle格式转换成paddleLite 格式，转换时报错\r\n转换命令：\r\n`opt --model_file ./model.pdmodel --param_file ./model.pdiparams --quant_model false --valid_targets huawei_ascend_npu --optimize_out ./tt`\r\n\r\n报错信息：\r\n![image](https://user-images.githubusercontent.com/39563142/223008767-5d0ba170-b48c-4eef-b650-9023d79e68ca.png)\r\n",
        "state": "closed",
        "user": "ldd-bdxt",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-03-06T02:55:56+00:00",
        "updated_at": "2025-02-11T06:41:32+00:00",
        "closed_at": "2025-02-11T06:41:31+00:00",
        "comments_count": [
            "XGZhang11",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1681,
        "title": "使用自动压缩PPYOLOE，得到的模型大小和推理时间基本没有变化",
        "body": "使用方法参考[官方示例文档](https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression/detection)，\r\n通过指令导出模型：\r\n\r\n```python\r\npython tools/export_model.py \\\r\n-c configs/ppyoloe/ppyoloe_plus_crn_s_80e_coco.yml \\\r\n-o weights=~/ss/code/PaddleYOLO/output/ppyoloe_plus_crn_s_80e_coco_shrimp/best_model.pdparams \\\r\n trt=True exclude_nms=True\r\n```\r\n\r\n通过指令训练模型：\r\n```\r\nCUDA_VISIBLE_DEVICES=0,1 python -m paddle.distributed.launch --log_dir=log --gpus 0,1 run.py \\\r\n          --config_path=./configs/ppyoloe_x_qat_dis.yaml --save_dir='./output/'\r\n```\r\n模型训练时的部分log如下：\r\n```\r\n2023-03-08 10:48:47,645-INFO: Total iter: 4900, epoch: 0, batch: 4900, loss: [11.598398]soft_label: [11.598398] \r\n2023-03-08 10:48:48,808-INFO: Total iter: 4910, epoch: 0, batch: 4910, loss: [11.745678]soft_label: [11.745678] \r\n2023-03-08 10:48:49,972-INFO: Total iter: 4920, epoch: 0, batch: 4920, loss: [11.701544]soft_label: [11.701544] \r\n2023-03-08 10:48:51,137-INFO: Total iter: 4930, epoch: 0, batch: 4930, loss: [11.786173]soft_label: [11.786173] \r\n2023-03-08 10:48:52,301-INFO: Total iter: 4940, epoch: 0, batch: 4940, loss: [11.767839]soft_label: [11.767839] \r\n2023-03-08 10:48:53,466-INFO: Total iter: 4950, epoch: 0, batch: 4950, loss: [11.527636]soft_label: [11.527636] \r\n2023-03-08 10:48:54,631-INFO: Total iter: 4960, epoch: 0, batch: 4960, loss: [11.843047]soft_label: [11.843047] \r\n2023-03-08 10:48:55,798-INFO: Total iter: 4970, epoch: 0, batch: 4970, loss: [10.901478]soft_label: [10.901478] \r\n2023-03-08 10:48:56,963-INFO: Total iter: 4980, epoch: 0, batch: 4980, loss: [11.668227]soft_label: [11.668227] \r\n2023-03-08 10:48:58,124-INFO: Total iter: 4990, epoch: 0, batch: 4990, loss: [11.696041]soft_label: [11.696041] \r\nEval iter: 0\r\n...\r\nEval iter: 2000\r\n[03/08 10:51:32] ppdet.metrics.metrics INFO: The bbox result is saved to bbox.json.\r\nloading annotations into memory...\r\nDone (t=0.06s)\r\ncreating index...\r\nindex created!\r\n[03/08 10:51:32] ppdet.metrics.coco_utils INFO: Start evaluate...\r\nLoading and preparing results...\r\nDONE (t=1.67s)\r\ncreating index...\r\nindex created!\r\nRunning per image evaluation...\r\nEvaluate annotation type *bbox*\r\nDONE (t=14.18s).\r\nAccumulating evaluation results...\r\nDONE (t=4.24s).\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.968\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.874\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.426\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.731\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.465\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.801\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.805\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.597\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.799\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711\r\n2023-03-08 10:51:53,520-INFO: epoch: 0 metric of compressed model is: 0.740954, best metric of compressed model is 0.740954\r\n2023-03-08 10:51:53,590-INFO: convert config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['mul', 'conv2d', 'pool2d', 'depthwise_conv2d', 'elementwise_add', 'leaky_relu'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': True, 'is_full_quantize': True, 'onnx_format': False, 'quant_post_first': False, 'scale_trainable': True, 'name': 'Distillation', 'loss': 'soft_label', 'node': [], 'alpha': 1.0, 'teacher_model_dir': './shrimp_baseline_export_model/ppyoloe_plus_crn_s_80e_1024_512_coco_shrimp_whole', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\n2023-03-08 10:51:59,765-INFO: ==> The metric of final model is 0.7410\r\n2023-03-08 10:51:59,765-INFO: ==> The ACT compression has been completed and the final model is saved in `./auto_compression_model_res_3_8_for_trt_full_quantize/`\r\n\r\n```\r\n\r\n配置文件内容如下：\r\n\r\n```\r\nGlobal:\r\n  reader_config: configs/shrimp_reader.yml\r\n  exclude_nms: True\r\n  arch: PPYOLOE    # When export exclude_nms=True, need set arch: PPYOLOE\r\n  Evaluation: True\r\n  model_dir: ./shrimp_baseline_export_model/ppyoloe_plus_crn_s_80e_1024_512_coco_shrimp_whole\r\n  model_filename: model.pdmodel\r\n  params_filename: model.pdiparams\r\n\r\n\r\nDistillation:\r\n  alpha: 1.0\r\n  loss: soft_label\r\n\r\nQuantAware:\r\n  for_tensorrt: true\r\n  is_full_quantize: true\r\n  onnx_format: false\r\n  use_pact: true\r\n  activation_quantize_type: 'moving_average_abs_max'\r\n  quantize_op_types:\r\n  - conv2d\r\n  - depthwise_conv2d\r\n\r\nTrainConfig:\r\n  train_iter: 5000\r\n  eval_iter: 1000\r\n  learning_rate:  \r\n    type: CosineAnnealingDecay\r\n    learning_rate: 0.00003\r\n    T_max: 6000\r\n  optimizer_builder:\r\n    optimizer: \r\n      type: SGD\r\n    weight_decay: 4.0e-05\r\n```\r\n\r\n模型自动压缩前【即export导出之后】的大小为28.65M，自动压缩之后模型大小为28.70M，TRT_FP32和TRT_FP16推理时间也几乎一致，请问是什么原因导致的？\r\n\r\n\r\n另外通过[全量化方法](https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/full_quantization/ppyoloe)得到的模型大小有所减少28.65M->7.48M，但是模型推理速度仍然与量化之前几乎一致。",
        "state": "closed",
        "user": "Nirvana93",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-03-08T05:58:05+00:00",
        "updated_at": "2025-02-11T06:41:32+00:00",
        "closed_at": "2025-02-11T06:41:32+00:00",
        "comments_count": [
            "mrljwlm",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1682,
        "title": "使用自动压缩resnet18后，得到的量化模型，不能单独使用tensorRT部署",
        "body": "大家好：\r\n           使用自动化压缩resnet18后,然后转换成onnx，最后有onnx转tensorRT报错：\r\n       \r\n![1678326633377](https://user-images.githubusercontent.com/12984410/223895146-c9e1a2a2-82ca-4aca-afeb-5925ee6066d2.png)\r\n",
        "state": "closed",
        "user": "tp111222",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-03-08T11:57:32+00:00",
        "updated_at": "2025-02-11T06:41:33+00:00",
        "closed_at": "2025-02-11T06:41:33+00:00",
        "comments_count": [
            "tp111222",
            "miraiaroha",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1689,
        "title": "离线量化的quant_post_static如何使用自己的数据集？",
        "body": "如题，在quant_post_static函数的下面的例子中，sample_generator如何使用自己已标注好的数据集？VOC格式，目标检测。\r\n```\r\nslim.quant.quant_post_static(\r\n        executor=exe,\r\n        model_dir='./inference_model',\r\n        quantize_model_path='./quant_post_static_model',\r\n        sample_generator=paddle.dataset.mnist.test(),\r\n        model_filename='fp32.pdmodel',\r\n        params_filename='fp32.pdiparams',\r\n        batch_nums=10)\r\n```",
        "state": "closed",
        "user": "dium6i",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-17T02:12:17+00:00",
        "updated_at": "2024-02-06T05:56:50+00:00",
        "closed_at": "2024-02-06T05:56:50+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1683,
        "title": "静态后量化matmul_v2 op出错",
        "body": "静态后量化 paddle官方picodet模型出错，因其中含有matmul_v2 op\r\n``` python\r\nimport paddle\r\nimport paddleslim as slim\r\nimport numpy as np\r\nplace = paddle.CPUPlace()\r\nexe = paddle.static.Executor(place)\r\npaddle.enable_static()\r\ndef calibrate_data():\r\n    while True:\r\n        image = np.random.uniform(0, 1, size=(3, 320, 320)).astype(\"float32\")\r\n        scale_factor = np.random.uniform(0, 1, size=(1,2)).astype(\"float32\")\r\n        yield image,scale_factor\r\n\r\nslim.quant.quant_post_static(\r\n        executor=exe,\r\n        model_dir='/home/picodet_s_320_coco_lcnet',\r\n        quantize_model_path='/home/picodet_s_320_coco_lcnet/quant_post_static_model',\r\n        sample_generator=calibrate_data,\r\n        quantizable_op_type=[\r\n                          \"conv2d\", \"depthwise_conv2d\", \"mul\", \"matmul\", \"matmul_v2\"],\r\n        model_filename='model.pdmodel',\r\n        params_filename='model.pdiparams',\r\n        batch_nums=1        )\r\n```\r\n\r\n``` bash\r\nTraceback (most recent call last):\r\n  File \"/Users/Desktop/baidu/aipe-edge/PPNC-ToolChain/tmp/tmp.py\", line 17, in <module>\r\n    slim.quant.quant_post_static(\r\n  File \"/Users/.pyenv/versions/3.8.15/lib/python3.8/site-packages/paddleslim/quant/quanter.py\", line 627, in quant_post_static\r\n    post_training_quantization.quantize()\r\n  File \"/Users/.pyenv/versions/3.8.15/lib/python3.8/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 431, in quantize\r\n    self._calculate_kl_hist_threshold()\r\n  File \"/Users/.pyenv/versions/3.8.15/lib/python3.8/site-packages/paddle/fluid/contrib/slim/quantization/post_training_quantization.py\", line 948, in _calculate_kl_hist_threshold\r\n    for i in range(weight_data.shape[1]):\r\nIndexError: tuple index out of range\r\n```\r\n将matmul_v2从quantizable_op_type去掉后，即可正常产出量化模型\r\n\r\n## 环境\r\npaddle 2.4.2\r\nslim 2.4.1\r\n",
        "state": "closed",
        "user": "Kevin-XiongC",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-10T07:36:36+00:00",
        "updated_at": "2024-02-06T05:46:33+00:00",
        "closed_at": "2024-02-06T05:46:33+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1691,
        "title": "我遇到了问题： No module named 'paddle.quantization' ",
        "body": "这是我的版本：\r\npaddlepaddle-gpu          2.3.2.post116\r\npaddleslim                2.3.0",
        "state": "closed",
        "user": "yui330",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-17T06:30:00+00:00",
        "updated_at": "2024-02-06T05:58:01+00:00",
        "closed_at": "2024-02-06T05:58:01+00:00",
        "comments_count": [
            "junghyun-avikus",
            "zzjjay",
            "Li-li-Zhen",
            "zzjjay",
            "Li-li-Zhen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1696,
        "title": "根据官方教程蒸馏训练的时候出错。",
        "body": "使用yolov7导出的onnx模型，自定义coco数据集，在蒸馏训练的时候报错。\r\n如下：\r\n    InvalidArgumentError: The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 27, 80, 80], X's size = 172800, 'shape' is [30, 3, 9, 40, 40], the capacity of 'shape' is 1296000.\r\n      [Hint: Expected capacity == in_size, but received capacity:1296000 != in_size:172800.] (at /paddle/paddle/fluid/operators/reshape_op.cc:230)\r\n      [operator < reshape2 > error]\r\n",
        "state": "closed",
        "user": "liang-bowen",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-22T08:37:23+00:00",
        "updated_at": "2024-02-06T05:58:17+00:00",
        "closed_at": "2024-02-06T05:58:17+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1702,
        "title": "yolo post training quantization",
        "body": "Hi, I was following along the post training quantization,\r\nand I am wondering if given examples codes can convert yolov5m as well.\r\n\r\nThe given yaml for yolov5 is yolov5s_ptq.yaml, so is the code specific to yolov5s only?\r\n\r\nWhen I ran post_quant on the yolov5m onnx, directly exported from the ultralytics pretrained model on coco, I get the following error.\r\n\r\n[WARNING] Incomplete symbolic shape inference\r\n2023-03-24 17:30:56,985-WARNING: [ShapeInferenceError] (op_type:Split, node name: x2paddle__model_24_Split_output_0): [ShapeInferenceError] Inferred shape and existing shape differ in dimension 4: (2) vs (28)\r\n2023-03-24 17:30:56,986-ERROR: x2paddle threw an exception, you can ask for help at: https://github.com/PaddlePaddle/X2Paddle/issues\r\n\r\nDo I need to make some modifications in the code, or is it the environment that I am running on.\r\n\r\nThe environments are the followings:\r\nPaddle 2.4.1 cuda 11.7\r\nPaddleSlim 2.4\r\nx2paddle 1.3.9",
        "state": "closed",
        "user": "junghyun-avikus",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-03-24T08:51:52+00:00",
        "updated_at": "2025-02-11T06:41:34+00:00",
        "closed_at": "2025-02-11T06:41:34+00:00",
        "comments_count": [
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1698,
        "title": "有两个问题想请教一下",
        "body": "1、根据自动化压缩的步骤，第一步测精度eval.py，结果报错TypeError: Require fetch_list[1] 's type shall be one of (Variable, str), but received NoneType.\r\n2、运行自动化压缩，报错\r\n![image](https://user-images.githubusercontent.com/63039098/227146819-0fdc686a-62c7-42bc-9a5a-f922e12fe7c6.png)\r\n\r\n",
        "state": "closed",
        "user": "railgun-zyy",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-23T08:33:37+00:00",
        "updated_at": "2024-02-06T04:06:54+00:00",
        "closed_at": "2024-02-06T04:06:54+00:00",
        "comments_count": [
            "railgun-zyy",
            "railgun-zyy",
            "railgun-zyy",
            "zzjjay",
            "ZihaoZhao",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1699,
        "title": "PaddleSlim中DynaBERT策略可以压缩Decoder-Only，Encoder-Decoder网络结构吗？",
        "body": "怎么使用PaddleSlim中DynaBERT策略可以压缩Decoder-Only，Encoder-Decoder网络呢？",
        "state": "closed",
        "user": "robotsp",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-23T12:21:54+00:00",
        "updated_at": "2024-02-06T04:06:36+00:00",
        "closed_at": "2024-02-06T04:06:36+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1704,
        "title": "请问自动压缩能只保留QAT环节吗",
        "body": "你好，我在使用过程中发现蒸馏可能会造成最后结果的比较大偏差，不方便控制变量；我想只针对模型进行QAT而不蒸馏，但我发现直接注释蒸馏相关内容发现这个不能取消，是一个强制的内容；然后我想通过只蒸馏少数node来变相解决这个问题，但是我发现修改了少数node后还是会直接报错（我写的node是按照自动蒸馏的出现的node然后抄上去的，但还是出现问题）\r\n\r\n请问有什么方法可实现单纯的QAT吗，谢谢（我尝试在ppdet下面的qat但是反而速度更慢了，只有ppslim重新封装后的可以得到正确预期的模型。",
        "state": "closed",
        "user": "sanbuphy",
        "closed_by": "sanbuphy",
        "created_at": "2023-03-29T08:21:08+00:00",
        "updated_at": "2023-04-04T07:39:27+00:00",
        "closed_at": "2023-04-04T07:39:27+00:00",
        "comments_count": [
            "zzjjay",
            "sanbuphy",
            "zzjjay",
            "sanbuphy",
            "zzjjay",
            "sanbuphy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1707,
        "title": "请问OCR识别自动压缩要消耗至少多少内存？",
        "body": "我在一台64G内存，V100显卡的机器上尝试自动压缩，发现内存缓慢不断增长但没有任何新的输出，等待很久后最后出现了Segmentation fault (core dumped)\r\n\r\n![image](https://user-images.githubusercontent.com/96160062/228722590-7854914d-a0c5-4cc8-b9d6-19fe45de9760.png)\r\n\r\n请问这个现象要怎么解决？ 谢谢",
        "state": "closed",
        "user": "sanbuphy",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-30T03:40:08+00:00",
        "updated_at": "2024-02-06T04:06:04+00:00",
        "closed_at": "2024-02-06T04:06:04+00:00",
        "comments_count": [
            "zzjjay",
            "sanbuphy",
            "zzjjay",
            "sanbuphy",
            "sanbuphy",
            "zzjjay",
            "sanbuphy",
            "zzjjay",
            "sanbuphy",
            "sanbuphy",
            "sanbuphy",
            "zzjjay",
            "sanbuphy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1710,
        "title": "请问 PTQ量化能否拥有onnx_format？",
        "body": "你好，我在使用ptq后发现量化算子都是fake_xxxxx格式的，但是我想转换为onnx使用，请问ptq是否能生成onnx_format的q，dq量化算子，谢谢。（我加入了onnx_format: True到配置但是好像没有明显的反应）",
        "state": "closed",
        "user": "sanbuphy",
        "closed_by": "sanbuphy",
        "created_at": "2023-03-31T08:06:27+00:00",
        "updated_at": "2023-03-31T08:42:18+00:00",
        "closed_at": "2023-03-31T08:42:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1709,
        "title": "windows10 ppyoloe plus trt=True 的模型自动压缩报错",
        "body": "系统：windows10\r\npaddle最新版\r\n训练模型为ppyoloe+\r\n导出模型时，不设置trt=True，模型自动压缩不会报错\r\n导出模型时，设置了trt=True，模型自动压缩就会报错。\r\n错误信息：\r\n2023-03-31 15:05:18,030-INFO: devices: gpu\r\n2023-03-31 15:05:30,720-INFO: Selected strategies: ['qat_dis']\r\n2023-03-31 15:05:39,768-INFO: train config.distill_node_pair: ['teacher_conv2d_305.tmp_1', 'conv2d_305.tmp_1', 'teacher_conv2d_309.tmp_0', 'conv2d_309.tmp_0', 'teacher_conv2d_312.tmp_1', 'conv2d_312.tmp_1', 'teacher_conv2d_316.tmp_0', 'conv2d_316.tmp_0', 'teacher_conv2d_319.tmp_1', 'conv2d_319.tmp_1', 'teacher_conv2d_323.tmp_0', 'conv2d_323.tmp_0']\r\n2023-03-31 15:05:40,647-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'conv2d_transpose', 'mul', 'matmul', 'matmul_v2'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': False, 'quant_post_first': False, 'scale_trainable': True, 'name': 'Distillation', 'loss': 'l2', 'node': [], 'alpha': 1.0, 'teacher_model_dir': 'D:\\\\ai\\\\paddle\\\\models\\\\ppyoloe_plus_crn_l_80e_coco_trt_animal8', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\nAdding quant op with weight:|██████████████████████████████████████████| 585/585\r\nAdding OutScale op:|███████████████████████████████████████████████████| 578/578\r\n2023-03-31 15:05:47,042-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'conv2d_transpose', 'mul', 'matmul', 'matmul_v2'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': False, 'quant_post_first': False, 'scale_trainable': True, 'name': 'Distillation', 'loss': 'l2', 'node': [], 'alpha': 1.0, 'teacher_model_dir': 'D:\\\\ai\\\\paddle\\\\models\\\\ppyoloe_plus_crn_l_80e_coco_trt_animal8', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\nAdding quant op with weight:|████████████████████████████████████████| 2275/2275\r\nAdding OutScale op:|█████████████████████████████████████████████████| 1181/1181\r\n2023-03-31 15:07:02,888-INFO: Total iter: 0, epoch: 0, batch: 0, loss: [1.5197452]l2: [1.5197452]\r\nTraceback (most recent call last):\r\n  File \"D:\\ai\\paddle\\PaddleSlim-develop\\example\\auto_compression\\detection\\run.py\", line 199, in <module>\r\n    main()\r\n  File \"D:\\ai\\paddle\\PaddleSlim-develop\\example\\auto_compression\\detection\\run.py\", line 189, in main\r\n    ac.compress()\r\n  File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 593, in compress\r\n    self.single_strategy_compress(strategy, config, strategy_idx,\r\n  File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 775, in single_strategy_compress\r\n    test_program_info = self._start_train(\r\n  File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 794, in _start_train\r\n    loss = self._exe.run(train_program_info.program, \\\r\n  File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1463, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\six.py\", line 719, in reraise\r\n    raise value\r\n  File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1450, in run\r\n    res = self._run_impl(program=program,\r\n  File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1720, in _run_impl\r\n    return self._run_parallel(program,\r\n  File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\executor.py\", line 1254, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\nRuntimeError: In user code:\r\n\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\tools\\export_model.py\", line 108, in <module>\r\n      main()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\tools\\export_model.py\", line 104, in main\r\n      run(FLAGS, cfg)\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\tools\\export_model.py\", line 73, in run\r\n      trainer.export(FLAGS.output_dir)\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\engine\\trainer.py\", line 1059, in export\r\n      static_model, pruned_input_spec = self._get_infer_cfg_and_input_spec(\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\engine\\trainer.py\", line 1019, in _get_infer_cfg_and_input_spec\r\n      input_spec, static_model.forward.main_program,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\program_translator.py\", line 734, in main_program\r\n      concrete_program = self.concrete_program\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\program_translator.py\", line 537, in concrete_program\r\n      return self.concrete_program_specify_input_spec(input_spec=None)\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\program_translator.py\", line 577, in concrete_program_specify_input_spec\r\n      concrete_program, _ = self.get_concrete_program(\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\program_translator.py\", line 485, in get_concrete_program\r\n      concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\program_translator.py\", line 955, in __getitem__\r\n      self._caches[item_id] = self._build_once(item)\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\program_translator.py\", line 939, in _build_once\r\n      concrete_program = ConcreteProgram.from_func_spec(\r\n    File \"<decorator-gen-119>\", line 2, in from_func_spec\r\n\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py\", line 26, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py\", line 67, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\program_translator.py\", line 888, in from_func_spec\r\n      outputs = static_func(*inputs)\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\meta_arch.py\", line 58, in forward\r\n      if self.training:\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 323, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, get_args, set_args,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 380, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\meta_arch.py\", line 68, in forward\r\n      for inp in inputs_list:\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 106, in convert_while_loop\r\n      _run_py_while(cond, body, getter, setter)\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 165, in _run_py_while\r\n      body()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\meta_arch.py\", line 75, in forward\r\n      outs.append(self.get_pred())\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\yolo.py\", line 127, in get_pred\r\n      return self._forward()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\yolo.py\", line 87, in _forward\r\n      if self.training:\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 323, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, get_args, set_args,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 380, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\yolo.py\", line 98, in _forward\r\n      if self.for_mot:\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 323, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, get_args, set_args,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 380, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\yolo.py\", line 109, in _forward\r\n      if self.return_idx:\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 323, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, get_args, set_args,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 380, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\yolo.py\", line 112, in _forward\r\n      elif self.post_process is not None:\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 323, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, get_args, set_args,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 380, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\architectures\\yolo.py\", line 117, in _forward\r\n      bbox, bbox_num = self.yolo_head.post_process(\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\heads\\ppyoloe_head.py\", line 373, in post_process\r\n      if self.exclude_post_process:\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 323, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, get_args, set_args,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 380, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\heads\\ppyoloe_head.py\", line 383, in post_process\r\n      if self.exclude_nms:\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 323, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, get_args, set_args,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 380, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\heads\\ppyoloe_head.py\", line 387, in post_process\r\n      bbox_pred, bbox_num, _ = self.nms(pred_bboxes, pred_scores)\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\layers.py\", line 553, in __call__\r\n      if self.trt and (int(paddle.version.major) == 0 or\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 323, in convert_ifelse\r\n      out = _run_py_ifelse(pred, true_fn, false_fn, get_args, set_args,\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\dygraph\\dygraph_to_static\\convert_operators.py\", line 380, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"D:\\ai\\paddle\\PaddleDetection-release-2.5\\ppdet\\modeling\\layers.py\", line 559, in __call__\r\n      bbox = bbox.reshape([1, -1, 6])\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\tensor\\manipulation.py\", line 3658, in reshape\r\n      helper.append_op(\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\layer_helper.py\", line 45, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 4017, in append_op\r\n      op = Operator(\r\n    File \"D:\\Anaconda3\\envs\\paddle2.4\\lib\\site-packages\\paddle\\fluid\\framework.py\", line 2858, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    PreconditionNotMetError: The meta data must be valid when call the mutable data function. (at ..\\paddle\\phi\\core\\dense_tensor.cc:111)\r\n      [operator < reshape2 > error]",
        "state": "open",
        "user": "truthsun22",
        "closed_by": null,
        "created_at": "2023-03-31T07:12:53+00:00",
        "updated_at": "2023-10-20T02:11:07+00:00",
        "closed_at": null,
        "comments_count": [
            "panp4n",
            "truthsun22"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1708,
        "title": "quant_post_static  量化ppyoloeplus-m模型报错求解",
        "body": "quant_post_static  量化ppyoloeplus-m模型报错：\r\n**ValueError: all input arrays must have the same shape**\r\n 大佬们能不能帮忙看看到底是哪里有问题，跪谢！\r\n\r\n版本信息：\r\nPaddleSlim 2.4.0\r\npaddlepaddle  2.4.2\r\nPaddleDetection 2.6\r\n\r\n我将下面的运行代码 插入到paddledetection的训练代码后面，想要训练完，导出模型之后，进行量化：\r\n```\r\ndef reader_wrapper(reader, input_list):\r\n    def gen():\r\n        for data in reader:\r\n            in_dict = {}\r\n            if isinstance(input_list, list):\r\n                for input_name in input_list:\r\n                    in_dict[input_name] = data[input_name]\r\n            elif isinstance(input_list, dict):\r\n                for input_name in input_list.keys():\r\n                    in_dict[input_list[input_name]] = data[input_name]\r\n            yield in_dict\r\n\r\n    return gen\r\n\r\ndef quant_model():\r\n    from paddleslim.quant import quant_post_static\r\n    from ppdet.core.workspace import create\r\n    paddle.enable_static()\r\n\r\n    dataset = create('TrainDataset')()\r\n    train_loader = create('EvalReader')(dataset, cfg['worker_num'], return_list=True)\r\n    train_loader = reader_wrapper(train_loader, ['image'])\r\n\r\n    place = paddle.CUDAPlace(0)\r\n    exe = paddle.static.Executor(place)\r\n\r\n    quant_post_static(\r\n        executor=exe,\r\n        model_dir=D:/export_model,\r\n        quantize_model_path=D:/quantize_model,\r\n        data_loader=train_loader,\r\n        model_filename=\"mode.pdmodel\",\r\n        params_filename=\"mode.pdiparams\",\r\n        batch_size=32,\r\n        batch_nums=10,\r\n        algo='avg',\r\n        hist_percent=0.999,\r\n        is_full_quantize=False,\r\n        bias_correction=False,\r\n        onnx_format=False,\r\n        skip_tensor_list=None)\r\n```\r\n报错信息如下：ValueError: all input arrays must have the same shape\r\n![image](https://user-images.githubusercontent.com/23266835/229031850-ad923d79-6a27-4710-a4d1-6a4a314286e9.png)\r\n",
        "state": "closed",
        "user": "mrljwlm",
        "closed_by": "XGZhang11",
        "created_at": "2023-03-31T05:36:18+00:00",
        "updated_at": "2024-02-06T05:58:52+00:00",
        "closed_at": "2024-02-06T05:58:52+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1713,
        "title": "修改过的yolov5s模型如何使用paddleslim",
        "body": "请问修改过的yolov5s模型导出了onnx模型之后如何使用paddleslim，我这边会报错，自动化压缩工具ACT（Auto Compression Toolkit）\r\n    Fail to generate inference model! Problem happend while export inference model from python code 'D:\\pro\\PaddleSlim-develop\\best_infer\\onnx2paddle_0\\x2paddle_code.py';\r\n\r\n===================Error Information===============\r\n2023-04-02 21:17:13,787-WARNING: In transformed code:\r\n\r\n    File \"D:\\pro\\PaddleSlim-develop\\./best_infer\\onnx2paddle_0\\x2paddle_code.py\", line 677, in forward\r\n        x2paddle__model_2_cv1_act_Sigmoid_output_0 = self.sigmoid2(x2paddle__model_2_cv1_conv_Conv_output_0)\r\n        x2paddle__model_2_cv2_act_Sigmoid_output_0 = self.sigmoid3(x2paddle__model_2_cv2_conv_Conv_output_0)\r\n        x2paddle__model_21_m_blocks_blocks_1_Concat_output_0 = paddle.reshape(x=x2paddle__model_21_m_blocks_blocks_1_Concat_output_0, shape=[-1, 36, 36, -1, 4])\r\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n        x2paddle__model_21_m_blocks_blocks_1_Constant_2_output_0_zeros = paddle.zeros_like(x=x2paddle__model_21_m_blocks_blocks_1_Constant_2_output_0)\r\n        x2paddle__model_21_m_blocks_blocks_1_ScatterND_output_0_input_inner_indices = paddle.scatter_nd_add(x=x2paddle__model_21_m_blocks_blocks_1_Constant_2_output_0_zeros, index=x2paddle__model_21_m_blocks_blocks_1_Concat_output_0, updates=x2paddle__model_21_m_blocks_blocks_1_Reshape_1_output_0)\r\n\r\n    File \"C:\\Users\\WANGWEI\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\tensor\\manipulation.py\", line 3645, in reshape\r\n        attrs[\"shape\"] = get_attr_shape(shape)\r\n    File \"C:\\Users\\WANGWEI\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\tensor\\manipulation.py\", line 3607, in get_attr_shape\r\n        assert unk_dim_idx == -1, (\r\n\r\n    AssertionError: Only one dimension value of 'shape' in reshape can be -1. But received shape[3] is also -1.\r\n\r\n        # N = x.shape()[2]              # N is an int. (NOT recommend under @to_static)\r\n        N = paddle.shape(x)[2]          # N is a Tensor. (Recommend)\r\n        z = paddle.reshape([N, -1, 4])  # z.shape is [-1, -1, 4]\r\n\r\n    If your target shape in Reshape represents dynamic shape, please turn it into a Tensor under @to_static. See above example for details.\r\n\r\n2023-04-02 21:17:13,790-ERROR: x2paddle threw an exception, you can ask for help at: https://github.com/PaddlePaddle/X2Paddle/issues",
        "state": "closed",
        "user": "stdio159",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-04-02T13:20:32+00:00",
        "updated_at": "2025-02-11T06:41:35+00:00",
        "closed_at": "2025-02-11T06:41:35+00:00",
        "comments_count": [
            "stdio159",
            "bigbeef",
            "stdio159",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1711,
        "title": "请教ptq什么时候支持量化校准表的保存",
        "body": "hi你好，我在使用ptq后得到了量化模型，我也开启了onnx_format，但在paddle2onnx的过程中遇到如下报错：\r\n![image](https://user-images.githubusercontent.com/96160062/229083525-f8eb0bc9-02d3-4c00-9363-d0d194a3a504.png)\r\n请问怎么才能让他生成对应的量化校准表呢，非常感谢",
        "state": "open",
        "user": "sanbuphy",
        "closed_by": null,
        "created_at": "2023-03-31T09:33:06+00:00",
        "updated_at": "2024-02-15T15:13:15+00:00",
        "closed_at": null,
        "comments_count": [
            "xu-peng-7",
            "XGZhang11",
            "sanbuphy"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1714,
        "title": "自动压缩后的模型，推理时不设置run_mode=trt_int8检测框偏离",
        "body": "如题，不设置run_mode=trt_int8，检测框位置不对\r\n设置run_mode=trt_int8检测框位置正确",
        "state": "closed",
        "user": "truthsun22",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-04-03T06:26:56+00:00",
        "updated_at": "2025-02-11T06:41:36+00:00",
        "closed_at": "2025-02-11T06:41:36+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1715,
        "title": "蒸馏量化自动压缩通过run.py启动，结果mAP都是0？",
        "body": "1、原先训练好的PPYOLOE+模型的验证结果是正常的：\r\n```\r\npython tools/eval.py -c configs/ppyoloe/ppyoloe_plus_crn_s_80e_coco_aerial_12086.yml -o use_gpu=true\r\n```\r\n```\r\nDONE (t=5.71s).\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.780\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.952\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.854\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.529\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.741\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.849\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.536\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.811\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.839\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.619\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.809\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.899\r\n[04/03 02:26:43] ppdet.engine INFO: Total sample number: 2417, averge FPS: 19.068464412115826\r\n```\r\n2、导出模型\r\n```\r\n# 不包含NMS：\r\npython tools/export_model.py \\\r\n        -c configs/ppyoloe/ppyoloe_plus_crn_s_80e_coco_aerial_12086.yml \\\r\n        -o weights=output/ppyoloe_plus_crn_s_80e_coco_aerial_12086/best_model.pdparams \\\r\n        trt=True exclude_post_process=True\r\n```\r\n3、使用paddleslim接口paddleslim.auto_compression.AutoCompression对模型进行自动压缩：\r\n```\r\npython run.py --config_path=./configs/ppyoloe_plus_s_qat_dis_12086.yaml --save_dir='./output_slim/ppyoloe_plus_crn_s_80e_coco_aerial_12086_slim/'\r\n```\r\n其中，导出的PPYOLOE+推理模型是不包含NMS的。\r\n蒸馏量化结果：\r\n```\r\n2023-04-03 05:34:08,633-INFO: Total iter: 4900, epoch: 0, batch: 4900, loss: [30.340824]soft_label: [30.340824] \r\n2023-04-03 05:34:11,048-INFO: Total iter: 4910, epoch: 0, batch: 4910, loss: [30.346943]soft_label: [30.346943] \r\n2023-04-03 05:34:13,515-INFO: Total iter: 4920, epoch: 0, batch: 4920, loss: [30.357788]soft_label: [30.357788] \r\n2023-04-03 05:34:15,968-INFO: Total iter: 4930, epoch: 0, batch: 4930, loss: [30.35611]soft_label: [30.35611] \r\n2023-04-03 05:34:18,390-INFO: Total iter: 4940, epoch: 0, batch: 4940, loss: [30.34336]soft_label: [30.34336] \r\n2023-04-03 05:34:20,854-INFO: Total iter: 4950, epoch: 0, batch: 4950, loss: [30.340946]soft_label: [30.340946] \r\n2023-04-03 05:34:23,312-INFO: Total iter: 4960, epoch: 0, batch: 4960, loss: [30.34417]soft_label: [30.34417] \r\n2023-04-03 05:34:25,771-INFO: Total iter: 4970, epoch: 0, batch: 4970, loss: [30.365654]soft_label: [30.365654] \r\n2023-04-03 05:34:28,246-INFO: Total iter: 4980, epoch: 0, batch: 4980, loss: [30.344555]soft_label: [30.344555] \r\n2023-04-03 05:34:30,687-INFO: Total iter: 4990, epoch: 0, batch: 4990, loss: [30.35045]soft_label: [30.35045] \r\nEval iter: 0\r\nEval iter: 100\r\nEval iter: 200\r\nEval iter: 300\r\nEval iter: 400\r\nEval iter: 500\r\nEval iter: 600\r\nEval iter: 700\r\nEval iter: 800\r\nEval iter: 900\r\nEval iter: 1000\r\nEval iter: 1100\r\nEval iter: 1200\r\nEval iter: 1300\r\nEval iter: 1400\r\nEval iter: 1500\r\nEval iter: 1600\r\nEval iter: 1700\r\nEval iter: 1800\r\n[04/03 05:39:22] ppdet.data.transform.operators WARNING: The actual image height: 663 is not equal to the height: 0.0 in annotation, and update sample['h'] by actual image height.\r\n[04/03 05:39:22] ppdet.data.transform.operators WARNING: The actual image width: 949 is not equal to the width: 0.0 in annotation, and update sample['w'] by actual image width.\r\nEval iter: 1900\r\nEval iter: 2000\r\nEval iter: 2100\r\nEval iter: 2200\r\nEval iter: 2300\r\nEval iter: 2400\r\n[04/03 05:41:01] ppdet.metrics.metrics INFO: The bbox result is saved to bbox.json.\r\nloading annotations into memory...\r\nDone (t=0.02s)\r\ncreating index...\r\nindex created!\r\n[04/03 05:41:01] ppdet.metrics.coco_utils INFO: Start evaluate...\r\nLoading and preparing results...\r\nDONE (t=6.01s)\r\ncreating index...\r\nindex created!\r\nRunning per image evaluation...\r\nEvaluate annotation type *bbox*\r\nDONE (t=21.99s).\r\nAccumulating evaluation results...\r\nDONE (t=10.59s).\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.016\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.027\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.083\r\n2023-04-03 05:41:41,076-INFO: epoch: 0 metric of compressed model is: 0.000599, best metric of compressed model is 0.000599\r\n2023-04-03 05:41:41,149-INFO: convert config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'quant_post_first': False, 'scale_trainable': True, 'name': 'Distillation', 'loss': 'soft_label', 'node': [], 'alpha': 1.0, 'teacher_model_dir': './output_inference/ppyoloe_plus_crn_s_80e_coco_aerial_12086', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams'}\r\n2023-04-03 05:42:15,542-INFO: ==> The metric of final model is 0.0006\r\n2023-04-03 05:42:15,542-INFO: ==> The ACT compression has been completed and the final model is saved in `./output_slim/ppyoloe_plus_crn_s_80e_coco_aerial_12086_slim/`\r\n```\r\n请大佬诊断下，蒸馏量化结果mAP=0.001的原因？感谢。",
        "state": "closed",
        "user": "yuanjim",
        "closed_by": "XGZhang11",
        "created_at": "2023-04-03T07:41:24+00:00",
        "updated_at": "2024-02-06T04:05:29+00:00",
        "closed_at": "2024-02-06T04:05:29+00:00",
        "comments_count": [
            "zzjjay",
            "yuanjim",
            "yuanjim",
            "zzjjay",
            "yuanjim",
            "zzjjay",
            "yuanjim",
            "huangjianyi0701",
            "zzjjay",
            "yuanjim",
            "tanchi30",
            "yuanjim"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1717,
        "title": "paddle detection中的solov2如何进行剪枝量化",
        "body": null,
        "state": "closed",
        "user": "panp4n",
        "closed_by": "ceci3",
        "created_at": "2023-04-07T01:57:44+00:00",
        "updated_at": "2024-02-06T06:26:59+00:00",
        "closed_at": "2024-02-06T06:26:59+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1718,
        "title": "请问在ACT中如何设定，使得部分卷积算子不被量化",
        "body": null,
        "state": "closed",
        "user": "qqqejjjj",
        "closed_by": "XGZhang11",
        "created_at": "2023-04-09T09:00:44+00:00",
        "updated_at": "2024-02-06T05:59:49+00:00",
        "closed_at": "2024-02-06T05:59:49+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1719,
        "title": "关于零基础在半个月内用PaddleSlim实现手动压缩模型的可行性",
        "body": "求问一下懂轻量化的大佬们。\r\n我的本科毕设，模型用的是PP-YOLOE+_SOD-l，我没有任何模型轻量化的基础，导师开会说不让用自动压缩说让我手动压缩，目标是半个月把这个事做完，半个月时间学轻量化并且做到手动压缩这件事可行吗？",
        "state": "closed",
        "user": "627992512",
        "closed_by": "627992512",
        "created_at": "2023-04-09T13:43:40+00:00",
        "updated_at": "2023-04-15T08:02:34+00:00",
        "closed_at": "2023-04-15T08:02:34+00:00",
        "comments_count": [
            "zzjjay",
            "627992512"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1722,
        "title": "yolov7使用自动压缩工具，卡在train config.distill_node_pair: train config.distill_node_pair: ['teacher_conv2d_160.tmp_1', 'conv2d_160.tmp_1', 'teacher_conv2d_172.tmp_1', 'conv2d_172.tmp_1', 'teacher_conv2d_181.tmp _1', 'conv2d_181.tmp_1']后直接退出",
        "body": "报错如图，按照流程使用官方提供的eyolov7-tiny.onnx已经实现压缩。\r\n![QQ截图20230412182823](https://user-images.githubusercontent.com/91938255/231431187-f87242df-ade4-41c4-9079-122cb0fc80ba.png)\r\n\r\n模型训练的是自己的数据集，格式是从voc转的，如图\r\n![image](https://user-images.githubusercontent.com/91938255/231430185-ca45dae6-8ce6-4aa4-bcd0-d5f6174e4878.png)\r\n求解答，万分感谢！！！！！\r\n",
        "state": "closed",
        "user": "maiyaitang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-04-12T10:32:14+00:00",
        "updated_at": "2025-02-11T06:41:38+00:00",
        "closed_at": "2025-02-11T06:41:37+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1720,
        "title": "在使用官方文档中的教程的对ppyoloe进行auto_compress的时候报错AttributeError: 'SchemaDict' object has no attribute 'check_or_download_dataset'",
        "body": null,
        "state": "closed",
        "user": "NoConfusionj",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-04-10T15:16:36+00:00",
        "updated_at": "2025-02-11T06:41:37+00:00",
        "closed_at": "2025-02-11T06:41:37+00:00",
        "comments_count": [
            "NoConfusionj",
            "GUANGHANXUE",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1724,
        "title": "基于修改过的yolov7-tiny，使用PaddleSlim/example/auto_compression/pytorch_yolo_series/自动压缩示例教程",
        "body": "在进行至README.md的导出至ONNX使用TensorRT部署阶段时，报错\r\n```\r\nTraceback (most recent call last):\r\n  File \"G:\\PythonDev\\YOLOProject\\PaddleSlimAC\\TensorRT\\trt_eval.py\", line 324, in <module>\r\n    main()\r\n  File \"G:\\PythonDev\\YOLOProject\\PaddleSlimAC\\TensorRT\\trt_eval.py\", line 303, in main\r\n    infer()\r\n  File \"G:\\PythonDev\\YOLOProject\\PaddleSlimAC\\TensorRT\\trt_eval.py\", line 279, in infer\r\n    outs = np.array(outs).reshape(1, -1, 85)\r\nValueError: could not broadcast input array from shape (3,80,80,16) into shape (1,3)\r\n```\r\n截至此错误之前，项目已生成\r\n![QQ截图20230413171818](https://user-images.githubusercontent.com/26647741/231714964-d9940a4d-2480-4869-8206-1fc3b76ebc2d.png)\r\n请问报错的原因是什么呢？需要修改什么参数吗?还是网络自身存在问题？\r\n求解答，谢谢!",
        "state": "closed",
        "user": "DSP3460",
        "closed_by": "XGZhang11",
        "created_at": "2023-04-13T09:24:50+00:00",
        "updated_at": "2024-02-06T06:00:24+00:00",
        "closed_at": "2024-02-06T06:00:24+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1725,
        "title": "PaddleSlim怎么和PaddleDetection联合使用（就是PaddleDetection中怎么调用PaddleSlim中一些函数的接口）",
        "body": null,
        "state": "closed",
        "user": "shangshanruowo",
        "closed_by": "shangshanruowo",
        "created_at": "2023-04-13T12:26:51+00:00",
        "updated_at": "2023-04-21T06:37:51+00:00",
        "closed_at": "2023-04-21T06:37:51+00:00",
        "comments_count": [
            "shangshanruowo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1728,
        "title": "SOLOv2：PrunerQAT时报错“TypeError: cannot pickle 'paddle.fluid.libpaddle.BlockDesc' object” ",
        "body": "<img width=\"982\" alt=\"image\" src=\"https://user-images.githubusercontent.com/66545456/231985022-d5b20b4e-6f53-4db9-810f-6a6ccc789d1e.png\">\r\n",
        "state": "closed",
        "user": "syyxtl",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-04-14T08:12:29+00:00",
        "updated_at": "2025-02-11T06:41:38+00:00",
        "closed_at": "2025-02-11T06:41:38+00:00",
        "comments_count": [
            "Dhao007",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1729,
        "title": "自动压缩工具压缩了ppyoloe_plus_s的模型，压缩前后性能没有提升",
        "body": "大佬们，我用自动压缩工具压缩了ppyoloe的，但是我用C++代码进行推断的时间没有什么提升，请问会是什么问题？\r\n\r\n这是我压缩前后的模型：\r\n链接：https://pan.baidu.com/s/1QYiPK_zu6j--rYp0ncq06g \r\n提取码：9dcw \r\n",
        "state": "closed",
        "user": "mrljwlm",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-04-15T05:40:38+00:00",
        "updated_at": "2025-02-11T06:41:39+00:00",
        "closed_at": "2025-02-11T06:41:39+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1730,
        "title": "paddleslim还有人维护嘛，现在支持transoformer剪枝嘛？有的话 有教程么？",
        "body": null,
        "state": "closed",
        "user": "syyxtl",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-04-15T09:24:03+00:00",
        "updated_at": "2025-02-11T06:41:40+00:00",
        "closed_at": "2025-02-11T06:41:40+00:00",
        "comments_count": [
            "ceci3",
            "zust-pss",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1731,
        "title": "关于用paddleslim自动化压缩之后的engine推理结果。",
        "body": "用yolov5 -l的检测模型训练了自己的数据集，然后转onnx用run.py自动化压缩。最后得到的onnx模型转engine之后。推理没有任何的输出信息。但是程序没有报告bug。",
        "state": "closed",
        "user": "xiyangyang99",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-04-17T06:09:56+00:00",
        "updated_at": "2025-02-11T06:41:41+00:00",
        "closed_at": "2025-02-11T06:41:41+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1734,
        "title": "指定某一层不进行量化",
        "body": "您好，想了解一下能否在量化时指定某一层不进行量化或者指定该层量化的bits为16？如果可以的话具体怎么操作呢\r\n",
        "state": "closed",
        "user": "Mobu59",
        "closed_by": "XGZhang11",
        "created_at": "2023-04-19T04:32:21+00:00",
        "updated_at": "2024-02-06T06:01:16+00:00",
        "closed_at": "2024-02-06T06:01:16+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1735,
        "title": "自动压缩里面的量化训练是先进行ptq再qat吗",
        "body": "自动压缩里面的量化训练是先进行ptq再qat吗，还是说是直接在浮点的预训练权重上进行qat微调",
        "state": "closed",
        "user": "everloom",
        "closed_by": "XGZhang11",
        "created_at": "2023-04-19T06:42:21+00:00",
        "updated_at": "2024-02-06T06:01:28+00:00",
        "closed_at": "2024-02-06T06:01:28+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1736,
        "title": "在使用静态量化的过程中如何指定融合算子",
        "body": "请问在训练后使用静态量化的过程中如何指定融合算子？\r\n在使用Paddle-Lite在TIMVX平台上部署PPOCRv3_det模型时发现，在模型量化时倒数第2层Conv2d_transpose层会将后面的relu层融合在一起，此时推理模型报错 nntp not  support this format。\r\n将relu层去掉之后经过同样量化操作，则可以正常执行。",
        "state": "closed",
        "user": "JPChen2000",
        "closed_by": "XGZhang11",
        "created_at": "2023-04-19T06:58:54+00:00",
        "updated_at": "2024-02-06T06:01:42+00:00",
        "closed_at": "2024-02-06T06:01:42+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1737,
        "title": "paddleslim怎么实现自定义模型剪枝？",
        "body": "请问一下paddleslim可以支持自己搭建模型减枝吗，还有可以根据稀疏训练后BN中γ进行通道剪枝吗，可以的话应该在那个里面进行修改呢？",
        "state": "open",
        "user": "shangshanruowo",
        "closed_by": null,
        "created_at": "2023-04-21T06:40:05+00:00",
        "updated_at": "2024-02-26T07:07:20+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "shangshanruowo",
            "ceci3",
            "shangshanruowo",
            "ceci3",
            "shangshanruowo",
            "ceci3",
            "shangshanruowo",
            "shangshanruowo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1742,
        "title": "save_quant_model.py  需要更新",
        "body": "代码从import开始就有点问题，paddle.static.load_inference_model(\r\n                 original_path, exe, model_filename=model_filename, params_filename=params_filename)\r\n\r\n然后\r\n            paddle.static.save_inference_model(\r\n                path_prefix = save_path,\r\n                feed_vars = [image],\r\n                fetch_vars = fetch_targets,\r\n                executor = exe,\r\n                program=inference_program)\r\n\r\n也需要更新，",
        "state": "closed",
        "user": "mysteriousHerb",
        "closed_by": "ceci3",
        "created_at": "2023-04-28T13:19:27+00:00",
        "updated_at": "2024-02-06T06:15:00+00:00",
        "closed_at": "2024-02-06T06:15:00+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1746,
        "title": "Unsupported operator named Clip",
        "body": "Got this error \"Unsupported operator named Clip\" while pruning MobileNet V1.\r\n\r\nCompare with the model in official example, the active func is different:\r\n\"relu\" was used in official example model:\r\n![image](https://user-images.githubusercontent.com/53440889/236766949-eff96a03-55e8-48f2-b9b2-5a1ae2fe2bcd.png)\r\n\r\n\"Clip\" (relu6) was used in MobileNet V1:\r\n \r\n![image](https://user-images.githubusercontent.com/53440889/236767236-db0bd9f3-110e-4566-a6f4-d919c665b9ec.png)\r\n",
        "state": "closed",
        "user": "Jason-wwww",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-05-08T07:51:31+00:00",
        "updated_at": "2025-02-11T06:41:42+00:00",
        "closed_at": "2025-02-11T06:41:42+00:00",
        "comments_count": [
            "Jason-wwww",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1748,
        "title": "量化示例报错（quant_aware_with_infermodel）",
        "body": "paddleslim版本：develop\r\n\r\n跑的demo：https://github.com/PaddlePaddle/PaddleSlim/tree/develop/demo/quant/quant_aware_with_infermodel\r\n唯一改动：--use_pact=True改为了--use_pact=False\r\n\r\n> 报错信息：\r\n> -----------  Configuration Arguments -----------\r\n> batch_size: 512\r\n> checkpoint_path: ./MobileNetV2_quantaware_ckpt/\r\n> distill_node_name_list: ['teacher_linear_1.tmp_0', 'linear_1.tmp_0']\r\n> learning_rate: 0.0001\r\n> model_path_prefix: ./pretrain/MobileNetV2_infer/inference\r\n> num_epoch: 1\r\n> save_iter_step: 100\r\n> teacher_model_path_prefix: ./pretrain/MobileNetV2_infer/inference\r\n> use_gpu: 1\r\n> use_pact: False\r\n> weight_decay: 4e-05\r\n> ------------------------------------------------\r\n> 2023-05-10 15:52:12,605-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'quant_post_first': False, 'scale_trainable': True, 'deploy_backend': None, 'quant_config': <paddle.static.quantization.quant_config.BaseQuantizer object at 0x7f0458e4bc18>}\r\n> I0510 15:52:12.890381 167726 interpretercore.cc:267] New Executor is Running.\r\n> W0510 15:52:12.896950 167726 gpu_resources.cc:90] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 10.2, Runtime API Version: 10.2\r\n> W0510 15:52:12.900543 167726 gpu_resources.cc:120] device: 0, cuDNN Version: 7.6.\r\n> 2023-05-10 15:52:17,043-INFO: train config.distill_node_pair: ['teacher_linear_1.tmp_0', 'linear_1.tmp_0']\r\n> 2023-05-10 15:52:17,319-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'quant_post_first': False, 'scale_trainable': True, 'deploy_backend': None, 'quant_config': <paddle.static.quantization.quant_config.BaseQuantizer object at 0x7f0458d40c50>}\r\n> Adding quant op with weight:|██████████████████████████████████████████| 159/159\r\n> Adding quant activation op:|███████████████████████████████████████████| 371/371\r\n> Adding OutScale op:|███████████████████████████████████████████████████| 158/158\r\n> 2023-05-10 15:52:19,853-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d', 'mul'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'quant_post_first': False, 'scale_trainable': True, 'deploy_backend': None, 'quant_config': <paddle.static.quantization.quant_config.BaseQuantizer object at 0x7f0458886fd0>}\r\n> Adding quant op with weight:|██████████████████████████████████████████| 651/651\r\n> Adding quant activation op:|███████████████████████████████████████████| 863/863\r\n> Adding OutScale op:|███████████████████████████████████████████████████| 321/321\r\n> /home/xuweixiang/local/anaconda3/lib/python3.7/site-packages/paddle/fluid/executor.py:1229: UserWarning: The variable x is not found in program. It is not declared or is pruned.\r\n> Traceback (most recent call last):\r\n>   File \"quant_aware_with_infermodel.py\", line 149, in <module>\r\n>     main()\r\n>   File \"quant_aware_with_infermodel.py\", line 144, in main\r\n>     quantize(args)\r\n>   File \"quant_aware_with_infermodel.py\", line 137, in quantize\r\n>     test_callback=test_callback)\r\n>   File \"../../../paddleslim/quant/quant_aware_with_infermodel.py\", line 219, in quant_aware_with_infermodel\r\n>     fetch_list=train_fetch_list)\r\n>   File \"/home/xuweixiang/local/anaconda3/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1435, in run\r\n>     use_prune=use_prune,\r\n>   File \"/home/xuweixiang/local/anaconda3/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1659, in _run_impl\r\n>     scope, list(feed.keys()), fetch_list, return_numpy\r\n>   File \"/home/xuweixiang/local/anaconda3/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 655, in run\r\n>     scope, feed_names, fetch_list\r\n> RuntimeError: (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.\r\n>   [Hint: holder_ should not be null.] (at /paddle/paddle/phi/core/dense_tensor_impl.cc:44)\r\n>   [operator < quantize_linear > error]",
        "state": "closed",
        "user": "WeixiangXu",
        "closed_by": "WeixiangXu",
        "created_at": "2023-05-10T07:59:21+00:00",
        "updated_at": "2024-02-29T02:50:05+00:00",
        "closed_at": "2024-02-29T02:50:05+00:00",
        "comments_count": [
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1749,
        "title": "咨询CNN+Transformer部署",
        "body": "您好，请问CNN+Transformer部署的思路过程是什么？有参考学习的代码吗？",
        "state": "closed",
        "user": "ywfwyht",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-05-11T06:45:11+00:00",
        "updated_at": "2025-02-11T06:41:42+00:00",
        "closed_at": "2025-02-11T06:41:42+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1755,
        "title": "paddleslim量化敏感度分析使用相似度评估精度损失，存在内存泄漏问题",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/develop/paddleslim/quant/analysis.py#L416\r\n\r\npaddle gpu:2.4.2 post112\r\npaddleslim2.4.1\r\n分析精度损失：评估函数不可使用，利用fp_int_cosine_similarity\r\n内存占用一直上升，直接到最后就是ResourceExhaustedError: Fail to alloc memory of 524288000 size, error code is 12.\r\n\r\n\r\nSampling stage, Run batch:|                                                | 0/1W0531 14:29:24.876821  1627 sampler.cpp:189] bvar is busy at sampling for 2 seconds!\r\n\r\n",
        "state": "closed",
        "user": "RenyanDiao",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-05-31T04:09:43+00:00",
        "updated_at": "2025-02-11T06:41:43+00:00",
        "closed_at": "2025-02-11T06:41:43+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1756,
        "title": "量化分析工具报错",
        "body": "我安装的paddlepaddle是2.4.2版本，但我运行量化分析工具\\example\\post_training_quantization\\detection\\analysis.py报错\r\n我直接打开python ,执行import paddleslim也是报同样的错\r\n[GCC 11.2.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import paddleslim\r\n/home/deepiot/anaconda3/envs/paddle2.4/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\n2023-05-31 17:36:22,721-WARNING: No module named 'paddle.static.quantization'\r\n2023-05-31 17:36:22,721-WARNING: If you want to use training-aware and post-training quantization, please use Paddle >= 2.3.0 or develop version\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/deepiot/ai/PaddleSlim/paddleslim/__init__.py\", line 20, in <module>\r\n    from paddleslim import quant\r\n  File \"/home/deepiot/ai/PaddleSlim/paddleslim/quant/__init__.py\", line 42, in <module>\r\n    from . import nn\r\n  File \"/home/deepiot/ai/PaddleSlim/paddleslim/quant/nn/__init__.py\", line 15, in <module>\r\n    from .conv_bn import QuantedConv2DBatchNorm, Conv2DBatchNormWrapper\r\n  File \"/home/deepiot/ai/PaddleSlim/paddleslim/quant/nn/conv_bn.py\", line 21, in <module>\r\n    from paddle.nn.quant.format import ConvertibleQuantedLayer\r\nModuleNotFoundError: No module named 'paddle.nn.quant.format'\r\n",
        "state": "closed",
        "user": "truthsun22",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-05-31T09:43:35+00:00",
        "updated_at": "2025-02-11T06:41:44+00:00",
        "closed_at": "2025-02-11T06:41:44+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1757,
        "title": "自动压缩报错CUDNN版本错误",
        "body": "系统ubuntu20.01。paddle和slim均是dev版本，CUDA11.6,cudnn8.4,按照官方说明这个是匹配的，但是执行自动压缩的时候，还是报版本不匹配，这是咋回事？\r\n2023-06-01 15:00:54,113-INFO: devices: gpu\r\n2023-06-01 15:01:03,250-INFO: Selected strategies: ['qat_dis']\r\n2023-06-01 15:01:11,724-INFO: train config.distill_node_pair: ['teacher_conv2d_305.tmp_1', 'conv2d_305.tmp_1', 'teacher_conv2d_309.tmp_0', 'conv2d_309.tmp_0', 'teacher_conv2d_312.tmp_1', 'conv2d_312.tmp_1', 'teacher_conv2d_316.tmp_0', 'conv2d_316.tmp_0', 'teacher_conv2d_319.tmp_1', 'conv2d_319.tmp_1', 'teacher_conv2d_323.tmp_0', 'conv2d_323.tmp_0']\r\n2023-06-01 15:01:12,023-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'quant_post_first': False, 'scale_trainable': True, 'deploy_backend': None, 'name': 'Distillation', 'loss': 'soft_label', 'node': [], 'alpha': 1.0, 'teacher_model_dir': '/home/deepiot/ai/models/ppyoloe_plus_crn_l_80e_coco_animal8', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams', 'quant_config': <paddle.static.quantization.quant_config.BaseQuantizer object at 0x7f7a74170a60>}\r\nAdding quant op with weight:|██████████████████████████████████████████| 468/468\r\nAdding OutScale op:|███████████████████████████████████████████████████| 464/464\r\n2023-06-01 15:01:17,119-INFO: quant_aware config {'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max', 'weight_bits': 8, 'activation_bits': 8, 'not_quant_pattern': ['skip_quant'], 'quantize_op_types': ['conv2d', 'depthwise_conv2d'], 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9, 'for_tensorrt': False, 'is_full_quantize': False, 'onnx_format': True, 'quant_post_first': False, 'scale_trainable': True, 'deploy_backend': None, 'name': 'Distillation', 'loss': 'soft_label', 'node': [], 'alpha': 1.0, 'teacher_model_dir': '/home/deepiot/ai/models/ppyoloe_plus_crn_l_80e_coco_animal8', 'teacher_model_filename': 'model.pdmodel', 'teacher_params_filename': 'model.pdiparams', 'quant_config': <paddle.static.quantization.quant_config.BaseQuantizer object at 0x7f7a4c427460>}\r\nAdding quant op with weight:|████████████████████████████████████████| 2476/2476\r\nAdding OutScale op:|█████████████████████████████████████████████████| 2230/2230\r\nI0601 15:05:05.469944 35715 interpreter_util.cc:518] Standalone Executor is Used.\r\nTraceback (most recent call last):\r\n  File \"/home/deepiot/ai/PaddleSlim/example/auto_compression/detection/run.py\", line 198, in <module>\r\n    main()\r\n  File \"/home/deepiot/ai/PaddleSlim/example/auto_compression/detection/run.py\", line 188, in main\r\n    ac.compress()\r\n  File \"/home/deepiot/anaconda3/envs/paddle_slim/lib/python3.9/site-packages/paddleslim-0.0.0.dev0-py3.9.egg/paddleslim/auto_compression/compressor.py\", line 586, in compress\r\n  File \"/home/deepiot/anaconda3/envs/paddle_slim/lib/python3.9/site-packages/paddleslim-0.0.0.dev0-py3.9.egg/paddleslim/auto_compression/compressor.py\", line 780, in single_strategy_compress\r\n  File \"/home/deepiot/anaconda3/envs/paddle_slim/lib/python3.9/site-packages/paddleslim-0.0.0.dev0-py3.9.egg/paddleslim/auto_compression/compressor.py\", line 799, in _start_train\r\n  File \"/home/deepiot/anaconda3/envs/paddle_slim/lib/python3.9/site-packages/paddle/fluid/executor.py\", line 1426, in run\r\n    res = self._run_impl(\r\n  File \"/home/deepiot/anaconda3/envs/paddle_slim/lib/python3.9/site-packages/paddle/fluid/executor.py\", line 1658, in _run_impl\r\n    ret = new_exe.run(\r\n  File \"/home/deepiot/anaconda3/envs/paddle_slim/lib/python3.9/site-packages/paddle/fluid/executor.py\", line 654, in run\r\n    tensors = self._new_exe.run(\r\nOSError: (External) CUDNN error(14), CUDNN_STATUS_VERSION_MISMATCH. \r\n  [Hint: Please search for the error code(14) on website (https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnStatus_t) to get Nvidia's official solution and advice about CUDNN Error.] (at ../paddle/phi/kernels/gpudnn/pool_grad_kernel.cu:284)\r\n  [operator < pool2d_grad > error]\r\n",
        "state": "closed",
        "user": "truthsun22",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-06-01T07:19:43+00:00",
        "updated_at": "2025-02-11T06:41:45+00:00",
        "closed_at": "2025-02-11T06:41:45+00:00",
        "comments_count": [
            "mufeng12399",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1759,
        "title": "paddleslim是否支持paddlevideo中的模型",
        "body": "paddleslim是否支持paddlevideo中的模型",
        "state": "closed",
        "user": "luyuanmengmmm",
        "closed_by": "ceci3",
        "created_at": "2023-06-04T09:21:46+00:00",
        "updated_at": "2024-02-06T05:57:22+00:00",
        "closed_at": "2024-02-06T05:57:21+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1765,
        "title": "ModuleNotFoundError: No module named 'paddle.nn.quant.format'",
        "body": "platform: windows11\r\npaddlepaddle-gpu: 2.4.2\r\npaddledet: 2.6.0\r\npaddleslim: setup安装\r\n\r\nexample/auto_compression/detection/run.py报错如下:\r\nModuleNotFoundError: No module named 'paddle.nn.quant.format'\r\n",
        "state": "closed",
        "user": "Victoria-1",
        "closed_by": "Victoria-1",
        "created_at": "2023-06-19T08:10:19+00:00",
        "updated_at": "2023-06-21T02:38:39+00:00",
        "closed_at": "2023-06-21T02:38:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1761,
        "title": "剪枝时axis对不上，正常卷积可以对上，深度可分离卷积就对不上了",
        "body": "使用pruner = L1NormFilterPruner(trainer.model, input_spec)时，对正常卷积的模型可以运行，但模型里面有深度可分离卷积的就会报错误，2023-06-10 16:31:29,724-WARNING: Leaves ['eager_tmp_5', 'batch_norm_75.tmp_0', 'batch_norm_75.tmp_1', 'batch_norm_76.tmp_0', 'batch_norm_76.tmp_1', 'batch_norm_77.tmp_0', 'batch_norm_77.tmp_1', 'batch_norm_78.tmp_0', 'batch_norm_78.tmp_1', 'batch_norm_79.tmp_0', 'batch_norm_79.tmp_1', 'batch_norm_80.tmp_0', 'batch_norm_80.tmp_1', 'batch_norm_81.tmp_0', 'batch_norm_81.tmp_1', 'batch_norm_82.tmp_0', 'batch_norm_82.tmp_1', 'batch_norm_83.tmp_0', 'batch_norm_83.tmp_1', 'batch_norm_84.tmp_0', 'batch_norm_84.tmp_1', 'batch_norm_85.tmp_0', 'batch_norm_85.tmp_1', 'batch_norm_86.tmp_0', 'batch_norm_86.tmp_1', 'batch_norm_87.tmp_0', 'batch_norm_87.tmp_1', 'batch_norm_88.tmp_0', 'batch_norm_88.tmp_1', 'batch_norm_89.tmp_0', 'batch_norm_89.tmp_1', 'batch_norm_90.tmp_0', 'batch_norm_90.tmp_1', 'batch_norm_91.tmp_0', 'batch_norm_91.tmp_1', 'reshape2_46.tmp_1', 'transpose_40.tmp_1', 'reshape2_47.tmp_1', 'transpose_41.tmp_1', 'reshape2_48.tmp_1', 'layer_norm_21.tmp_0', 'layer_norm_21.tmp_1', 'reshape2_49.tmp_1', 'transpose_42.tmp_1', 'transpose_43.tmp_1', 'transpose_44.tmp_1', 'reshape2_50.tmp_1', 'dropout_18.tmp_1', 'layer_norm_22.tmp_0', 'layer_norm_22.tmp_1', 'dropout_19.tmp_1', 'layer_norm_23.tmp_0', 'layer_norm_23.tmp_1', 'reshape2_51.tmp_1', 'transpose_45.tmp_1', 'transpose_46.tmp_1', 'transpose_47.tmp_1', 'reshape2_52.tmp_1', 'dropout_20.tmp_1', 'layer_norm_24.tmp_0', 'layer_norm_24.tmp_1', 'dropout_21.tmp_1', 'layer_norm_25.tmp_0', 'layer_norm_25.tmp_1', 'reshape2_53.tmp_1', 'transpose_48.tmp_1', 'reshape2_54.tmp_1', 'transpose_49.tmp_1', 'reshape2_55.tmp_1', 'batch_norm_92.tmp_0', 'batch_norm_92.tmp_1', 'batch_norm_93.tmp_0', 'batch_norm_93.tmp_1', 'batch_norm_94.tmp_0', 'batch_norm_94.tmp_1', 'batch_norm_95.tmp_0', 'batch_norm_95.tmp_1', 'batch_norm_96.tmp_0', 'batch_norm_96.tmp_1', 'batch_norm_97.tmp_0', 'batch_norm_97.tmp_1', 'reshape2_56.tmp_1', 'transpose_50.tmp_1', 'reshape2_57.tmp_1', 'transpose_51.tmp_1', 'reshape2_58.tmp_1', 'layer_norm_26.tmp_0', 'layer_norm_26.tmp_1', 'reshape2_59.tmp_1', 'transpose_52.tmp_1', 'transpose_53.tmp_1', 'transpose_54.tmp_1', 'reshape2_60.tmp_1', 'dropout_22.tmp_1', 'layer_norm_27.tmp_0', 'layer_norm_27.tmp_1', 'dropout_23.tmp_1', 'layer_norm_28.tmp_0', 'layer_norm_28.tmp_1', 'reshape2_61.tmp_1', 'transpose_55.tmp_1', 'transpose_56.tmp_1', 'transpose_57.tmp_1', 'reshape2_62.tmp_1', 'dropout_24.tmp_1', 'layer_norm_29.tmp_0', 'layer_norm_29.tmp_1', 'dropout_25.tmp_1', 'layer_norm_30.tmp_0', 'layer_norm_30.tmp_1', 'reshape2_63.tmp_1', 'transpose_58.tmp_1', 'transpose_59.tmp_1', 'transpose_60.tmp_1', 'reshape2_64.tmp_1', 'dropout_26.tmp_1', 'layer_norm_31.tmp_0', 'layer_norm_31.tmp_1', 'dropout_27.tmp_1', 'layer_norm_32.tmp_0', 'layer_norm_32.tmp_1', 'reshape2_65.tmp_1', 'transpose_61.tmp_1', 'transpose_62.tmp_1', 'transpose_63.tmp_1', 'reshape2_66.tmp_1', 'dropout_28.tmp_1', 'layer_norm_33.tmp_0', 'layer_norm_33.tmp_1', 'dropout_29.tmp_1', 'layer_norm_34.tmp_0', 'layer_norm_34.tmp_1', 'reshape2_67.tmp_1', 'transpose_64.tmp_1', 'reshape2_68.tmp_1', 'transpose_65.tmp_1', 'reshape2_69.tmp_1', 'batch_norm_98.tmp_0', 'batch_norm_98.tmp_1', 'batch_norm_99.tmp_0', 'batch_norm_99.tmp_1', 'batch_norm_100.tmp_0', 'batch_norm_100.tmp_1', 'batch_norm_101.tmp_0', 'batch_norm_101.tmp_1', 'batch_norm_102.tmp_0', 'batch_norm_102.tmp_1', 'batch_norm_103.tmp_0', 'batch_norm_103.tmp_1', 'reshape2_70.tmp_1', 'transpose_66.tmp_1', 'reshape2_71.tmp_1', 'transpose_67.tmp_1', 'reshape2_72.tmp_1', 'layer_norm_35.tmp_0', 'layer_norm_35.tmp_1', 'reshape2_73.tmp_1', 'transpose_68.tmp_1', 'transpose_69.tmp_1', 'transpose_70.tmp_1', 'reshape2_74.tmp_1', 'dropout_30.tmp_1', 'layer_norm_36.tmp_0', 'layer_norm_36.tmp_1', 'dropout_31.tmp_1', 'layer_norm_37.tmp_0', 'layer_norm_37.tmp_1', 'reshape2_75.tmp_1', 'transpose_71.tmp_1', 'transpose_72.tmp_1', 'transpose_73.tmp_1', 'reshape2_76.tmp_1', 'dropout_32.tmp_1', 'layer_norm_38.tmp_0', 'layer_norm_38.tmp_1', 'dropout_33.tmp_1', 'layer_norm_39.tmp_0', 'layer_norm_39.tmp_1', 'reshape2_77.tmp_1', 'transpose_74.tmp_1', 'transpose_75.tmp_1', 'transpose_76.tmp_1', 'reshape2_78.tmp_1', 'dropout_34.tmp_1', 'layer_norm_40.tmp_0', 'layer_norm_40.tmp_1', 'dropout_35.tmp_1', 'layer_norm_41.tmp_0', 'layer_norm_41.tmp_1', 'reshape2_79.tmp_1', 'transpose_77.tmp_1', 'reshape2_80.tmp_1', 'transpose_78.tmp_1', 'reshape2_81.tmp_1', 'batch_norm_104.tmp_0', 'batch_norm_104.tmp_1', 'batch_norm_105.tmp_0', 'batch_norm_105.tmp_1', 'batch_norm_106.tmp_0', 'batch_norm_106.tmp_1', 'batch_norm_107.tmp_0', 'batch_norm_107.tmp_1', 'batch_norm_108.tmp_0', 'batch_norm_108.tmp_1', 'batch_norm_109.tmp_0', 'batch_norm_109.tmp_1', 'batch_norm_110.tmp_0', 'batch_norm_110.tmp_1', 'pool2d_6.tmp_1', 'pool2d_7.tmp_1', 'pool2d_8.tmp_1', 'batch_norm_111.tmp_0', 'batch_norm_111.tmp_1', 'batch_norm_112.tmp_0', 'batch_norm_112.tmp_1', 'batch_norm_113.tmp_0', 'batch_norm_113.tmp_1', 'batch_norm_114.tmp_0', 'batch_norm_114.tmp_1', 'batch_norm_115.tmp_0', 'batch_norm_115.tmp_1', 'batch_norm_116.tmp_0', 'batch_norm_116.tmp_1', 'batch_norm_117.tmp_0', 'batch_norm_117.tmp_1', 'batch_norm_118.tmp_0', 'batch_norm_118.tmp_1', 'batch_norm_119.tmp_0', 'batch_norm_119.tmp_1', 'batch_norm_120.tmp_0', 'batch_norm_120.tmp_1', 'batch_norm_121.tmp_0', 'batch_norm_121.tmp_1', 'batch_norm_122.tmp_0', 'batch_norm_122.tmp_1', 'batch_norm_123.tmp_0', 'batch_norm_123.tmp_1', 'batch_norm_124.tmp_0', 'batch_norm_124.tmp_1', 'batch_norm_125.tmp_0', 'batch_norm_125.tmp_1', 'batch_norm_126.tmp_0', 'batch_norm_126.tmp_1', 'batch_norm_127.tmp_0', 'batch_norm_127.tmp_1', 'batch_norm_128.tmp_0', 'batch_norm_128.tmp_1', 'batch_norm_129.tmp_0', 'batch_norm_129.tmp_1', 'batch_norm_130.tmp_0', 'batch_norm_130.tmp_1', 'batch_norm_131.tmp_0', 'batch_norm_131.tmp_1', 'batch_norm_132.tmp_0', 'batch_norm_132.tmp_1', 'batch_norm_133.tmp_0', 'batch_norm_133.tmp_1', 'batch_norm_134.tmp_0', 'batch_norm_134.tmp_1', 'batch_norm_135.tmp_0', 'batch_norm_135.tmp_1', 'batch_norm_136.tmp_0', 'batch_norm_136.tmp_1', 'batch_norm_137.tmp_0', 'batch_norm_137.tmp_1', 'batch_norm_138.tmp_0', 'batch_norm_138.tmp_1', 'batch_norm_139.tmp_0', 'batch_norm_139.tmp_1', 'batch_norm_140.tmp_0', 'batch_norm_140.tmp_1', 'shape_6.tmp_0_slice_0', 'shape_6.tmp_0_slice_1', 'reshape2_82.tmp_1', 'tmp_166', 'shape_7.tmp_0_slice_0', 'shape_7.tmp_0_slice_1', 'reshape2_83.tmp_1', 'tmp_174', 'shape_8.tmp_0_slice_0', 'shape_8.tmp_0_slice_1', 'reshape2_84.tmp_1', 'tmp_182', 'concat_37.tmp_0', 'shape_9.tmp_0_slice_1', 'batch_norm_141.tmp_0', 'batch_norm_141.tmp_1', 'batch_norm_142.tmp_0', 'batch_norm_142.tmp_1', 'batch_norm_143.tmp_0', 'batch_norm_143.tmp_1', 'reshape2_85.tmp_1', 'reshape2_86.tmp_1', 'shape_10.tmp_0_slice_1', 'batch_norm_144.tmp_0', 'batch_norm_144.tmp_1', 'batch_norm_145.tmp_0', 'batch_norm_145.tmp_1', 'batch_norm_146.tmp_0', 'batch_norm_146.tmp_1', 'reshape2_87.tmp_1', 'reshape2_88.tmp_1', 'shape_11.tmp_0_slice_1', 'batch_norm_147.tmp_0', 'batch_norm_147.tmp_1', 'batch_norm_148.tmp_0', 'batch_norm_148.tmp_1', 'batch_norm_149.tmp_0', 'batch_norm_149.tmp_1', 'reshape2_89.tmp_1', 'reshape2_90.tmp_1', 'transpose_79.tmp_1', 'reshape2_91.tmp_1', 'multiclass_nms3_1.tmp_0', 'multiclass_nms3_1.tmp_1', 'multiclass_nms3_1.tmp_2'] will be skipped when parsing graph.\r\n2023-06-10 16:31:32,172-WARNING: Couldn't find relative variables of conv2d_34.w_0 because conv2d_34.w_0 is not in target program or model. Please make sure conv2d_34.w_0 is in your program if you are using static API of PaddlePaddle. And make sure your model in correct mode and contains conv2d_34.w_0 if you are using dynamic API of PaddlePaddle.\r\nTraceback (most recent call last):\r\n  File \"D:/DeepLearning/DeepLearning_project/PaddleDetection-release/test01.py\", line 110, in <module>\r\n    pruner = L1NormFilterPruner(trainer.model, input_spec)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\dygraph\\prune\\l1norm_pruner.py\", line 18, in __init__\r\n    model, inputs, sen_file=sen_file, opt=opt, skip_leaves=skip_leaves)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\dygraph\\prune\\filter_pruner.py\", line 68, in __init__\r\n    model, inputs, skip_leaves=self.skip_leaves)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\dygraph\\prune\\var_group.py\", line 33, in __init__\r\n    params, graph, skip_leaves=skip_leaves)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\collections.py\", line 220, in create_pruning_collections\r\n    worker.prune(param, pruned_axis=0, pruned_idx=[])\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 94, in prune\r\n    self._prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 208, in _prune\r\n    self._visit_and_search(output_var, channel_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 117, in _visit_and_search\r\n    self._prune_op(op, var, axis, transforms)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 147, in _prune_op\r\n    worker.prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 94, in prune\r\n    self._prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 286, in _prune\r\n    self._visit_and_search(out_var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 117, in _visit_and_search\r\n    self._prune_op(op, var, axis, transforms)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 147, in _prune_op\r\n    worker.prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 94, in prune\r\n    self._prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 336, in _prune\r\n    self._visit_and_search(in_var, y_pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 114, in _visit_and_search\r\n    self._prune_op(op, var, axis, transforms)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 147, in _prune_op\r\n    worker.prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 94, in prune\r\n    self._prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 321, in _prune\r\n    self._visit_and_search(in_var, actual_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 114, in _visit_and_search\r\n    self._prune_op(op, var, axis, transforms)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 147, in _prune_op\r\n    worker.prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 94, in prune\r\n    self._prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 278, in _prune\r\n    self._visit_and_search(in_var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 114, in _visit_and_search\r\n    self._prune_op(op, var, axis, transforms)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 147, in _prune_op\r\n    worker.prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 94, in prune\r\n    self._prune(var, pruned_axis, pruned_idx)\r\n  File \"D:\\DeepLearning\\Anaconda3\\envs\\PaddleDetection\\lib\\site-packages\\paddleslim\\prune\\prune_worker.py\", line 215, in _prune\r\n    pruned_axis, var.name(), channel_axis)\r\nAssertionError: pruned_axis: 4; var: conv2d_117.tmp_0 channel_axis: 1\r\n\r\n进程已结束,退出代码1\r\n模型中有深度可分离卷积和正常卷积",
        "state": "closed",
        "user": "shangshanruowo",
        "closed_by": "shangshanruowo",
        "created_at": "2023-06-10T08:39:19+00:00",
        "updated_at": "2024-03-04T02:45:28+00:00",
        "closed_at": "2024-03-04T02:45:28+00:00",
        "comments_count": [
            "minghaoBD",
            "shangshanruowo"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1772
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1762,
        "title": "关于Yolov5s 的qat量化问题。",
        "body": "官方这边有如何进行量化的方式吗，我使用paddledetection套件+paddleslim套件一起，量化失败，",
        "state": "closed",
        "user": "sg-goldrush",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-06-11T02:11:11+00:00",
        "updated_at": "2025-02-18T06:41:54+00:00",
        "closed_at": "2025-02-18T06:41:54+00:00",
        "comments_count": [
            "sg-goldrush",
            "lizexu123",
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1767,
        "title": "动态图QAT如何指定部分层不量化？",
        "body": "paddleslim.QAT()\r\n我注意到\r\n[paddle/quantization/imperative/qat.py](https://github.com/PaddlePaddle/Paddle/blob/1b8a1a982845ffef44679f79da363a8e7f3b20ba/python/paddle/quantization/imperative/qat.py#LL181C1-L182C1)中有`self.linear_0.skip_quant = True`，\r\nQ1：在模型定义时在某一层（如self.conv1）设定了 `self.conv1.skip_quant=True`，如何检查该层确实没有被量化？\r\nQ2：有办法不在模型定义中，而是通过config接口指定哪些层不量化吗？",
        "state": "closed",
        "user": "WeixiangXu",
        "closed_by": "WeixiangXu",
        "created_at": "2023-06-22T14:56:28+00:00",
        "updated_at": "2024-02-29T02:50:27+00:00",
        "closed_at": "2024-02-29T02:50:27+00:00",
        "comments_count": [
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1766,
        "title": "[Paddle2ONNX] Oops, there are some operators not supported yet",
        "body": "运行如下代码报错了：[Paddle2ONNX] Oops, there are some operators not supported yet，including fake_channel_wise_quantize_dequantize_abs_max,fake_quantize_dequantize_moving_average_abs_max,\r\n\r\n```python\r\nimport fastdeploy as fd\r\nimport os\r\nimport cv2\r\nimport time\r\noption = fd.RuntimeOption()\r\n#option.use_openvino_backend()\r\noption.use_ort_backend()\r\n#option.use_paddle_infer_backend()\r\n#option.use_trt_backend()\r\n#option.set_trt_cache_file(os.path.join(\"ppyoloe_crn_l_300e_coco_qat\", \"model.trt\"))\r\n#option.set_trt_input_shape(\"image\", min_shape=[1, 3, 640, 640])\r\n#option.set_trt_input_shape(\"scale_factor\", min_shape=[1, 2])\r\nmodel_file = os.path.join(\"ppyoloe_l_qat\", \"model.pdmodel\")\r\nparams_file = os.path.join(\"ppyoloe_l_qat\", \"model.pdiparams\")\r\nconfig_file = os.path.join(\"ppyoloe_l_qat\", \"infer_cfg.yml\")\r\nmodel = fd.vision.detection.PPYOLOE( model_file, params_file, config_file, runtime_option=option)\r\n\r\n```\r\n\r\nppyoloe_l_qat里面的模型是通过如下生成的，我将model、params分别重命名为model.pdmodel、model.pdiparams, infer_cfg.yml是从训练的文件拷贝出来的。再用上述方式推理报了文章开头的错：\r\n```python\r\nfrom paddlelite.lite import *\r\n# 1. 创建opt实例\r\nopt=Opt()\r\n# 2. 指定输入模型地址 \r\nopt.set_model_dir(\"/data/ai/xc/PaddleDetection-release-2.6/output_inference/ppyoloe_l_qat\")\r\n# 3. 指定转化类型： arm、x86、opencl、npu\r\nopt.set_valid_places(\"x86\")\r\n# 4. 指定模型转化类型： naive_buffer、protobuf\r\nopt.set_model_type(\"protobuf\")\r\n# 4. 输出模型地址\r\nopt.set_optimize_out(\"/data/ai/xc/PaddleDetection-release-2.6/output_inference/ppyoloe_l_qat_paddlelite/ppyoloe_l_qat_paddlelite\")\r\n# 5. 执行模型优化\r\nopt.run()\r\n```\r\n训练和导出代码如下：\r\n```python\r\n\r\npython tools/train.py -c configs/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml \\\r\n--use_vdl=true \\\r\n--vdl_log_dir=vdl_dir/scalar5  \\\r\n--slim_config configs/slim/quant/ppyoloe_l_qat.yml  \\\r\n--eval\r\n\r\npython tools/export_model.py \\\r\n-c configs/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml  \\\r\n--slim_config configs/slim/quant/ppyoloe_l_qat.yml \\\r\n-o weights=output/ppyoloe_l_qat/model_final\r\n\r\n\r\n```\r\n\r\n\r\n环境如下：\r\n```bash\r\npip list | grep paddle\r\npaddle-bfloat           0.1.7\r\npaddle2onnx             1.0.6\r\npaddlefsl               1.1.0\r\npaddlenlp               2.4.9\r\npaddlepaddle-gpu        2.4.1.post112\r\npaddleslim              2.4.1\r\nx2paddle                1.4.0\r\n```\r\n\r\n求破，在线等，急。",
        "state": "closed",
        "user": "aixuedegege",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-06-21T11:48:43+00:00",
        "updated_at": "2025-02-11T06:42:18+00:00",
        "closed_at": "2025-02-11T06:41:46+00:00",
        "comments_count": [
            "Wst-sd",
            "aixuedegege",
            "Wst-sd",
            "PlumBlossomMaid",
            "Wst-sd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1773,
        "title": "自动压缩模型run.py报错",
        "body": "数据集为voc格式，在运行run.py文件时报错\r\n\r\n\r\n报错信息：\r\n-------data.items()----------\r\ndict_items([('im_id', <paddle.fluid.libpaddle.Tensor object at 0x7feabc5bec30>), ('gt_class', [<paddle.fluid.libpaddle.Tensor object at 0x7feaa459e1f0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459e0f0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459dfb0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459deb0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459ddb0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459dcb0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459dbb0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459dab0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459d9b0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459d8b0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459d7b0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459d6b0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459d5b0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459d4b0>, <paddle.fluid.libpaddle.Tensor object at 0x7feaa459d3b0>, <paddle.fluid.libpaddle.Tensor obje\r\n-------type(data.items())----------\r\n<class 'dict_items'>\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'paddle.fluid.libpaddle.Tensor'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 202, in <module>\r\n    main()\r\n  File \"run.py\", line 192, in main\r\n    ac.compress()\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 594, in compress\r\n    train_config)\r\n  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 754, in single_strategy_compress\r\n    feed_target_names, fetch_targets)\r\n  File \"run.py\", line 89, in eval_function\r\n    data_all = convert_numpy_data(data, metric)\r\n  File \"run.py\", line 73, in convert_numpy_data\r\n    data_all = {k: np.array(v) for k, v in data.items()}\r\n  File \"run.py\", line 73, in <dictcomp>\r\n    data_all = {k: np.array(v) for k, v in data.items()}\r\nValueError: setting an array element with a sequence.\r\n",
        "state": "closed",
        "user": "InternetNoMemory",
        "closed_by": "InternetNoMemory",
        "created_at": "2023-07-04T06:43:37+00:00",
        "updated_at": "2023-07-04T08:31:54+00:00",
        "closed_at": "2023-07-04T08:31:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1768,
        "title": "uie-x支持",
        "body": "slim支持uie-x以及uie-x finetune后的模型吗？",
        "state": "closed",
        "user": "heyuqi1970",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-06-24T15:14:55+00:00",
        "updated_at": "2025-02-11T06:41:47+00:00",
        "closed_at": "2025-02-11T06:41:47+00:00",
        "comments_count": [
            "aixuedegege",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1774,
        "title": "mobilenet-v2结构per-channel定点在matmul_v2层报错",
        "body": "我使用pytorch导出的mbv2 onnx模型转为静态paddle图再进行后训练量化。量化模型可以正确生成，但运行报错：RuntimeError: (PreconditionNotMet) The number of first scale values must be the same with corresponding dimension value of Input(X) when the `Scales` has two elements, but 1280 != 1000 here.\r\n  [Hint: Expected scales[0]->numel() == in->dims()[x_num_col_dims], but received scales[0]->numel():1280 != in->dims()[x_num_col_dims]:1000.]\r\n\r\n若设置quant_post_static函数中的is_full_quantize为False并设置quantizable_op_type为[\"conv2d\", \"depthwise_conv2d\", \"mul\",\"elementwise_add\",\"pool2d\"]，则不会出现该错误。请问是matmul_v2这个算子不支持per-channel定点吗？",
        "state": "closed",
        "user": "GtxMiracle",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-07-06T13:15:24+00:00",
        "updated_at": "2025-02-11T06:41:47+00:00",
        "closed_at": "2025-02-11T06:41:47+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1780,
        "title": "ValueError: (InvalidArgument) Unsupported data type of Scale and Bias",
        "body": "用最新的paddlenlp 的develop代码，在llm/bloom/里 跑run_eval.py 自动下载的模型跑时会报错：\r\n![44ce9f86235ec73aaac69e59a06f819e](https://github.com/PaddlePaddle/PaddleSlim/assets/49263480/c627254e-7afa-4024-80f1-de56da838df3)\r\n",
        "state": "closed",
        "user": "xiaoluomi",
        "closed_by": "xiaoluomi",
        "created_at": "2023-08-08T10:54:24+00:00",
        "updated_at": "2023-08-08T10:54:35+00:00",
        "closed_at": "2023-08-08T10:54:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1788
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1775,
        "title": "是否支持fp16的QAT训练",
        "body": "是否支持fp16的QAT训练，如何修改配置文件",
        "state": "closed",
        "user": "kamiLight",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-07-10T07:27:08+00:00",
        "updated_at": "2025-02-11T06:41:48+00:00",
        "closed_at": "2025-02-11T06:41:48+00:00",
        "comments_count": [
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1776,
        "title": "UIE-X模型压缩和蒸馏",
        "body": "可以使用UIE-X对模型进行压缩和蒸馏？",
        "state": "closed",
        "user": "tianchiguaixia",
        "closed_by": "ceci3",
        "created_at": "2023-07-12T09:14:14+00:00",
        "updated_at": "2024-02-06T05:56:43+00:00",
        "closed_at": "2024-02-06T05:56:43+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1777,
        "title": "序列标注模型蒸馏问题",
        "body": "1、crf的模型蒸馏该怎么写？看文心序列标注的蒸馏，主要是fc进行softmax，但crf模型fc后面加了一个crf decode，这种情况也是对teacher模型的fc进行softmax么\r\n2、模型蒸馏step1是直接看loss么，选择loss较低的模型就行？\r\n3、目前随机选择了一个step1 loss较低的，然后进行step2蒸馏，最终模型比teacher模型f1少了0.1+（teacher：0.910143，student：0.77），这种情况正常么？比较怀疑是蒸馏loss写得不正确\r\n4、直接用蒸馏的模型热启，进行finetune，效果和模型蒸馏差不多甚至更好。是不是模型蒸馏写得不对导致的？\r\n模型蒸馏相关代码\r\n\r\nteacher_logits/student_logits = fluid.layers.fc(\r\n            size=self._flags.num_out_dimension,\r\n            input=input_feature,\r\n            param_attr=fluid.ParamAttr(\r\n                name=ernie_model._name+'fc_1',\r\n                initializer=fluid.initializer.Uniform(\r\n                    low=-init_bound, high=init_bound),\r\n                regularizer=fluid.regularizer.L2DecayRegularizer(\r\n                    regularization_coeff=1e-4)))\r\n\r\nteacher_pred = fluid.layers.crf_decoding(\r\n            input=teacher_logits, param_attr=fluid.ParamAttr(name='crfw'))\r\n## pred_loss\r\npred_loss = fluid.layers.mean(\r\n                fluid.layers.linear_chain_crf(\r\n                    input=student_logits,\r\n                    label=teacher_pred,\r\n                    param_attr=fluid.ParamAttr(\r\n                        name='crfw',\r\n                        learning_rate=crf_lr)))\r\n## teacher predict loss\r\nteacher_ce_loss = fluid.layers.mean(\r\n                fluid.layers.linear_chain_crf(\r\n                    input=teacher_logits,\r\n                    label=unpad_labels,\r\n                    param_attr=fluid.ParamAttr(\r\n                        name='crfw',\r\n                        learning_rate=crf_lr)))\r\n ## student predict loss\r\n student_ce_loss = fluid.layers.mean(\r\n            fluid.layers.linear_chain_crf(\r\n                input=student_logits,\r\n                label=unpad_labels,\r\n                param_attr=fluid.ParamAttr(\r\n                    name='crfw',\r\n                    learning_rate=crf_lr)))",
        "state": "closed",
        "user": "OliveLv",
        "closed_by": "ceci3",
        "created_at": "2023-07-25T03:29:08+00:00",
        "updated_at": "2024-02-06T05:55:51+00:00",
        "closed_at": "2024-02-06T05:55:51+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1781,
        "title": "PP-OCRV4 det自动压缩报错",
        "body": "单卡报错\r\n![image](https://github.com/PaddlePaddle/PaddleSlim/assets/12406017/2ca75957-1e4c-4162-acb5-2bd355ee24bb)\r\n\r\n多卡报错\r\n![image](https://github.com/PaddlePaddle/PaddleSlim/assets/12406017/a4fee74c-d940-4b48-8dfb-1fd85e8affd4)\r\n\r\n已经确认paddle2.4.2 在机器上单卡多卡均无问题\r\n配置文件为用v4 student的dataset部分替换example/auto_compression/ocr/configs/ppocrv3_rec_qat_dist.yaml中的数据部分",
        "state": "closed",
        "user": "WenmuZhou",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-08-11T10:26:12+00:00",
        "updated_at": "2025-02-11T06:41:49+00:00",
        "closed_at": "2025-02-11T06:41:49+00:00",
        "comments_count": [
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1784,
        "title": "量化感知训练以后如何只保留原始模型权重",
        "body": "寒武纪量化工具产生的模型精度较低，想要使用QAT对模型参数进行微调，然后导出模型时只保留原始模型结构及参数，不需要伪量化节点和量化参数，有寒武纪工具自行量化，如何操作",
        "state": "closed",
        "user": "marsbzp",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-08-16T05:40:31+00:00",
        "updated_at": "2025-02-11T06:41:50+00:00",
        "closed_at": "2025-02-11T06:41:50+00:00",
        "comments_count": [
            "SpectrePrediction"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1787,
        "title": "使用Cascade RCNN模型无法进行量化",
        "body": "![image](https://github.com/PaddlePaddle/PaddleSlim/assets/66475164/b945c57d-d5b1-41fe-8813-37b08228477a)\r\n",
        "state": "closed",
        "user": "lrp123456",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-08-17T09:09:19+00:00",
        "updated_at": "2025-02-11T06:41:50+00:00",
        "closed_at": "2025-02-11T06:41:50+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1799,
        "title": "请问PaddleSlim中自研PTQ的流程是怎样的？",
        "body": "- https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/tutorials/quant/advanced_quantization.md\r\n\r\n\r\n\r\n",
        "state": "closed",
        "user": "liguodongiot",
        "closed_by": "liguodongiot",
        "created_at": "2023-10-19T09:39:41+00:00",
        "updated_at": "2023-10-19T09:42:41+00:00",
        "closed_at": "2023-10-19T09:42:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1789,
        "title": "'SchemaDict' object has no attribute 'check_or_download_dataset'",
        "body": "l\r\n执行paddleslim/example/full_quantization/picodet/run.py,出现这个对象SchemaDict没有定义'check_or_download_dataset这个属性的错误，请教下这个是什么问题？我这边按照最新版本装的paddlepaddle-gpu:\r\npython -m pip install paddlepaddle-gpu==2.5.1.post102 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\r\npaddleslim版本为2.4.1PaddleDetection版本为2.6\r\n\r\n\r\niuxj@liuxj-desktop:~/fallai/paddleslim/example/full_quantization/picodet$ python run.py --config_path=./configs/picodet_npu_with_postprocess.yaml --save_dir='./output/'\r\nWarning: Unable to use JDE/FairMOT/ByteTrack, please install lap, for example: `pip install lap`, see https://github.com/gatagat/lap\r\n-----------  Running Arguments -----------\r\n Distillation:\r\n\t alpha: 1.0\r\n\t loss: l2\r\n Global:\r\n\t Evaluation: True\r\n\t include_post_process: True\r\n\t input_list: ['image', 'scale_factor']\r\n\t model_dir: ./picodet_s_416_voc_npu\r\n\t model_filename: model.pdmodel\r\n\t params_filename: model.pdiparams\r\n\t reader_config: ./configs/voc_detection.yml\r\n PTQ:\r\n\t activation_quantize_type: moving_average_abs_max\r\n\t algo: avg\r\n\t batch_nums: 10\r\n\t batch_size: 32\r\n\t onnx_format: False\r\n\t quantizable_op_type: ['conv2d', 'depthwise_conv2d']\r\n QuantAware:\r\n\t activation_bits: 8\r\n\t activation_quantize_type: moving_average_abs_max\r\n\t quantize_op_types: ['conv2d', 'depthwise_conv2d']\r\n\t use_pact: True\r\n\t weight_bits: 8\r\n TrainConfig:\r\n\t eval_iter: 1000\r\n\t learning_rate:\r\n\t\t T_max: 8000\r\n\t\t learning_rate: 1e-05\r\n\t\t type: CosineAnnealingDecay\r\n\t optimizer_builder:\r\n\t\t optimizer:\r\n\t\t\t type: SGD\r\n\t\t weight_decay: 4e-05\r\n\t train_iter: 8000\r\n------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 170, in <module>\r\n    main()\r\n  File \"run.py\", line 126, in main\r\n    train_loader = create('TrainReader')(reader_cfg['TrainDataset'],\r\n  File \"/usr/local/lib/python3.8/dist-packages/paddledet-2.6.0-py3.8.egg/ppdet/data/reader.py\", line 167, in __call__\r\n    self.dataset.check_or_download_dataset()\r\nAttributeError: 'SchemaDict' object has no attribute 'check_or_download_dataset'\r\n\r\n各位大侠帮忙看看是什么原因？",
        "state": "closed",
        "user": "liuxinglau",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-08-20T15:43:00+00:00",
        "updated_at": "2025-02-11T06:41:51+00:00",
        "closed_at": "2025-02-11T06:41:51+00:00",
        "comments_count": [
            "pcycccccc",
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1797,
        "title": "paddslim在python3.11下无法使用",
        "body": "1.python3.11只支持pip install paddlepaddle==2.5.1\r\n2.paddleslim最高版本是2.4.1\r\n3.在上述情况下，使用 import paddleslim会出错，如下：\r\n\r\n===============================================================================\r\n发生异常: ImportError\r\ncannot import name 'MSRA' from 'paddle.fluid.initializer' (/home/zhijh/miniconda3/envs/paddleslim311/lib/python3.11/site-packages/paddle/fluid/initializer.py)\r\n  File \"/home/zhijh/Projects/PaddleSlim/quant.py\", line 2, in <module>\r\n    import paddleslim as slim\r\nImportError: cannot import name 'MSRA' from 'paddle.fluid.initializer' (/home/zhijh/miniconda3/envs/paddleslim311/lib/python3.11/site-packages/paddle/fluid/initializer.py)",
        "state": "closed",
        "user": "JiaheZhi",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-09-25T01:40:50+00:00",
        "updated_at": "2025-02-11T06:41:54+00:00",
        "closed_at": "2025-02-11T06:41:54+00:00",
        "comments_count": [
            "yrqs",
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1795,
        "title": "ValueError: Incorrect setting for output(s) of operator \"unsqueeze2\", should set: [XShape].",
        "body": "ValueError: Incorrect setting for output(s) of operator \"unsqueeze2\", should set: [XShape]. 跑yolov6s ACT自动蒸馏量化用自己的数据集，output8个类别的权重转成onnx，数据集配置成类似COCO文件格式跑的，出现这个报错什么问题？\r\n\r\n\r\n\r\nyolov6s_v2_qat_dis.yaml里面是这样设置的：\r\n\r\n  model_dir: ./weights/best_ckpt.onnx\r\n  image_path: None   # If image_path is set, it will be trained directly based on unlabeled images, no need to set the COCO dataset path.\r\n  coco_dataset_dir: /PaddleSlim/dataset/output/\r\n  coco_train_image_dir: /PaddleSlim/dataset/output/images/train\r\n  coco_train_anno_path: /PaddleSlim/dataset/output/annotations/instances_train2017.json\r\n  coco_val_image_dir: /PaddleSlim/dataset/output/images/val\r\n  coco_val_anno_path: /PaddleSlim/dataset/output/annotations/instances_val2017.json\r\n\r\n\r\n\r\n具体报错信息如下：\r\n------------------------------------------\r\nloading annotations into memory...\r\nDone (t=1.31s)\r\ncreating index...\r\nindex created!\r\nloading annotations into memory...\r\nDone (t=0.11s)\r\ncreating index...\r\nindex created!\r\n2023-09-05 03:53:17,517-INFO: Loaded model from: ./weights/best_ckpt_infer\r\nW0905 03:53:17.518724 17334 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.2\r\nW0905 03:53:17.523062 17334 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\r\n2023-09-05 03:53:18,756-INFO: devices: gpu\r\n2023-09-05 03:53:21,163-INFO: Loaded model from: ./weights/best_ckpt_infer\r\n2023-09-05 03:53:25,687-INFO: Loaded model from: ./weights/best_ckpt_infer\r\n2023-09-05 03:53:25,691-INFO: Selected strategies: ['qat_dis']\r\n2023-09-05 03:53:28,010-INFO: Loaded model from: ./weights/best_ckpt_infer\r\n2023-09-05 03:53:30,340-INFO: Loaded model from: ./weights/best_ckpt_infer\r\n2023-09-05 03:53:32,443-INFO: Loaded model from: ./weights/best_ckpt_infer\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 148, in <module>\r\n    main()\r\n  File \"run.py\", line 136, in main\r\n    ac.compress()\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 594, in compress\r\n    train_config)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 771, in single_strategy_compress\r\n    strategy, config, train_config)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleslim/auto_compression/compressor.py\", line 517, in _prepare_program\r\n    default_distill_node_pair=self.default_distill_node_pair)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleslim/auto_compression/create_compressed_program.py\", line 273, in build_distill_program\r\n    feed_target_names=feed_target_names)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleslim/auto_compression/create_compressed_program.py\", line 197, in _load_program_and_merge\r\n    merge_feed=merge_feed)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddleslim/dist/single_distiller.py\", line 103, in merge\r\n    type=op.type, inputs=inputs, outputs=outputs, attrs=attrs)\r\n  File \"/usr/local/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 4023, in append_op\r\n    attrs=kwargs.get(\"attrs\", None),\r\n  File \"/usr/local/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2953, in __init__\r\n    % (type, m.name)\r\nValueError: Incorrect setting for output(s) of operator \"unsqueeze2\", should set: [XShape].",
        "state": "closed",
        "user": "NutshellLee",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-09-05T04:00:13+00:00",
        "updated_at": "2025-02-11T06:41:52+00:00",
        "closed_at": "2025-02-11T06:41:52+00:00",
        "comments_count": [
            "ceci3",
            "lizexu123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1796,
        "title": "GroundingDINO量化报错没注册ms_deformable_attn",
        "body": "你好，我在尝试用PaddleSlim对PaddleMix中的GroundingDINO进行量化，发现如下报错：\r\nRuntimeError: (NotFound) Operator (ms_deformable_attn) is not registered.\r\n[Hint: op_info_ptr should not be null.] (at ../paddle/fluid/framework/op_info.h:151)\r\n\r\n请问这个可以解决吗？还是说不支持含ms_deformable_attn这种特殊算子的模型？",
        "state": "closed",
        "user": "yrqs",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-09-21T06:48:41+00:00",
        "updated_at": "2025-02-11T06:41:53+00:00",
        "closed_at": "2025-02-11T06:41:53+00:00",
        "comments_count": [
            "CheckGuest",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1798,
        "title": "自动量化报错[operator < elementwise_sub > error]",
        "body": "在PaddlePaddle2.5 PaddleSlim dev版本进行自动量化训练，启动的时候报错：NotFoundError: The kernel (elementwise_sub) with key (GPU, Undefined(AnyLayout), uint8) is not found and GPU kernel cannot fallback to CPU one. (at ../paddle/fluid/framework/phi_utils.cc:144)",
        "state": "closed",
        "user": "kongdebug",
        "closed_by": "kongdebug",
        "created_at": "2023-10-03T08:45:05+00:00",
        "updated_at": "2024-02-13T04:03:54+00:00",
        "closed_at": "2024-02-13T04:03:54+00:00",
        "comments_count": [
            "ceci3",
            "kongdebug"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1803,
        "title": "paddle_inference_eval验证性能，int8和fp32精度差距很大",
        "body": "压缩好的 bert mrpc模型，使用paddle_inference_eval验证性能，发现int8和fp32精度差距很大\r\n--precision=fp32 84\r\n--precision=fp16 84\r\n--precision=int8  61",
        "state": "closed",
        "user": "oydf",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-11-08T07:32:49+00:00",
        "updated_at": "2025-02-11T06:41:56+00:00",
        "closed_at": "2025-02-11T06:41:56+00:00",
        "comments_count": [
            "ceci3",
            "lizexu123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1804,
        "title": "请问paddleslim可以对kie推理模型进行裁剪吗？",
        "body": "kie的两个模型加起来有2G，可以使用paddleslim轻量化吗？如何解决下述报错：\r\n\r\n我参考：[地址](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/infer/paddleslim/paddle_slim_cn.html)\r\n\r\n然后报错：\r\n`(paddleocr) root@DESKTOP-VSUROIT:/home/huang/paddle-ocr-gpu# python core_code/paddle_slim_kie.py\r\n/root/miniconda3/envs/paddleocr/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nI1108 16:21:45.052196 580245 interpretercore.cc:237] New Executor is Running.\r\nW1108 16:21:45.303526 580245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.2, Runtime API Version: 11.8\r\nW1108 16:21:45.304080 580245 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\r\n2023-11-08 16:21:51,999-INFO: devices: gpu\r\n2023-11-08 16:21:58,532-INFO: Selected strategies: []\r\nTraceback (most recent call last):\r\n  File \"/home/huang/paddle-ocr-gpu/core_code/paddle_slim_kie.py\", line 54, in <module>\r\n    ac.compress()\r\n  File \"/root/miniconda3/envs/paddleocr/lib/python3.9/site-packages/paddleslim-0.0.0.dev0-py3.9.egg/paddleslim/auto_compression/compressor.py\", line 577, in compress\r\nAssertionError\r\n`\r\n\r\n我的list如下\r\n![image](https://github.com/PaddlePaddle/PaddleSlim/assets/56833624/69e07796-a585-4011-823e-4248e6b170cf)\r\n\r\n\r\n我的代码如下：\r\nimport paddle\r\nfrom PIL import Image\r\nfrom paddle.vision.datasets import DatasetFolder\r\nfrom paddle.vision.transforms import transforms\r\nfrom paddleslim.auto_compression import AutoCompression\r\n\r\npaddle.enable_static()\r\n\r\nclass ImageNetDataset(DatasetFolder):\r\n    def __init__(self, path, image_size=224):\r\n        super().__init__(path)\r\n        normalize = transforms.Normalize(\r\n            mean=[123.675, 116.28, 103.53], std=[58.395, 57.120, 57.375])\r\n        self.transform = transforms.Compose([\r\n            transforms.Resize(256),\r\n            transforms.CenterCrop(image_size), transforms.Transpose(),\r\n            normalize\r\n        ])\r\n\r\n    def __getitem__(self, idx):\r\n        img_path, _ = self.samples[idx]\r\n        return self.transform(Image.open(img_path).convert('RGB'))\r\n\r\n    def __len__(self):\r\n        return len(self.samples)\r\n\r\ntrain_dataset = ImageNetDataset(\"./train_data/XFUND/zh_train/\")\r\nimage = paddle.static.data(\r\n    name='inputs', shape=[None] + [3, 224, 224], dtype='float32')\r\ntrain_loader = paddle.io.DataLoader(train_dataset, feed_list=[image], batch_size=32, return_list=False)\r\n\r\nac = AutoCompression(\r\n    model_dir=\"./inference/ser_vi_layoutxlm_xfund_infer\",\r\n    model_filename=\"inference.pdmodel\",\r\n    params_filename=\"inference.pdiparams\",\r\n    save_dir=\"./slim_xfund_infer\",\r\n    config={'Quantization': {}, \"HyperParameterOptimization\": {'ptq_algo': ['avg'], 'max_quant_count': 3}},\r\n    train_dataloader=train_loader,\r\n    eval_dataloader=train_loader)\r\nac.compress()",
        "state": "closed",
        "user": "hzlirz",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-11-08T09:00:53+00:00",
        "updated_at": "2025-02-18T06:41:54+00:00",
        "closed_at": "2025-02-18T06:41:54+00:00",
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1801,
        "title": "yolov5使用PaddleSlim/example/auto_compression/pytorch_yolo_series/run.py报错",
        "body": "\r\n![微信图片编辑_20231102171024](https://github.com/PaddlePaddle/PaddleSlim/assets/44639000/b6983540-b2c6-41e1-b91c-947369177391)\r\n![微信图片编辑_20231102171030](https://github.com/PaddlePaddle/PaddleSlim/assets/44639000/f85401de-74de-48dc-9c66-ab04472498ef)\r\n\r\n我搜索了相关问题，但是没有得到回答，\r\n我使用paddleyolo训练了yolov5的模型，随后打算用paddleslim进行自动压缩，在成功加载网络后，得到了如图的报错，请问该如何修改代码，使用的是develop版本的paddleslim",
        "state": "closed",
        "user": "ianWeichengZhang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-11-02T09:11:01+00:00",
        "updated_at": "2025-02-11T06:41:55+00:00",
        "closed_at": "2025-02-11T06:41:55+00:00",
        "comments_count": [
            "mufeng12399",
            "GDbbq",
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1807,
        "title": "No default configuration file found at repository's root",
        "body": "https://readthedocs.org/projects/paddleslim/builds/22572627/\r\n\r\nNo default configuration file found at repository's root\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSlim/assets/4617245/360ed3ea-c703-4301-9dfa-49e39d226f20)\r\n",
        "state": "closed",
        "user": "co63oc",
        "closed_by": "co63oc",
        "created_at": "2023-11-16T13:00:51+00:00",
        "updated_at": "2024-12-12T01:58:28+00:00",
        "closed_at": "2024-12-12T01:58:28+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1808,
        "title": "使用paddleslim的模型自动化压缩工具ACT报错",
        "body": "按照paddleslim/example/auto_compression的Readme.md进行操作，运行运行自动化压缩时报错：\r\n```\r\n\r\nTraceback (most recent call last):\r\n  File \"/aidata/CYHan/auto_compass.py\", line 42, in <module>\r\n    ac.compress()\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/paddleslim/auto_compression/compressor.py\", line 593, in compress\r\n    self.single_strategy_compress(strategy, config, strategy_idx,\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/paddleslim/auto_compression/compressor.py\", line 715, in single_strategy_compress\r\n    post_quant_hpo.quant_post_hpo(\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/paddleslim/quant/post_quant_hpo.py\", line 425, in quant_post_hpo\r\n    from smac.configspace import ConfigurationSpace\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/smac/__init__.py\", line 27, in <module>\r\n    from smac.facade import (\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/smac/facade/__init__.py\", line 1, in <module>\r\n    from smac.facade.abstract_facade import AbstractFacade\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/smac/facade/abstract_facade.py\", line 10, in <module>\r\n    from dask.distributed import Client\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/dask/distributed.py\", line 13, in <module>\r\n    from distributed import *\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/distributed/__init__.py\", line 23, in <module>\r\n    from distributed.actor import Actor, ActorFuture, BaseActorFuture\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/distributed/actor.py\", line 13, in <module>\r\n    from distributed.client import Future\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/distributed/client.py\", line 117, in <module>\r\n    from distributed.worker import get_client, get_worker, secede\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/distributed/worker.py\", line 120, in <module>\r\n    from distributed.worker_memory import (\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/site-packages/distributed/worker_memory.py\", line 56, in <module>\r\n    WorkerDataParameter: TypeAlias = Union[\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/typing.py\", line 243, in inner\r\n    return func(*args, **kwds)\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/typing.py\", line 316, in __getitem__\r\n    return self._getitem(self, parameters)\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/typing.py\", line 421, in Union\r\n    parameters = _remove_dups_flatten(parameters)\r\n  File \"/root/anaconda3/envs/cyhan_paddle/lib/python3.9/typing.py\", line 215, in _remove_dups_flatten\r\n    all_params = set(params)\r\nTypeError: unhashable type: 'list'\r\n```\r\npython版本3.9 \r\npaddlepaddle-gpu版本2.4.2 \r\npaddleslim版本2.4.0\r\n求解问题出在那里？",
        "state": "closed",
        "user": "EddieEduardo",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-11-24T03:22:48+00:00",
        "updated_at": "2025-02-11T06:41:56+00:00",
        "closed_at": "2025-02-11T06:41:56+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1812,
        "title": "我在使用静态离线量化的时候遇到这个问题 TypeError: When the type of 'input' in assign is numpy.ndarray, the data type of 'input' must be bool, float32, int32 or int64, but received uint8.",
        "body": "\r\nTypeError: When the type of 'input' in assign is numpy.ndarray, the data type of 'input' must be bool, float32, int32 or int64, but received uint8.",
        "state": "closed",
        "user": "sranqiu",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-12-05T14:22:35+00:00",
        "updated_at": "2025-02-11T06:41:57+00:00",
        "closed_at": "2025-02-11T06:41:57+00:00",
        "comments_count": [
            "XGZhang11"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1814,
        "title": "离线量化paddleocr rec模型存在问题",
        "body": "报错提示“ValueError: (InvalidArgument)  shape should have the save dim with perm, but received shape size is:4, perm size is:3.\r\n  [Hint: Expected shape.size() == perm.size(), but received shape.size():4 != perm.size():3.] (at ../paddle/phi/kernels/funcs/transpose_function.cu.h:663)\r\n  [operator < transpose2 > error]\r\n”\r\n\r\n版本说明：paddleslim ：develop PaddlePaddle: 2.5.1   paddlelite:2.13rc0",
        "state": "closed",
        "user": "tangjinhan",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-12-09T07:40:16+00:00",
        "updated_at": "2025-05-13T06:48:59+00:00",
        "closed_at": "2025-05-13T06:48:59+00:00",
        "comments_count": [
            "XGZhang11",
            "ZIKAIHHUANG"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1813,
        "title": "我使用自定义数据集进行静态离线量化的时候出现了问题",
        "body": "Bug:\r\n    raise TypeError(\r\nTypeError: batch data con only contains: tensor, numpy.ndarray, dict, list, number, but got <class 'paddle.fluid.framework.Variable'\r\n\r\n版本信息：\r\npaddlepaddle-gpu   2.5.2\r\npaddleslim               release/2.5（python stepup.py install 安装）\r\n\r\n静态离线量化代码：\r\n```\r\nimport argparse\r\nimport paddle\r\nfrom paddle.io import DataLoader\r\nfrom paddleslim.quant import quant_post_static\r\nfrom model.dataset import VimeoDataset\r\n\r\npaddle.enable_static()\r\npaddle.set_device(\"gpu\")\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--batch_size', default=16, type=int, help='minibatch size')\r\n    parser.add_argument('--data_root', type=str, required=True, help='Path to the dataset')\r\n    args = parser.parse_args()\r\n\r\n    img0 = paddle.static.data(name=\"img0\", shape=[None, 3, None, None], dtype=\"float32\")\r\n    img1 = paddle.static.data(name=\"img1\", shape=[None, 3, None, None], dtype=\"float32\")\r\n    timestep = paddle.static.data(name=\"timestep\", shape=[None, 1, None, None], dtype=\"float32\")\r\n\r\n    val_dataset = VimeoDataset(args.data_root, \"val\")\r\n    val_dataloader = DataLoader(val_dataset, feed_list=[img0, img1, timestep], return_list=False, batch_size=args.batch_size, shuffle=False, drop_last=False)\r\n\r\n    exe = paddle.paddle.static.Executor(paddle.CUDAPlace(0))\r\n    quant_post_static(\r\n        executor=exe,\r\n        model_dir=\"./static_eval_model\",\r\n        quantize_model_path=\"./quant_post_static_model\",\r\n        data_loader=val_dataloader,\r\n        model_filename=\"flownet.pdmodel\",\r\n        params_filename=\"flownet.pdiparams\",\r\n        batch_size=args.batch_size,\r\n        algo=\"KL\",\r\n    )\r\n```",
        "state": "closed",
        "user": "sranqiu",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-12-06T02:11:26+00:00",
        "updated_at": "2025-02-11T06:41:58+00:00",
        "closed_at": "2025-02-11T06:41:58+00:00",
        "comments_count": [
            "ZhangHandi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1815,
        "title": "怎么把paddleslim量化之后的模型部署在昇腾硬件上",
        "body": "用paddleslim的ACT自动压缩工具对yolov7进行压缩之后，得到的模型虽然保存的参数是int8的范围，但是类型是float，也就是压缩前后的onnx文件体积没变，然后要把这个onnx模型部署在昇腾的开发板Atlas 500上。我的操作如下：\r\n\r\n首先把onnx模型转化为昇腾支持的om模型，转化命令为：\r\natc --framework=5 --model=./model/yolov7.onnx --input_shape=\"images:1,3,640,640\" \\\r\n        --output=./model/yolov7 --compression_optimize=./scripts/compression_opt.config --soc_version=Ascend310 \\\r\n        --log=info --insert_op_conf=./scripts/aipp.cfg\r\n这里的compression_optimize参数是相当于加了一个后训练量化PTQ，把float的参数转为int8，之后按照昇腾官方例子程序，链接如下：\r\nhttps://gitee.com/ascend/samples/tree/master/inference/modelInference/sampleYOLOV7\r\n按照链接中的内容执行推理，输出的图片上一个预测框都没有。\r\n\r\n按照相同的方法把未量化的onnx模型部署在Atlas 500上，可以正常输出，该onnx转om模型的命令为：\r\natc --framework=5 --model=./model/yolov7.onnx --input_shape=\"images:1,3,640,640\" \\\r\n        --output=./model/yolov7 --soc_version=Ascend310 \\\r\n        --log=info --insert_op_conf=./scripts/aipp.cfg\r\n\r\n如果把未量化的onnx模型（大小和量化后一样）加上PTQ转化一下，命令如下（与第一个相同）：\r\natc --framework=5 --model=./model/yolov7.onnx --input_shape=\"images:1,3,640,640\" \\\r\n        --output=./model/yolov7 --compression_optimize=./scripts/compression_opt.config --soc_version=Ascend310 \\\r\n        --log=info --insert_op_conf=./scripts/aipp.cfg\r\n同样不能正常推理。\r\n\r\n所以目前来看是因为加了PTQ导致无法正常推理，但是有没有方法直接导出一个参数为int8格式保存的onnx可以直接在昇腾硬件上转化部署呢，用INT8 MKL-DNN可行吗？这是用在x86CPU上加速的方法，能否用在昇腾硬件上呢",
        "state": "closed",
        "user": "chairman-lu",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-12-12T06:03:23+00:00",
        "updated_at": "2025-02-11T06:41:59+00:00",
        "closed_at": "2025-02-11T06:41:59+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1824,
        "title": "在自动压缩中，如何查看蒸馏时的模型本身损失？",
        "body": "蒸馏过程中目前打印的信息“INFO: Total iter: 240, epoch: 0, batch: 240, loss: 2.9188854694366455 soft_label: 2.9188854694366455” 只有蒸馏损失，当alpha<1.0时，应该有蒸馏损失+模型自身损失，但是不知道查看接口。",
        "state": "closed",
        "user": "Wst-sd",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2023-12-29T06:47:17+00:00",
        "updated_at": "2025-02-18T06:41:55+00:00",
        "closed_at": "2025-02-18T06:41:55+00:00",
        "comments_count": [
            "XGZhang11",
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1827,
        "title": "自动压缩中的蒸馏损失为多个时，配置文件要怎么设置？",
        "body": "![提问](https://github.com/PaddlePaddle/PaddleSlim/assets/125892081/f2733284-bc28-479a-ae5e-681f2105edf0)\r\n我想在蒸馏中同时使用soft_label,和l2loss ，节点添加了4个（两组），但是尝试了修改配置文件用loss: [soft_label,l2] 和loss: soft_label, l2 均报错，请问正确的格式是怎么样的？",
        "state": "closed",
        "user": "Wst-sd",
        "closed_by": "Wst-sd",
        "created_at": "2024-01-02T02:56:04+00:00",
        "updated_at": "2024-02-06T08:28:06+00:00",
        "closed_at": "2024-02-06T08:28:06+00:00",
        "comments_count": [
            "ceci3",
            "Wst-sd"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1834,
        "title": "act 自动压缩pytorch_yolo实例中，python onnx--> tensorrt int8推理结果异常",
        "body": "# 设备\r\nunbuntu20\r\nnvidia 1080ti\r\ncuda 11.7\r\nternsorrt 8.6\r\npaddleslim 2.6\r\npaddle 2.6\r\n\r\n# 复现过程\r\n1. 下载链接提供yolov5s.onnx,  跑pytorch_yolo_series样例，得到量化后模型\r\n2. onnx推理预测，fp32 和 fp16结果均正常，  int8没有框；\r\n3.  运行时，加载tensort模型会打印的消息，可能是造成结果异常的原因；fp32 和 fp16也会打印下面的内容，但是输出的图片结果是正常的。如下图，正常输出的结果\r\n```\r\n[01/16/2024-03:40:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::1513] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::1513, condition: engineDims.nbDims == dims.nbDims\r\n)\r\n```\r\n![output](https://github.com/PaddlePaddle/PaddleSlim/assets/86715812/49fa5469-78f2-42ef-b381-f5fbf9568176)\r\n",
        "state": "closed",
        "user": "GDbbq",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-01-16T03:47:56+00:00",
        "updated_at": "2025-02-11T06:42:00+00:00",
        "closed_at": "2025-02-11T06:42:00+00:00",
        "comments_count": [
            "lizexu123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1843,
        "title": "配置pruner的时候显示 0 collections",
        "body": null,
        "state": "closed",
        "user": "BAYEKHELIX",
        "closed_by": "BAYEKHELIX",
        "created_at": "2024-02-03T15:19:20+00:00",
        "updated_at": "2024-02-04T03:10:19+00:00",
        "closed_at": "2024-02-04T03:10:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1837,
        "title": "AttributeError: module 'paddleslim' has no attribute 'models'",
        "body": "安装信息如下：\r\n\r\npaddlepaddle-gpu          2.6.0.post117\r\npaddleslim                2.6.0\r\n\r\n\r\n遇到的问题如下：\r\n>>> import paddleslim as slim\r\n>>> \r\n>>> \r\n>>> model = slim.models.MobileNet()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'paddleslim' has no attribute 'models'",
        "state": "closed",
        "user": "taoxunqiang",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-01-31T11:46:36+00:00",
        "updated_at": "2025-02-11T06:42:01+00:00",
        "closed_at": "2025-02-11T06:42:01+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1844,
        "title": "新年好！静态模型离线量化wav2lip，结束后发现没有所谓的 scale 文件",
        "body": "我的量化代码是基于官方提供的:[quant_post.py](https://github.com/PaddlePaddle/PaddleSlim/blob/develop/demo/quant/quant_post/quant_post.py):\r\n```\r\n\r\nimport os\r\nimport sys\r\nimport logging\r\nimport functools\r\nimport random\r\nsys.path[0] = os.path.join(\r\n    os.path.dirname(\"__file__\"), os.path.pardir, os.path.pardir)\r\nfrom paddleslim.common import get_logger\r\nfrom paddleslim.quant import quant_post_static\r\nfrom utility import add_arguments, print_arguments\r\n# import imagenet_reader as reader\r\nimport os\r\nfrom paddle.io import Dataset, DataLoader\r\nimport argparse\r\nimport paddle\r\nimport numpy as np\r\n\r\n_logger = get_logger(__name__, level=logging.INFO)\r\n\r\nparser = argparse.ArgumentParser(description=__doc__)\r\nadd_arg = functools.partial(add_arguments, argparser=parser)\r\n# yapf: disable\r\n# ############ 量化参数\r\nadd_arg('batch_size', int, 32, \"Minibatch size.\")\r\nadd_arg('batch_num', int, 1, \"Batch number\")\r\nadd_arg('use_gpu', bool, True, \"Whether to use GPU or not.\")\r\nadd_arg('cpu', bool, False, \"Whether to use CPU or not.\")\r\nadd_arg('model_path', str, \"../../inference_model/\", \"model dir\")\r\nadd_arg('save_path', str, \"../../quant_model/Wav2lip/\", \"model dir to save quanted model\")\r\nadd_arg('model_filename', str, 'wav2lipmodelhq_netG.pdmodel', \"model file name\")\r\nadd_arg('params_filename', str, 'wav2lipmodelhq_netG.pdiparams', \"params file name\")\r\nadd_arg('algo', str, 'avg', \"calibration algorithm\")\r\nadd_arg('round_type', str, 'round', \"The method of converting the quantized weights.\")\r\nadd_arg('hist_percent', float, 0.9999, \"The percentile of algo:hist\")\r\nadd_arg('is_full_quantize', bool, False, \"Whether is full quantization or not.\")\r\nadd_arg('bias_correction', bool, False, \"Whether to use bias correction\")\r\nadd_arg('ce_test', bool, False, \"Whether to CE test.\")\r\nadd_arg('onnx_format', bool, True, \"Whether to export the quantized model with format of ONNX.\")\r\nadd_arg('input_name', list, ['audio_sequences', 'face_sequences'], \"The name of model input.\")\r\nadd_arg('config_file', str, '../../configs/wav2lip_hq.yaml', \"config file path.\")\r\nadd_arg('evaluate_only', bool, True, \"if evaluate_only ?.\")\r\n\r\n\r\nclass LRS2PreprocessedDataset(Dataset):\r\n    def __init__(self, preprocessed_root):\r\n        super().__init__()\r\n        self.preprocessed_root = preprocessed_root\r\n        self.vidname = self.get_count_samples(preprocessed_root)\r\n\r\n    def get_count_samples(self, preprocessed_root):\r\n        # data/my_lrs2_preprocessed/real_data\r\n        count = 0\r\n        data_all = []\r\n        while True:\r\n            mel_data_path = os.path.join(preprocessed_root, f'audio{count}.npy')\r\n            img_data_path = os.path.join(preprocessed_root, f'face{count}.npy')\r\n            if not os.path.exists(mel_data_path) or not os.path.exists(img_data_path):\r\n                'in root:{}, {} or {} is not found'.format(preprocessed_root, mel_data_path, img_data_path)\r\n                if count == 0:\r\n                    print(mel_data_path, 'data is None ! .....error')\r\n                    exit()\r\n                else:\r\n                    return data_all\r\n            data_all.append([mel_data_path, img_data_path])\r\n            count += 1\r\n\r\n    def _load_one_sample(self, idx):\r\n        one_mel = np.load(os.path.join(self.preprocessed_root, f'audio{idx}.npy'))\r\n        one_img = np.load(os.path.join(self.preprocessed_root, f'face{idx}.npy'))\r\n        return one_mel, one_img\r\n\r\n    def __getitem__(self, idx):\r\n        return self._load_one_sample(idx)\r\n\r\n    def __len__(self):\r\n        return len(self.vidname)\r\n\r\n\r\ndef run_quantize(args, data_set):\r\n    if args.ce_test:\r\n        # set seed\r\n        seed = 111\r\n        np.random.seed(seed)\r\n        paddle.seed(seed)\r\n        random.seed(seed)\r\n        shuffle = False\r\n\r\n    place = paddle.CUDAPlace(0) if args.use_gpu else paddle.CPUPlace()\r\n    # val_dataset = reader.ImageNetDataset(mode='test')\r\n\r\n    image_shape = [6, 96, 96]\r\n    image = paddle.static.data(\r\n        name=args.input_name[1], shape=[None] + image_shape, dtype='float32')\r\n    voice_shape = [1, 80, 16]\r\n    voice = paddle.static.data(\r\n        name=args.input_name[0], shape=[None] + voice_shape, dtype='float32')\r\n\r\n    data_loader = paddle.io.DataLoader(\r\n        dataset=data_set,\r\n        places=place,\r\n        feed_list=[voice, image],\r\n        drop_last=False,\r\n        return_list=False,\r\n        batch_size=args.batch_size,\r\n        shuffle=False)\r\n\r\n    assert os.path.exists(args.model_path), \"args.model_path doesn't exist\"\r\n    assert os.path.isdir(args.model_path), \"args.model_path must be a dir\"\r\n    exe = paddle.static.Executor(place)\r\n    quant_post_static(\r\n        executor=exe,\r\n        model_dir=args.model_path,\r\n        quantize_model_path=args.save_path,\r\n        data_loader=data_loader,\r\n        model_filename=args.model_filename,\r\n        params_filename=args.params_filename,\r\n        batch_size=args.batch_size,\r\n        batch_nums=args.batch_num,\r\n        algo=args.algo,\r\n        round_type=args.round_type,\r\n        hist_percent=args.hist_percent,\r\n        is_full_quantize=args.is_full_quantize,\r\n        bias_correction=args.bias_correction,\r\n        onnx_format=args.onnx_format)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    args = parser.parse_args()\r\n    if args.cpu:\r\n        paddle.set_device('cpu')\r\n    data_set = LRS2PreprocessedDataset(preprocessed_root='../../data/my_lrs2_preprocessed/real_data')\r\n    paddle.enable_static()\r\n    run_quantize(args, data_set)\r\n\r\n```\r\n运行结果：\r\n![1707467010525](https://github.com/PaddlePaddle/PaddleSlim/assets/143715628/a15ce8e4-59d1-4233-af52-45e4e469c8e4)\r\n\r\n确实得到了 模型文件和权重文件，但是没有官方说的[ scale 文件](https://github.com/PaddlePaddle/Paddle2ONNX/blob/develop/docs/zh/quantize.md)\r\n\r\n补充：我的前向计算的dataloader数据已经wav2lip模型前向计算测试过，没问题。\r\npaddlepaddle版本最新稳定版本，python=3.8，paddleslim=2.6\r\n\r\n谢谢~",
        "state": "closed",
        "user": "drakitLiu",
        "closed_by": "wanghaoshuang",
        "created_at": "2024-02-09T08:27:11+00:00",
        "updated_at": "2024-03-11T02:45:37+00:00",
        "closed_at": "2024-03-11T02:45:37+00:00",
        "comments_count": [
            "drakitLiu",
            "xiaoluomi",
            "xiaoluomi",
            "xiaoluomi",
            "xiaoluomi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1847,
        "title": "如何使用sensitive来确定yolov3 mobilenetv3的剪枝率呀？",
        "body": "我按照https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.1/static/slim/sensitive 这个指示来做；想要查看yolov3 mobilenetv3的敏感度，但直接报错\r\n![image](https://github.com/PaddlePaddle/PaddleSlim/assets/54930060/65a48509-9939-4a40-a4ce-32a8a1a0b4b7)\r\n\r\n\r\n我发现只有PaddleDtection2.4以下的才有这个sensitive。我使用PaddlePaddle2.1/2.4  PaddleDetection2.1/2.4 都报这个错误。、\r\n是怎么回事呢？\r\n就是如何知道yolov3 mobilenetv3的敏感度呀？？ 想得到yolov3 mobilenetv1那种图",
        "state": "closed",
        "user": "sg-goldrush",
        "closed_by": "sg-goldrush",
        "created_at": "2024-02-20T21:09:09+00:00",
        "updated_at": "2024-04-01T14:37:47+00:00",
        "closed_at": "2024-04-01T14:37:47+00:00",
        "comments_count": [
            "zzjjay",
            "sg-goldrush",
            "zzjjay",
            "sg-goldrush",
            "sg-goldrush",
            "sg-goldrush",
            "zzjjay",
            "sg-goldrush",
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1855,
        "title": "想问一下你们刚更新的目标检测模型离线量化示例，它支持旋转框吗？例如ppyoloe-r",
        "body": "我看到你们新提交的代码中有目标检测离线量化示例，里面功能很多，想请问你们这次支持旋转框吗，我刚刚尝试配环境使用ppyoloe-r进行离线量化，但加载数据那好像出问题了，我使用paddledetection中的slim是可以量化的。\r\n\r\n还有想问在paddledetection中的slim可不可以使用PaddleSlim提供量化分析工具，我觉得这个很不错，可以跳过一些敏感层的量化",
        "state": "open",
        "user": "shangshanruowo",
        "closed_by": null,
        "created_at": "2024-02-27T02:33:57+00:00",
        "updated_at": "2024-03-04T08:10:51+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "shangshanruowo",
            "wanghaoshuang",
            "shangshanruowo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1856,
        "title": "[Bug]TypeError: 'float' object is not iterable",
        "body": "### 软件环境\r\n\r\n```Markdown\r\n- paddlepaddle:2.6.0\r\n- paddlepaddle-gpu: 2.6.0\r\n- paddlenlp: 2.7.2\r\n- paddleslim:2.6.0\r\n```\r\n\r\n\r\n### 重复问题\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### 错误描述\r\n\r\n```Markdown\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 384, in <module>\r\n    main()\r\n  File \"run.py\", line 377, in main\r\n    ac.compress()\r\n  File \"/root/.conda/envs/lzx/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 586, in compress\r\n    self.single_strategy_compress(strategy, config, strategy_idx,\r\n  File \"/root/.conda/envs/lzx/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py\", line 753, in single_strategy_compress\r\n    metric = self.eval_function(self._exe, inference_program,\r\n  File \"run.py\", line 278, in eval_function\r\n    res = metric.accumulate()\r\n  File \"/root/.conda/envs/lzx/lib/python3.8/site-packages/paddlenlp/metrics/glue.py\", line 371, in accumulate\r\n    preds = [item for sublist in self.preds for item in sublist]\r\n  File \"/root/.conda/envs/lzx/lib/python3.8/site-packages/paddlenlp/metrics/glue.py\", line 371, in <listcomp>\r\n    preds = [item for sublist in self.preds for item in sublist]\r\nTypeError: 'float' object is not iterable\r\n```\r\n\r\n\r\n### 稳定复现步骤 & 代码\r\n\r\nhttps://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression/pytorch_huggingface \r\n在使用PaddleSlim，进行自动压缩时，python run.py --config_path=./config/stsb.yaml --save_dir='./output/stsb'\r\nstsb.yaml，改成了\r\n![image](https://github.com/PaddlePaddle/PaddleNLP/assets/39205361/41352cfb-e0f4-49bd-935e-d01315ef5e83)\r\n只有这个，失败了",
        "state": "closed",
        "user": "lizexu123",
        "closed_by": "ceci3",
        "created_at": "2024-02-27T06:00:22+00:00",
        "updated_at": "2024-03-01T03:47:27+00:00",
        "closed_at": "2024-03-01T03:47:27+00:00",
        "comments_count": [
            "lizexu123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1861,
        "title": "使用paddleslim模型动态剪枝后，如何保存模型呢",
        "body": "我是用paddle.save(net.state_dict(),path)来进行保存，发现剪枝后模型比剪枝前的模型都要大，但是通过paddle.summary(net, (1, 3, 32, 32))查看模型确实变小了\r\n\r\n\r\npaddlepaddle=2.6.0\r\npaddleslim=2.6.0\r\n\r\n以下是我的代码：\r\nfrom __future__ import print_function\r\nimport paddle\r\nfrom paddle.vision.models import mobilenet_v1\r\nnet = mobilenet_v1(pretrained=False)\r\npaddle.summary(net, (1, 3, 32, 32))\r\n\r\nimport paddle.vision.transforms as T\r\ntransform = T.Compose([\r\n                    T.Transpose(),\r\n                    T.Normalize([127.5], [127.5])\r\n                ])\r\ntrain_dataset = paddle.vision.datasets.Cifar10(mode=\"train\", backend=\"cv2\",transform=transform)\r\nval_dataset = paddle.vision.datasets.Cifar10(mode=\"test\", backend=\"cv2\",transform=transform)\r\n\r\n# print(f'train samples count: {len(train_dataset)}')\r\n# print(f'val samples count: {len(val_dataset)}')\r\n# for data in train_dataset:\r\n#     print(f'image shape: {data[0].shape}; label: {data[1]}')\r\n#     break\r\n\r\nfrom paddle.static import InputSpec as Input\r\noptimizer = paddle.optimizer.Momentum(\r\n        learning_rate=0.1,\r\n        parameters=net.parameters())\r\n\r\ninputs = [Input([None, 3, 32, 32], 'float32', name='image')]\r\nlabels = [Input([None, 1], 'int64', name='label')]\r\n\r\nmodel = paddle.Model(net, inputs, labels)\r\n\r\nmodel.prepare(\r\n        optimizer,\r\n        paddle.nn.CrossEntropyLoss(),\r\n        paddle.metric.Accuracy(topk=(1, 5)))\r\n\r\nmodel.fit(train_dataset, epochs=2, batch_size=128, verbose=1)\r\nresult = model.evaluate(val_dataset,batch_size=128, log_freq=10, verbose=0)\r\npaddle.save(net.state_dict(), \"./runs/FPGMFilterPruner/model.pdparams\")\r\n\r\n\r\nfrom paddleslim.dygraph import L1NormFilterPruner, FPGMFilterPruner\r\npruner = FPGMFilterPruner(net, [1, 3, 32, 32], opt=optimizer)\r\n\r\n\r\ndef eval_fn():\r\n    result = model.evaluate(\r\n        val_dataset,\r\n        batch_size=128, verbose=0)\r\n    return result['acc_top1']\r\n\r\n\r\npruner.sensitive(eval_func=eval_fn, sen_file=\"./sen.pickle\")\r\n\r\n\r\nfrom paddleslim.analysis import dygraph_flops\r\nflops = dygraph_flops(net, [1, 3, 32, 32])\r\nprint(f\"FLOPs before pruning: {flops}\")\r\n\r\nplan = pruner.sensitive_prune(0.4, skip_vars=[\"conv2d_26.w\"])\r\npaddle.save(net.state_dict(), \"./runs/FPGMFilterPruner/pruning.pdparams\")\r\n\r\n\r\nflops = dygraph_flops(net, [1, 3, 32, 32])\r\nprint(f\"FLOPs after pruning: {flops}\")\r\nprint(f\"Pruned FLOPs: {round(plan.pruned_flops*100, 2)}%\")\r\n\r\nresult = model.evaluate(val_dataset,batch_size=128, log_freq=10, verbose=0)\r\nprint(f\"before fine-tuning: {result}\")\r\n\r\nmodel.fit(train_dataset, epochs=2, batch_size=128, verbose=1)\r\nresult = model.evaluate(val_dataset,batch_size=128, log_freq=10, verbose=0)\r\nprint(f\"after fine-tuning: {result}\")\r\npaddle.save(net.state_dict(), \"./runs/FPGMFilterPruner/pruned.pdparams\")\r\n\r\n\r\npaddle.summary(net, (1, 3, 32, 32))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "MiXianif",
        "closed_by": null,
        "created_at": "2024-03-14T08:23:04+00:00",
        "updated_at": "2024-03-15T11:05:10+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1857,
        "title": "有考虑过新增人脸检测模型的压缩例程嘛？",
        "body": "如题，翻了一下仓库没看到有对人脸检测模型做量化的",
        "state": "closed",
        "user": "Zheng-Bicheng",
        "closed_by": "Zheng-Bicheng",
        "created_at": "2024-02-27T07:51:28+00:00",
        "updated_at": "2024-03-29T09:47:24+00:00",
        "closed_at": "2024-03-29T09:47:24+00:00",
        "comments_count": [
            "ceci3",
            "Zheng-Bicheng",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1858,
        "title": "请问出现这种情况的原因会是什么？# 自动压缩 autoCompression",
        "body": "代码如下：\r\n![微信图片_20240228164204](https://github.com/PaddlePaddle/PaddleSlim/assets/143715628/9e0b6a58-ccfb-4c87-978d-61036453b646)\r\n\r\n错误如下：\r\n![微信图片_20240228163918](https://github.com/PaddlePaddle/PaddleSlim/assets/143715628/5527a4a7-d2e2-42f2-b8c3-81fe4953396b)\r\n（接上图）\r\n![微信图片_202402281639181](https://github.com/PaddlePaddle/PaddleSlim/assets/143715628/4667facd-e66f-41b9-9523-af3f428e4375)\r\n",
        "state": "closed",
        "user": "drakitLiu",
        "closed_by": "wanghaoshuang",
        "created_at": "2024-02-28T09:59:38+00:00",
        "updated_at": "2024-03-04T02:32:20+00:00",
        "closed_at": "2024-03-04T02:30:21+00:00",
        "comments_count": [
            "lizexu123",
            "zzjjay",
            "wanghaoshuang",
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1862,
        "title": "文档中提供的自动压缩后RT-DETR模型的准确率很低",
        "body": "环境：\r\npaddledet                    2.6.0\r\npaddlepaddle-gpu             2.4.2\r\npaddleslim                   2.6.0\r\n\r\n复现步骤：\r\n尝试使用文档中提供的已自动压缩的RT-DETR-R50，下载并解压\r\nhttps://github.com/PaddlePaddle/PaddleSlim/blob/cbc4d1d8a809f79ae3b6aae776ec4b2cba66ce07/example/auto_compression/detection/README.md?plain=1#L52\r\n使用GPU和fp32模式推理图片，具体指令：\r\n`python3 paddle_inference_eval.py --model_path=output/rtdetr_r50vd_6x_coco_quant --reader_config=configs/rtdetr_reader.yml --image_file=000000144941.jpg --device=GPU --precision=fp32`\r\n推理结果是：\r\n```\r\nW0322 15:17:07.880046 23290 analysis_predictor.cc:1395] The one-time configuration of analysis predictor failed, which may be due to native predictor called first and its configurations taken effect.\r\n--- Running analysis [ir_graph_build_pass]\r\n--- Running analysis [ir_analysis_pass]\r\n--- Running IR pass [is_test_pass]\r\n--- Running IR pass [simplify_with_basic_ops_pass]\r\n--- Running IR pass [conv_bn_fuse_pass]\r\n--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\r\n--- Running IR pass [embedding_eltwise_layernorm_fuse_pass]\r\n--- Running IR pass [multihead_matmul_fuse_pass_v2]\r\n--- Running IR pass [fused_multi_transformer_encoder_pass]\r\n--- Running IR pass [fused_multi_transformer_decoder_pass]\r\n--- Running IR pass [fused_multi_transformer_encoder_fuse_qkv_pass]\r\n--- Running IR pass [fused_multi_transformer_decoder_fuse_qkv_pass]\r\n--- Running IR pass [multi_devices_fused_multi_transformer_encoder_fuse_qkv_pass]\r\n--- Running IR pass [multi_devices_fused_multi_transformer_decoder_fuse_qkv_pass]\r\n--- Running IR pass [fuse_multi_transformer_layer_pass]\r\n--- Running IR pass [gpu_cpu_squeeze2_matmul_fuse_pass]\r\n--- Running IR pass [gpu_cpu_reshape2_matmul_fuse_pass]\r\n--- Running IR pass [gpu_cpu_flatten2_matmul_fuse_pass]\r\n--- Running IR pass [gpu_cpu_map_matmul_v2_to_mul_pass]\r\n--- Running IR pass [gpu_cpu_map_matmul_v2_to_matmul_pass]\r\nW0322 15:17:12.930387 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.930546 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.930656 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.935962 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936060 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936131 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936201 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936271 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936342 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936410 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936480 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936549 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936619 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936689 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936758 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.936829 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.940769 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.940857 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.940928 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.940999 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941068 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941138 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941207 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941277 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941346 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941416 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941485 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941555 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941625 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941694 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.941763 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945178 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945257 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945327 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945396 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945466 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945534 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945602 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945672 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945741 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945811 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945880 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.945948 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.946018 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.946086 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.946156 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949091 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949169 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949239 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949309 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949379 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949447 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949517 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949585 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949653 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949723 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949790 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949859 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949929 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.949998 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.950066 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.952968 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953047 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953115 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953184 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953253 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953321 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953389 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953459 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953527 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953596 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953665 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953734 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953804 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953872 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.953941 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.956862 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.956943 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957013 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957082 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957149 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957218 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957286 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957355 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957423 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957492 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957561 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957630 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957700 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957767 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.957836 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.960781 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.960860 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.960929 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.960999 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.961066 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.961134 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.961202 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.961270 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.961339 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.961408 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:17:12.961477 23290 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nI0322 15:17:12.961534 23290 fuse_pass_base.cc:59] ---  detected 14 subgraphs\r\n--- Running IR pass [matmul_scale_fuse_pass]\r\n--- Running IR pass [multihead_matmul_fuse_pass_v3]\r\n--- Running IR pass [gpu_cpu_map_matmul_to_mul_pass]\r\n--- Running IR pass [fc_fuse_pass]\r\n--- Running IR pass [fc_elementwise_layernorm_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_act_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add2_act_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_fuse_pass]\r\n--- Running IR pass [transpose_flatten_concat_fuse_pass]\r\n--- Running IR pass [constant_folding_pass]\r\n--- Running IR pass [auto_mixed_precision_pass]\r\n--- Running IR pass [runtime_context_cache_pass]\r\n--- Running analysis [ir_params_sync_among_devices_pass]\r\nI0322 15:17:36.090184 23290 ir_params_sync_among_devices_pass.cc:89] Sync params from CPU to GPU\r\n--- Running analysis [adjust_cudnn_workspace_size_pass]\r\n--- Running analysis [inference_op_replace_pass]\r\n--- Running analysis [memory_optimize_pass]\r\nI0322 15:17:36.764639 23290 memory_optimize_pass.cc:219] Cluster name : fill_constant_213.tmp_0  size: 4\r\nI0322 15:17:36.764690 23290 memory_optimize_pass.cc:219] Cluster name : tmp_143  size: 4\r\nI0322 15:17:36.764705 23290 memory_optimize_pass.cc:219] Cluster name : conv2d_118.tmp_0.quantized  size: 26214400\r\nI0322 15:17:36.764717 23290 memory_optimize_pass.cc:219] Cluster name : batch_norm_6.tmp_2  size: 26214400\r\nI0322 15:17:36.764729 23290 memory_optimize_pass.cc:219] Cluster name : fill_constant_325.tmp_0  size: 4\r\nI0322 15:17:36.764741 23290 memory_optimize_pass.cc:219] Cluster name : fill_constant_49.tmp_0  size: 4\r\nI0322 15:17:36.764753 23290 memory_optimize_pass.cc:219] Cluster name : elementwise_add_0  size: 26214400\r\nI0322 15:17:36.764765 23290 memory_optimize_pass.cc:219] Cluster name : flatten_33.tmp_0.quantized.dequantized  size: 9600\r\nI0322 15:17:36.764777 23290 memory_optimize_pass.cc:219] Cluster name : conv2d_115.tmp_0.quantized.dequantized  size: 26214400\r\nI0322 15:17:36.764789 23290 memory_optimize_pass.cc:219] Cluster name : relu_5.tmp_0.quantized.dequantized  size: 26214400\r\nI0322 15:17:36.764801 23290 memory_optimize_pass.cc:219] Cluster name : concat_4.tmp_0  size: 8601600\r\nI0322 15:17:36.764812 23290 memory_optimize_pass.cc:219] Cluster name : image  size: 4915200\r\nI0322 15:17:36.764824 23290 memory_optimize_pass.cc:219] Cluster name : transpose_10.tmp_0  size: 307200\r\nI0322 15:17:36.764837 23290 memory_optimize_pass.cc:219] Cluster name : scale_factor  size: 8\r\nI0322 15:17:36.764847 23290 memory_optimize_pass.cc:219] Cluster name : elementwise_add_18  size: 8601600\r\nI0322 15:17:36.764858 23290 memory_optimize_pass.cc:219] Cluster name : cast_2.tmp_0  size: 2150400\r\nI0322 15:17:36.764876 23290 memory_optimize_pass.cc:219] Cluster name : sigmoid_28.tmp_0.quantized.dequantized  size: 4800\r\nI0322 15:17:36.764886 23290 memory_optimize_pass.cc:219] Cluster name : conv2d_118.tmp_0.quantized.dequantized  size: 26214400\r\nI0322 15:17:36.764902 23290 memory_optimize_pass.cc:219] Cluster name : im_shape  size: 8\r\n--- Running analysis [ir_graph_to_program_pass]\r\nI0322 15:17:37.901614 23290 analysis_predictor.cc:1318] ======= optimize end =======\r\nI0322 15:17:37.951170 23290 naive_executor.cc:110] ---  skip [feed], feed -> scale_factor\r\nI0322 15:17:37.951238 23290 naive_executor.cc:110] ---  skip [feed], feed -> image\r\nI0322 15:17:37.951278 23290 naive_executor.cc:110] ---  skip [feed], feed -> im_shape\r\nI0322 15:17:37.998129 23290 naive_executor.cc:110] ---  skip [save_infer_model/scale_0.tmp_0], fetch -> fetch\r\nI0322 15:17:37.998183 23290 naive_executor.cc:110] ---  skip [save_infer_model/scale_1.tmp_0], fetch -> fetch\r\nW0322 15:17:38.045212 23290 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 10.2\r\nW0322 15:17:38.052327 23290 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\n[Benchmark]Inference time(ms): min=90.2, max=90.2, avg=90.2\r\nbicycle: 0.732\r\nbicycle: 0.709\r\n```\r\n使用图片为\r\n![000000144941](https://github.com/PaddlePaddle/PaddleSlim/assets/26888350/e3eba219-5849-4410-abdb-329c4137796d)\r\n结果与图片明显不符\r\n\r\n另外也尝试用coco的一个子数据集进行批量测试，[tiny_coco_dataset](https://github.com/lizhogn/tiny_coco_dataset)\r\n指令为：\r\n`python3 paddle_inference_eval.py --model_path=output/rtdetr_r50vd_6x_coco_quant --reader_config=configs/rtdetr_reader.yml --device=GPU --precision=fp32 --benchmark=True`\r\n结果为：\r\n```\r\nW0322 15:43:39.533730 27379 analysis_predictor.cc:1395] The one-time configuration of analysis predictor failed, which may be due to native predictor called first and its configurations taken effect.\r\n--- Running analysis [ir_graph_build_pass]\r\n--- Running analysis [ir_analysis_pass]\r\n--- Running IR pass [is_test_pass]\r\n--- Running IR pass [simplify_with_basic_ops_pass]\r\n--- Running IR pass [conv_bn_fuse_pass]\r\n--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\r\n--- Running IR pass [embedding_eltwise_layernorm_fuse_pass]\r\n--- Running IR pass [multihead_matmul_fuse_pass_v2]\r\n--- Running IR pass [fused_multi_transformer_encoder_pass]\r\n--- Running IR pass [fused_multi_transformer_decoder_pass]\r\n--- Running IR pass [fused_multi_transformer_encoder_fuse_qkv_pass]\r\n--- Running IR pass [fused_multi_transformer_decoder_fuse_qkv_pass]\r\n--- Running IR pass [multi_devices_fused_multi_transformer_encoder_fuse_qkv_pass]\r\n--- Running IR pass [multi_devices_fused_multi_transformer_decoder_fuse_qkv_pass]\r\n--- Running IR pass [fuse_multi_transformer_layer_pass]\r\n--- Running IR pass [gpu_cpu_squeeze2_matmul_fuse_pass]\r\n--- Running IR pass [gpu_cpu_reshape2_matmul_fuse_pass]\r\n--- Running IR pass [gpu_cpu_flatten2_matmul_fuse_pass]\r\n--- Running IR pass [gpu_cpu_map_matmul_v2_to_mul_pass]\r\n--- Running IR pass [gpu_cpu_map_matmul_v2_to_matmul_pass]\r\nW0322 15:43:48.186563 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.186674 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.186748 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.190639 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.190724 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.190795 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.190865 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.190945 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.191016 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.191084 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.191152 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.191220 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.191287 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.191356 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.191424 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.191493 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194361 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194439 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194509 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194578 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194646 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194715 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194783 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194851 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194929 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.194999 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.195067 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.195135 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.195204 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.195272 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.195340 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198206 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198283 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198352 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198421 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198489 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198558 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198626 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198694 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198762 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198832 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198909 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.198979 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.199047 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.199115 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.199183 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202046 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202122 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202191 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202260 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202329 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202397 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202466 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202534 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202602 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202670 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202740 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202808 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202876 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.202955 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.203024 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.205875 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.205950 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206020 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206089 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206156 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206224 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206292 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206362 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206429 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206497 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206565 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206633 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206702 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206769 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.206838 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.209704 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.209784 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.209851 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.209920 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.209988 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210057 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210124 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210193 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210261 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210330 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210397 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210465 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210534 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210602 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.210670 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.213546 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.213624 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.213691 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.213759 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.213827 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.213894 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.213961 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.214030 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.214097 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.214165 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nW0322 15:43:48.214233 27379 gpu_cpu_map_matmul_to_mul_pass.cc:425] matmul op not support broadcast, please check inputs'shape. \r\nI0322 15:43:48.214284 27379 fuse_pass_base.cc:59] ---  detected 14 subgraphs\r\n--- Running IR pass [matmul_scale_fuse_pass]\r\n--- Running IR pass [multihead_matmul_fuse_pass_v3]\r\n--- Running IR pass [gpu_cpu_map_matmul_to_mul_pass]\r\n--- Running IR pass [fc_fuse_pass]\r\n--- Running IR pass [fc_elementwise_layernorm_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_act_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add2_act_fuse_pass]\r\n--- Running IR pass [conv_elementwise_add_fuse_pass]\r\n--- Running IR pass [transpose_flatten_concat_fuse_pass]\r\n--- Running IR pass [constant_folding_pass]\r\n--- Running IR pass [auto_mixed_precision_pass]\r\n--- Running IR pass [runtime_context_cache_pass]\r\n--- Running analysis [ir_params_sync_among_devices_pass]\r\nI0322 15:44:08.669596 27379 ir_params_sync_among_devices_pass.cc:89] Sync params from CPU to GPU\r\n--- Running analysis [adjust_cudnn_workspace_size_pass]\r\n--- Running analysis [inference_op_replace_pass]\r\n--- Running analysis [memory_optimize_pass]\r\nI0322 15:44:09.206269 27379 memory_optimize_pass.cc:219] Cluster name : fill_constant_213.tmp_0  size: 4\r\nI0322 15:44:09.206315 27379 memory_optimize_pass.cc:219] Cluster name : tmp_143  size: 4\r\nI0322 15:44:09.206326 27379 memory_optimize_pass.cc:219] Cluster name : conv2d_118.tmp_0.quantized  size: 26214400\r\nI0322 15:44:09.206336 27379 memory_optimize_pass.cc:219] Cluster name : batch_norm_6.tmp_2  size: 26214400\r\nI0322 15:44:09.206346 27379 memory_optimize_pass.cc:219] Cluster name : fill_constant_325.tmp_0  size: 4\r\nI0322 15:44:09.206353 27379 memory_optimize_pass.cc:219] Cluster name : fill_constant_49.tmp_0  size: 4\r\nI0322 15:44:09.206362 27379 memory_optimize_pass.cc:219] Cluster name : elementwise_add_0  size: 26214400\r\nI0322 15:44:09.206372 27379 memory_optimize_pass.cc:219] Cluster name : flatten_33.tmp_0.quantized.dequantized  size: 9600\r\nI0322 15:44:09.206380 27379 memory_optimize_pass.cc:219] Cluster name : conv2d_115.tmp_0.quantized.dequantized  size: 26214400\r\nI0322 15:44:09.206389 27379 memory_optimize_pass.cc:219] Cluster name : relu_5.tmp_0.quantized.dequantized  size: 26214400\r\nI0322 15:44:09.206398 27379 memory_optimize_pass.cc:219] Cluster name : concat_4.tmp_0  size: 8601600\r\nI0322 15:44:09.206406 27379 memory_optimize_pass.cc:219] Cluster name : image  size: 4915200\r\nI0322 15:44:09.206414 27379 memory_optimize_pass.cc:219] Cluster name : transpose_10.tmp_0  size: 307200\r\nI0322 15:44:09.206423 27379 memory_optimize_pass.cc:219] Cluster name : scale_factor  size: 8\r\nI0322 15:44:09.206431 27379 memory_optimize_pass.cc:219] Cluster name : elementwise_add_18  size: 8601600\r\nI0322 15:44:09.206440 27379 memory_optimize_pass.cc:219] Cluster name : cast_2.tmp_0  size: 2150400\r\nI0322 15:44:09.206449 27379 memory_optimize_pass.cc:219] Cluster name : sigmoid_28.tmp_0.quantized.dequantized  size: 4800\r\nI0322 15:44:09.206457 27379 memory_optimize_pass.cc:219] Cluster name : conv2d_118.tmp_0.quantized.dequantized  size: 26214400\r\nI0322 15:44:09.206466 27379 memory_optimize_pass.cc:219] Cluster name : im_shape  size: 8\r\n--- Running analysis [ir_graph_to_program_pass]\r\nI0322 15:44:09.936969 27379 analysis_predictor.cc:1318] ======= optimize end =======\r\nI0322 15:44:09.971310 27379 naive_executor.cc:110] ---  skip [feed], feed -> scale_factor\r\nI0322 15:44:09.971345 27379 naive_executor.cc:110] ---  skip [feed], feed -> image\r\nI0322 15:44:09.971355 27379 naive_executor.cc:110] ---  skip [feed], feed -> im_shape\r\nI0322 15:44:10.002552 27379 naive_executor.cc:110] ---  skip [save_infer_model/scale_0.tmp_0], fetch -> fetch\r\nI0322 15:44:10.002584 27379 naive_executor.cc:110] ---  skip [save_infer_model/scale_1.tmp_0], fetch -> fetch\r\nloading annotations into memory...\r\nDone (t=0.01s)\r\ncreating index...\r\nindex created!\r\n[03/22 15:44:10] ppdet.data.source.coco INFO: Load [48 samples valid, 2 samples invalid] in file /home/foia_xlc/dataset/tiny_coco_dataset/tiny_coco/annotations/instances_val2017.json.\r\nEvaluating:   0%|                                                                                                                                                                    | 0/48 [00:00<?, ?it/s]W0322 15:44:10.055075 27379 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 10.2\r\nW0322 15:44:10.060184 27379 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\r\nEvaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:06<00:00,  7.55it/s]\r\n[03/22 15:44:16] ppdet.metrics.metrics INFO: The bbox result is saved to bbox.json.\r\nloading annotations into memory...\r\nDone (t=0.01s)\r\ncreating index...\r\nindex created!\r\n[03/22 15:44:16] ppdet.metrics.coco_utils INFO: Start evaluate...\r\nLoading and preparing results...\r\nDONE (t=0.21s)\r\ncreating index...\r\nindex created!\r\nRunning per image evaluation...\r\nEvaluate annotation type *bbox*\r\nDONE (t=0.27s).\r\nAccumulating evaluation results...\r\nDONE (t=0.37s).\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n[Benchmark]Inference time(ms): min=71.54, max=2036.7, avg=121.4\r\n[Benchmark] COCO mAP: 0.0\r\n```\r\nmAP为0\r\n\r\n请问是什么原因？谢谢！",
        "state": "closed",
        "user": "bittergourd1224",
        "closed_by": "bittergourd1224",
        "created_at": "2024-03-22T07:47:57+00:00",
        "updated_at": "2024-05-15T03:33:02+00:00",
        "closed_at": "2024-05-15T03:33:02+00:00",
        "comments_count": [
            "wanghaoshuang",
            "xiaoluomi",
            "xiaoluomi",
            "bittergourd1224",
            "xiaoluomi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1863,
        "title": "如何固定Softmax这个op的量化参数",
        "body": "如何固定softmax的quantized参数，我需要将scale固定为1/256，zp固定为-128。CMSIS-NN应该是只支持这种方式的，参考TFLite.\r\n\r\n* https://www.tensorflow.org/lite/performance/quantization_spec?hl=zh-cn",
        "state": "closed",
        "user": "Zheng-Bicheng",
        "closed_by": "xiaoluomi",
        "created_at": "2024-03-27T10:27:56+00:00",
        "updated_at": "2024-04-03T10:28:31+00:00",
        "closed_at": "2024-04-03T10:28:31+00:00",
        "comments_count": [
            "xiaoluomi",
            "Zheng-Bicheng",
            "xiaoluomi",
            "Zheng-Bicheng",
            "xiaoluomi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1865,
        "title": "关于自动压缩yolov8-s，run.py的时候出错。",
        "body": "版本：paddleslim2.5 paddledet2.6 paddleYOLO2.5训练出来的 yolov8s模型，根据示例进行自动压缩出错。\r\n\r\n我模型导出来，模型输入 为image，这里报错，说data没有image这个属性；该如何修改？？\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleSlim/assets/54930060/7725a119-97c7-4905-9302-a1a3d72d2987)\r\n",
        "state": "closed",
        "user": "sg-goldrush",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-04-01T14:41:39+00:00",
        "updated_at": "2025-04-15T06:42:31+00:00",
        "closed_at": "2025-04-15T06:42:31+00:00",
        "comments_count": [
            "zzjjay",
            "sg-goldrush",
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1866,
        "title": "报错：var_tensor.shape[0]，tuple index out of range",
        "body": "遇到如下报错，不知道为什么，dataloader拿出的数据应该是正确的\r\nMon Apr 08 21:36:18-INFO: Collect quantized variable names ...\r\nSampling stage, Run batch:|                                              | 0/100\r\nTraceback (most recent call last):\r\n  File \"/home/suncheng01/Projects/Stage1_Deblurring/export/paddleslim_quant_post.py\", line 99, in <module>\r\n    main()\r\n  File \"/home/suncheng01/Projects/Stage1_Deblurring/export/paddleslim_quant_post.py\", line 94, in main\r\n    quantize(args)\r\n  File \"/home/suncheng01/Projects/Stage1_Deblurring/export/paddleslim_quant_post.py\", line 74, in quantize\r\n    quant_post_static(\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddleslim/quant/quanter.py\", line 669, in quant_post_static\r\n    post_training_quantization.quantize()\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddle/static/quantization/post_training_quantization.py\", line 480, in quantize\r\n    self._sampling()\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddle/static/quantization/post_training_quantization.py\", line 748, in _sampling\r\n    self._sample_avg()\r\n  File \"/opt/conda/lib/python3.10/site-packages/paddle/static/quantization/post_training_quantization.py\", line 904, in _sample_avg\r\n    np.abs(var_tensor.reshape(var_tensor.shape[0], -1)),\r\nIndexError: tuple index out of range",
        "state": "closed",
        "user": "Suncheng2022",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-04-08T13:42:05+00:00",
        "updated_at": "2025-04-15T06:42:32+00:00",
        "closed_at": "2025-04-15T06:42:32+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1868,
        "title": "rtdetr进行自动压缩过程中报错如下",
        "body": "运行指令:\r\npython run.py --config_path=./configs/rtdetr_hgnetv2_x_qat_dis.yaml --save_dir='./output/' --devices='cpu'\r\n\r\n配置文件：\r\n\r\nGlobal:\r\n  reader_config: configs/rtdetr_reader.yml\r\n  include_nms: False\r\n  Evaluation: True\r\n  model_dir: ./models/rtdetr_hgnetv2_6x_coco/\r\n  model_filename: model.pdmodel\r\n  params_filename: model.pdiparams\r\n\r\nDistillation:\r\n  alpha: 1.0\r\n  loss: soft_label\r\n\r\n\r\nTrainConfig:\r\n  train_iter: 500\r\n  eval_iter: 100\r\n  learning_rate:\r\n    type: CosineAnnealingDecay\r\n    learning_rate: 0.00003\r\n    T_max: 10000\r\n  optimizer_builder:\r\n    optimizer:\r\n      type: SGD\r\n    weight_decay: 4.0e-05\r\n\r\n报错信息：\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::ThreadPoolTempl<paddle::framework::StlThreadEnvironment>::WorkerLoop(int)\r\n1   paddle::framework::ProgramInterpreter::RunInstructionAsync(unsigned long)\r\n2   paddle::framework::ProgramInterpreter::RunInstruction(paddle::framework::Instruction const&)\r\n3   paddle::framework::ProgramInterpreter::RunOperator(paddle::framework::Instruction const&)\r\n4   phi::KernelImpl<void (*)(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, std::string const&, std::string const&, bool, phi::DenseTensor*), &(void phi::GridSampleKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, std::string const&, std::string const&, bool, phi::DenseTensor*))>::Compute(phi::KernelContext*)\r\n5   void phi::GridSampleKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, std::string const&, std::string const&, bool, phi::DenseTensor*)\r\n",
        "state": "open",
        "user": "desinerPol",
        "closed_by": null,
        "created_at": "2024-04-20T09:27:02+00:00",
        "updated_at": "2024-05-07T10:03:20+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "desinerPol"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1867,
        "title": "paddleslim量化的模型如何使用openvino进行推理",
        "body": null,
        "state": "closed",
        "user": "jiwenfei",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-04-12T09:15:38+00:00",
        "updated_at": "2025-05-06T06:44:21+00:00",
        "closed_at": "2025-05-06T06:44:21+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1869,
        "title": "rtdetr nms false",
        "body": "指令：python run.py --config_path=./configs/rtdetr_hgnetv2_x_qat_dis.yaml --save_dir='./output/' --devices='gpu'\r\n\r\n配置nms为False\r\nGlobal:\r\n  reader_config: configs/rtdetr_reader.yml\r\n  include_nms: False\r\n  Evaluation: True\r\n  model_dir: ./models/rtdetr_hgnetv2_6x_coco_no_post/\r\n  model_filename: model.pdmodel\r\n  params_filename: model.pdiparams\r\n\r\n量化报错\r\n\r\n File \"/home/weconai/sda1/PaddleSlim/example/auto_compression/detection/run.py\", line 198, in <module>\r\n    main()\r\n  File \"/home/weconai/sda1/PaddleSlim/example/auto_compression/detection/run.py\", line 188, in main\r\n    ac.compress()\r\n  File \"/home/weconai/.conda/envs/ppslim/lib/python3.10/site-packages/paddleslim-2.6.0-py3.10.egg/paddleslim/auto_compression/compressor.py\", line 586, in compress\r\n    self.single_strategy_compress(strategy, config, strategy_idx,\r\n  File \"/home/weconai/.conda/envs/ppslim/lib/python3.10/site-packages/paddleslim-2.6.0-py3.10.egg/paddleslim/auto_compression/compressor.py\", line 780, in single_strategy_compress\r\n    test_program_info = self._start_train(\r\n  File \"/home/weconai/.conda/envs/ppslim/lib/python3.10/site-packages/paddleslim-2.6.0-py3.10.egg/paddleslim/auto_compression/compressor.py\", line 827, in _start_train\r\n    metric = self.eval_function(\r\n  File \"/home/weconai/sda1/PaddleSlim/example/auto_compression/detection/run.py\", line 109, in eval_function\r\n    assert \"Not support arch={} now.\".format(global_config['arch'])\r\nKeyError: 'arch'",
        "state": "closed",
        "user": "desinerPol",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-04-20T09:57:45+00:00",
        "updated_at": "2025-05-06T06:44:22+00:00",
        "closed_at": "2025-05-06T06:44:22+00:00",
        "comments_count": [
            "wanghaoshuang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1870,
        "title": "AttributeError",
        "body": "  File \"deploy/slim/distill/distill_train.py\", line 188, in <module>\r\n    main(args)\r\n  File \"deploy/slim/distill/distill_train.py\", line 173, in main\r\n    iters=s_builder.iters,\r\nAttributeError: 'SegBuilder' object has no attribute 'iters'",
        "state": "open",
        "user": "YaoXu97",
        "closed_by": null,
        "created_at": "2024-04-24T04:45:03+00:00",
        "updated_at": "2024-04-29T10:08:26+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "YaoXu97"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1871,
        "title": " from paddleslim.dygraph.dist中没有import AdaptorBase",
        "body": "from paddleslim.dygraph.dist import AdaptorBase出现错误，显示没有AdaptorBase，打开文件位置，发现的确没有，但是安装paddleslim好像是没啥问题",
        "state": "closed",
        "user": "wangfeiyun",
        "closed_by": "zzjjay",
        "created_at": "2024-04-26T02:40:25+00:00",
        "updated_at": "2024-04-26T10:06:15+00:00",
        "closed_at": "2024-04-26T06:17:42+00:00",
        "comments_count": [
            "zzjjay",
            "wangfeiyun",
            "wangfeiyun",
            "zzjjay",
            "wangfeiyun",
            "wangfeiyun",
            "wangfeiyun",
            "zzjjay",
            "wangfeiyun",
            "wangfeiyun",
            "wangfeiyun",
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1872,
        "title": "离线量化paddleocr文字识别模型报错问题ValueError: (InvalidArgument)  shape should have the save dim with perm, but received shape size is:4, perm size is:3",
        "body": "Traceback (most recent call last):                                                  \r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\PPOCRLabel.py\", line 2843, in <module>    \r\n    sys.exit(main())                                                                \r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\PPOCRLabel.py\", line 2831, in main        \r\n    app, _win = get_main_app(sys.argv)                                              \r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\PPOCRLabel.py\", line 2821, in get_main_app\r\n    win = MainWindow(lang=args.lang,                                                \r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\PPOCRLabel.py\", line 114, in __init__     \r\n    result = self.ocr.ocr('./data/paddle.png', cls=True, det=True)\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\..\\paddleocr.py\", line 682, in ocr\r\n    dt_boxes, rec_res, _ = self.__call__(img, cls)\r\n    dt_boxes, elapse = self.text_detector(img)\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\tools\\infer\\predict_det.py\", line 250, in __call__\r\n    self.predictor.run()\r\nValueError: (InvalidArgument)  shape should have the save dim with perm, but received shape size is:4, perm size is:3.\r\n  [Hint: Expected shape.size() == perm.size(), but received shape.size():4 != perm.size():3.] (at ../paddle/phi/kernels/funcs/transpose_func\r\ntion.cu.h:663)\r\n  [operator < transpose2 > error]\r\n(PaddleOCR) PS F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel> python PPOCRLabel.py --lang ch\r\n[2024/05/07 17:13:43] ppocr WARNING: When args.layout is false, args.ocr is automatically set to false\r\nTraceback (most recent call last):\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\PPOCRLabel.py\", line 2846, in <module>\r\n    sys.exit(main())\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\PPOCRLabel.py\", line 2834, in main\r\n    app, _win = get_main_app(sys.argv)\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\PPOCRLabel.py\", line 2824, in get_main_app\r\n    win = MainWindow(lang=args.lang,\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\PPOCRLabel.py\", line 112, in __init__\r\n    result = self.ocr.ocr('./data/paddle.png', cls=True, det=True)\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\PPOCRLabel\\..\\paddleocr.py\", line 682, in ocr\r\n    dt_boxes, rec_res, _ = self.__call__(img, cls)\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\tools\\infer\\predict_system.py\", line 75, in __call__\r\n    dt_boxes, elapse = self.text_detector(img)\r\n  File \"F:\\hzk\\PaddleOCR-2.7.5\\tools\\infer\\predict_det.py\", line 250, in __call__\r\n    self.predictor.run()\r\nValueError: (InvalidArgument)  shape should have the save dim with perm, but received shape size is:4, perm size is:3.\r\n  [Hint: Expected shape.size() == perm.size(), but received shape.size():4 != perm.size():3.] (at ../paddle/phi/kernels/funcs/transpose_func\r\ntion.cu.h:663)\r\n  [operator < transpose2 > error]\r\n配置文件：ch_PPOCRv4_rec.yml\r\n",
        "state": "closed",
        "user": "ZIKAIHHUANG",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-05-08T02:17:13+00:00",
        "updated_at": "2025-05-13T06:49:00+00:00",
        "closed_at": "2025-05-13T06:49:00+00:00",
        "comments_count": [
            "FrostML"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1878,
        "title": "The dtype of LinearQuanter's output is float",
        "body": "\r\n\r\n```\r\nimport paddle\r\nimport numpy as np\r\nfrom paddle.nn.quant.format import LinearQuanter\r\n\r\ndata = paddle.to_tensor(np.random.randn(2)).astype(paddle.float32)\r\nint8_quanter = LinearQuanter(scales= 1.0, bit_length=8)\r\nint16_quanter = LinearQuanter(scales= 1.0, bit_length=16)\r\nquanted_data = int8_quanter(data)\r\nprint(quanted_data)\r\nprint(quanted_data.astype(paddle.int8))\r\nquanted_data = int16_quanter(data)\r\nprint(quanted_data)\r\nprint(quanted_data.astype(paddle.int16))\r\n```",
        "state": "closed",
        "user": "wanghaoshuang",
        "closed_by": "wanghaoshuang",
        "created_at": "2024-06-06T03:56:58+00:00",
        "updated_at": "2024-06-06T03:57:22+00:00",
        "closed_at": "2024-06-06T03:57:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1873,
        "title": "请问，压缩V4检测 server模型，需要使用什么数据集？",
        "body": "请问，压缩V4检测 server模型，需要使用什么数据集？\r\n\r\n我使用自有的数据，验证精度不佳。我想请问我可以使用什么数据集进行验证，能尽可能保持模型的精度呢?",
        "state": "open",
        "user": "TinyQi",
        "closed_by": null,
        "created_at": "2024-05-13T09:04:52+00:00",
        "updated_at": "2024-07-08T12:59:00+00:00",
        "closed_at": null,
        "comments_count": [
            "ceci3",
            "TinyQi",
            "TinyQi",
            "TinyQi",
            "TinyQi",
            "ceci3",
            "huangguifeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1874,
        "title": "无法复现教程中的OCR v3检测模型的量化精度",
        "body": "我使用文档中：https://github.com/PaddlePaddle/PaddleSlim/tree/release/2.6/example/auto_compression/ocr的量化脚本进行量化，经过训练后模型的精度下降很大，请问我哪里做错了嘛？\r\n\r\n精度的前后对比如下：\r\n![image](https://github.com/PaddlePaddle/PaddleSlim/assets/28993936/f98745e4-dc6d-4e65-aee1-12d5f4a8bb9d)\r\n\r\n\r\n我使用的配置文件如下：\r\nGlobal:\r\n  model_type: det\r\n  model_dir: /share/disk3/xcq/02.model_cache/pretrain_models/ch_PP-OCRv3_det_infer_bak/\r\n  model_filename: inference.pdmodel\r\n  params_filename: inference.pdiparams\r\n  algorithm: DB\r\n  \r\nDistillation:\r\n  alpha: 1.0\r\n  loss: l2\r\n\r\nQuantAware:\r\n  use_pact: true\r\n  activation_bits: 8\r\n  is_full_quantize: false\r\n  onnx_format: True\r\n  activation_quantize_type: moving_average_abs_max\r\n  weight_quantize_type: channel_wise_abs_max\r\n  not_quant_pattern:\r\n  - skip_quant\r\n  quantize_op_types:\r\n  - conv2d\r\n  - depthwise_conv2d\r\n  weight_bits: 8\r\n\r\nTrainConfig:\r\n  epochs: 3\r\n  eval_iter: 200\r\n  learning_rate: \r\n    type: CosineAnnealingDecay \r\n    learning_rate: 0.00005\r\n  optimizer_builder:\r\n    optimizer:\r\n      type: Adam\r\n    weight_decay: 5.0e-05\r\n\r\nPostProcess:\r\n  name: DBPostProcess\r\n  thresh: 0.3\r\n  box_thresh: 0.6\r\n  max_candidates: 1000\r\n  unclip_ratio: 1.5\r\n  \r\nMetric:\r\n  name: DetMetric\r\n  main_indicator: hmean\r\n  \r\nTrain:\r\n  dataset:\r\n    name: SimpleDataSet\r\n    data_dir: /share/disk3/xcq/01.ImageData/010.OpenSourceData/icdar2015/text_localization/\r\n    label_file_list:\r\n      - /share/disk3/xcq/01.ImageData/010.OpenSourceData/icdar2015/text_localization/train_icdar2015_label.txt\r\n    ratio_list: [1.0]\r\n    transforms:\r\n    - DecodeImage:\r\n        img_mode: BGR\r\n        channel_first: false\r\n    - DetLabelEncode: null\r\n    - IaaAugment:\r\n        augmenter_args:\r\n        - type: Fliplr\r\n          args:\r\n            p: 0.5\r\n        - type: Affine\r\n          args:\r\n            rotate:\r\n            - -10\r\n            - 10\r\n        - type: Resize\r\n          args:\r\n            size:\r\n            - 0.5\r\n            - 3\r\n    - EastRandomCropData:\r\n        size:\r\n        - 960\r\n        - 960\r\n        max_tries: 50\r\n        keep_ratio: true\r\n    - MakeBorderMap:\r\n        shrink_ratio: 0.4\r\n        thresh_min: 0.3\r\n        thresh_max: 0.7\r\n    - MakeShrinkMap:\r\n        shrink_ratio: 0.4\r\n        min_text_size: 8\r\n    - NormalizeImage:\r\n        scale: 1./255.\r\n        mean:\r\n        - 0.485\r\n        - 0.456\r\n        - 0.406\r\n        std:\r\n        - 0.229\r\n        - 0.224\r\n        - 0.225\r\n        order: hwc\r\n    - ToCHWImage: null\r\n    - KeepKeys:\r\n        keep_keys:\r\n        - image\r\n        - threshold_map\r\n        - threshold_mask\r\n        - shrink_map\r\n        - shrink_mask\r\n  loader:\r\n    shuffle: true\r\n    drop_last: false\r\n    batch_size_per_card: 4\r\n    num_workers: 0\r\n    \r\nEval:\r\n  dataset:\r\n    name: SimpleDataSet\r\n    data_dir: /share/disk3/xcq/01.ImageData/010.OpenSourceData/icdar2015/text_localization/\r\n    label_file_list:\r\n      - /share/disk3/xcq/01.ImageData/010.OpenSourceData/icdar2015/text_localization/test_icdar2015_label.txt\r\n    transforms:\r\n    - DecodeImage:\r\n        img_mode: BGR\r\n        channel_first: false\r\n    - DetLabelEncode: null\r\n    - DetResizeForTest: null\r\n    - NormalizeImage:\r\n        scale: 1./255.\r\n        mean:\r\n        - 0.485\r\n        - 0.456\r\n        - 0.406\r\n        std:\r\n        - 0.229\r\n        - 0.224\r\n        - 0.225\r\n        order: hwc\r\n    - ToCHWImage: null\r\n    - KeepKeys:\r\n        keep_keys:\r\n        - image\r\n        - shape\r\n        - polys\r\n        - ignore_tags\r\n  loader:\r\n    shuffle: false\r\n    drop_last: false\r\n    batch_size_per_card: 1\r\n    num_workers: 0",
        "state": "closed",
        "user": "TinyQi",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-05-13T12:55:55+00:00",
        "updated_at": "2025-05-20T06:43:43+00:00",
        "closed_at": "2025-05-20T06:43:43+00:00",
        "comments_count": [
            "ceci3"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1876,
        "title": "BMN模型和AttentionLSTM模型量化压缩和蒸馏方案",
        "body": "1、BMN模型和AttentionLSTM模型是否有量化压缩和蒸馏的方案？训练完成的AttentionLSTM模型的模型参数和计算量如何计算？\r\n2、模型使用自动压缩，参数文件大小没有变化，如何处理这种情况？",
        "state": "open",
        "user": "AvaMins",
        "closed_by": null,
        "created_at": "2024-05-23T08:17:04+00:00",
        "updated_at": "2024-05-29T09:40:34+00:00",
        "closed_at": null,
        "comments_count": [
            "wanghaoshuang",
            "AvaMins"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1879,
        "title": "使用paddleslim的模型自动化压缩工具ACT优化TPSMM模型报错",
        "body": "Traceback (most recent call last):\r\n  File \"run.py\", line 212, in <module>\r\n    main()\r\n  File \"run.py\", line 205, in main\r\n    ac.compress()\r\n  File \"/data/huangyan/anaconda/anaconda3/envs/yolov5sperson/lib/python3.8/site-packages/paddleslim-0.0.0.dev0-py3.8.egg/paddleslim/auto_compression/compressor.py\", line 586, in compress\r\n    self.single_strategy_compress(strategy, config, strategy_idx,\r\n  File \"/data/huangyan/anaconda/anaconda3/envs/yolov5sperson/lib/python3.8/site-packages/paddleslim-0.0.0.dev0-py3.8.egg/paddleslim/auto_compression/compressor.py\", line 753, in single_strategy_compress\r\n    metric = self.eval_function(self._exe, inference_program,\r\n  File \"run.py\", line 104, in eval_function\r\n    pred = exe.run(\r\n  File \"/data/huangyan/anaconda/anaconda3/envs/yolov5sperson/lib/python3.8/site-packages/paddle/base/executor.py\", line 1746, in run\r\n    res = self._run_impl(\r\n  File \"/data/huangyan/anaconda/anaconda3/envs/yolov5sperson/lib/python3.8/site-packages/paddle/base/executor.py\", line 1952, in _run_impl\r\n    ret = new_exe.run(\r\n  File \"/data/huangyan/anaconda/anaconda3/envs/yolov5sperson/lib/python3.8/site-packages/paddle/base/executor.py\", line 831, in run\r\n    tensors = self._new_exe.run(\r\nValueError: In user code:\r\n\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/bin/x2paddle\", line 8, in <module>\r\n      sys.exit(main())\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/x2paddle/convert.py\", line 497, in main\r\n      enable_onnx_checker=args.enable_onnx_checker)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/x2paddle/convert.py\", line 311, in onnx2paddle\r\n      mapper.paddle_graph.gen_model(save_dir)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/x2paddle/core/program.py\", line 297, in gen_model\r\n      self.dygraph2static(save_dir, input_shapes, input_types)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/x2paddle/core/program.py\", line 583, in dygraph2static\r\n      osp.join(save_dir, \"inference_model/model\"))\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/jit.py\", line 631, in wrapper\r\n      func(layer, path, input_spec, **configs)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/jit.py\", line 861, in save\r\n      inner_input_spec, with_hook=with_hook)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 528, in concrete_program_specify_input_spec\r\n      *desired_input_spec, with_hook=with_hook)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 436, in get_concrete_program\r\n      concrete_program, partial_program_layer = self._program_cache[cache_key]\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 801, in __getitem__\r\n      self._caches[item_id] = self._build_once(item)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 790, in _build_once\r\n      **cache_key.kwargs)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\", line 51, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 733, in from_func_spec\r\n      outputs = static_func(*inputs)\r\n    File \"./x2paddle_code.py\", line 103, in forward\r\n      x2paddle_onnx__Gemm_190 = paddle.reshape(x=x2paddle_onnx__Flatten_189, shape=[1, 512])\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/tensor/manipulation.py\", line 2139, in reshape\r\n      return paddle.fluid.layers.reshape(x=x, shape=shape, name=name)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 6450, in reshape\r\n      \"XShape\": x_shape})\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 44, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 3621, in append_op\r\n      attrs=kwargs.get(\"attrs\", None))\r\n    File \"/data/huangyan/anaconda/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2635, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    InvalidArgumentError: The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 512, 1, 1], X's size = 1024, 'shape' is [1, 512], the capacity of 'shape' is 512.\r\n      [Hint: Expected capacity == in_size, but received capacity:512 != in_size:1024.] (at ../paddle/fluid/operators/reshape_op.cc:234)\r\n      [operator < reshape2 > error]\r\n\r\n\r\n请问该如何修改呢，期待解答！！",
        "state": "closed",
        "user": "kiyojimini",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-06-16T03:41:01+00:00",
        "updated_at": "2025-06-24T06:45:36+00:00",
        "closed_at": "2025-06-24T06:45:04+00:00",
        "comments_count": [
            "YZW-explorer",
            "CheckGuest"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1881,
        "title": "404 not found",
        "body": "https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/tutorials/pruning/overview.md#l1normfilterpruner\r\n这个链接下的各种剪枝示例文档都显示404 not found\r\n",
        "state": "open",
        "user": "T-liuhuan",
        "closed_by": null,
        "created_at": "2024-07-03T04:05:36+00:00",
        "updated_at": "2024-07-03T04:05:40+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1880,
        "title": "yolov5离线量化报错",
        "body": "-----------  Running Arguments -----------\r\n arch: YOLOv5\r\n dataset_dir: /mnt/data01/luoshiyong/data/liugang\r\n model_dir: /mnt/data01/luoshiyong/code/PaddleSlim-release-2.5/yolov5out/best.onnx\r\n skip_tensors: None\r\n train_anno_path: annotations/instances1_train.json\r\n train_image_dir: images/train\r\n val_anno_path: annotations/instances1_val.json\r\n val_image_dir: images/val\r\n------------------------------------------\r\nloading annotations into memory...\r\nDone (t=0.22s)\r\ncreating index...\r\nindex created!\r\nI0626 11:09:01.155823 541758 interpretercore.cc:237] New Executor is Running.\r\n2024-06-26 11:09:01,300-INFO: Loaded model from: /mnt/data01/luoshiyong/code/PaddleSlim-release-2.5/yolov5out/best_infer\r\nWed Jun 26 11:09:01-INFO: Load model and set data loader ...\r\nWed Jun 26 11:09:01-WARNING: The old way to load inference model is deprecated. Please specify path_prefix. model path: /mnt/data01/luoshiyong/code/PaddleSlim-release-2.5/yolov5out/best_infer/model.pdmodel, params path: /mnt/data01/luoshiyong/code/PaddleSlim-release-2.5/yolov5out/best_infer/model.pdiparams\r\nW0626 11:09:01.377684 541758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.2, Runtime API Version: 11.6\r\nW0626 11:09:01.419098 541758 gpu_resources.cc:149] device: 0, cuDNN Version: 8.4.\r\nWed Jun 26 11:09:05-INFO: Collect quantized variable names ...\r\nSampling stage, Run batch:|                                               | 0/32\r\nTraceback (most recent call last):\r\n  File \"post_quant.py\", line 98, in <module>\r\n    main()\r\n  File \"post_quant.py\", line 72, in main\r\n    quant_post_static(\r\n  File \"/home/cisdi/anaconda3/envs/luoshiyong/lib/python3.8/site-packages/paddleslim-Stopping.at.filesystem.boundary._GIT_DISCOVERY_ACROSS_FILESYSTEM.not.set_.-py3.8.egg/paddleslim/quant/quanter.py\", line 669, in quant_post_static\r\n  File \"/home/cisdi/anaconda3/envs/luoshiyong/lib/python3.8/site-packages/paddle/static/quantization/post_training_quantization.py\", line 482, in quantize\r\n    self._executor.run(\r\n  File \"/home/cisdi/anaconda3/envs/luoshiyong/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1392, in run\r\n    res = self._run_impl(\r\n  File \"/home/cisdi/anaconda3/envs/luoshiyong/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 1618, in _run_impl\r\n    ret = new_exe.run(\r\n  File \"/home/cisdi/anaconda3/envs/luoshiyong/lib/python3.8/site-packages/paddle/fluid/executor.py\", line 654, in run\r\n    tensors = self._new_exe.run(\r\nValueError: (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 512, 1, 1], X's size = 512, 'shape' is [2, 512], the capacity of 'shape' is 1024.\r\n  [Hint: Expected capacity == in_size, but received capacity:1024 != in_size:512.] (at ../paddle/fluid/operators/reshape_op.cc:234)\r\n  [operator < reshape2 > error]\r\n",
        "state": "open",
        "user": "luoshiyong",
        "closed_by": null,
        "created_at": "2024-06-26T03:12:39+00:00",
        "updated_at": "2024-07-10T04:07:41+00:00",
        "closed_at": null,
        "comments_count": [
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1882,
        "title": "请问如何使用paddleslim对uie-x-base进行微调后的模型进行量化、压缩",
        "body": "参考https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression 这个方法直接报错，请指导，谢谢",
        "state": "open",
        "user": "AllenMeng2009",
        "closed_by": null,
        "created_at": "2024-07-05T02:31:17+00:00",
        "updated_at": "2024-07-11T04:02:49+00:00",
        "closed_at": null,
        "comments_count": [
            "FrostML",
            "AllenMeng2009"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1894
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1885,
        "title": "ACTdis-quant量化模型后，如何转换为int8类型的模型，并测试量化后的模型大小？",
        "body": null,
        "state": "open",
        "user": "ryy321",
        "closed_by": null,
        "created_at": "2024-07-18T10:37:41+00:00",
        "updated_at": "2024-07-18T10:37:44+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1883,
        "title": "OCR模型自动压缩PPOCRV4_rec报错",
        "body": "2024-07-08 18:00:06,589-INFO：选定的策略：['qat_dis']\r\n回溯（最近一次调用最后一次）：\r\n文件“run.py”，第 171 行，在\r\nmain()中\r\n文件“run.py”，第 164 行，在 main\r\nac.compress() 中\r\n文件“/root/miniconda3/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py”，第 586 行，在 compress\r\nself.single_strategy_compress(strategy, config, strategies_idx,\r\n文件“/root/miniconda3/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py”，第 769 行，在 single_strategy_compress\r\ntrain_program_info, test_program_info = self._prepare_program(\r\n文件“/root/miniconda3/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py”, 第 506 行, 在 _prepare_program\r\ntrain_program_info 中, test_program_info = build_distill_program(\r\n文件“/root/miniconda3/lib/python3.8/site-packages/paddleslim/auto_compression/create_compressed_program.py”, 第 327 行, 在 build_distill_program\r\ntrain_program 中, data_name_map = _load_program_and_merge(\r\n文件“/root/miniconda3/lib/python3.8/site-packages/paddleslim/auto_compression/create_compressed_program.py”, 第 219 行, 在 _load_program_and_merge 中\r\n合并(\r\n文件“/root/miniconda3/lib/python3.8/site-packages/paddleslim/dist/single_distiller.py”, 行197，在合并\r\nstudent_program.global_block().append_op(\r\n文件“/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py”中，第 4013 行，在 append_op\r\nop = Operator(\r\n文件“/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py”中，第 2889 行，在init\r\n中 引发 ValueError(\r\nValueError: 运算符“dropout”的输出设置不正确，应设置：[Mask]。",
        "state": "open",
        "user": "huangguifeng",
        "closed_by": null,
        "created_at": "2024-07-08T14:39:27+00:00",
        "updated_at": "2025-04-29T03:33:00+00:00",
        "closed_at": null,
        "comments_count": [
            "huangguifeng",
            "huangguifeng",
            "Xingyu-Romantic",
            "MS-IOD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1884,
        "title": "量化ch_PP-OCRv4_det后导出报错",
        "body": "环境：\r\nUbantu 20.04\r\npaddlepaddle-gpu        2.6.1\r\npaddleslim              2.3.2\r\n\r\n你好！\r\n我用quant.py量化ch_PP-OCRv4_det后，用export_model.py导出模型的时候出错。好像是每层Conv2D都加了一层MAOutputScaleLayer，而export_model.py期望不加MAOutputScaleLayer的Conv2D层。有解决的方法么？\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/shui/ascent-paddleocr/deploy/slim/quantization/export_model.py\", line 179, in <module>\r\n    main()\r\n  File \"/home/shui/ascent-paddleocr/deploy/slim/quantization/export_model.py\", line 173, in main\r\n    export_single_model(model, arch_config, save_path, logger, input_shape,\r\n  File \"/home/shui/ascent-paddleocr/tools/export_model.py\", line 196, in export_single_model\r\n    layer.rep()\r\n  File \"/home/shui/ascent-paddleocr/ppocr/modeling/backbones/rec_lcnetv3.py\", line 201, in rep\r\n    kernel, bias = self._get_kernel_bias()\r\n  File \"/home/shui/ascent-paddleocr/ppocr/modeling/backbones/rec_lcnetv3.py\", line 220, in _get_kernel_bias\r\n    kernel_conv_1x1, bias_conv_1x1 = self._fuse_bn_tensor(self.conv_1x1)\r\n  File \"/home/shui/ascent-paddleocr/ppocr/modeling/backbones/rec_lcnetv3.py\", line 244, in _fuse_bn_tensor\r\n    kernel = branch.conv.weight\r\n  File \"/home/shui/.local/lib/python3.10/site-packages/paddle/nn/layer/layers.py\", line 1657, in __getattr__\r\n    return object.__getattribute__(self, name)\r\nAttributeError: 'MAOutputScaleLayer' object has no attribute 'weight'\r\n\r\n```",
        "state": "open",
        "user": "aijim",
        "closed_by": null,
        "created_at": "2024-07-18T07:56:53+00:00",
        "updated_at": "2024-11-07T08:33:22+00:00",
        "closed_at": null,
        "comments_count": [
            "ArthurisYun",
            "piupuer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1891,
        "title": "运行yoloe离线量化失败",
        "body": "利用example里yoloe的全量化代码，使用自己的数据集进行量化，遇到如下问题\r\n```\r\nI0803 17:00:04.758946  7608 program_interpreter.cc:212] New Executor is Running.\r\nloading annotations into memory...\r\nDone (t=0.01s)\r\ncreating index...\r\nindex created!\r\n[08/03 17:00:04] ppdet.data.source.coco INFO: Load [1236 samples valid, 0 samples invalid] in file /root/autodl-tmp/voc_train.json.\r\nW0803 17:00:04.825512  7608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.4, Runtime API Version: 11.3\r\nW0803 17:00:04.827611  7608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.2.\r\nTraceback (most recent call last):\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddleslim-2.6.0-py3.8.egg/paddleslim/quant/quanter.py\", line 617, in quant_post_static\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/static/quantization/post_training_quantization.py\", line 315, in __init__\r\n    assert isinstance(\r\nAssertionError: data_loader only accepts `paddle.io.DataLoader`.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"post_quant.py\", line 107, in <module>\r\n    main()\r\n  File \"post_quant.py\", line 80, in main\r\n    quant_post_static(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddleslim-2.6.0-py3.8.egg/paddleslim/quant/quanter.py\", line 644, in quant_post_static\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/paddle/static/quantization/post_training_quantization.py\", line 315, in __init__\r\n    assert isinstance(\r\nAssertionError: data_loader only accepts `paddle.io.DataLoader`.\r\n```\r\n\r\n其中，我注意到实例代码里使用的数据加载写法是\r\n\r\n```\r\ndef reader_wrapper(reader, input_list):\r\n    def gen():\r\n        for data in reader:\r\n            in_dict = {}\r\n            if isinstance(input_list, list):\r\n                for input_name in input_list:\r\n                    in_dict[input_name] = data[input_name]\r\n            elif isinstance(input_list, dict):\r\n                for input_name in input_list.keys():\r\n                    in_dict[input_list[input_name]] = data[input_name]\r\n            yield in_dict\r\n\r\n    return gen\r\n\r\n...\r\n\r\n    train_loader = create('EvalReader')(reader_cfg['TrainDataset'],\r\n                                        reader_cfg['worker_num'],\r\n                                        return_list=True)\r\n\r\n    train_loader = reader_wrapper(train_loader, global_config['input_list'])\r\n```\r\n最终得到是一个function，这是正确的数据载入写法吗？\r\n是否有reader转为DataLoader的快捷方法？",
        "state": "open",
        "user": "Dimweaker",
        "closed_by": null,
        "created_at": "2024-08-03T09:07:30+00:00",
        "updated_at": "2024-08-03T09:09:07+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1890,
        "title": "似乎你们的剪枝相关的函数写的有点问题",
        "body": "该函数的引用方式：\r\nfrom paddleslim.nas.ofa.utils import nlp_utils\r\n该函数的原文：\r\ndef compute_neuron_head_importance(task_name,\r\n                                   model,\r\n                                   data_loader,\r\n                                   num_layers,\r\n                                   num_heads,\r\n                                   loss_fct=paddle.nn.loss.CrossEntropyLoss(),\r\n                                   intermediate_name='linear1',\r\n                                   output_name='linear2'):\r\n    \"\"\"\r\n    Compute the importance of multi-head attention and feed-forward  neuron in each transformer layer.\r\n\r\n    Args:\r\n        task_name(str): task name.\r\n        model(paddle.nn.Layer): the instance of transformer model.\r\n        data_loader(DataLoader): An iterable data loader is used for evaluate. An instance of `paddle.io.Dataloader`.\r\n        num_layers(int): number of transformer layers.\r\n        num_heads(int): number of heads in each multi-head attention.\r\n        loss_fct(Loss|optional): loss function can be a `paddle.nn.Layer` instance. Default: `nn.loss.CrossEntropyLoss()`.\r\n        intermediate_name(str|optional): the name of intermediate `Linear` layer in feed-forward. Default: `linear1`.\r\n        output_name(str|optional): the name of output `Linear` layer in feed-forward. Default: `linear2`.\r\n    \"\"\"\r\n    head_importance = paddle.zeros(\r\n        shape=[num_layers, num_heads], dtype='float32')\r\n    head_mask = paddle.ones(shape=[num_layers, num_heads], dtype='float32')\r\n    head_mask.stop_gradient = False\r\n\r\n    intermediate_weight = []\r\n    intermediate_bias = []\r\n    output_weight = []\r\n\r\n    for name, w in model.named_parameters():\r\n        if intermediate_name in name:\r\n            if len(w.shape) > 1:\r\n                intermediate_weight.append(w)\r\n            else:\r\n                intermediate_bias.append(w)\r\n\r\n        if output_name in name:\r\n            if len(w.shape) > 1:\r\n                output_weight.append(w)\r\n\r\n    neuron_importance = []\r\n    for w in intermediate_weight:\r\n        neuron_importance.append(np.zeros(shape=[w.shape[1]], dtype='float32'))\r\n\r\n    if task_name.lower() != 'mnli':\r\n        data_loader = (data_loader, )\r\n    for data in data_loader:\r\n        for batch in data:\r\n            if isinstance(batch, dict):\r\n                input_ids, segment_ids, labels = batch['input_ids'], batch[\r\n                    'token_type_ids'], batch['labels']\r\n            else:\r\n                input_ids, segment_ids, labels = batch\r\n            logits = model(\r\n                input_ids, segment_ids, attention_mask=[None, head_mask])\r\n            loss = loss_fct(logits, labels)\r\n            loss.backward()\r\n            head_importance += paddle.abs(\r\n                paddle.to_tensor(head_mask.gradient()))\r\n\r\n            for w1, b1, w2, current_importance in zip(\r\n                    intermediate_weight, intermediate_bias, output_weight,\r\n                    neuron_importance):\r\n                current_importance += np.abs(\r\n                    (np.sum(w1.numpy() * w1.gradient(), axis=0) + b1.numpy() *\r\n                     b1.gradient()))\r\n                current_importance += np.abs(\r\n                    np.sum(w2.numpy() * w2.gradient(), axis=1))\r\n\r\n    return head_importance, neuron_importance\r\n\r\n在使用该函数时，我遇到了报错：\r\nAttributeError                            Traceback (most recent call last)\r\nCell In[46], line 180\r\n    172 dev_batch_sampler = paddle.io.BatchSampler(\r\n    173     dev_ds, batch_size=4, shuffle=False)\r\n    174 dev_data_loader = DataLoader(\r\n    175     dataset=dev_ds,\r\n    176     #batch_sampler=dev_batch_sampler,\r\n    177     #collate_fn=batchify_fn\r\n    178     )\r\n--> 180 head_importance, neuron_importance = nlp_utils.compute_neuron_head_importance(\r\n    181     task_name='cluewsc2020',\r\n    182     model=ofa_model.model,\r\n    183     data_loader=dev_ds,\r\n    184     loss_fct=paddle.nn.loss.CrossEntropyLoss(\r\n    185         ) if [True,False] else paddle.nn.loss.MSELoss(),\r\n    186     num_layers=model.ppminilm.config['num_hidden_layers'],\r\n    187     num_heads=model.ppminilm.config['num_attention_heads'])\r\n    189 # 重新组合参数的顺序\r\n    190 reorder_neuron_head(ofa_model.model, head_importance, neuron_importance)\r\n\r\nFile /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleslim/nas/ofa/utils/nlp_utils.py:76, in compute_neuron_head_importance(task_name, model, data_loader, num_layers, num_heads, loss_fct, intermediate_name, output_name)\r\n     74 else:\r\n     75     input_ids, segment_ids, labels = batch\r\n---> 76 logits = model(\r\n     77     input_ids, segment_ids, attention_mask=[None, head_mask])\r\n     78 loss = loss_fct(logits, labels)\r\n     79 loss.backward()\r\n\r\nFile /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/nn/layer/layers.py:1426, in Layer.__call__(self, *inputs, **kwargs)\r\n   1417 if (\r\n   1418     (not in_to_static_mode())\r\n   1419     and (not self._forward_pre_hooks)\r\n   (...)\r\n   1423     and (not in_profiler_mode())\r\n   1424 ):\r\n   1425     self._build_once(*inputs, **kwargs)\r\n-> 1426     return self.forward(*inputs, **kwargs)\r\n   1427 else:\r\n   1428     return self._dygraph_call_func(*inputs, **kwargs)\r\n\r\nFile /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddlenlp/transformers/ppminilm/modeling.py:300, in PPMiniLMForSequenceClassification.forward(self, input_ids, token_type_ids, position_ids, attention_mask)\r\n    270 def forward(self, input_ids, token_type_ids=None, position_ids=None, attention_mask=None):\r\n    271     r\"\"\"\r\n    272     Args:\r\n    273         input_ids (Tensor):\r\n   (...)\r\n    298 \r\n    299     \"\"\"\r\n--> 300     _, pooled_output = self.ppminilm(\r\n    301         input_ids, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask\r\n    302     )\r\n    304     pooled_output = self.dropout(pooled_output)\r\n    305     logits = self.classifier(pooled_output)\r\n\r\nFile /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/nn/layer/layers.py:1426, in Layer.__call__(self, *inputs, **kwargs)\r\n   1417 if (\r\n   1418     (not in_to_static_mode())\r\n   1419     and (not self._forward_pre_hooks)\r\n   (...)\r\n   1423     and (not in_profiler_mode())\r\n   1424 ):\r\n   1425     self._build_once(*inputs, **kwargs)\r\n-> 1426     return self.forward(*inputs, **kwargs)\r\n   1427 else:\r\n   1428     return self._dygraph_call_func(*inputs, **kwargs)\r\n\r\nFile /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddlenlp/transformers/ppminilm/modeling.py:230, in PPMiniLMModel.forward(self, input_ids, token_type_ids, position_ids, attention_mask)\r\n    226     attention_mask = paddle.unsqueeze(\r\n    227         (input_ids == self.pad_token_id).astype(self.pooler.dense.weight.dtype) * -1e4, axis=[1, 2]\r\n    228     )\r\n    229 else:\r\n--> 230     if attention_mask.ndim == 2:\r\n    231         # attention_mask [batch_size, sequence_length] -> [batch_size, 1, 1, sequence_length]\r\n    232         attention_mask = attention_mask.unsqueeze(axis=[1, 2]).astype(paddle.get_default_dtype())\r\n    233         attention_mask = (1.0 - attention_mask) * -1e4\r\n\r\nAttributeError: 'list' object has no attribute 'ndim'\r\n\r\n经过我的甄别，我觉得该函数的attention_mask部分写的有问题：\r\ninput_ids, segment_ids, attention_mask=[None, head_mask])\r\n在这一行代码中，attention_mask=[None, head_mask]，这导致了函数的报错",
        "state": "open",
        "user": "yedaotian9",
        "closed_by": null,
        "created_at": "2024-07-27T17:13:07+00:00",
        "updated_at": "2024-10-08T02:07:09+00:00",
        "closed_at": null,
        "comments_count": [
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1895,
        "title": "运行离线量化脚本quant_post.py失败",
        "body": "使用PaddleSlim/demo/quant/quant_post/quant_post.py静态离线量化ch_ppocr_mobile_v2.0_rec_infer模型：\r\n![image](https://github.com/user-attachments/assets/9f9b3887-6dbc-4bad-a39b-e4e63727945d)\r\n执行命令如下所示：\r\n`python quant_post.py --model_path ./ch_ppocr_mobile_v2.0_rec_infer --save_path ./quant_model/OCRv2_rec`\r\n但是我收到了下面的错误：\r\n![image](https://github.com/user-attachments/assets/309a1497-1e97-4ba4-b132-3354667b840d)\r\n请问我该如何正确离线量化。",
        "state": "open",
        "user": "xdd130",
        "closed_by": null,
        "created_at": "2024-10-17T07:35:26+00:00",
        "updated_at": "2024-11-01T03:41:05+00:00",
        "closed_at": null,
        "comments_count": [
            "FrostML"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1896,
        "title": "本地只有4张4090显卡是否可以使用LoRA训练LLama 3.1 8b的模型",
        "body": "我现在只有4张4090显卡，单卡显存24G，总显存只有96G，是否可以训练LLama 3.1 8b的模型，我现在按照官网文档无法运行成功，请问如何调整参数可以在比较少显存的情况下进行训练",
        "state": "open",
        "user": "yaphet266",
        "closed_by": null,
        "created_at": "2024-10-21T06:54:20+00:00",
        "updated_at": "2024-11-28T07:59:07+00:00",
        "closed_at": null,
        "comments_count": [
            "zzjjay"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1899,
        "title": "自动压缩中使用蒸馏训练后 模型结果异常",
        "body": "原模型精度挺高的 但使用蒸馏训练后模型精度就不对了 把模型输出结果打印出来看后发现不同输入都会得到同一个输出 大佬帮忙看看什么原因呢\r\n---------------------------------------------------------------------------\r\n训练过程中的输出\r\n2024-11-07 09:50:47,799-INFO: start to test metric before compress\r\nEvaluation stage, Run batch:|██████████████████████████████████████████| 447/447\r\n2024-11-07 09:50:49,434-INFO: metric of compressed model is: 0.9664429530201343\r\n2024-11-07 09:50:49,726-INFO: train config.distill_node_pair: ['teacher_elementwise_add_0', 'elementwise_add_0']\r\nI1107 09:50:50.019730 3462931 interpreter_util.cc:648] Standalone Executor is Used.\r\n2024-11-07 09:50:50,217-INFO: Total iter: 0, epoch: 0, batch: 0, loss: 6.939813137054443 l2: 6.939813137054443 \r\n2024-11-07 09:50:50,312-INFO: Total iter: 10, epoch: 0, batch: 10, loss: 6.67962646484375 l2: 6.67962646484375 \r\n2024-11-07 09:50:50,405-INFO: Total iter: 20, epoch: 0, batch: 20, loss: 4.862423419952393 l2: 4.862423419952393 \r\n2024-11-07 09:50:50,498-INFO: Total iter: 30, epoch: 0, batch: 30, loss: 5.843245506286621 l2: 5.843245506286621 \r\n2024-11-07 09:50:50,591-INFO: Total iter: 40, epoch: 0, batch: 40, loss: 1.7612680196762085 l2: 1.7612680196762085 \r\n2024-11-07 09:50:50,685-INFO: Total iter: 50, epoch: 0, batch: 50, loss: 3.830599308013916 l2: 3.830599308013916 \r\n2024-11-07 09:50:50,781-INFO: Total iter: 60, epoch: 0, batch: 60, loss: 2.4715871810913086 l2: 2.4715871810913086 \r\n2024-11-07 09:50:50,873-INFO: Total iter: 70, epoch: 0, batch: 70, loss: 3.5432209968566895 l2: 3.5432209968566895 \r\n2024-11-07 09:50:50,967-INFO: Total iter: 80, epoch: 0, batch: 80, loss: 0.6653429865837097 l2: 0.6653429865837097 \r\n2024-11-07 09:50:51,064-INFO: Total iter: 90, epoch: 0, batch: 90, loss: 2.188952922821045 l2: 2.188952922821045 \r\n2024-11-07 09:50:51,166-INFO: Total iter: 100, epoch: 0, batch: 100, loss: 2.6419882774353027 l2: 2.6419882774353027 \r\n2024-11-07 09:50:51,262-INFO: Total iter: 110, epoch: 0, batch: 110, loss: 3.7801308631896973 l2: 3.7801308631896973 \r\n2024-11-07 09:50:51,355-INFO: Total iter: 120, epoch: 0, batch: 120, loss: 0.8452658653259277 l2: 0.8452658653259277 \r\n2024-11-07 09:50:51,449-INFO: Total iter: 130, epoch: 0, batch: 130, loss: 0.6925385594367981 l2: 0.6925385594367981 \r\n2024-11-07 09:50:51,546-INFO: Total iter: 140, epoch: 0, batch: 140, loss: 1.122310996055603 l2: 1.122310996055603 \r\n2024-11-07 09:50:51,640-INFO: Total iter: 150, epoch: 0, batch: 150, loss: 1.561903953552246 l2: 1.561903953552246 \r\n2024-11-07 09:50:51,735-INFO: Total iter: 160, epoch: 0, batch: 160, loss: 1.165655493736267 l2: 1.165655493736267 \r\n2024-11-07 09:50:51,830-INFO: Total iter: 170, epoch: 0, batch: 170, loss: 1.6543434858322144 l2: 1.6543434858322144 \r\n2024-11-07 09:50:51,924-INFO: Total iter: 180, epoch: 0, batch: 180, loss: 2.673067808151245 l2: 2.673067808151245 \r\n2024-11-07 09:50:52,017-INFO: Total iter: 190, epoch: 0, batch: 190, loss: 0.8985536098480225 l2: 0.8985536098480225 \r\n2024-11-07 09:50:52,110-INFO: Total iter: 200, epoch: 0, batch: 200, loss: 1.004972219467163 l2: 1.004972219467163 \r\n2024-11-07 09:50:52,203-INFO: Total iter: 210, epoch: 0, batch: 210, loss: 1.3521126508712769 l2: 1.3521126508712769 \r\n2024-11-07 09:50:52,296-INFO: Total iter: 220, epoch: 0, batch: 220, loss: 1.9136583805084229 l2: 1.9136583805084229 \r\n2024-11-07 09:50:52,390-INFO: Total iter: 230, epoch: 0, batch: 230, loss: 1.0522427558898926 l2: 1.0522427558898926 \r\n2024-11-07 09:50:52,483-INFO: Total iter: 240, epoch: 0, batch: 240, loss: 1.7291829586029053 l2: 1.7291829586029053 \r\n2024-11-07 09:50:52,577-INFO: Total iter: 250, epoch: 0, batch: 250, loss: 1.1346322298049927 l2: 1.1346322298049927 \r\n2024-11-07 09:50:52,670-INFO: Total iter: 260, epoch: 0, batch: 260, loss: 1.5537294149398804 l2: 1.5537294149398804 \r\n2024-11-07 09:50:52,765-INFO: Total iter: 270, epoch: 0, batch: 270, loss: 1.1103237867355347 l2: 1.1103237867355347 \r\n2024-11-07 09:50:52,859-INFO: Total iter: 280, epoch: 0, batch: 280, loss: 1.165198564529419 l2: 1.165198564529419 \r\n2024-11-07 09:50:52,953-INFO: Total iter: 290, epoch: 0, batch: 290, loss: 1.611351728439331 l2: 1.611351728439331 \r\n2024-11-07 09:50:53,047-INFO: Total iter: 300, epoch: 0, batch: 300, loss: 2.0881824493408203 l2: 2.0881824493408203 \r\n2024-11-07 09:50:53,140-INFO: Total iter: 310, epoch: 0, batch: 310, loss: 1.252273678779602 l2: 1.252273678779602 \r\n2024-11-07 09:50:53,234-INFO: Total iter: 320, epoch: 0, batch: 320, loss: 1.1105802059173584 l2: 1.1105802059173584 \r\n2024-11-07 09:50:53,327-INFO: Total iter: 330, epoch: 0, batch: 330, loss: 1.5239158868789673 l2: 1.5239158868789673 \r\n2024-11-07 09:50:53,420-INFO: Total iter: 340, epoch: 0, batch: 340, loss: 1.9464023113250732 l2: 1.9464023113250732 \r\n2024-11-07 09:50:53,514-INFO: Total iter: 350, epoch: 0, batch: 350, loss: 0.2952193021774292 l2: 0.2952193021774292 \r\n2024-11-07 09:50:53,608-INFO: Total iter: 360, epoch: 0, batch: 360, loss: 0.6373522877693176 l2: 0.6373522877693176 \r\n2024-11-07 09:50:53,709-INFO: Total iter: 370, epoch: 0, batch: 370, loss: 0.74739009141922 l2: 0.74739009141922 \r\n2024-11-07 09:50:53,810-INFO: Total iter: 380, epoch: 0, batch: 380, loss: 1.026517629623413 l2: 1.026517629623413 \r\n2024-11-07 09:50:53,905-INFO: Total iter: 390, epoch: 0, batch: 390, loss: 1.248557448387146 l2: 1.248557448387146 \r\n2024-11-07 09:50:53,999-INFO: Total iter: 400, epoch: 0, batch: 400, loss: 0.1199449747800827 l2: 0.1199449747800827 \r\n2024-11-07 09:50:54,093-INFO: Total iter: 410, epoch: 0, batch: 410, loss: 1.060091257095337 l2: 1.060091257095337 \r\n2024-11-07 09:50:54,187-INFO: Total iter: 420, epoch: 0, batch: 420, loss: 0.37600892782211304 l2: 0.37600892782211304 \r\n2024-11-07 09:50:54,281-INFO: Total iter: 430, epoch: 0, batch: 430, loss: 1.43874990940094 l2: 1.43874990940094 \r\n2024-11-07 09:50:54,374-INFO: Total iter: 440, epoch: 0, batch: 440, loss: 1.549577236175537 l2: 1.549577236175537 \r\n2024-11-07 09:50:54,467-INFO: Total iter: 450, epoch: 0, batch: 450, loss: 1.316918134689331 l2: 1.316918134689331 \r\n2024-11-07 09:50:54,560-INFO: Total iter: 460, epoch: 0, batch: 460, loss: 2.0584702491760254 l2: 2.0584702491760254 \r\n2024-11-07 09:50:54,653-INFO: Total iter: 470, epoch: 0, batch: 470, loss: 2.3895020484924316 l2: 2.3895020484924316 \r\n2024-11-07 09:50:54,747-INFO: Total iter: 480, epoch: 0, batch: 480, loss: 0.838370680809021 l2: 0.838370680809021 \r\n2024-11-07 09:50:54,843-INFO: Total iter: 490, epoch: 0, batch: 490, loss: 1.3764344453811646 l2: 1.3764344453811646 \r\nEvaluation stage, Run batch:|██████████████████████████████████████████| 447/447\r\n2024-11-07 09:50:56,525-INFO: epoch: 0 metric of compressed model is: 0.252796, best metric of compressed model is 0.252796\r\n-------------------------------------------------------------------------\r\n配置文件\r\nGlobal:\r\n  model_dir: MobileNetV1_infer\r\n  model_filename: /home/ai/zgr/classification/MobileNetV4/output/resnet18_pd_1/inference_model/model.pdmodel\r\n  params_filename: /home/ai/zgr/classification/MobileNetV4/output/resnet18_pd_1/inference_model/model.pdiparams\r\n  batch_size: 1\r\n  data_dir: /home/ai/zgr/model_cut/data/flower_datasets\r\n\r\n# ChannelPrune:\r\n#   pruned_ratio: 0.1\r\n#   prune_params_name:\r\n#   - conv2d_0.w_0\r\n#   criterion: l1_norm\r\n  \r\nDistillation:\r\n  alpha: 1.0\r\n  loss: l2\r\n\r\nTrainConfig:\r\n  epochs: 1\r\n  eval_iter: 500\r\n  learning_rate: \r\n    type: CosineAnnealingDecay \r\n    learning_rate: 0.015\r\n  optimizer_builder:\r\n    optimizer:\r\n      type: Momentum\r\n    weight_decay: 0.00002\r\n  origin_metric: 0.9664429530201343\r\n",
        "state": "open",
        "user": "dreamcatcher-zgr",
        "closed_by": null,
        "created_at": "2024-11-07T01:55:29+00:00",
        "updated_at": "2024-11-07T01:55:33+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1904,
        "title": "剪枝后未加速",
        "body": "结构化剪枝后的模型（剪枝率约为45%）与原模型的速度在GPU上测的结果没有提升，但是在CPU上测的结果有大幅提升（剪枝后的模型速度约为未剪枝的两倍），请问这是为什么？剪枝后模型需要额外的GPU设置才能加速吗\r\n剪枝前的部分参数shape如下：\r\nbackbone.conv1.conv1.conv.weight:[64, 3, 7, 7]\r\nbackbone.conv1.conv1.norm.weight:[64]\r\nbackbone.conv1.conv1.norm.bias:[64]\r\nbackbone.conv1.conv1.norm._mean:[64]\r\nbackbone.conv1.conv1.norm._variance:[64]\r\nbackbone.res2.res2a.branch2a.conv.weight:[64, 64, 1, 1]\r\nbackbone.res2.res2a.branch2a.norm.weight:[64]\r\nbackbone.res2.res2a.branch2a.norm.bias:[64]\r\nbackbone.res2.res2a.branch2a.norm._mean:[64]\r\nbackbone.res2.res2a.branch2a.norm._variance:[64]\r\n与之对应的剪枝后的部分参数shape如下：\r\nbackbone.conv1.conv1.conv.weight:[56, 3, 7, 7]\r\nbackbone.conv1.conv1.norm.weight:[56]\r\nbackbone.conv1.conv1.norm.bias:[56]\r\nbackbone.conv1.conv1.norm._mean:[56]\r\nbackbone.conv1.conv1.norm._variance:[56]\r\nbackbone.res2.res2a.branch2a.conv.weight:[40, 56, 1, 1]\r\nbackbone.res2.res2a.branch2a.norm.weight:[40]\r\nbackbone.res2.res2a.branch2a.norm.bias:[40]\r\nbackbone.res2.res2a.branch2a.norm._mean:[40]\r\nbackbone.res2.res2a.branch2a.norm._variance:[40]\r\n\r\n",
        "state": "open",
        "user": "dsdsknfsk",
        "closed_by": null,
        "created_at": "2024-12-19T11:45:53+00:00",
        "updated_at": "2024-12-21T02:26:38+00:00",
        "closed_at": null,
        "comments_count": [
            "dsdsknfsk"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1908,
        "title": "请问下如何使用paddleslim对微调后的uie-m-base模型进行自动压缩",
        "body": "环境：",
        "state": "closed",
        "user": "zwjwhxz",
        "closed_by": "zwjwhxz",
        "created_at": "2025-02-24T09:32:58+00:00",
        "updated_at": "2025-02-24T09:33:28+00:00",
        "closed_at": "2025-02-24T09:33:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1910,
        "title": "ValueError: Input X contains NaN.",
        "body": "在运行量化（PTQ）任务时，当进行平滑量化（Smooth Quantization）并调用 `KMeans` 聚类时，输入数据中出现了 `NaN` 值，导致程序崩溃。该问题发生在模型的 `linear_217` 层。\n\n\nLayer shift_smooth_help_layer_37 Piece piece_1, loss: 0.0002034902572631836, alpha : 4.5\nFind Better K-Piece 2\nSearch 3 Piece\nsearch for piece piece_0; centroids value is 1.232672095298767\nLayer shift_smooth_help_layer_37 Piece piece_0, loss: 0.00023603439331054688, alpha : 1.0\nsearch for piece piece_1; centroids value is 3.4432828426361084\nLayer shift_smooth_help_layer_37 Piece piece_1, loss: 0.0002543926239013672, alpha : 1.0\nsearch for piece piece_2; centroids value is 7.919163227081299\nLayer shift_smooth_help_layer_37 Piece piece_2, loss: 0.00019800662994384766, alpha : 5.5\nFind Better K-Piece 3\n[smooth search] search input of linear_133\nSearch 1 Piece\nsearch for piece piece_0; centroids value is 1.7744877338409424\nLayer linear_133 Piece piece_0, loss: 0.0002846717834472656, alpha : 0.79\nFind Better K-Piece 1\nSearch 2 Piece\nsearch for piece piece_0; centroids value is 1.7283637523651123\nLayer linear_133 Piece piece_0, loss: 0.00033354759216308594, alpha : 1.0\nsearch for piece piece_1; centroids value is 9.28531265258789\nLayer linear_133 Piece piece_1, loss: 0.00025582313537597656, alpha : 2.0\nFind Better K-Piece 2\nLAUNCH INFO 2025-02-28 06:31:39,766 Pod failed\nLAUNCH ERROR 2025-02-28 06:31:39,766 Container failed !!!\nContainer rank 0 status failed cmd ['python', 'run_quantization_peft.py', './config/repllama_02/ptq_argument_fp.json'] code 1 log log/workerlog.0\nLAUNCH INFO 2025-02-28 06:31:39,766 ------------------------- ERROR LOG DETAIL -------------------------\nce_2, loss: 0.0151214599609375, alpha : 0.44\nFind Better K-Piece 3\n[smooth search] search input of linear_217\nSearch 1 Piece\nTraceback (most recent call last):\n  File \"/mnt/ceph_home/[MASKED_NAME]/PaddleNLP/llm/run_quantization_peft.py\", line 722, in <module>\n    main()\n  File \"/mnt/ceph_home/[MASKED_NAME]/PaddleNLP/llm/run_quantization_peft.py\", line 643, in main\n    apply_smooth(quant_args, trainer, ptq_dataloader, ptq_model_config)\n  File \"/mnt/ceph_home/[MASKED_NAME]/PaddleNLP/llm/utils/quant.py\", line 182, in apply_smooth\n    smooth.update_weight()\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/paddleslim-0.0.0.dev0-py3.10.egg/paddleslim/quant/advanced/smooth.py\", line 196, in update_weight\n    s = self.search_function.search(\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/paddleslim-0.0.0.dev0-py3.10.egg/paddleslim/quant/advanced/piecewise_search.py\", line 87, in search\n    centroids, labels = k_means(act_abs_max, k_piece)\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/paddleslim-0.0.0.dev0-py3.10.egg/paddleslim/quant/advanced/utils.py\", line 33, in k_means\n    k_means.fit(weight)\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py\", line 1454, in fit\n    X = validate_data(\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 2944, in validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/mnt/ceph_home/[MASKED_NAME]/miniconda3/envs/paddle/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\nLAUNCH INFO 2025-02-28 06:31:39,766 Exit code 1\n\n\n```bash\n   python -m paddle.distributed.launch --gpus 0,1 \\\n     run_quantization_peft.py \\\n     ./config/repllama/ptq_argument.json\n```\n模型为merge后的castorini/repllama-v1-7b-lora-passage，可以跑通awq_argument.json，但是ptq_argument.json的时候会报错",
        "state": "open",
        "user": "tianyumyum",
        "closed_by": null,
        "created_at": "2025-02-28T08:40:32+00:00",
        "updated_at": "2025-02-28T08:40:37+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1909,
        "title": "请问如何对使用paddleslim 对微调后的uie-m-base模型进行自动压缩？",
        "body": "环境：\npaddlenlp             2.8.1\npaddlepaddle-gpu      2.6.1\npaddleslim            2.6.\n\n使用paddleslim2.6版本中的example/auto_compression/nlp/run_uie.py脚本，运行报错oved in a future version, please use `max_length` instead.\n/appslog/miniconda3/envs/pEnv39/lib/python3.9/site-packages/paddlenlp/transformers/tokenizer_utils_base.py:1912: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\nException in thread Thread-1:\nTraceback (most recent call last):\n  File \"/appslog/miniconda3/envs/pEnv39/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"/appslog/miniconda3/envs/pEnv39/lib/python3.9/threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/appslog/miniconda3/envs/pEnv39/lib/python3.9/site-packages/paddle/io/dataloader/dataloader_iter.py\", line 235, in _thread_loop\n    batch = self._dataset_fetcher.fetch(\n  File \"/appslog/miniconda3/envs/pEnv39/lib/python3.9/site-packages/paddle/io/dataloader/fetcher.py\", line 77, in fetch\n    data.append(self.dataset[idx])\n  File \"/appslog/miniconda3/envs/pEnv39/lib/python3.9/site-packages/paddlenlp/datasets/dataset.py\", line 263, in __getitem__\n    return self._transform(self.new_data[idx]) if self._transform_pipline else self.new_data[idx]\n  File \"/appslog/miniconda3/envs/pEnv39/lib/python3.9/site-packages/paddlenlp/datasets/dataset.py\", line 255, in _transform\n    data = fn(data)\n  File \"/appslog/homezwj/pycharmProject/clsLab/UIE/scriptTrain/compresslim/run_uie_org.py\", line 105, in convert_example\n    \"token_type_ids\": encoded_inputs[\"token_type_ids\"],\nKeyError: 'token_type_ids",
        "state": "open",
        "user": "zwjwhxz",
        "closed_by": null,
        "created_at": "2025-02-24T09:36:30+00:00",
        "updated_at": "2025-02-24T09:36:34+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1907,
        "title": "matmul_v2进行paddleslim自动压缩量化后，不能使用paddlelite进行转换",
        "body": "paddlepaddle2.5.2 paddleslim2.6, paddlelite2.13rc0, python 3.10 平台 x86\n\n目前，我模型中有一个**matmul_v2**算子，我使用**paddleslim**的自动压缩量化后，使用**paddle inference**可以正确推理量化后的模型；但使用paddle_lite_opt --model_dir=./inference_model_q --optimize_out=p --optimize_out_type=naive_buffer --valid_targets=x86 ，报错如下：\n\n1.Model is successfully loaded!\n[F  2/ 3 22:10: 6.227 ...optimizer/mir/static_kernel_pick_pass.cc:180 Apply] Check failed: !instruct.kernels().empty(): No kernels found for matmul_v2\nAborted (core dumped)\n\n如果我不量化**matmul_v2**算子，就能够使用paddle_lite_opt进行转换成nb文件，最终也能推理；\n请问这是**matmul_v2**算子的问题，还是x86平台的问题，我看到x86平台不支持**matmul_v2**算子，但我不量化**matmul_v2**算子，模型也是能正确转换和推理部署的；\n\n",
        "state": "open",
        "user": "sg-goldrush",
        "closed_by": null,
        "created_at": "2025-02-03T14:12:16+00:00",
        "updated_at": "2025-02-05T06:48:19+00:00",
        "closed_at": null,
        "comments_count": [
            "sg-goldrush"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1906,
        "title": "在自动压缩时；ValueError: Incorrect setting for output(s) of operator \"squeeze2\", should set: [XShape]. 报错",
        "body": "D:\\conda\\envs\\onnx_to_paddle\\python.exe D:\\pycharmProject\\onnx_to_paddle\\pd_model\\slim_model.py \nD:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\_distutils_hack\\__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n  warnings.warn(\n2025-01-24 11:32:45,684-WARNING: post-quant-hpo is not support in system other than linux\nI0124 11:32:46.185770  8572 program_interpreter.cc:212] New Executor is Running.\n2025-01-24 11:32:46,196-INFO: devices: cpu\n2025-01-24 11:32:46,228-INFO: Selected strategies: ['qat_dis']\n{'ShapeTensor': [], 'ShapeTensorList': [], 'ValueTensor': []}\n{'X': [var x2paddle_input2 : LOD_TENSOR.shape(-1, 8, 32).dtype(float32).stop_gradient(False)], 'Y': [persist var teacher_x2paddle_gc_0_weight : LOD_TENSOR.shape(32, 512).dtype(float32).stop_gradient(False)]}\n{'X': [var x2paddle_input1 : LOD_TENSOR.shape(-1, 8, 8).dtype(float32).stop_gradient(False)], 'Y': [var teacher_matmul_v2_0.tmp_0 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)]}\n{'X': [var teacher_matmul_v2_1.tmp_0 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)], 'Y': [persist var teacher_x2paddle_gc_0_bias : LOD_TENSOR.shape(512,).dtype(float32).stop_gradient(False)]}\n{'Bias': [persist var teacher_layer_norm_0.b_0 : LOD_TENSOR.shape(512,).dtype(float32).stop_gradient(False)], 'Scale': [persist var teacher_layer_norm_0.w_0 : LOD_TENSOR.shape(512,).dtype(float32).stop_gradient(False)], 'X': [var teacher_elementwise_add_0 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)]}\n{'X': [var teacher_layer_norm_0.tmp_2 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)]}\n{'X': [var teacher_relu_0.tmp_0 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)], 'Y': [persist var teacher_x2paddle_gc_1_weight : LOD_TENSOR.shape(512, 512).dtype(float32).stop_gradient(False)]}\n{'X': [var x2paddle_input1 : LOD_TENSOR.shape(-1, 8, 8).dtype(float32).stop_gradient(False)], 'Y': [var teacher_matmul_v2_2.tmp_0 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)]}\n{'X': [var teacher_matmul_v2_3.tmp_0 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)], 'Y': [persist var teacher_x2paddle_gc_1_bias : LOD_TENSOR.shape(512,).dtype(float32).stop_gradient(False)]}\n{'Bias': [persist var teacher_layer_norm_1.b_0 : LOD_TENSOR.shape(512,).dtype(float32).stop_gradient(False)], 'Scale': [persist var teacher_layer_norm_1.w_0 : LOD_TENSOR.shape(512,).dtype(float32).stop_gradient(False)], 'X': [var teacher_elementwise_add_1 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)]}\n{'X': [var teacher_layer_norm_1.tmp_2 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)]}\n{'Axis': [], 'Index': [var teacher_fill_constant_1.tmp_0 : LOD_TENSOR.shape(1,).dtype(int64).stop_gradient(True)], 'X': [var teacher_relu_1.tmp_0 : LOD_TENSOR.shape(-1, 8, 512).dtype(float32).stop_gradient(False)]}\n{'X': [var teacher_gather_0.tmp_0 : LOD_TENSOR.shape(-1, 1, 512).dtype(float32).stop_gradient(False)]}\nTraceback (most recent call last):\n  File \"D:\\pycharmProject\\onnx_to_paddle\\pd_model\\slim_model.py\", line 75, in <module>\n    ac.compress()\n  File \"D:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 586, in compress\n    self.single_strategy_compress(strategy, config, strategy_idx,\n  File \"D:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 769, in single_strategy_compress\n    train_program_info, test_program_info = self._prepare_program(\n  File \"D:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\paddleslim\\auto_compression\\compressor.py\", line 506, in _prepare_program\n    train_program_info, test_program_info = build_distill_program(\n  File \"D:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\paddleslim\\auto_compression\\create_compressed_program.py\", line 327, in build_distill_program\n    train_program, data_name_map = _load_program_and_merge(\n  File \"D:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\paddleslim\\auto_compression\\create_compressed_program.py\", line 219, in _load_program_and_merge\n    merge(\n  File \"D:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\paddleslim\\dist\\single_distiller.py\", line 197, in merge\n    student_program.global_block().append_op(\n  File \"D:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\paddle\\base\\framework.py\", line 4468, in append_op\n    op = Operator(\n  File \"D:\\conda\\envs\\onnx_to_paddle\\lib\\site-packages\\paddle\\base\\framework.py\", line 3117, in __init__\n    raise ValueError(\nValueError: Incorrect setting for output(s) of operator \"squeeze2\", should set: [XShape].\n\nProcess finished with exit code 1\n\n\n\n\n\n我利用，paddleslim的自动压缩功能，其中有个错误；这里如何解决呢？ \n我模型的gather {'X': [var teacher_gather_0.tmp_0 : LOD_TENSOR.shape(-1, 1, 512).dtype(float32).stop_gradient(False)]} 输出是正常的；应该能输入到squeeze2中吧？\n\n（模型能正常使用paddle inference推理）\n\n![Image](https://github.com/user-attachments/assets/75fd60c0-5307-4401-b0d0-4ebb8434d8fe)",
        "state": "closed",
        "user": "sg-goldrush",
        "closed_by": "sg-goldrush",
        "created_at": "2025-01-24T03:41:36+00:00",
        "updated_at": "2025-01-24T14:51:18+00:00",
        "closed_at": "2025-01-24T14:51:18+00:00",
        "comments_count": [
            "sg-goldrush",
            "sg-goldrush",
            "sg-goldrush"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1911,
        "title": "我利用paddle构建了一个神经网络，用了pygmtools，能正常训练验证和导出模型；目前，在进行自动量化的时候，报错；",
        "body": "版本 : python3.11  paddlepaddle 2.5.1 paddleslim 2.6\n\n\n/Users/benediction/anaconda3/envs/chongda_v2_env/bin/python /Users/benediction/PycharmProjects/chongda_v2/my_slim/gcn_slim.py \n/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n2025-03-08 23:32:01,459-WARNING: post-quant-hpo is not support in system other than linux\ndata数据: [<paddle.fluid.libpaddle.Tensor object at 0x3139c8270>, <paddle.fluid.libpaddle.Tensor object at 0x3139c82b0>]\nI0308 23:32:01.555936 70862912 interpretercore.cc:237] New Executor is Running.\n2025-03-08 23:32:01,562-INFO: devices: cpu\nTraceback (most recent call last):\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddleslim/common/patterns_common.py\", line 76, in is_final_op_with_trainable_var\n    return is_final_op_with_trainable_var(next_op, graph)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddleslim/common/patterns_common.py\", line 76, in is_final_op_with_trainable_var\n    return is_final_op_with_trainable_var(next_op, graph)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddleslim/common/patterns_common.py\", line 76, in is_final_op_with_trainable_var\n    return is_final_op_with_trainable_var(next_op, graph)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [Previous line repeated 991 more times]\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddleslim/common/patterns_common.py\", line 72, in is_final_op_with_trainable_var\n    next_ops = sorted(graph.next_ops(op))\n                      ^^^^^^^^^^^^^^^^^^\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddleslim/core/graph_wrapper.py\", line 347, in next_ops\n    for out_var in op.all_outputs():\n                   ^^^^^^^^^^^^^^^^\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddleslim/core/graph_wrapper.py\", line 132, in all_outputs\n    return [\n           ^\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddleslim/core/graph_wrapper.py\", line 133, in <listcomp>\n    self._graph.var(var_name) for var_name in self._op.output_arg_names\n    ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddleslim/core/graph_wrapper.py\", line 297, in var\n    return VarWrapper(block.var(name), self)\n                      ^^^^^^^^^^^^^^^\n  File \"/Users/benediction/anaconda3/envs/chongda_v2_env/lib/python3.11/site-packages/paddle/fluid/framework.py\", line 3718, in var\n    v = self.vars.get(name, None)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\nRecursionError: maximum recursion depth exceeded while calling a Python object\n\n报错信息如上；\n\n量化代码如下：\n\n\n\nimport json\nimport os\nimport pickle\nimport sys\nimport pygmtools as pygm\nimport paddle\nfrom paddle.io import Dataset, DataLoader\nfrom paddleslim.auto_compression import AutoCompression\nsys.setrecursionlimit(10000)\npaddle.enable_static()\n\ndataset_path = \"../src/data/match_dataset\"\npygm.set_backend(\"paddle\")  # 设置 Paddle 后端\ndevice = paddle.set_device(\"gpu\" if paddle.is_compiled_with_cuda() else \"cpu\")\nmax_size = 32\n\nclass MyDataset(Dataset):\n    def __init__(self, pickle_files, dataset_path):\n        pickle_files = json.load(open(pickle_files))\n        self.data_files = [f\"{dataset_path}/{file}\" for file in pickle_files]\n        self.device = \"cpu\"\n    def __len__(self):\n        return len(self.data_files)\n    def __getitem__(self, index):\n        with open(self.data_files[index], \"rb\") as file:\n            data = pickle.load(file)\n        return tuple(data)\n\ntrain_dataset = MyDataset(f\"{dataset_path}/new_parts.json\", dataset_path)\n\ntrain_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n\n\nac = AutoCompression(\n    model_dir=\"./inference_model\",\n    model_filename=\"inference.pdmodel\",\n    params_filename=\"inference.pdiparams\",\n    save_dir=\"inference_model_q\",\n    # config={\"QuantPost\": {}, \"HyperParameterOptimization\": {'ptq_algo': ['avg'], 'max_quant_count': 3}},\n    config={\"QuantAware\": {'quantize_op_types': [''], 'not_quant_pattern':['skip_quant']},\"Distillation\": {}},  ### 如果您的系统为Windows系统, 请使用当前这一行配置\n    train_dataloader=train_loader,\n    eval_dataloader=train_loader  # 或者另一个验证集的 DataLoader\n)\nac.compress()\n\n\n",
        "state": "closed",
        "user": "sg-goldrush",
        "closed_by": "sg-goldrush",
        "created_at": "2025-03-08T15:42:21+00:00",
        "updated_at": "2025-03-13T02:50:59+00:00",
        "closed_at": "2025-03-13T02:50:59+00:00",
        "comments_count": [
            "sg-goldrush"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleSlim",
        "number": 1912,
        "title": "paddleslim QAT如何量化residual connection",
        "body": "paddleslim QAT如何量化残差连接？\n\n```\nfrom paddle.vision.models import resnet18\nfrom paddleslim import QAT\nnet = resnet18(pretrained=False)\n\nquanter = QAT()\nquanter.quantize(net)\n```\n上面样例只能在conv等计算层前插入QDQ，而残差连接没有被插入QDQ。\n\n<img width=\"522\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e2f65f4e-2813-471f-a991-1683d6ebba89\" />",
        "state": "closed",
        "user": "WeixiangXu",
        "closed_by": "WeixiangXu",
        "created_at": "2025-03-17T14:08:14+00:00",
        "updated_at": "2025-03-19T12:54:47+00:00",
        "closed_at": "2025-03-19T12:54:46+00:00",
        "comments_count": [
            "WeixiangXu"
        ],
        "labels": []
    }
]