[
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 19,
        "title": "Bert with Executor on 2 x 8, 4 x 8, 8 x 8 v100",
        "body": "A follow up scripts of issue\r\nhttps://github.com/PaddlePaddle/Fleet/issues/18",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2019-06-03T16:11:17+00:00",
        "updated_at": "2024-03-06T06:22:43+00:00",
        "closed_at": "2024-03-06T06:22:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 44,
        "title": "新增基于Distribute Transpiler Fleet的训练+预测完整示例",
        "body": "提供一个完整示例。给出一个基于Fleet进行模型预测的说明文档，并link到对应的代码行。",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2019-08-06T00:26:13+00:00",
        "updated_at": "2024-03-06T06:28:55+00:00",
        "closed_at": "2024-03-06T06:28:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 40,
        "title": "fleet模式，训练过程中如何进行模型评估？",
        "body": "paddle-cpu最新版本\r\n单独训练没有问题，能正常收敛。\r\n如果想在训练过程中进行模型评估，要怎么做，目前开源的代码中没有找见。我按如下的fluid.unique_name.guard的方式构造test_program的时候报错。\r\n![image](https://user-images.githubusercontent.com/5926307/62207016-9f0efe80-b3c5-11e9-96ae-d90a61686977.png)\r\n\r\n报错信息：\r\n![image](https://user-images.githubusercontent.com/5926307/62206441-6884b400-b3c4-11e9-966f-5fe131cf2e24.png)\r\n\r\n\r\n代码：\r\n组网部分\r\n![image](https://user-images.githubusercontent.com/5926307/62206606-c74a2d80-b3c4-11e9-9c5b-357ffdadd147.png)\r\n\r\n\r\n\r\n训练代码：\r\n\r\n`import logging\r\nimport multiprocessing\r\nimport os\r\nimport time\r\n\r\nfrom paddle import fluid\r\n\r\nimport nlpt.model.global_key_manager as global_key_manager\r\nfrom nlpt.utils.optimization import optimization\r\nfrom nlpt.utils import log\r\nfrom nlpt.utils.init import init_checkpoint, init_parameters\r\nfrom paddle.fluid.incubate.fleet.parameter_server.distribute_transpiler import fleet\r\nfrom paddle.fluid.incubate.fleet.base import role_maker\r\n\r\n\r\nclass Config(object):\r\n\r\n    # common params\r\n    def __init__(self):\r\n        self.label_map_config = None\r\n        self.do_lower_case = False\r\n        self.use_cuda = True\r\n        self.in_tokens = False\r\n        self.random_seed = 1\r\n        self.lr_scheduler = 'linear_warmup_decay'\r\n        self.use_fp16 = False\r\n        self.loss_scaling = 1.0\r\n        self.weight_decay = 0\r\n        self.init_parameters = None\r\n        self.init_checkpoint = None\r\n        self.use_fast_executor = False\r\n        #self.ernie_config_path = \"./thirdparty/config/ernie_config.json\"\r\n        self.vocab_path = os.path.join(os.path.dirname(__file__) + '/../config/vocab.txt')\r\n        self.verbose = True\r\n        self.is_local = os.getenv(\"PADDLE_IS_LOCAL\", \"0\") == \"1\"\r\n        self.evaluate = \"acc,auc,recall\"\r\n\r\n        # when online should be set default\r\n        self.num_iteration_per_drop_scope = 1\r\n        self.is_ernie = True\r\n\r\n        # default data_config_path\r\n        self.data_config_path = \"../nlpt/config/data_config.json\"\r\n\r\n        # default data path\r\n        self.train_set = \"../train_data/classify\"\r\n        self.test_set = \"../test_data/classify\"\r\n        self.dev_set = \"../thirdparty/dev_data\"\r\n        self.predict_set = \"./thirdparty/classify/predict_data\"\r\n\r\n        # default save model\r\n        self.save_inference_model_path = \"./output/inference_models\"\r\n        self.checkpoints = \"./output/checkpoints\"\r\n\r\n\r\nclass BaseModel(object):\r\n    \"\"\"The `BaseModel` class adds training & evaluation routines to a `Network`.\r\n    \"\"\"\r\n\r\n    def __init__(self, config, create_net):\r\n        print('BaseModel init....')\r\n        self.config = config\r\n        if config.use_cuda:\r\n            place = fluid.CUDAPlace(int(os.getenv('FLAGS_selected_gpus', '0')))\r\n            self.dev_count = fluid.core.get_cuda_device_count()\r\n        else:\r\n            place = fluid.CPUPlace()\r\n            self.dev_count = int(os.environ.get('CPU_NUM', multiprocessing.cpu_count()))\r\n\r\n        self.executor = fluid.Executor(place)\r\n        self.startup_prog = fluid.Program()\r\n\r\n        self.key_dict_manger = global_key_manager.key_dict_manager\r\n\r\n        # multi nodes\r\n        self.num_trainers = 1\r\n        self.trainer_id = 0\r\n        self.is_fleet = False\r\n\r\n        self.create_net = create_net\r\n\r\n        # Todo: replace by warmup_proportion\r\n        self.warmup_steps = 0\r\n\r\n        logging.debug(\"PADDLE_IS_LOCAL:%d\" % config.is_local)\r\n        # init fleet if needed\r\n        if not self.config.use_cuda:\r\n            self.init_fleet_paddle_cloud(config.is_local)\r\n\r\n        self.build_reader()\r\n        logging.debug(\"finish build reader\")\r\n\r\n        self.build_program()\r\n        logging.debug(\"finish build graph\")\r\n\r\n        if self.is_fleet:\r\n            if fleet.is_worker():\r\n                self.set_reader_provider()\r\n        else:\r\n            self.set_reader_provider()\r\n\r\n        if self.config.use_cuda:\r\n            self.prepare_nccl2_env(config.is_local)\r\n            logging.debug(\"finish prepare nccl2 env\")\r\n            # run startup_prog after transpile for nccl2\r\n            self.executor.run(self.startup_prog)\r\n        else:\r\n            self.prepare_fleet_paddle_cloud(config.is_local)\r\n            logging.debug(\"finish prepare fleet env\")\r\n\r\n\r\n        self.load_pretrained_models()\r\n\r\n        self.build_executor()\r\n        logging.debug(\"finish build executor\")\r\n\r\n        # should be executed after self.build_reader() is called\r\n        if self.reader.label_map:\r\n            self.config.label_id2text = {id_label:text_label for text_label, id_label in self.reader.label_map.items()}\r\n\r\n        self.print_config()\r\n\r\n    def print_config(self):\r\n        print(\"*********************************** Task Config **************************************\")\r\n        for k, v in self.config.__dict__.items():\r\n            print(\"{0}:{1}\".format(k, v))\r\n        print(\"**************************************************************************************\")\r\n\r\n    # TODO:need override\r\n    def init_reader(self):\r\n        print(\"init reader...\")\r\n\r\n    def extend_graph_vars(self, create_net):\r\n        \"\"\" add metrics for standard classify task\r\n        \"\"\"\r\n        def wrapper(* config, **kwconfig):\r\n            pyreader, graph_vars = create_net(*config, **kwconfig)\r\n            for k, v in graph_vars.items():\r\n                v.persistable = True\r\n\r\n            return pyreader, graph_vars\r\n\r\n        return wrapper\r\n\r\n    def build_reader(self):\r\n        self.init_reader()\r\n        if not self.reader:\r\n            print(\"reader not init.\")\r\n            return\r\n        if self.is_fleet and fleet.is_server():\r\n            print(\"fleet server not need reader ...\")\r\n            return\r\n        if self.config.do_train:\r\n            self.train_data_generator = self.reader.data_generator(\r\n                data_path=self.config.train_set,\r\n                batch_size=self.config.batch_size,\r\n                epoch=self.config.epoch,\r\n                shuffle=True,\r\n                phase=\"train\")\r\n\r\n        if self.config.do_test:\r\n            self.test_data_generator = self.reader.data_generator(\r\n                data_path=self.config.test_set,\r\n                batch_size=self.config.batch_size,\r\n                epoch=1,\r\n                shuffle=False)\r\n\r\n        if self.config.do_val:\r\n            self.dev_data_generator = self.reader.data_generator(\r\n                data_path=self.config.dev_set,\r\n                batch_size=self.config.batch_size,\r\n                epoch=1,\r\n                shuffle=False)\r\n    \r\n        if self.config.do_predict:\r\n            self.predict_data_generator = self.reader.data_generator(\r\n                data_path=self.config.predict_set,\r\n                batch_size=self.config.batch_size,\r\n                epoch=1,\r\n                shuffle=False,\r\n                phase=\"predict\")\r\n\r\n    def build_program(self):\r\n        self.define_train_program()\r\n        self.define_test_program()\r\n        self.define_infer_program()\r\n\r\n\r\n    def build_executor(self):\r\n        if self.is_fleet:\r\n            exec_strategy = fluid.ExecutionStrategy()\r\n            exec_strategy.num_threads = self.dev_count\r\n            build_strategy = fluid.BuildStrategy()\r\n            build_strategy.async_mode = False\r\n            print(\"CPU_NUM = \", self.dev_count)\r\n            if self.dev_count > 1:\r\n                build_strategy.reduce_strategy = fluid.BuildStrategy.ReduceStrategy.Reduce\r\n\r\n            self.train_exe = fluid.ParallelExecutor(\r\n                use_cuda=self.config.use_cuda,\r\n                loss_name=self.graph_vars[\"loss\"].name,\r\n                main_program=self.train_program,\r\n                build_strategy=build_strategy,\r\n                exec_strategy=exec_strategy)\r\n        else:\r\n            exec_strategy = fluid.ExecutionStrategy()\r\n            exec_strategy.num_iteration_per_drop_scope = self.config.num_iteration_per_drop_scope\r\n            if self.config.use_fast_executor:\r\n                exec_strategy.use_experimental_executor = True\r\n\r\n            self.train_exe = fluid.ParallelExecutor(\r\n                use_cuda=self.config.use_cuda,\r\n                loss_name=self.graph_vars[\"loss\"].name,\r\n                exec_strategy=exec_strategy,\r\n                main_program=self.train_program,\r\n                num_trainers=self.num_trainers,\r\n                trainer_id=self.trainer_id)\r\n\r\n\r\n\r\n    # TODO: need override\r\n    def loss_optimizer(self):\r\n        print(\"init loss_optimizer\")\r\n        if not self.config.use_cuda and not self.config.is_local:\r\n            print(\"is fleet ....\")\r\n            optimizer = fluid.optimizer.Adam(learning_rate=self.config.learning_rate)\r\n            self.optimizer = fleet.distributed_optimizer(optimizer)\r\n            self.optimizer.minimize(self.graph_vars[\"loss\"])\r\n            print(\"minimize fleet paddle cloud...\")\r\n        else:\r\n            # optimizer, scheduled_lr = optimization(\r\n            #     loss=self.graph_vars[\"loss\"],\r\n            #     warmup_steps=self.warmup_steps,\r\n            #     num_train_steps=1000,\r\n            #     learning_rate=self.config.learning_rate,\r\n            #     train_program=self.train_program,\r\n            #     startup_prog=self.startup_prog,\r\n            #     weight_decay=self.config.weight_decay,\r\n            #     scheduler=self.config.lr_scheduler,\r\n            #     use_fp16=self.config.use_fp16,\r\n            #     loss_scaling=self.config.loss_scaling)\r\n            # self.optimizer = optimizer\r\n            self.optimizer = fluid.optimizer.Adam(learning_rate=self.config.learning_rate)\r\n            self.optimizer.minimize(self.graph_vars[\"loss\"])\r\n\r\n    def define_train_program(self):\r\n        self.train_program = fluid.Program()\r\n        with fluid.program_guard(self.train_program, self.startup_prog):\r\n            with fluid.unique_name.guard():\r\n                create_net = self.extend_graph_vars(self.create_net)\r\n                self.train_pyreader, graph_vars = create_net(pyreader_name=\"train_reader\")\r\n                self.graph_vars = self.check_graph_vars(graph_vars)\r\n                self.loss_optimizer()\r\n\r\n\r\n    def define_test_program(self):\r\n        self.test_program = fluid.Program()\r\n        with fluid.program_guard(self.test_program, self.startup_prog):\r\n            with fluid.unique_name.guard():\r\n                create_net = self.extend_graph_vars(self.create_net)\r\n                self.test_pyreader, graph_vars = create_net(pyreader_name=\"test_reader\")\r\n                self.graph_vars = self.check_graph_vars(graph_vars)\r\n        self.test_program = self.test_program.clone(for_test=True)\r\n\r\n    def define_infer_program(self):\r\n        self.infer_program = fluid.Program()\r\n        with fluid.program_guard(self.infer_program, self.startup_prog):\r\n            with fluid.unique_name.guard():\r\n                self.feed_target_names, self.inference_output = self.create_net(pyreader_name=\"infer_reader\", is_inference=True)\r\n        self.infer_program = self.infer_program.clone(for_test=True)\r\n\r\n    def check_graph_vars(self, graph_vars):\r\n        keys = list(graph_vars.keys())\r\n        for k in keys:\r\n            if not self.key_dict_manger.check_key_legitimacy(k):\r\n                del graph_vars[k]\r\n\r\n        print(\"after check \", graph_vars)\r\n        return graph_vars\r\n\r\n    def load_pretrained_models(self):\r\n        config = self.config\r\n        exe = self.executor\r\n\r\n        if config.do_train:\r\n            if config.init_checkpoint and config.init_parameters:\r\n                raise ValueError(\r\n                    \"ERROR: config 'init_checkpoint' and 'init_parameters' \"\r\n                    \"both are set! Only one of them should be set. \"\r\n                    \"if you want warmstart checkpoint keep its learning_rate and moments, plese set 'init_checkpoint'. \"\r\n                    \"if you want warmstart checkpoint with only its parameters, and you want reset a new learning_rate \"\r\n                    \"by config, plese set 'init_parameters'\")\r\n\r\n            if config.init_checkpoint:\r\n                init_checkpoint(\r\n                    exe,\r\n                    config.init_checkpoint,\r\n                    main_program=self.train_program,\r\n                    use_fp16=config.use_fp16)\r\n\r\n            elif config.init_parameters:\r\n                init_parameters(\r\n                    exe,\r\n                    config.init_parameters,\r\n                    main_program=self.train_program,\r\n                    use_fp16=config.use_fp16)\r\n\r\n        elif config.do_val or config.do_test or config.do_predict:\r\n            if config.init_checkpoint:\r\n                init_checkpoint(\r\n                    exe,\r\n                    config.init_checkpoint,\r\n                    main_program=self.train_program,\r\n                    use_fp16=config.use_fp16)\r\n            elif config.init_parameters:\r\n                init_parameters(\r\n                    exe,\r\n                    config.init_parameters,\r\n                    main_program=self.train_program,\r\n                    use_fp16=config.use_fp16)\r\n            else:\r\n                raise ValueError(\"config 'init_checkpoint' or 'init_paramters' should be set if\"\r\n                                 \"only doing validation or testing or predict!\")\r\n\r\n\r\n    # TODO: need to override\r\n    def set_reader_provider(self):\r\n        print(\"set pyreader data provider.\")\r\n        self.use_lod_tensor = True\r\n        self.train_pyreader.decorate_tensor_provider(self.train_data_generator)\r\n        if self.config.do_val or self.config.do_test or self.config.do_predict:\r\n            self.test_pyreader.decorate_tensor_provider(self.test_data_generator)\r\n\r\n    def prepare_nccl2_env(self, is_local):\r\n        if not is_local:\r\n            port = os.getenv(\"PADDLE_PORT\", \"6174\")\r\n            trainers = os.getenv(\"PADDLE_TRAINERS\")  # ip,ip...\r\n            logging.debug(\"trainers form env:{}\".format(trainers))\r\n\r\n            \r\n            trainer_endpoints = []\r\n            for trainer_ip in trainers.split(\",\"):\r\n                trainer_endpoint = \":\".join([trainer_ip, port])\r\n                trainer_endpoints.append(trainer_endpoint)\r\n            trainer_endpoints = \",\".join(trainer_endpoints)\r\n            logging.debug(\"trainers endpoints:{}\".format(trainer_endpoints))\r\n\r\n            #eplist = []\r\n            #for ip in pserver_ips.split(\",\"):\r\n            #    eplist.append(':'.join([ip, port]))\r\n            #pserver_endpoints = \",\".join(eplist)  # ip:port,ip:port...\r\n            num_trainers = int(os.getenv(\"PADDLE_TRAINERS_NUM\", \"0\"))\r\n\r\n            current_endpoint = os.getenv(\"POD_IP\") + \":\" + port\r\n            logging.debug(\"current_endpoint: {}\".format(current_endpoint))\r\n\r\n            trainer_id = int(os.getenv(\"PADDLE_TRAINER_ID\", \"0\"))\r\n\r\n            config = fluid.DistributeTranspilerConfig()\r\n            config.mode = \"nccl2\"\r\n\r\n            t = fluid.DistributeTranspiler(config=config)\r\n            #t.transpile(trainer_id, pservers=pserver_endpoints, trainers=trainers)\r\n            t.transpile(trainer_id, trainers=trainer_endpoints, current_endpoint=current_endpoint, \\\r\n                        program=self.train_program, startup_program=self.startup_prog)\r\n\r\n            self.num_trainers = num_trainers\r\n            self.trainer_id = trainer_id\r\n            logging.debug(\"nccl_num_trainers:{} nccl_trainer_id:{}\".format(self.num_trainers, self.trainer_id))\r\n\r\n\r\n\r\n    def init_fleet_paddle_cloud(self, is_local):\r\n        if is_local:\r\n            self.is_fleet = False\r\n        else:\r\n            role = role_maker.PaddleCloudRoleMaker()\r\n            fleet.init(role)\r\n            self.is_fleet = True\r\n            # self.startup_prog = fleet.startup_program\r\n            print(\"init fleet paddle cloud...\")\r\n\r\n\r\n    def prepare_fleet_paddle_cloud(self, is_local):\r\n        if is_local:\r\n            self.executor.run(self.startup_prog)\r\n        else:\r\n            if fleet.is_server():\r\n                fleet.init_server()\r\n                fleet.run_server()\r\n            elif fleet.is_worker():\r\n                fleet.init_worker()\r\n                self.executor.run(self.startup_prog)\r\n\r\n\r\n    def train(self):\r\n        if self.is_fleet and fleet.is_server():\r\n            print(\"is fleet.server, over\")\r\n            return\r\n        # print(\"worker_index%d start train....\" % fleet.worker_index())\r\n        self.train_pyreader.start()\r\n        steps = 0\r\n        time_begin = time.time()\r\n        fetch_list = ['embedding_0.w_0', 'sequence_conv_0.w_0', 'fc_0.w_0']\r\n        while True:\r\n            try:\r\n                steps += 1\r\n                if steps % self.config.skip_steps != 0:\r\n                    var_emb, var_conv, var_fc = self.train_exe.run(fetch_list=fetch_list)\r\n                    print(\"var_emb is {}\".format(var_emb))\r\n                    print(\"var_conv is {}\".format(var_conv))\r\n                    print(\"var_fc is {}\".format(var_fc))\r\n                    # print(\"all_parameters is {}\".format(fluid.default_main_program().block(0).all_parameters()))\r\n                else:\r\n                    if self.config.verbose:\r\n                        print(\"train pyreader queue size: %d, \" % (self.train_pyreader.queue.size()))\r\n\r\n                    outputs, current_learning_rate = self.evaluate(self.train_exe,\r\n                                                                   self.train_program,\r\n                                                                   self.train_pyreader,\r\n                                                                   self.graph_vars,\r\n                                                                   \"train\",\r\n                                                                   steps)\r\n\r\n                    num_train_examples = self.reader.get_num_examples(self.config.train_set)\r\n                    current_example, current_epoch = self.reader.get_train_progress()\r\n                    time_end = time.time()\r\n                    used_time = time_end - time_begin\r\n                    log_info = \"current_learning_rate: %f, \" % current_learning_rate\r\n                    log_info += \"epoch: %d, progress: %d/%d, step: %d, \" % (\r\n                    current_epoch, current_example, num_train_examples, steps)\r\n                    log_info += \"speed: %f steps/s\" % (self.config.skip_steps / used_time)\r\n                    print(log_info)\r\n\r\n                    try:\r\n                        if outputs:\r\n                            import paddlecloud.visual_util as visualdl\r\n                            x_dic = {\"x_name\": \"step\", \"x_value\": steps}\r\n                            y_ls = []\r\n                            for key, value in outputs.items():\r\n                                y = {}\r\n                                y[\"y_name\"] = key\r\n                                y[\"y_value\"] = value\r\n                                y_ls.append(y)\r\n\r\n                            visualdl.show_fluid_trend(x_dic, y_ls, tag=\"train\")\r\n                    except Exception:\r\n                        print(\"import paddlecloud.visual_util failed\")\r\n\r\n                    time_begin = time.time()\r\n\r\n                if steps % self.config.save_steps == 0:\r\n                    save_checkpoint_path = os.path.join(self.config.checkpoints, \"step_\" + str(steps))\r\n                    fluid.io.save_persistables(self.executor, save_checkpoint_path, self.train_program)\r\n                    # fleet.save_persistables(self.executor, save_checkpoint_path, self.train_program)\r\n                    print(\"save checkpoinmts to %s\" % save_checkpoint_path)\r\n                    # save_inference_model_path = os.path.join(self.config.save_inference_model_path, \"step_\" + str(steps))\r\n                    # fluid.io.save_inference_model(\r\n                    #     save_inference_model_path,\r\n                    #     self.feed_target_names,\r\n                    #     [self.inference_output],\r\n                    #     self.executor,\r\n                    #     main_program=self.infer_program)\r\n                    # print(\"save inference model to %s\" % save_inference_model_path)\r\n\r\n                if steps % self.config.validation_steps == 0:\r\n                    # evaluate dev set\r\n                    if self.config.do_val:\r\n                        self.do_test_val(\"dev\", steps)\r\n                    # evaluate test set\r\n                    if self.config.do_test:\r\n                        self.do_test_val(\"test\", steps)\r\n\r\n            except fluid.core.EOFException:\r\n                save_path = os.path.join(self.config.checkpoints, \"step_\" + str(steps))\r\n                fluid.io.save_persistables(self.executor, save_path, self.train_program)\r\n                # fleet.save_persistables(self.executor, save_checkpoint_path, self.train_program)\r\n                save_inference_model_path = os.path.join(self.config.save_inference_model_path, \"step_\" + str(steps))\r\n                # fleet.save_inference_model(self.executor, save_inference_model_path, self.feed_target_names, [self.inference_output], main_program=self.infer_program)\r\n                # fluid.io.save_inference_model(\r\n                #     save_inference_model_path,\r\n                #     self.feed_target_names,\r\n                #     [self.inference_output],\r\n                #     self.executor,\r\n                #     main_program=self.infer_program)\r\n                # print(\"save inference model to %s\" % (save_inference_model_path))\r\n\r\n                self.train_pyreader.reset()\r\n                if self.is_fleet:\r\n                    fleet.stop_worker()\r\n                break\r\n\r\n        # final eval on dev set\r\n        if self.config.do_val:\r\n            print(\"Final validation result:\")\r\n            self.do_test_val(\"dev\", steps)\r\n\r\n        # final eval on test set\r\n        if self.config.do_test:\r\n            print(\"Final test result:\")\r\n            self.do_test_val(\"test\", steps)\r\n\r\n    def do_test_val(self, eval_phase, step):\r\n        if eval_phase == \"dev\":\r\n            data_generator = self.dev_data_generator\r\n        elif eval_phase == \"test\":\r\n            data_generator = self.test_data_generator\r\n        elif eval_phase == \"predict\":\r\n            data_generator = self.predict_data_generator\r\n        else:\r\n            raise ValueError(\"%s is illegal\" % eval_phase)\r\n\r\n        if self.use_lod_tensor:\r\n            self.test_pyreader.decorate_paddle_reader(data_generator)\r\n        else:\r\n            self.test_pyreader.decorate_tensor_provider(data_generator)\r\n\r\n        outputs, current_learning_rate = self.evaluate(self.executor,\r\n                                                       self.test_program,\r\n                                                       self.test_pyreader,\r\n                                                       self.graph_vars,\r\n                                                       eval_phase,\r\n                                                       step)\r\n        try:\r\n            if outputs and len(outputs) != 0:\r\n                import paddlecloud.visual_util as visualdl\r\n                x_dic = {\"x_name\": \"step\", \"x_value\": step}\r\n                y_ls = []\r\n                for key, value in outputs.items():\r\n                    y = {}\r\n                    y[\"y_name\"] = key\r\n                    y[\"y_value\"] = value\r\n                    y_ls.append(y)\r\n\r\n                visualdl.show_fluid_trend(x_dic, y_ls, tag=eval_phase)\r\n        except Exception:\r\n            print(\"import paddlecloud.visual_util failed\")\r\n\r\n    # TODO: need override\r\n    def evaluate(self, exe, program, pyreader, graph_vars, eval_phase, step):\r\n        print(\"evaluate in base model...\")\r\n\r\n\r\n    def predict(self):\r\n        # Todo:\r\n        logging.debug(\"start do predict\")\r\n        self.do_test_val(\"predict\", 0)\r\n\r\n\r\nlog.init_log(\"./log/test\", level=logging.DEBUG)\r\n`\r\n",
        "state": "closed",
        "user": "Melonzhou",
        "closed_by": "michaelowenliu",
        "created_at": "2019-07-31T11:02:23+00:00",
        "updated_at": "2024-03-06T06:28:49+00:00",
        "closed_at": "2024-03-06T06:28:49+00:00",
        "comments_count": [
            "seiriosPlus",
            "Melonzhou",
            "seiriosPlus",
            "zle1992"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 58,
        "title": "update readme",
        "body": "https://github.com/PaddlePaddle/Fleet/tree/develop/examples/word2vec\r\n",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "guru4elephant",
        "created_at": "2019-08-30T04:52:56+00:00",
        "updated_at": "2019-11-22T05:12:48+00:00",
        "closed_at": "2019-11-22T05:12:48+00:00",
        "comments_count": [
            "MrChengmo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 33,
        "title": "Document and source code do not match",
        "body": "The Example Codes do not match with the Readme",
        "state": "closed",
        "user": "ZHUI",
        "closed_by": "guru4elephant",
        "created_at": "2019-07-10T09:42:02+00:00",
        "updated_at": "2019-08-02T05:21:46+00:00",
        "closed_at": "2019-08-02T05:21:46+00:00",
        "comments_count": [
            "guru4elephant",
            "guru4elephant"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 55,
        "title": "有Fleet使用DGC的示例吗",
        "body": "Fleet的collective源码主要实现了dgc算法，请问有用dgc算法进行分布式训练的示例吗",
        "state": "closed",
        "user": "listenlink",
        "closed_by": "gongweibao",
        "created_at": "2019-08-23T06:07:17+00:00",
        "updated_at": "2022-11-30T04:14:57+00:00",
        "closed_at": "2019-12-04T02:37:23+00:00",
        "comments_count": [
            "guru4elephant",
            "listenlink",
            "wangxicoding",
            "xbinglzh",
            "wangxicoding"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 37,
        "title": "quick start example can not work with launch_ps",
        "body": "```\r\npython -m paddle.distributed.launch_ps --worker_num 2 --server_num 2 distributed_train.py\r\n```\r\ndoes not work",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "guru4elephant",
        "created_at": "2019-07-25T00:08:11+00:00",
        "updated_at": "2019-07-30T01:02:29+00:00",
        "closed_at": "2019-07-30T01:02:29+00:00",
        "comments_count": [
            "guru4elephant"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 18,
        "title": "Bert with Executor on 1 x 1, 1 x 8 v100",
        "body": "Bert model needs a standard benchmark scripts for speed comparison. Previously, Executor has been optimized so that it is comparable with ParallelExecutor on single card. \r\nhttps://github.com/PaddlePaddle/Paddle/pull/17743\r\nhttps://github.com/PaddlePaddle/Paddle/pull/17616\r\nhttps://github.com/PaddlePaddle/Paddle/pull/17536\r\n\r\nTargeting release version = Paddle Fluid 1.5",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2019-06-03T16:09:39+00:00",
        "updated_at": "2024-03-06T06:22:31+00:00",
        "closed_at": "2024-03-06T06:22:31+00:00",
        "comments_count": [
            "guru4elephant"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 34,
        "title": "exe.run方法中报错：paddle.fluid.core_avx.EnforceNotMet: Invoke operator create_double_buffer_reader error.",
        "body": "paddle版本：1.5.0-cpu\r\ncnn分类任务，使用pyreader方式进行数据读取，batch是自己组的，具体代码和错误如下：\r\n`# -*- coding: utf-8 -*\r\nimport sys\r\nsys.path.append(\"../\")\r\nimport collections\r\nimport paddle.fluid as fluid\r\nimport paddle.fluid.param_attr as attr\r\nfrom nlpt.model.base_model import Config\r\nfrom nlpt.encoder.base_encoder import ernie_encoder\r\nfrom nlpt.encoder.base_encoder import custom_encoder_tensor\r\nfrom nlpt.encoder.base_encoder import language_model_encoder\r\nfrom nlpt.encoder.base_encoder import pairwise_matching_encoder\r\nfrom nlpt.model.classify_model import ClassifyModel\r\nfrom nlpt.model.custom_model import CustomModel\r\nfrom nlpt.model.lm_model import LanguageModel\r\nfrom nlpt.model.matching_model import MatchingModel\r\nfrom nlpt.model.sequence_label import SequenceLabelModel\r\n\r\nclass ModelConfig(Config):\r\n    def __init__(self):\r\n        Config.__init__(self)\r\n        self.use_cuda = False  # 使用GPU训练时设置为true，使用CPU训练时设置为false\r\n        self.do_train = True  # 训练模型时设置为ture\r\n        self.do_val = False  # 训练过程中需要进行验证集评估的时候设置为true\r\n        self.do_test = False  # 训练过程中需要进行测试集评估的时候设置为true\r\n        self.do_predict = False  # 如果需要直接做预测，请设置为true\r\n        self.batch_size = 13  # batch_size大小\r\n        self.learning_rate = 2e-5  # 学习率设置\r\n        self.save_steps = 1000  # 模型保存的间隔, 即训练多少个batch之后保存一次模型\r\n        self.weight_decay = 0  # 衰减权重\r\n        self.validation_steps = 100  # 当do_val或者do_test设置为true时生效，表示训练间隔多少个batch之后开始评估和预测\r\n        self.epoch = 5  # 训练多少轮\r\n        self.skip_steps = 10  # 间隔多少个batch时打印训练日志\r\n        self.num_labels = 2  # 分类任务中，类别数量\r\n        self.max_seq_len = 128  # 输入文本的最大长度\r\n        self.is_ernie = False  # 当前任务是基于ernie的时候为true，否则为false\r\n        self.evaluate = \"acc,auc,recall\"  # 评估指标设置，可以设置一到多个评估指标，各指标以逗号隔开，指标包括：acc, auc, recall, precision, f1。\r\n        # 需要做预测或者热启动的时候请填写该参数，其对应的模型为我们在训练过程中存储到./output/checkpoints中的数据\r\n        # self.init_checkpoint = \"./init_model/\"\r\n        self.is_local = True\r\n\r\n\r\ndef create_model(pyreader_name, is_inference=False):\r\n    py_reader, list = custom_encoder_tensor(cfg, pyreader_name)\r\n    text_a = list[0]\r\n    label = list[1]\r\n    text_a_mask = list[2]\r\n    text_a_lens = list[3]\r\n\r\n    dict_dim = 33261\r\n    emb_dim = 128\r\n    hid_dim = 128\r\n    hid_dim2 = 96\r\n    win_size = 3\r\n\r\n    unpad_data = fluid.layers.sequence_unpad(text_a, length=text_a_lens)\r\n\r\n    emb = fluid.layers.embedding(input=unpad_data, size=[dict_dim, emb_dim])\r\n\r\n    conv = fluid.nets.sequence_conv_pool(\r\n        input=emb,\r\n        num_filters=hid_dim,\r\n        filter_size=win_size,\r\n        act=\"tanh\",\r\n        pool_type=\"max\")\r\n\r\n    # full connect layer\r\n    fc_1 = fluid.layers.fc(input=[conv], size=hid_dim2)\r\n\r\n    # softmax layer\r\n    prediction = fluid.layers.fc(input=[fc_1], size=cfg.num_labels, act=\"softmax\")\r\n\r\n    if is_inference:\r\n        feed_targets_name = [text_a.name, text_a_lens.name]\r\n        return feed_targets_name, prediction\r\n\r\n    cost = fluid.layers.cross_entropy(input=prediction, label=label)\r\n    avg_cost = fluid.layers.mean(x=cost)\r\n\r\n    graph_vars = collections.OrderedDict()\r\n    graph_vars[\"loss\"] = avg_cost\r\n    graph_vars[\"classify_infer\"] = prediction\r\n    graph_vars[\"label\"] = label\r\n\r\n    return py_reader, graph_vars\r\n\r\n\r\nif __name__ == '__main__':\r\n    cfg = ModelConfig()\r\n    _, graph_vars = create_model('init')\r\n    if graph_vars.__contains__(\"classify_infer\"):\r\n        model = ClassifyModel(cfg, create_model)\r\n    elif graph_vars.__contains__(\"match_pos_score\"):\r\n        model = MatchingModel(cfg, create_model)\r\n    elif graph_vars.__contains__(\"sequence_label_infer\"):\r\n        model = SequenceLabelModel(cfg, create_model)\r\n    elif graph_vars.__contains__(\"lm_input\"):\r\n        model = LanguageModel(cfg, create_model)\r\n    else:\r\n        model = CustomModel(cfg, create_model)\r\n    if cfg.do_train:\r\n        model.train()\r\n    if cfg.do_predict:\r\n        model.predict()`\r\n\r\n\r\n\r\nmodel.py\r\n\r\n`import logging\r\nimport multiprocessing\r\nimport os\r\nimport time\r\n\r\nfrom paddle import fluid\r\n\r\nimport nlpt.model.global_key_manager as global_key_manager\r\nfrom nlpt.utils.optimization import optimization\r\nfrom nlpt.utils import log\r\nfrom nlpt.utils.init import init_checkpoint, init_parameters\r\nfrom paddle.fluid.incubate.fleet.parameter_server.distribute_transpiler import fleet\r\nfrom paddle.fluid.transpiler.distribute_transpiler import DistributeTranspilerConfig\r\nimport paddle.fluid.incubate.fleet.base.role_maker as role_maker\r\n\r\n\r\nclass Config(object):\r\n\r\n    # common params\r\n    def __init__(self):\r\n        self.label_map_config = None\r\n        self.do_lower_case = False\r\n        self.use_cuda = True\r\n        self.in_tokens = False\r\n        self.random_seed = 1\r\n        self.lr_scheduler = 'linear_warmup_decay'\r\n        self.use_fp16 = False\r\n        self.loss_scaling = 1.0\r\n        self.weight_decay = 0\r\n        self.init_parameters = None\r\n        self.init_checkpoint = None\r\n        self.use_fast_executor = False\r\n        #self.ernie_config_path = \"./thirdparty/config/ernie_config.json\"\r\n        self.vocab_path = os.path.join(os.path.dirname(__file__) + '/../config/vocab.txt')\r\n        self.verbose = True\r\n        self.is_local = os.getenv(\"PADDLE_IS_LOCAL\", \"0\") == \"1\"\r\n        self.evaluate = \"acc,auc,recall\"\r\n\r\n        # when online should be set default\r\n        self.num_iteration_per_drop_scope = 1\r\n        self.is_ernie = True\r\n\r\n        # default data_config_path\r\n        self.data_config_path = \"../nlpt/config/data_config.json\"\r\n\r\n        # default data path\r\n        self.train_set = \"../train_data/classify\"\r\n        self.test_set = \"../test_data/classify\"\r\n        self.dev_set = \"../thirdparty/classify/dev_data/\"\r\n        self.predict_set = \"../thirdparty/classify/predict_data/\"\r\n\r\n        # default save model\r\n        self.save_inference_model_path = \"./output/inference_models\"\r\n        self.checkpoints = \"./output/checkpoints\"\r\n\r\n\r\nclass BaseModel(object):\r\n    \"\"\"The `BaseModel` class adds training & evaluation routines to a `Network`.\r\n    \"\"\"\r\n\r\n    def __init__(self, config, create_net):\r\n        print('BaseModel init....')\r\n        self.config = config\r\n        if config.use_cuda:\r\n            place = fluid.CUDAPlace(int(os.getenv('FLAGS_selected_gpus', '0')))\r\n            self.dev_count = fluid.core.get_cuda_device_count()\r\n        else:\r\n            place = fluid.CPUPlace()\r\n            self.dev_count = int(os.environ.get('CPU_NUM', multiprocessing.cpu_count()))\r\n\r\n        self.executor = fluid.Executor(place)\r\n        self.startup_prog = fluid.Program()\r\n\r\n        self.key_dict_manger = global_key_manager.key_dict_manager\r\n\r\n        # multi nodes\r\n        self.num_trainers = 1\r\n        self.trainer_id = 0\r\n        self.is_fleet = False\r\n\r\n        self.create_net = create_net\r\n\r\n        # Todo: replace by warmup_proportion\r\n        self.warmup_steps = 0\r\n        self.build_reader()\r\n        logging.debug(\"finish build reader\")\r\n\r\n        if not self.config.use_cuda:\r\n            self.init_fleet(config.is_local)\r\n\r\n        self.build_program()\r\n        logging.debug(\"finish build graph\")\r\n\r\n        logging.debug(\"PADDLE_IS_LOCAL:%d\" % config.is_local)\r\n        if self.config.use_cuda:\r\n            self.prepare_nccl2_env(config.is_local)\r\n            logging.debug(\"finish prepare nccl2 env\")\r\n            # run startup_prog after transpile for nccl2\r\n            self.executor.run(self.startup_prog)\r\n        else:\r\n            self.prepare_fleet_2(config.is_local)\r\n            logging.debug(\"finish prepare fleet env\")\r\n\r\n\r\n        self.load_pretrained_models()\r\n\r\n        self.build_executor()\r\n        logging.debug(\"finish build executor\")\r\n\r\n        # should be executed after self.build_reader() is called\r\n        if self.reader.label_map:\r\n            self.config.label_id2text = {id_label:text_label for text_label, id_label in self.reader.label_map.items()}\r\n\r\n        self.print_config()\r\n\r\n    def print_config(self):\r\n        print(\"*********************************** Task Config **************************************\")\r\n        for k, v in self.config.__dict__.items():\r\n            print(\"{0}:{1}\".format(k, v))\r\n        print(\"**************************************************************************************\")\r\n\r\n    # TODO:need override\r\n    def init_reader(self):\r\n        print(\"init reader...\")\r\n\r\n    def extend_graph_vars(self, create_net):\r\n        \"\"\" add metrics for standard classify task\r\n        \"\"\"\r\n        def wrapper(* config, **kwconfig):\r\n            pyreader, graph_vars = create_net(*config, **kwconfig)\r\n            for k, v in graph_vars.items():\r\n                v.persistable = True\r\n\r\n            return pyreader, graph_vars\r\n\r\n        return wrapper\r\n\r\n    def build_reader(self):\r\n        self.init_reader()\r\n        if not self.reader:\r\n            print(\"reader not init.\")\r\n            return\r\n\r\n        if self.config.do_train:\r\n            self.train_data_generator = self.reader.data_generator(\r\n                data_path=self.config.train_set,\r\n                batch_size=self.config.batch_size,\r\n                epoch=self.config.epoch,\r\n                shuffle=True,\r\n                phase=\"train\")\r\n\r\n        if self.config.do_test:\r\n            self.test_data_generator = self.reader.data_generator(\r\n                data_path=self.config.test_set,\r\n                batch_size=self.config.batch_size,\r\n                epoch=1,\r\n                shuffle=False)\r\n\r\n        if self.config.do_val:\r\n            self.dev_data_generator = self.reader.data_generator(\r\n                data_path=self.config.dev_set,\r\n                batch_size=self.config.batch_size,\r\n                epoch=1,\r\n                shuffle=False)\r\n    \r\n        if self.config.do_predict:\r\n            self.predict_data_generator = self.reader.data_generator(\r\n                data_path=self.config.predict_set,\r\n                batch_size=self.config.batch_size,\r\n                epoch=1,\r\n                shuffle=False,\r\n                phase=\"predict\")\r\n\r\n    def build_program(self):\r\n        self.define_train_program()\r\n        self.define_test_program()\r\n        self.define_infer_program()\r\n        self.set_reader_provider()\r\n\r\n    def build_executor(self):\r\n        if self.is_fleet:\r\n            exec_strategy = fluid.ExecutionStrategy()\r\n            exec_strategy.num_threads = int(os.getenv(\"CPU_NUM\"))\r\n            build_strategy = fluid.BuildStrategy()\r\n            build_strategy.async_mode = False\r\n\r\n            if int(os.getenv(\"CPU_NUM\")) > 1:\r\n                build_strategy.reduce_strategy = fluid.BuildStrategy.ReduceStrategy.Reduce\r\n\r\n            self.train_exe = fluid.ParallelExecutor(\r\n                use_cuda=self.config.use_cuda,\r\n                loss_name=self.graph_vars[\"loss\"].name,\r\n                main_program=self.train_program,\r\n                build_strategy=build_strategy,\r\n                exec_strategy=exec_strategy)\r\n        else:\r\n            exec_strategy = fluid.ExecutionStrategy()\r\n            exec_strategy.num_iteration_per_drop_scope = self.config.num_iteration_per_drop_scope\r\n            if self.config.use_fast_executor:\r\n                exec_strategy.use_experimental_executor = True\r\n\r\n            self.train_exe = fluid.ParallelExecutor(\r\n                use_cuda=self.config.use_cuda,\r\n                loss_name=self.graph_vars[\"loss\"].name,\r\n                exec_strategy=exec_strategy,\r\n                main_program=self.train_program,\r\n                num_trainers=self.num_trainers,\r\n                trainer_id=self.trainer_id)\r\n\r\n\r\n\r\n    # TODO: need override\r\n    def loss_optimizer(self):\r\n        print(\"init loss_optimizer\")\r\n        if not self.config.use_cuda and not self.config.is_local:\r\n            print(\"is fleet ....\")\r\n            self.optimizer = fluid.optimizer.Adam(learning_rate=self.config.learning_rate)\r\n        else:\r\n            optimizer, scheduled_lr = optimization(\r\n                loss=self.graph_vars[\"loss\"],\r\n                warmup_steps=self.warmup_steps,\r\n                num_train_steps=1000,\r\n                learning_rate=self.config.learning_rate,\r\n                train_program=self.train_program,\r\n                startup_prog=self.startup_prog,\r\n                weight_decay=self.config.weight_decay,\r\n                scheduler=self.config.lr_scheduler,\r\n                use_fp16=self.config.use_fp16,\r\n                loss_scaling=self.config.loss_scaling)\r\n            self.optimizer = optimizer\r\n\r\n\r\n\r\n\r\n\r\n\r\n    def define_train_program(self):\r\n        if self.is_fleet:\r\n            self.train_program = fleet.main_program\r\n        else:\r\n            self.train_program = fluid.Program()\r\n        with fluid.program_guard(self.train_program, self.startup_prog):\r\n            with fluid.unique_name.guard():\r\n                create_net = self.extend_graph_vars(self.create_net)\r\n                self.train_pyreader, graph_vars = create_net(pyreader_name=\"train_reader\")\r\n                self.graph_vars = self.check_graph_vars(graph_vars)\r\n                self.loss_optimizer()\r\n\r\n\r\n    def define_test_program(self):\r\n        self.test_program = fluid.Program()\r\n        with fluid.program_guard(self.test_program, self.startup_prog):\r\n            with fluid.unique_name.guard():\r\n                create_net = self.extend_graph_vars(self.create_net)\r\n                self.test_pyreader, graph_vars = create_net(pyreader_name=\"test_reader\")\r\n                self.graph_vars = self.check_graph_vars(graph_vars)\r\n        self.test_program = self.test_program.clone(for_test=True)\r\n\r\n\r\n    def define_infer_program(self):\r\n        self.infer_program = fluid.Program()\r\n        with fluid.program_guard(self.infer_program, self.startup_prog):\r\n            with fluid.unique_name.guard():\r\n                self.feed_target_names, self.inference_output = self.create_net(pyreader_name=\"infer_reader\", is_inference=True)\r\n        self.infer_program = self.infer_program.clone(for_test=True)\r\n\r\n    def check_graph_vars(self, graph_vars):\r\n        keys = list(graph_vars.keys())\r\n        for k in keys:\r\n            if not self.key_dict_manger.check_key_legitimacy(k):\r\n                del graph_vars[k]\r\n\r\n        print(\"after check \", graph_vars)\r\n        return graph_vars\r\n\r\n    def load_pretrained_models(self):\r\n        config = self.config\r\n        exe = self.executor\r\n\r\n        if config.do_train:\r\n            if config.init_checkpoint and config.init_parameters:\r\n                raise ValueError(\r\n                    \"ERROR: config 'init_checkpoint' and 'init_parameters' \"\r\n                    \"both are set! Only one of them should be set. \"\r\n                    \"if you want warmstart checkpoint keep its learning_rate and moments, plese set 'init_checkpoint'. \"\r\n                    \"if you want warmstart checkpoint with only its parameters, and you want reset a new learning_rate \"\r\n                    \"by config, plese set 'init_parameters'\")\r\n\r\n            if config.init_checkpoint:\r\n                init_checkpoint(\r\n                    exe,\r\n                    config.init_checkpoint,\r\n                    main_program=self.train_program,\r\n                    use_fp16=config.use_fp16)\r\n\r\n            elif config.init_parameters:\r\n                init_parameters(\r\n                    exe,\r\n                    config.init_parameters,\r\n                    main_program=self.train_program,\r\n                    use_fp16=config.use_fp16)\r\n\r\n        elif config.do_val or config.do_test or config.do_predict:\r\n            if config.init_checkpoint:\r\n                init_checkpoint(\r\n                    exe,\r\n                    config.init_checkpoint,\r\n                    main_program=self.train_program,\r\n                    use_fp16=config.use_fp16)\r\n            elif config.init_parameters:\r\n                init_parameters(\r\n                    exe,\r\n                    config.init_parameters,\r\n                    main_program=self.train_program,\r\n                    use_fp16=config.use_fp16)\r\n            else:\r\n                raise ValueError(\"config 'init_checkpoint' or 'init_paramters' should be set if\"\r\n                                 \"only doing validation or testing or predict!\")\r\n\r\n\r\n    # TODO: need to override\r\n    def set_reader_provider(self):\r\n        print(\"set pyreader data provider.\")\r\n        # self.use_lod_tensor = True\r\n        # self.train_pyreader.decorate_tensor_provider(self.train_data_generator)\r\n        # self.test_pyreader.decorate_tensor_provider(self.test_data_generator)\r\n\r\n    def prepare_nccl2_env(self, is_local):\r\n        if not is_local:\r\n            port = os.getenv(\"PADDLE_PORT\", \"6174\")\r\n            trainers = os.getenv(\"PADDLE_TRAINERS\")  # ip,ip...\r\n            logging.debug(\"trainers form env:{}\".format(trainers))\r\n\r\n            \r\n            trainer_endpoints = []\r\n            for trainer_ip in trainers.split(\",\"):\r\n                trainer_endpoint = \":\".join([trainer_ip, port])\r\n                trainer_endpoints.append(trainer_endpoint)\r\n            trainer_endpoints = \",\".join(trainer_endpoints)\r\n            logging.debug(\"trainers endpoints:{}\".format(trainer_endpoints))\r\n\r\n            #eplist = []\r\n            #for ip in pserver_ips.split(\",\"):\r\n            #    eplist.append(':'.join([ip, port]))\r\n            #pserver_endpoints = \",\".join(eplist)  # ip:port,ip:port...\r\n            num_trainers = int(os.getenv(\"PADDLE_TRAINERS_NUM\", \"0\"))\r\n\r\n            current_endpoint = os.getenv(\"POD_IP\") + \":\" + port\r\n            logging.debug(\"current_endpoint: {}\".format(current_endpoint))\r\n\r\n            trainer_id = int(os.getenv(\"PADDLE_TRAINER_ID\", \"0\"))\r\n\r\n            config = fluid.DistributeTranspilerConfig()\r\n            config.mode = \"nccl2\"\r\n\r\n            t = fluid.DistributeTranspiler(config=config)\r\n            #t.transpile(trainer_id, pservers=pserver_endpoints, trainers=trainers)\r\n            t.transpile(trainer_id, trainers=trainer_endpoints, current_endpoint=current_endpoint, \\\r\n                        program=self.train_program, startup_program=self.startup_prog)\r\n\r\n            self.num_trainers = num_trainers\r\n            self.trainer_id = trainer_id\r\n            logging.debug(\"nccl_num_trainers:{} nccl_trainer_id:{}\".format(self.num_trainers, self.trainer_id))\r\n\r\n    def init_fleet(self, is_local):\r\n        if not is_local:\r\n            trainer_id = int(os.environ[\"PADDLE_TRAINER_ID\"])\r\n            print(\"trainer_id:\", trainer_id)\r\n            trainers = int(os.environ[\"PADDLE_TRAINERS\"])\r\n            print(\"trainers:\", trainers)\r\n            training_role = os.environ[\"PADDLE_TRAINING_ROLE\"]\r\n            training_role = role_maker.Role.WORKER if training_role == \"TRAINER\" else role_maker.Role.SERVER\r\n\r\n            num_trainers = int(os.getenv(\"PADDLE_TRAINERS_NUM\", \"0\"))\r\n            self.num_trainers = num_trainers\r\n            self.trainer_id = trainer_id\r\n            ports = os.getenv(\"PADDLE_PSERVER_PORTS\")\r\n            print(\"ports:\", ports)\r\n            pserver_ip = os.getenv(\"PADDLE_PSERVER_IP\", \"\")\r\n            print(\"pserver_ip:\", pserver_ip)\r\n            pserver_endpoints = []\r\n            for port in ports.split(\",\"):\r\n                pserver_endpoints.append(':'.join([pserver_ip, port]))\r\n\r\n            role = role_maker.UserDefinedRoleMaker(current_id=trainer_id, role=training_role, worker_num=trainers,\r\n                                                   server_endpoints=pserver_endpoints)\r\n\r\n            fleet.init(role_maker=role)\r\n\r\n            self.startup_prog = fleet.startup_program\r\n\r\n\r\n    def prepare_fleet_2(self, is_local):\r\n        if not is_local:\r\n            strategy = DistributeTranspilerConfig()\r\n            # strategy.sync_mode = bool(int(os.getenv(\"DISTRIBUTED_SYNC_MODE\")))\r\n            strategy.sync_mode = True\r\n            optimizer = fleet.distributed_optimizer(self.optimizer, strategy)\r\n            optimizer.minimize(self.graph_vars[\"loss\"])\r\n\r\n            print(\"minimize fleet2 ...\")\r\n            if fleet.is_server():\r\n                # with open(\"pserver.proto.{}\".format(fleet.server_endpoints()[fleet.server_index()]), \"w\") as f:\r\n                #     f.write(str(fleet.main_program))\r\n                fleet.init_server()\r\n                fleet.run_server()\r\n            elif fleet.is_worker():\r\n                fleet.init_worker()\r\n                self.executor.run(self.startup_prog)\r\n                # train_loop(fleet.main_program, fleet.worker_index() == 0)\r\n                # fleet.stop_worker()\r\n            print(\"fleet_num_trainers:{} fleet_trainer_id:{}\".format(self.num_trainers, self.trainer_id))\r\n            self.is_fleet = True\r\n        else:\r\n            self.executor.run(self.startup_prog)\r\n\r\n\r\n\r\n    def prepare_fleet(self, is_local):\r\n        if not is_local:\r\n            pserver_endpoints = os.getenv(\"PADDLE_PSERVER_ENDPOINTS\")\r\n            pserver_endpoints = pserver_endpoints.split(\",\")\r\n\r\n            role = role_maker.UserDefinedRoleMaker(\r\n                current_id=int(os.getenv(\"CURRENT_ID\")),\r\n                role=role_maker.Role.WORKER if bool(int(os.getenv(\"IS_WORKER\"))) else role_maker.Role.SERVER,\r\n                worker_num=int(os.getenv(\"WORKER_NUM\")),\r\n                server_endpoints=pserver_endpoints\r\n            )\r\n\r\n            fleet.init(role_maker=role)\r\n            strategy = DistributeTranspilerConfig()\r\n            strategy.sync_mode = bool(int(os.getenv(\"DISTRIBUTED_SYNC_MODE\")))\r\n            optimizer = fleet.distributed_optimizer(self.optimizer, strategy)\r\n            optimizer.minimize(self.graph_vars[\"loss\"])\r\n\r\n            print(\"minimize fleet ...\")\r\n            if fleet.is_server():\r\n                with open(\"pserver.proto.{}\".format(fleet.server_endpoints()[fleet.server_index()]), \"w\") as f:\r\n                    f.write(str(fleet.main_program))\r\n                fleet.init_server()\r\n                fleet.run_server()\r\n            elif fleet.is_worker():\r\n                fleet.init_worker()\r\n                self.executor.run(fleet.startup_program)\r\n                # train_loop(fleet.main_program, fleet.worker_index() == 0)\r\n                # fleet.stop_worker()\r\n        else:\r\n            self.executor.run(self.startup_prog)\r\n\r\n\r\n\r\n    def train(self):\r\n        print(\"start train....\")\r\n        self.train_pyreader.start()\r\n        steps = 0\r\n        time_begin = time.time()\r\n        while True:\r\n            try:\r\n                steps += 1\r\n                if steps % self.config.skip_steps != 0:\r\n                    self.train_exe.run(fetch_list=[])\r\n                else:\r\n                    if self.config.verbose:\r\n                        print(\"train pyreader queue size: %d, \" % self.train_pyreader.queue.size())\r\n\r\n                    outputs, current_learning_rate = self.evaluate(self.train_exe,\r\n                                                                   self.train_program,\r\n                                                                   self.train_pyreader,\r\n                                                                   self.graph_vars,\r\n                                                                   \"train\",\r\n                                                                   steps)\r\n\r\n                    num_train_examples = self.reader.get_num_examples(self.config.train_set)\r\n                    current_example, current_epoch = self.reader.get_train_progress()\r\n                    time_end = time.time()\r\n                    used_time = time_end - time_begin\r\n\r\n                    log_info = \"current_learning_rate: %f, \" % current_learning_rate\r\n                    log_info += \"epoch: %d, progress: %d/%d, step: %d, \" % (\r\n                    current_epoch, current_example, num_train_examples, steps)\r\n                    log_info += \"speed: %f steps/s\" % (self.config.skip_steps / used_time)\r\n                    print(log_info)\r\n\r\n                    try:\r\n                        if outputs:\r\n                            import paddlecloud.visual_util as visualdl\r\n                            x_dic = {\"x_name\": \"step\", \"x_value\": steps}\r\n                            y_ls = []\r\n                            for key, value in outputs.items():\r\n                                y = {}\r\n                                y[\"y_name\"] = key\r\n                                y[\"y_value\"] = value\r\n                                y_ls.append(y)\r\n\r\n                            visualdl.show_fluid_trend(x_dic, y_ls, tag=\"train\")\r\n                    except Exception:\r\n                        print(\"import paddlecloud.visual_util failed\")\r\n\r\n                    time_begin = time.time()\r\n\r\n                if steps % self.config.save_steps == 0:\r\n                    save_checkpoint_path = os.path.join(self.config.checkpoints, \"step_\" + str(steps))\r\n                    fluid.io.save_persistables(self.executor, save_checkpoint_path, self.train_program)\r\n                    print(\"save checkpoinmts to %s\" % save_checkpoint_path)\r\n                    save_inference_model_path = os.path.join(self.config.save_inference_model_path, \"step_\" + str(steps))\r\n                    fluid.io.save_inference_model(\r\n                        save_inference_model_path,\r\n                        self.feed_target_names,\r\n                        [self.inference_output],\r\n                        self.executor,\r\n                        main_program=self.infer_program)\r\n                    print(\"save inference model to %s\" % save_inference_model_path)\r\n\r\n                if steps % self.config.validation_steps == 0:\r\n                    # evaluate dev set\r\n                    if self.config.do_val:\r\n                        self.do_test_val(\"dev\", steps)\r\n                    # evaluate test set\r\n                    if self.config.do_test:\r\n                        self.do_test_val(\"test\", steps)\r\n\r\n            except fluid.core.EOFException:\r\n                save_path = os.path.join(self.config.checkpoints, \"step_\" + str(steps))\r\n                fluid.io.save_persistables(self.executor, save_path, self.train_program)\r\n                save_inference_model_path = os.path.join(self.config.save_inference_model_path, \"step_\" + str(steps))\r\n                fluid.io.save_inference_model(\r\n                    save_inference_model_path,\r\n                    self.feed_target_names,\r\n                    [self.inference_output],\r\n                    self.executor,\r\n                    main_program=self.infer_program)\r\n                print(\"save inference model to %s\" % save_inference_model_path)\r\n\r\n                self.train_pyreader.reset()\r\n                break\r\n\r\n        # final eval on dev set\r\n        if self.config.do_val:\r\n            print(\"Final validation result:\")\r\n            self.do_test_val(\"dev\", steps)\r\n\r\n        # final eval on test set\r\n        if self.config.do_test:\r\n            print(\"Final test result:\")\r\n            self.do_test_val(\"test\", steps)\r\n\r\n    def do_test_val(self, eval_phase, step):\r\n        if eval_phase == \"dev\":\r\n            data_generator = self.dev_data_generator\r\n        elif eval_phase == \"test\":\r\n            data_generator = self.test_data_generator\r\n        elif eval_phase == \"predict\":\r\n            data_generator = self.predict_data_generator\r\n        else:\r\n            raise ValueError(\"%s is illegal\" % eval_phase)\r\n\r\n        if self.use_lod_tensor:\r\n            self.test_pyreader.decorate_paddle_reader(data_generator)\r\n        else:\r\n            self.test_pyreader.decorate_tensor_provider(data_generator)\r\n\r\n        outputs, current_learning_rate = self.evaluate(self.executor,\r\n                                                       self.test_program,\r\n                                                       self.test_pyreader,\r\n                                                       self.graph_vars,\r\n                                                       eval_phase,\r\n                                                       step)\r\n        try:\r\n            if outputs and len(outputs) != 0:\r\n                import paddlecloud.visual_util as visualdl\r\n                x_dic = {\"x_name\": \"step\", \"x_value\": step}\r\n                y_ls = []\r\n                for key, value in outputs.items():\r\n                    y = {}\r\n                    y[\"y_name\"] = key\r\n                    y[\"y_value\"] = value\r\n                    y_ls.append(y)\r\n\r\n                visualdl.show_fluid_trend(x_dic, y_ls, tag=eval_phase)\r\n        except Exception:\r\n            print(\"import paddlecloud.visual_util failed\")\r\n\r\n    # TODO: need override\r\n    def evaluate(self, exe, program, pyreader, graph_vars, eval_phase, step):\r\n        print(\"evaluate in base model...\")\r\n\r\n\r\n    def predict(self):\r\n        # Todo:\r\n        logging.debug(\"start do predict\")\r\n        self.do_test_val(\"predict\", 0)\r\n\r\n\r\nlog.init_log(\"./log/test\", level=logging.DEBUG)\r\n`\r\n\r\n错误信息：\r\n![image](https://user-images.githubusercontent.com/5926307/61427204-de623780-a94f-11e9-9856-e1fc28afd6c0.png)\r\n![image](https://user-images.githubusercontent.com/5926307/61427209-e3bf8200-a94f-11e9-9714-b3b0c61db8a8.png)\r\n",
        "state": "closed",
        "user": "Melonzhou",
        "closed_by": "guru4elephant",
        "created_at": "2019-07-18T03:33:47+00:00",
        "updated_at": "2019-07-30T01:02:44+00:00",
        "closed_at": "2019-07-30T01:02:44+00:00",
        "comments_count": [
            "seiriosPlus",
            "Melonzhou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 62,
        "title": "[feature request]make slot features and slot values for each trainer desc",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2019-09-09T04:50:51+00:00",
        "updated_at": "2024-03-06T06:29:23+00:00",
        "closed_at": "2024-03-06T06:29:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 59,
        "title": "Fleet ps on paddlecloud coredump when stop",
        "body": "env: paddle 1.5.1 with fleet， 1 ps, 2 trainers, use dataset\r\n\r\nps and worker0 stop success, but worker1 coredump\r\ntrainer failed, exit_code=134\r\npure virtual method called\r\nterminate called without an active exception\r\npure virtual method called\r\nterminate called recursively\r\n./thirdparty/paddle_cpu/bin/python: line 11:  2727 Aborted                 (core dumped) $SCRIPTPATH/python \"$@\"\r\n*********************error messages********************",
        "state": "closed",
        "user": "anpark",
        "closed_by": "michaelowenliu",
        "created_at": "2019-08-31T04:06:43+00:00",
        "updated_at": "2024-03-06T06:29:03+00:00",
        "closed_at": "2024-03-06T06:29:03+00:00",
        "comments_count": [
            "seiriosPlus",
            "anpark",
            "anpark"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 72,
        "title": "subprocess.CalledProcessError 。。。returned non-zero exit status 1",
        "body": "在孔明集群中运行collective_operators，出现错误：\r\n+ ./python2_paddle150/bin/python -m paddle.distributed.launch --selected_gpus=0,1,2,3,4,5,6,7 --log_dir mylog ./train.py --model=ResNet50 --batch_size=8 --total_images=1281167 --data_dir=./ --class_dim=100 --image_shape=3,224,224 --model_save_dir=./output --lr=0.1 --num_epochs=90 --l2_decay=1e-4 --nccl_comm_num=2 WARNING: Logging before InitGoogleLogging() is written to STDERR I1002 15:31:38.199759 1621 init.cc:67] Init commandline: dummy /home/slurm/job/tmp/job-136870/python2_paddle150/lib/python2.7/site-packages/paddle/distributed/launch.py --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,initial_cpu_memory_in_mb,init_allocated_mem,free_idle_memory,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_pinned_memory,cpu_deterministic,use_mkldnn,rpc_deadline,rpc_server_profile_path,enable_rpc_profiler,rpc_send_thread_num,rpc_get_thread_num,rpc_prefetch_thread_num,rpc_disable_reuse_port,communicator_independent_recv_thread,communicator_send_queue_size,communicator_min_send_grad_num_before_recv,communicator_thread_pool_size,communicator_max_merge_var_num,communicator_fake_rpc,communicator_send_wait_times,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,cudnn_deterministic,enable_cublas_tensor_op_math,conv_workspace_size_limit,cudnn_exhaustive_search,selected_gpus,sync_nccl_allreduce,limit_of_tmp_allocation,times_excess_than_required_tmp_allocation,enable_inplace_whitelist,cudnn_batchnorm_spatial_persistent  Traceback (most recent call last): File \"/home/slurm/job/tmp/job-136870/python2_paddle150/lib/python2.7/runpy.py\", line 174, in _run_module_as_main \"__main__\", fname, loader, pkg_name) File \"/home/slurm/job/tmp/job-136870/python2_paddle150/lib/python2.7/runpy.py\", line 72, in _run_code exec code in run_globals File \"/home/slurm/job/tmp/job-136870/python2_paddle150/lib/python2.7/site-packages/paddle/distributed/launch.py\", line 222, in <module> launch() File \"/home/slurm/job/tmp/job-136870/python2_paddle150/lib/python2.7/site-packages/paddle/distributed/launch.py\", line 218, in launch start_procs(args) File \"/home/slurm/job/tmp/job-136870/python2_paddle150/lib/python2.7/site-packages/paddle/distributed/launch.py\", line 211, in start_procs returncode=procs[i].returncode, cmd=cmds[i]) subprocess.CalledProcessError: Command '['/home/slurm/job/tmp/job-136870/python2_paddle150/bin/python', '-u', './train.py', '--model=ResNet50', '--batch_size=8', '--total_images=1281167', '--data_dir=./', '--class_dim=100', '--image_shape=3,224,224', '--model_save_dir=./output', '--lr=0.1', '--num_epochs=90', '--l2_decay=1e-4', '--nccl_comm_num=2']' returned non-zero exit status 1 \r\n\r\n，对于原始的demo修改了run.sh\r\n\r\n#!/bin/bash\r\n\r\nexport LD_LIBRARY_PATH=/home/work/cuda-9.0/lib64:$LD_LIBRARY_PATH\r\nexport LD_LIBRARY_PATH=/home/work/cudnn/cudnn_v7/cuda/lib64:$LD_LIBRARY_PATH\r\nexport LD_LIBRARY_PATH=$PWD/nccl_2.3.5/lib/:$LD_LIBRARY_PATH\r\n\r\n\r\nexport FLAGS_cudnn_exhaustive_search=0\r\nexport GLOG_v=1\r\nexport GLOG_logtostderr=1\r\nexport FLAGS_eager_delete_tensor_gb=0\r\nexport NCCL_DEBUG=INFO\r\n# Unset proxy\r\nunset https_proxy http_proxy\r\nset -xe\r\n\r\nMODEL=ResNet50 #VGG16\r\nMODEL_SAVE_PATH=\"./output\"\r\n\r\n# training params\r\nNUM_EPOCHS=90\r\nBATCH_SIZE=8\r\nLR=0.1\r\n\r\n# data params\r\n# the path of the data set\r\nDATA_PATH=\"./\"\r\nTOTAL_IMAGES=1281167\r\nCLASS_DIM=100\r\nIMAGE_SHAPE=3,224,224\r\n\r\n# gpu params\r\nNCCL_COMM_NUM=2\r\nset -x\r\nconfig=\"--selected_gpus=0,1,2,3,4,5,6,7 --log_dir mylog\"\r\ntouch ./utils/__init__.py\r\n./python2_paddle150/bin/python -m paddle.distributed.launch ${config} \\\r\n       ./train.py \\\r\n       --model=${MODEL} \\\r\n       --batch_size=${BATCH_SIZE} \\\r\n       --total_images=${TOTAL_IMAGES} \\\r\n       --data_dir=${DATA_PATH} \\\r\n       --class_dim=${CLASS_DIM} \\\r\n       --image_shape=${IMAGE_SHAPE} \\\r\n       --model_save_dir=${MODEL_SAVE_PATH} \\\r\n       --lr=${LR} \\\r\n       --num_epochs=${NUM_EPOCHS} \\\r\n       --l2_decay=1e-4 \\\r\n       --nccl_comm_num=2 \\\r\n\r\n该脚本作为submit命令 job-script参数。\r\n麻烦帮忙解答。\r\n\r\n",
        "state": "closed",
        "user": "bit-pku-zdf",
        "closed_by": "michaelowenliu",
        "created_at": "2019-10-03T06:32:08+00:00",
        "updated_at": "2024-03-06T06:29:29+00:00",
        "closed_at": "2024-03-06T06:29:29+00:00",
        "comments_count": [
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 87,
        "title": "多卡训练时，每个step运行后是merge所有卡的梯度，还是只merge当前卡的梯度？",
        "body": "比如我用2台机器，共16卡，每次训练一个step之后进行测试，那么这个时候测试的模型是merge所有gpu的梯度的模型，还是只是merge了当前这张卡的梯度呢？",
        "state": "closed",
        "user": "sandyhouse",
        "closed_by": "sandyhouse",
        "created_at": "2019-10-24T11:12:23+00:00",
        "updated_at": "2019-10-24T11:12:57+00:00",
        "closed_at": "2019-10-24T11:12:57+00:00",
        "comments_count": [
            "sandyhouse",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 74,
        "title": "*** SIGTERM (@0x38400000db2) received by PID 5342 (TID 0x7efe568a6700) from PID 3506; stack trace: ***",
        "body": "在孔明集群中运行collective demo，出现如下错误\r\n\r\nWARNING:root:set nccl_comm_num=1 since you only have 1 node. server not ready, wait 3 sec to retry... not ready endpoints:['127.0.0.1:6171', '127.0.0.1:6172', '127.0.0.1:6173', '127.0.0.1:6174', '127.0.0.1:6175', '127.0.0.1:6176', '127.0.0.1:6177'] server not ready, wait 3 sec to retry... not ready endpoints:['127.0.0.1:6171', '127.0.0.1:6172', '127.0.0.1:6173', '127.0.0.1:6174', '127.0.0.1:6175', '127.0.0.1:6176', '127.0.0.1:6177'] server not ready, wait 3 sec to retry... not ready endpoints:['127.0.0.1:6171', '127.0.0.1:6172', '127.0.0.1:6173', '127.0.0.1:6174', '127.0.0.1:6175', '127.0.0.1:6176', '127.0.0.1:6177'] W1005 11:17:27.760031 5342 init.cc:212] *** Aborted at 1570245447 (unix time) try \"date -d @1570245447\" if you are using GNU date *** W1005 11:17:27.761384 5342 init.cc:212] PC: @ 0x0 (unknown) W1005 11:17:27.761484 5342 init.cc:212] *** SIGTERM (@0x38400000db2) received by PID 5342 (TID 0x7efe568a6700) from PID 3506; stack trace: *** W1005 11:17:27.762459 5342 init.cc:212] @ 0x7efe5647d160 (unknown) W1005 11:17:27.763466 5342 init.cc:212] @ 0x7efe55a95ed3 __GI_select W1005 11:17:27.764262 5342 init.cc:212] @ 0x7efe4aa9b2ad time_sleep W1005 11:17:27.764425 5342 init.cc:212] @ 0x4b8934 PyEval_EvalFrameEx W1005 11:17:27.764565 5342 init.cc:212] @ 0x4b88af PyEval_EvalFrameEx W1005 11:17:27.764710 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.764847 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.764991 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.765123 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.765264 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.765395 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.765534 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.765666 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.765805 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.765940 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.766070 5342 init.cc:212] @ 0x4b88af PyEval_EvalFrameEx W1005 11:17:27.766199 5342 init.cc:212] @ 0x4b88af PyEval_EvalFrameEx W1005 11:17:27.766336 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.766465 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.766604 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.766733 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.766877 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.767011 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.767155 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.767288 5342 init.cc:212] @ 0x4b83b7 PyEval_EvalFrameEx W1005 11:17:27.767426 5342 init.cc:212] @ 0x4ba7c8 PyEval_EvalCodeEx W1005 11:17:27.767554 5342 init.cc:212] @ 0x4ba8f2 PyEval_EvalCode W1005 11:17:27.767681 5342 init.cc:212] @ 0x4e6e9d PyRun_FileExFlags W1005 11:17:27.767832 5342 init.cc:212] @ 0x4e8721 PyRun_SimpleFileExFlags W1005 11:17:27.767956 5342 init.cc:212] @ 0x415bbd Py_Main W1005 11:17:27.768987 5342 init.cc:212] @ 0x7efe559d7bd5 __libc_start_main W1005 11:17:27.769170 5342 init.cc:212] @ 0x414d51 (unknown)\r\n\r\njob 地址\r\nhttp://yq01-sys-hic-p40-0189.yq01.baidu.com:8388/v1/slurmjobs/137316/workspace\r\n麻烦哪位大神可以帮忙解决，万分感谢",
        "state": "closed",
        "user": "bit-pku-zdf",
        "closed_by": "sandyhouse",
        "created_at": "2019-10-05T09:10:42+00:00",
        "updated_at": "2019-10-08T12:25:30+00:00",
        "closed_at": "2019-10-08T12:25:30+00:00",
        "comments_count": [
            "sandyhouse",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 85,
        "title": "Image-Text Matching example ",
        "body": "\r\nA distributed training example of image-text matching is needed. In detail, validation can be performed during training every several epochs.",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "gongweibao",
        "created_at": "2019-10-23T02:00:47+00:00",
        "updated_at": "2019-10-25T01:12:05+00:00",
        "closed_at": "2019-10-25T01:12:05+00:00",
        "comments_count": [
            "bit-pku-zdf",
            "bit-pku-zdf",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 95,
        "title": "Can't load images.",
        "body": "Hi, I want to run the following command:\r\n```CUDA_VISIBLE_DEVICES=0 python -m paddle.distributed.launch --selected_gpus=0 train_with_fleet.py --batch_size=128 --model=ResNet50 --total_images=50000 --data_dir=/data/PaddlePaddle/imagenet/```\r\nbut I get `'NoneType' object has no attribute 'shape'`, which means that probably images couldn't be found.\r\n\r\nInside `imagenet` directory I have `train_list.txt` and `train` dir, where in `train_list.txt` I point to images inside `train` direcotry. This works just fine for `PaddlePaddle/models/` repository when I run resnet50 from there. Here it doesn't work. At first I got error that `train.txt` doesn't exist, so I created it, just renamed my previous `train_list.txt`, but it still doesn't work. \r\n\r\nCould you clarify what the structure of the directory with dataset should look like??\r\n\r\n",
        "state": "closed",
        "user": "ghost",
        "closed_by": "michaelowenliu",
        "created_at": "2019-10-30T12:55:33+00:00",
        "updated_at": "2024-03-06T06:29:43+00:00",
        "closed_at": "2024-03-06T06:29:43+00:00",
        "comments_count": [
            "sandyhouse",
            "ghost",
            "sandyhouse",
            "ghost",
            "sandyhouse",
            "ghost",
            "sandyhouse"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 160,
        "title": "python3 下 example的ctr模型报错",
        "body": "https://github.com/PaddlePaddle/Fleet/blob/develop/examples/ctr/criteo_reader.py#L54\r\n这句话在python3和python2下不同，所以要么要list()包一下，要么在paddle在_gen_str()需要判断一下.",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "michaelowenliu",
        "created_at": "2020-03-26T02:41:40+00:00",
        "updated_at": "2024-03-06T06:29:59+00:00",
        "closed_at": "2024-03-06T06:29:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 157,
        "title": "Why not compile the main program in the _try_to_compile() function in collective mode?",
        "body": "```python \r\ndef _try_to_compile(self, startup_program, main_program):\r\n        node_num = self._node_num()\r\n        assert node_num >= 1, \"nccl2 node_num must >= 1, now:{}\" % node_num\r\n\r\n        exec_strategy = self._strategy.exec_strategy\r\n\r\n        if node_num <= 1:\r\n            if self._strategy.nccl_comm_num > 1:\r\n                logging.warn(\"set nccl_comm_num=1 since you only have 1 node.\")\r\n            self._strategy.nccl_comm_num = 1\r\n\r\n            if self._strategy.use_hierarchical_allreduce:\r\n                logging.warn(\r\n                    \"set use_hierarchical_allreduce=False since you only have 1 node.\"\r\n                )\r\n            self._strategy.use_hierarchical_allreduce = False\r\n\r\n        sync_allreduce = os.getenv(\"FLAGS_sync_nccl_allreduce\")\r\n        if sync_allreduce is None or sync_allreduce == \"1\":\r\n            exec_strategy.num_threads = self._strategy.nccl_comm_num + 1\r\n            if self._strategy.use_hierarchical_allreduce:\r\n                exec_strategy.num_threads = 2 * self._strategy.nccl_comm_num + 1\r\n            if exec_strategy.num_threads > 4:\r\n                logging.warn(\r\n                    \"if you use use_hierarchical_allreduce or \"\r\n                    \"with multi nccl comm, please export FLAGS_sync_nccl_allreduce = 0\"\r\n                )\r\n\r\n        # NOTE. open sync_batch_norm will hang when use multi num_threads\r\n        sync_batch_norm = self._strategy.sync_batch_norm\r\n        if sync_batch_norm is not None and sync_batch_norm is True:\r\n            self._strategy.nccl_comm_num = 1\r\n            self._strategy.use_hierarchical_allreduce = False\r\n            exec_strategy.num_threads = 1\r\n            logging.warn(\r\n                \"use sync_batch_norm will hang when set num_threads > 1, so \"\r\n                \"set num_threads=1, nccl_comm_num=1, use_hierarchical_allreduce=False.\"\r\n            )\r\n\r\n        if self.print_config:\r\n            print(\"node_num:\", node_num, \"num_threads:\",\r\n                  exec_strategy.num_threads, \"use_hierarchical_allreduce:\",\r\n                  self._strategy.use_hierarchical_allreduce, \"nccl_comm_num:\",\r\n                  self._strategy.nccl_comm_num, \"FLAGS_sync_nccl_allreduce:\",\r\n                  sync_allreduce)\r\n\r\n        self._transpile(startup_program, main_program)\r\n\r\n       \\** if self._strategy.mode == \"collective\":\\**\r\n            \\**return main_program\\**\r\n\r\n        self._strategy.num_trainers = fleet.worker_num()\r\n        self._strategy.trainer_id = fleet.worker_index()\r\n        self._strategy.trainers_endpoints = fleet.worker_endpoints()\r\n        self._strategy.enable_backward_optimizer_op_deps = True\r\n\r\n        self._compiled_program = compiler.CompiledProgram(main_program)\r\n\r\n        self._compiled_program.with_data_parallel(\r\n            loss_name=self._loss.name,\r\n            build_strategy=self._strategy,\r\n            exec_strategy=self._strategy.exec_strategy,\r\n            share_vars_from=None)\r\n\r\n        return self._compiled_program\r\n```",
        "state": "closed",
        "user": "larenzhang",
        "closed_by": "larenzhang",
        "created_at": "2020-03-17T08:06:08+00:00",
        "updated_at": "2020-03-17T10:11:23+00:00",
        "closed_at": "2020-03-17T10:11:23+00:00",
        "comments_count": [
            "sandyhouse",
            "larenzhang",
            "sandyhouse",
            "larenzhang",
            "sandyhouse",
            "larenzhang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 171,
        "title": "paddle fleet 我用distribute_transpiler模式训练，我想把embeding 固定 住。报错",
        "body": "paddle fleet 我用distribute_transpiler模式训练，我想把embeding 固定住，trainable=False，训练的时候报错说embeding 没有初始化。trainable改成true就没问题了，可以帮忙看下嘛？\r\n<img width=\"1280\" alt=\"82991b0195420d1e04368be78bb5d558\" src=\"https://user-images.githubusercontent.com/16644339/80305709-0e007300-87f1-11ea-8908-3b80acdb70c1.png\">\r\n",
        "state": "closed",
        "user": "zle1992",
        "closed_by": "michaelowenliu",
        "created_at": "2020-04-26T11:06:47+00:00",
        "updated_at": "2024-03-06T06:30:10+00:00",
        "closed_at": "2024-03-06T06:30:10+00:00",
        "comments_count": [
            "seiriosPlus",
            "zle1992",
            "zle1992"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 172,
        "title": "paddle fleet 没有分布式预测的例子嘛？",
        "body": "求一个分布式预测计算auc的例子",
        "state": "closed",
        "user": "zle1992",
        "closed_by": "michaelowenliu",
        "created_at": "2020-05-07T14:15:33+00:00",
        "updated_at": "2024-03-06T06:30:16+00:00",
        "closed_at": "2024-03-06T06:30:16+00:00",
        "comments_count": [
            "guru4elephant",
            "Flowingsun007",
            "mingoahead"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 177,
        "title": "add fleet lightning framework base",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-09T02:54:44+00:00",
        "updated_at": "2024-03-06T06:30:21+00:00",
        "closed_at": "2024-03-06T06:30:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 178,
        "title": "add image_dataset_from_filelist interface for image data loading",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-09T02:55:24+00:00",
        "updated_at": "2024-03-06T06:31:55+00:00",
        "closed_at": "2024-03-06T06:31:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 180,
        "title": "run fleet distributed training with fleet_lightning and fleet",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-09T02:56:36+00:00",
        "updated_at": "2024-03-06T06:32:28+00:00",
        "closed_at": "2024-03-06T06:32:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 73,
        "title": "core_avx",
        "body": "",
        "state": "closed",
        "user": "xinwang-intel",
        "closed_by": "xinwang-intel",
        "created_at": "2019-10-04T08:04:24+00:00",
        "updated_at": "2019-10-04T08:04:55+00:00",
        "closed_at": "2019-10-04T08:04:55+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 61,
        "title": "[feature request]check loss's program id when a user has multiple losses to be minimized.",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2019-09-09T04:49:03+00:00",
        "updated_at": "2024-03-06T06:29:09+00:00",
        "closed_at": "2024-03-06T06:29:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 186,
        "title": "add faster_rcnn as application model in lightning",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-12T07:51:17+00:00",
        "updated_at": "2024-03-06T06:32:33+00:00",
        "closed_at": "2024-03-06T06:32:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 156,
        "title": "Fleet as a distributed training plugin for paddle",
        "body": "add upload and download functions for Baidu Cloud.",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-03-13T04:47:23+00:00",
        "updated_at": "2024-03-06T06:29:50+00:00",
        "closed_at": "2024-03-06T06:29:50+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 179,
        "title": "add Resnet50 model module. The model is loaded from a saved model with program and variable information",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-09T02:56:05+00:00",
        "updated_at": "2024-03-06T06:32:22+00:00",
        "closed_at": "2024-03-06T06:32:22+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 161,
        "title": "quick_start的示例在1.7.1下报错",
        "body": "https://github.com/PaddlePaddle/Fleet/blob/develop/examples/quick-start/distributed_train.py#L37\r\n在1.7.1下这里需要加上fleet.init_worker(), 执行完了后，需要加上fleet.stop_worker()",
        "state": "closed",
        "user": "ccmeteorljh",
        "closed_by": "michaelowenliu",
        "created_at": "2020-03-26T02:52:55+00:00",
        "updated_at": "2024-03-06T06:30:04+00:00",
        "closed_at": "2024-03-06T06:30:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 86,
        "title": "Can't see the benefits in speed of distributed training",
        "body": "The general purpose of using distributed training is to speed up training, however, I can't see that during mine.\r\nI train NeXtVLAD referring to https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/PaddleVideo.\r\nIn the beginning, I used node-alone multi-card training(8 cards in total), the training process of which is as follows:\r\n![image](https://user-images.githubusercontent.com/19339442/67465506-e41a9800-f677-11e9-8ea7-5d3e089b982f.png)\r\n(it costs about 20s per step)\r\nThen, I used  multi-node multi-card training(16 cards in total), the training process of which is as follows:\r\n![image](https://user-images.githubusercontent.com/19339442/67465721-46739880-f678-11e9-9896-8dfd51aa4f9e.png)\r\n(it costs about 40s per step)\r\nTo double check this problem, I used only one card to train the model, it's like this:\r\n![image](https://user-images.githubusercontent.com/19339442/67465800-74f17380-f678-11e9-80fb-036f83546466.png)\r\n(it costs even less time per step)\r\nHere is how I read data in the training:\r\n![image](https://user-images.githubusercontent.com/19339442/67465944-bda92c80-f678-11e9-91ce-86d3a4200f63.png)\r\nAnd I used Fleet to organize the distributed training:\r\n![image](https://user-images.githubusercontent.com/19339442/67466072-02cd5e80-f679-11e9-877c-18d2be9467a7.png)\r\nI need help. Thx. BR.",
        "state": "closed",
        "user": "Winter523",
        "closed_by": "michaelowenliu",
        "created_at": "2019-10-24T08:12:57+00:00",
        "updated_at": "2024-03-06T06:29:37+00:00",
        "closed_at": "2024-03-06T06:29:37+00:00",
        "comments_count": [
            "sandyhouse",
            "Winter523",
            "sandyhouse",
            "guru4elephant"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 187,
        "title": "add transformer model as application model in lightning",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-12T07:51:23+00:00",
        "updated_at": "2024-03-06T06:32:39+00:00",
        "closed_at": "2024-03-06T06:32:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 176,
        "title": "load_program resnet 实例报错",
        "body": "运行代码如下：\r\n```\r\nimport paddle.fluid as fluid\r\nimport time\r\nimport os\r\nimport numpy as np\r\nfrom paddle.fluid.incubate.fleet.collective import fleet, DistributedStrategy\r\nfrom paddle.fluid.incubate.fleet.base import role_maker\r\nfrom save_load import Model\r\n\r\ndef build_strategy():\r\n    exec_strategy = fluid.ExecutionStrategy()\r\n    exec_strategy.num_iteration_per_drop_scope = 30\r\n    dist_strategy = DistributedStrategy()\r\n    dist_strategy.mode = \"collective\"\r\n    dist_strategy.collective_mode = \"grad_allreduce\"\r\n    dist_strategy.nccl_comm_num = 1\r\n    dist_strategy.exec_strategy = exec_strategy\r\n    return dist_strategy\r\n\r\n\r\ndef gen_data():\r\n    return {\"image\": np.random.random(size=(32,3,224,224)).astype('float32'),\r\n            \"label\": np.random.randint(10, size=(32, 1)).astype('int64')}\r\n\r\n\r\nprogram_path = 'resnet'\r\ntest_model = Model()\r\ntest_model.load_model(program_path)\r\n#print(test_model.main_program)\r\nwith fluid.program_guard(test_model.main_program, test_model.startup_program):\r\n    with fluid.unique_name.guard(test_model.generator):\r\n        optimizer = fluid.optimizer.Momentum(learning_rate=test_model.lr,\r\n                                             momentum=0.9,\r\n                                             parameter_list = test_model.parameter_list,\r\n                                             regularization=fluid.regularizer.L2Decay(0.0001))\r\n        role = role_maker.PaddleCloudRoleMaker(is_collective=True)\r\n        fleet.init(role)\r\n        dist_strategy = build_strategy()\r\n        dist_optimizer = fleet.distributed_optimizer(optimizer, strategy=dist_strategy)\r\n        _, param_grads = dist_optimizer.minimize(test_model.loss,startup_program=test_model.startup_program, parameter_list=test_model.parameter_list)\r\n\r\ngpu_id = int(os.getenv(\"FLAGS_selected_gpus\", \"0\"))\r\nplace = fluid.CUDAPlace(gpu_id)\r\nexe = fluid.Executor(place)\r\nexe.run(test_model.startup_program)\r\nstep = 1001\r\ntotal_time = 0\r\nfor i in range(step):\r\n    start_time = time.time()\r\n    cost_val = exe.run(\r\n        program=fleet.main_program,\r\n        feed=gen_data(),\r\n        fetch_list=[test_model.loss.name])\r\n    end_time = time.time()\r\n    total_time += (end_time - start_time)\r\n```\r\n\r\n单机两卡运行正常，单机四卡报Nccl error：\r\n![截屏2020-06-08上午9 44 44 (2)](https://user-images.githubusercontent.com/19721227/83985890-5f159200-a96d-11ea-930f-71e6122afe38.png)\r\n",
        "state": "closed",
        "user": "qjing666",
        "closed_by": "qjing666",
        "created_at": "2020-06-08T01:50:37+00:00",
        "updated_at": "2020-06-15T02:37:50+00:00",
        "closed_at": "2020-06-15T02:37:50+00:00",
        "comments_count": [
            "qjing666"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 188,
        "title": "add tsn model as application model in lightning",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-12T07:51:27+00:00",
        "updated_at": "2024-03-06T06:32:44+00:00",
        "closed_at": "2024-03-06T06:32:44+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 190,
        "title": "add bert model for application model",
        "body": "",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "mapingshuo",
        "created_at": "2020-06-12T07:51:35+00:00",
        "updated_at": "2020-09-24T14:01:34+00:00",
        "closed_at": "2020-09-24T14:01:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 191,
        "title": "add pip install for fleet_lightning",
        "body": "",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "mapingshuo",
        "created_at": "2020-06-13T01:42:03+00:00",
        "updated_at": "2020-09-24T14:01:51+00:00",
        "closed_at": "2020-09-24T14:01:51+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 189,
        "title": "add vgg16 as application model in lightning",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-12T07:51:31+00:00",
        "updated_at": "2024-03-06T06:32:52+00:00",
        "closed_at": "2024-03-06T06:32:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 192,
        "title": "add travis ci",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-13T01:42:10+00:00",
        "updated_at": "2024-03-06T06:32:58+00:00",
        "closed_at": "2024-03-06T06:32:58+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 198,
        "title": "add resnet50 model test",
        "body": null,
        "state": "closed",
        "user": "qjing666",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-19T09:50:06+00:00",
        "updated_at": "2024-03-06T06:33:07+00:00",
        "closed_at": "2024-03-06T06:33:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 182,
        "title": "使用fleet lightning 接口，单机单卡训练imagenet，性能不符合预期",
        "body": "复现代码：\r\n```\r\nimport fleet_lightning as lighting\r\nimport paddle.fluid as fluid\r\nfrom paddle.fluid.incubate.fleet.collective import fleet, DistributedStrategy\r\nimport paddle.fluid.incubate.fleet.base.role_maker as role_maker\r\nimport time\r\n# lightning help users to focus more on learning to train a large scale model\r\n# if you want to learn how to write a model, lightning is not for you\r\n# focus more on engineering staff in fleet-lightning\r\nconfigs = lighting.parse_train_configs()\r\n\r\nmodel = lighting.applications.Resnet50()\r\nloader = lighting.imagenet_dataset_from_filelist(\r\n    \"/ssd2/lilong/ImageNet/val.txt\",model.inputs)\r\n\r\noptimizer = fluid.optimizer.Momentum(\r\n    learning_rate=configs.lr,\r\n    momentum=configs.momentum,\r\n    parameter_list=model.parameter_list(),\r\n    regularization=fluid.regularizer.L2Decay(0.0001))\r\noptimizer.minimize(model.loss,\r\n                   parameter_list=model.parameter_list())\r\n\r\nplace = fluid.CUDAPlace(0)\r\nexe = fluid.Executor(place)\r\nexe.run(fluid.default_startup_program())\r\ntotal_time = 0\r\nfor i, data in enumerate(loader()):\r\n    start_time = time.time()\r\n    cost_val = exe.run(fluid.default_main_program(),\r\n                       feed=data,\r\n                       fetch_list=[model.loss.name])\r\n    end_time = time.time()\r\n    total_time += (end_time - start_time)\r\n    print(\" step%d cost = %f, total time cost = %f\" %\r\n          ( i, cost_val[0], total_time))\r\n```\r\n\r\n数据集：5万张图片，batch size：32\r\n总训练时间：287.22s\r\n性能：174.08 imgs/s\r\n",
        "state": "closed",
        "user": "qjing666",
        "closed_by": "qjing666",
        "created_at": "2020-06-11T03:06:25+00:00",
        "updated_at": "2020-06-15T02:40:41+00:00",
        "closed_at": "2020-06-15T02:40:41+00:00",
        "comments_count": [
            "qjing666"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 199,
        "title": "Add Bert performance test in lightning",
        "body": "",
        "state": "closed",
        "user": "qjing666",
        "closed_by": "qjing666",
        "created_at": "2020-06-19T09:52:13+00:00",
        "updated_at": "2020-08-17T08:53:02+00:00",
        "closed_at": "2020-08-17T08:53:02+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 200,
        "title": "Add Bert model test in lightning",
        "body": null,
        "state": "closed",
        "user": "qjing666",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-19T09:52:17+00:00",
        "updated_at": "2024-03-06T06:32:10+00:00",
        "closed_at": "2024-03-06T06:32:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 201,
        "title": "Add transformer model test in lightning",
        "body": null,
        "state": "closed",
        "user": "qjing666",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-19T09:52:23+00:00",
        "updated_at": "2024-03-06T06:31:43+00:00",
        "closed_at": "2024-03-06T06:31:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 202,
        "title": "add transformer performance test in lightning",
        "body": "",
        "state": "closed",
        "user": "qjing666",
        "closed_by": "qjing666",
        "created_at": "2020-06-19T09:52:31+00:00",
        "updated_at": "2020-08-17T08:53:04+00:00",
        "closed_at": "2020-08-17T08:53:04+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 204,
        "title": "Add VGG performance test in lightning",
        "body": "",
        "state": "closed",
        "user": "qjing666",
        "closed_by": "qjing666",
        "created_at": "2020-06-19T09:53:14+00:00",
        "updated_at": "2020-08-17T08:53:08+00:00",
        "closed_at": "2020-08-17T08:53:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 205,
        "title": "Add visual tools in lightning",
        "body": null,
        "state": "closed",
        "user": "qjing666",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-19T09:53:39+00:00",
        "updated_at": "2024-03-06T06:31:18+00:00",
        "closed_at": "2024-03-06T06:31:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 203,
        "title": "Add VGG model test in lightning",
        "body": null,
        "state": "closed",
        "user": "qjing666",
        "closed_by": "michaelowenliu",
        "created_at": "2020-06-19T09:53:10+00:00",
        "updated_at": "2024-03-06T06:33:13+00:00",
        "closed_at": "2024-03-06T06:33:13+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 210,
        "title": "多卡训练时做多卡评估",
        "body": "现在Fleet可以支持 多卡训练的时候做**多卡**评估么?\r\n之前记得涉及到allreduce的事情代码量很繁琐，现在有新的方案or简洁的代码示例么？\r\n谢谢",
        "state": "closed",
        "user": "shippingwang",
        "closed_by": "gavin1332",
        "created_at": "2020-07-01T12:05:23+00:00",
        "updated_at": "2020-07-13T05:20:05+00:00",
        "closed_at": "2020-07-13T05:20:04+00:00",
        "comments_count": [
            "gavin1332",
            "gavin1332",
            "gavin1332",
            "shippingwang",
            "gavin1332",
            "gavin1332"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 208,
        "title": "bert_large 在fleet_lightning 中运行报错 CUDA ERROR",
        "body": "复现：运行fleet_lightning下bert_app.py\r\n\r\n```\r\npython -m paddle.distributed.launch --selected_gpu=0,1,2,3,4,5,6,7 --logdir mylog bert_app.py\r\n```\r\n\r\n![截屏2020-06-23下午3 06 20 (2)](https://user-images.githubusercontent.com/19721227/85371773-66d75800-b563-11ea-8eb2-93de013c9246.png)\r\n",
        "state": "closed",
        "user": "qjing666",
        "closed_by": "qjing666",
        "created_at": "2020-06-23T07:07:05+00:00",
        "updated_at": "2020-08-17T08:51:42+00:00",
        "closed_at": "2020-08-17T08:51:42+00:00",
        "comments_count": [
            "qjing666"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 215,
        "title": "Fleet会开源其源码吗",
        "body": "Fleet是否能够开放其分布式参数服务器代码，我们希望基于参数服务器开发一些op",
        "state": "closed",
        "user": "tomcheng0618",
        "closed_by": "guru4elephant",
        "created_at": "2020-07-10T16:00:57+00:00",
        "updated_at": "2020-07-13T04:21:00+00:00",
        "closed_at": "2020-07-13T04:21:00+00:00",
        "comments_count": [
            "guru4elephant",
            "tomcheng0618",
            "guru4elephant"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 221,
        "title": "fleet_lightning添加一下Readme",
        "body": "",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-07-20T06:08:15+00:00",
        "updated_at": "2020-07-20T07:34:21+00:00",
        "closed_at": "2020-07-20T07:34:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 216,
        "title": "EMA失效",
        "body": "在基于Fleet开发的代码中使用EMA会失效\r\n代码见：\r\nhttps://github.com/PaddlePaddle/PaddleClas/blob/master/tools/program.py#L364 https://github.com/PaddlePaddle/PaddleClas/blob/master/tools/train.py#L119 \r\n\r\n![image](https://user-images.githubusercontent.com/13645332/87265264-f2a22b80-c4f4-11ea-84ee-c751a2d09da9.png)\r\n\r\n\r\nEMA参考\r\nhttps://www.paddlepaddle.org.cn/documentation/docs/zh/develop/api_cn/optimizer_cn/ExponentialMovingAverage_cn.html#exponentialmovingaverage\r\n\r\n怀疑是distributed_optimizer的问题....",
        "state": "closed",
        "user": "shippingwang",
        "closed_by": "michaelowenliu",
        "created_at": "2020-07-11T14:22:21+00:00",
        "updated_at": "2024-03-06T06:31:06+00:00",
        "closed_at": "2024-03-06T06:31:06+00:00",
        "comments_count": [
            "guru4elephant",
            "shippingwang",
            "guru4elephant",
            "gavin1332",
            "shippingwang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 227,
        "title": "Docker Image for lightning",
        "body": "Provide a docker image that supports lightning ",
        "state": "closed",
        "user": "qjing666",
        "closed_by": "michaelowenliu",
        "created_at": "2020-07-27T08:08:10+00:00",
        "updated_at": "2024-03-06T06:33:20+00:00",
        "closed_at": "2024-03-06T06:33:20+00:00",
        "comments_count": [],
        "labels": [
            "enhancement"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 240,
        "title": "model.load_imagenet_from_file does not work",
        "body": "I tried different input file list, it reported error.\r\n``` python\r\nmodel = lighting.applications.Resnet50()\r\nloader = model.load_imagenet_from_file(\"/xx/train_list.txt\")\r\n```",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-08-06T15:01:26+00:00",
        "updated_at": "2024-03-06T06:30:32+00:00",
        "closed_at": "2024-03-06T06:30:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 222,
        "title": "Fleet/examples/distribute_ctr/local_cluster.sh  ERROR---原始demo报错",
        "body": "run: sh local_cluster.sh async\r\nget error:\r\n/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"async_train.py\", line 116, in <module>\r\n    train(params)\r\n  File \"async_train.py\", line 108, in train\r\n    fluid.io.save_persistables(executor=exe, dirname=model_path)\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 647, in save_persistables\r\n    filename=filename)\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 301, in save_vars\r\n    filename=filename)\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 356, in save_vars\r\n    executor.run(save_program)\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet:\r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::framework::OperatorWithKernel::ParseInputDataType(paddle::framework::ExecutionContext const&, std::string const&, paddle::framework::proto::VarType_Type*) const\r\n3   paddle::framework::OperatorWithKernel::IndicateVarDataType(paddle::framework::ExecutionContext const&, std::string const&) const\r\n4   paddle::operators::SaveOp::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const\r\n5   paddle::framework::OperatorWithKernel::ChooseKernel(paddle::framework::RuntimeContext const&, paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n8   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n9   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n10  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n11  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 327, in save_vars\r\n    attrs={'file_path': os.path.normpath(save_file_path)})\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 301, in save_vars\r\n    filename=filename)\r\n  File \"/home/XXX/apps/anaconda3/envs/paddle2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 647, in save_persistables\r\n    filename=filename)\r\n  File \"async_train.py\", line 108, in train\r\n    fluid.io.save_persistables(executor=exe, dirname=model_path)\r\n  File \"async_train.py\", line 116, in <module>\r\n    train(params)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The Tensor in the save Op's Input Variable X(SparseFeatFactors) is not initialized.\r\n  [Hint: Expected t->IsInitialized() == true, but received t->IsInitialized():0 != true:1.] at (/paddle/paddle/fluid/framework/operator.cc:1289)\r\n  [operator < save > error]\r\npure virtual method called\r\nterminate called without an active exception\r\nW0720 16:02:18.644717 457584 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0720 16:02:18.644743 457584 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0720 16:02:18.644749 457584 init.cc:221] The detail failure signal is:\r\n\r\nW0720 16:02:18.644757 457584 init.cc:224] *** Aborted at 1595232138 (unix time) try \"date -d @1595232138\" if you are using GNU date ***\r\nW0720 16:02:18.647378 457584 init.cc:224] PC: @                0x0 (unknown)\r\nW0720 16:02:18.647464 457584 init.cc:224] *** SIGABRT (@0x3f20006fa50) received by PID 457296 (TID 0x7f039d309700) from PID 457296; stack trace: ***\r\nW0720 16:02:18.649935 457584 init.cc:224]     @     0x7f03c41b55d0 (unknown)\r\nW0720 16:02:18.652567 457584 init.cc:224]     @     0x7f03c3706207 __GI_raise\r\nW0720 16:02:18.655143 457584 init.cc:224]     @     0x7f03c37078f8 __GI_abort\r\nW0720 16:02:18.656950 457584 init.cc:224]     @     0x7f03ae19c84a __gnu_cxx::__verbose_terminate_handler()\r\nW0720 16:02:18.658381 457584 init.cc:224]     @     0x7f03ae19af47 __cxxabiv1::__terminate()\r\nW0720 16:02:18.660149 457584 init.cc:224]     @     0x7f03ae19af7d std::terminate()\r\nW0720 16:02:18.661695 457584 init.cc:224]     @     0x7f03ae19b988 __cxa_pure_virtual\r\nW0720 16:02:18.667204 457584 init.cc:224]     @     0x7f03a9543a6d grpc::internal::CallOpSet<>::FinalizeResult()\r\nW0720 16:02:18.671972 457584 init.cc:224]     @     0x7f03a95460d3 grpc::CompletionQueue::AsyncNextInternal()\r\nW0720 16:02:18.675379 457584 init.cc:224]     @     0x7f03a9516f69 paddle::operators::distributed::GRPCClient::Proceed()\r\nW0720 16:02:18.676784 457584 init.cc:224]     @     0x7f03ae1b7421 execute_native_thread_routine_compat\r\nW0720 16:02:18.679189 457584 init.cc:224]     @     0x7f03c41addd5 start_thread\r\nW0720 16:02:18.681900 457584 init.cc:224]     @     0x7f03c37cdead __clone\r\nW0720 16:02:18.684314 457584 init.cc:224]     @                0x0 (unknown)\r\n\r\n\r\n版本：\r\npython=2.7.18\r\npaddlepaddle=1.8.2\r\npython和pd都是在anaconda下装的，服务器只有CPU。\r\n运行单机命令python -u local_train.py --test=True &> train.log &得到的结果与README.md中的一致，能跑成功。\r\n是不是fluid.io.save_persistables(executor=exe, dirname=model_path)这个命令在分布式下有问题呀？\r\n咋回事呢？求解答～",
        "state": "closed",
        "user": "starsblinking",
        "closed_by": "gongweibao",
        "created_at": "2020-07-23T04:22:03+00:00",
        "updated_at": "2020-07-28T03:39:27+00:00",
        "closed_at": "2020-07-28T03:39:27+00:00",
        "comments_count": [
            "gentelyang",
            "starsblinking"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 250,
        "title": "add download data from hadoop with X's APIs",
        "body": "",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "mapingshuo",
        "created_at": "2020-08-20T01:52:17+00:00",
        "updated_at": "2020-09-24T14:03:35+00:00",
        "closed_at": "2020-09-24T14:03:35+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 248,
        "title": "build benchmark scripts based on fleet-X",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-08-18T23:54:57+00:00",
        "updated_at": "2024-03-06T06:28:30+00:00",
        "closed_at": "2024-03-06T06:28:30+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 242,
        "title": "寻之前的某个页面",
        "body": "请问下，之前有个页面链接哪去了：\r\n\r\nhttps://github.com/PaddlePaddle/Fleet/blob/develop/markdown_doc/transpiler/transpiler_cpu.md",
        "state": "closed",
        "user": "leesusu",
        "closed_by": "leesusu",
        "created_at": "2020-08-13T03:22:15+00:00",
        "updated_at": "2020-08-16T03:00:15+00:00",
        "closed_at": "2020-08-16T03:00:15+00:00",
        "comments_count": [
            "leesusu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 261,
        "title": "add downloadable small dataset for each example, a user should run it successfully with net access",
        "body": null,
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-02T05:42:19+00:00",
        "updated_at": "2024-03-06T06:28:10+00:00",
        "closed_at": "2024-03-06T06:28:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 275,
        "title": "add a word2vec model for fleetX",
        "body": "since word2vec is to learn word representation, it can be view as a pre-training model. \r\nplease add word2vec pre-training model with parameter server training.",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-08T15:06:16+00:00",
        "updated_at": "2024-03-06T06:30:40+00:00",
        "closed_at": "2024-03-06T06:30:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 281,
        "title": "add perplexity metric to Bert model",
        "body": "```python\r\nimport numpy as np\r\nimport fleetx as X\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport paddle.distributed.fleet as fleet\r\nimport paddle.distributed.fleet.base.role_maker as role_maker\r\nimport time\r\n\r\n# FleetX help users to focus more on learning to train a large scale model\r\n# if you want to learn how to write a model, fleetx is not for you\r\n# focus more on engineering staff in fleet-x\r\n\r\nconfigs = X.parse_train_configs()\r\nbatch_size=53\r\nconfigs.lr = 1e-4\r\n\r\nrole = role_maker.PaddleCloudRoleMaker(is_collective=True)\r\nfleet.init(role)\r\n# load Bert_large / Bert_base model\r\nmodel = X.applications.BertLarge()\r\ndata_loader = model.load_digital_dataset_from_file(\r\n    data_dir='../../data/bert/train',\r\n    vocab_path='uncased_L-24_H-1024_A-16/vocab.txt',\r\n    max_seq_len=512,\r\n    batch_size=batch_size,\r\n    in_tokens=False,\r\n)\r\n\r\nplace = fluid.CUDAPlace(int(os.environ.get('FLAGS_selected_gpus', 0)))\r\nexec_strategy = fluid.ExecutionStrategy()\r\nexec_strategy.num_threads = 2\r\nexec_strategy.num_iteration_per_drop_scope = 1\r\ndist_strategy = fleet.DistributedStrategy()\r\ndist_strategy.execution_strategy = exec_strategy\r\ndist_strategy.nccl_comm_num = 3\r\ndist_strategy.recompute_configs = {\"checkpoints\": model.checkpoints}\r\ndist_strategy.recompute = True\r\nprint(\"base lr: \", configs.lr)\r\nscheduled_lr = X.utils.linear_warmup_decay(configs.lr, warmup_steps=4000,\r\n                                               num_train_steps=1000000)\r\noptimizer = fluid.optimizer.Adam(learning_rate=scheduled_lr)\r\noptimizer = fleet.distributed_optimizer(optimizer, dist_strategy)\r\n\r\nclip_norm_thres = 1.0\r\nfluid.clip.set_gradient_clip(\r\n    clip=fluid.clip.GradientClipByGlobalNorm(clip_norm=clip_norm_thres))\r\n\r\noptimizer.minimize(model.loss)\r\n\r\n\r\ntrainer = X.MultiGPUTrainer()\r\ntrainer.fit(model, data_loader, epoch=10)\r\n```\r\n\r\nresult:\r\n\r\n```shell\r\nworker_index: 0, step11, train_loss: 10.793158, total time cost = 9.053438, step per second: 0.110455, speed: 0.110455\r\nworker_index: 0, step12, train_loss: 10.778522, total time cost = 17.794933, step per second: 0.112392, speed: 0.114397\r\nworker_index: 0, step13, train_loss: 10.719225, total time cost = 27.523812, step per second: 0.108997, speed: 0.102787\r\nworker_index: 0, step14, train_loss: 10.759233, total time cost = 36.688284, step per second: 0.109027, speed: 0.109117\r\nworker_index: 0, step15, train_loss: 10.764440, total time cost = 46.571331, step per second: 0.107362, speed: 0.101183\r\nworker_index: 0, step16, train_loss: 10.703083, total time cost = 56.291579, step per second: 0.106588, speed: 0.102878\r\nworker_index: 0, step17, train_loss: 10.717890, total time cost = 64.846372, step per second: 0.107947, speed: 0.116894\r\n```\r\n\r\nexpected result:\r\n\r\nadd perplexity metric",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-09T03:52:32+00:00",
        "updated_at": "2024-03-06T06:33:37+00:00",
        "closed_at": "2024-03-06T06:33:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 253,
        "title": "Install fleet-x failed",
        "body": "I am using `pip install fleet-x` to install \"fleet-x\", but it failed and got this log:\r\n```shell\r\n(paddle) [root@2b4b7f89d99c ~]# pip install fleet-x\r\nLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\nCollecting fleet-x\r\n  Using cached https://mirrors.aliyun.com/pypi/packages/68/59/d435442e36543f39e753d88d81bfaf897559dcf655bc8ed91976c41e76d6/fleet-x-0.0.2.tar.gz (19 kB)\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /usr/local/envs/paddle/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-of86qle5/fleet-x/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-of86qle5/fleet-x/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-nl8satpk\r\n         cwd: /tmp/pip-install-of86qle5/fleet-x/\r\n    Complete output (9 lines):\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/tmp/pip-install-of86qle5/fleet-x/setup.py\", line 25, in <module>\r\n        from fleetx.version import fleetx_version\r\n      File \"/tmp/pip-install-of86qle5/fleet-x/fleetx/__init__.py\", line 16, in <module>\r\n        from . import applications\r\n      File \"/tmp/pip-install-of86qle5/fleet-x/fleetx/applications/__init__.py\", line 15, in <module>\r\n        from model import *\r\n    ModuleNotFoundError: No module named 'model'\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\r\n```\r\nWishing someone to help me, thanks!",
        "state": "closed",
        "user": "HerbertArthur",
        "closed_by": "qjing666",
        "created_at": "2020-08-24T12:26:00+00:00",
        "updated_at": "2020-08-25T08:39:31+00:00",
        "closed_at": "2020-08-25T08:39:31+00:00",
        "comments_count": [
            "HerbertArthur",
            "qjing666",
            "HerbertArthur",
            "qjing666",
            "HerbertArthur",
            "qjing666",
            "qjing666",
            "HerbertArthur"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 286,
        "title": "Benchmark数据与代码的对应关系",
        "body": "Feature 需求:\r\n\r\n在 https://github.com/PaddlePaddle/FleetX/tree/develop/benchmark/paddle 中，可以看到resnet的性能很棒。\r\n\r\n如果用户想要复现这些数据，却会陷入困惑。不如在Readme里面添加Acc效果对应的脚本，说明其训练的脚本、启动命令、使用的机器数目，卡数，GPU卡的型号，速度等。\r\n\r\n期待。",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-09T11:59:51+00:00",
        "updated_at": "2024-03-06T06:26:06+00:00",
        "closed_at": "2024-03-06T06:26:06+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 297,
        "title": "增加每个benchmark脚本的复现环境说明",
        "body": "目前每个benchmark脚本的运行环境并没有完全统一，官方需要说明具体的复现环境，或者复现流程",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-11T15:52:40+00:00",
        "updated_at": "2024-03-06T06:25:06+00:00",
        "closed_at": "2024-03-06T06:25:06+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 336,
        "title": "FleetX 静态图的例子和Benchmark 应该增加paddle.enable_static()",
        "body": "FleetX 静态图的例子和Benchmark 应该增加paddle.enable_static()",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-23T03:25:18+00:00",
        "updated_at": "2024-03-06T06:33:48+00:00",
        "closed_at": "2024-03-06T06:33:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 339,
        "title": "FleetX 文档中的静态图例子应该添加 enable_static()",
        "body": "\r\n以下文档中的静态图例子应该添加 enable_static()\r\n\r\nhttps://fleet-x.readthedocs.io/en/latest/paddle_fleet/fleet_quick_start_cn.html",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "mapingshuo",
        "created_at": "2020-09-23T11:50:38+00:00",
        "updated_at": "2020-09-30T05:20:03+00:00",
        "closed_at": "2020-09-30T05:20:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 346,
        "title": "downloader增加cache功能",
        "body": "![image](https://user-images.githubusercontent.com/23031310/94153928-f1f02300-feaf-11ea-9f07-380b170a3873.png)\r\n",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "qjing666",
        "created_at": "2020-09-24T13:50:27+00:00",
        "updated_at": "2020-10-20T06:04:39+00:00",
        "closed_at": "2020-10-20T06:04:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 349,
        "title": "downloader如果有required字段没有配置需要报错",
        "body": "前面脚本的字段imagenet_path，现在改为data_path，实际上data_path为required，需要报错",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-25T10:59:30+00:00",
        "updated_at": "2024-03-06T06:34:07+00:00",
        "closed_at": "2024-03-06T06:34:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 340,
        "title": "Readme 的静态图例子应添加 enable_static",
        "body": "https://github.com/PaddlePaddle/FleetX/blob/develop/README.md",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-23T11:51:24+00:00",
        "updated_at": "2024-03-06T06:33:56+00:00",
        "closed_at": "2024-03-06T06:33:56+00:00",
        "comments_count": [
            "mapingshuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 357,
        "title": "redundant empty line in the checkpoints file",
        "body": "![image](https://user-images.githubusercontent.com/23031310/94637551-74427200-030a-11eb-86c7-f8a915fa8ebd.png)\r\n\r\nThe following error occurred because of this bug:\r\n\r\n![image](https://user-images.githubusercontent.com/23031310/94637609-9e942f80-030a-11eb-8ff4-f7031006ed7e.png)\r\n ",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "mapingshuo",
        "created_at": "2020-09-30T02:49:35+00:00",
        "updated_at": "2020-09-30T02:52:25+00:00",
        "closed_at": "2020-09-30T02:52:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 356,
        "title": "Can I have the MD5 code of the released models",
        "body": null,
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "michaelowenliu",
        "created_at": "2020-09-30T02:44:20+00:00",
        "updated_at": "2024-03-06T06:34:13+00:00",
        "closed_at": "2024-03-06T06:34:13+00:00",
        "comments_count": [
            "guru4elephant"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 361,
        "title": "Fleetx should support Py3",
        "body": "![image](https://user-images.githubusercontent.com/23031310/94652593-dad88780-032c-11eb-92db-7d79f4829a80.png)\r\n\r\n\"/\" -> \"//\"",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "qjing666",
        "created_at": "2020-09-30T06:54:43+00:00",
        "updated_at": "2020-10-20T06:04:08+00:00",
        "closed_at": "2020-10-20T06:04:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 360,
        "title": "当Batch size不足一个句子时，应报错退出",
        "body": "![image](https://user-images.githubusercontent.com/23031310/94652443-9baa3680-032c-11eb-9c0c-728b8d3e5575.png)\r\n",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "qjing666",
        "created_at": "2020-09-30T06:52:53+00:00",
        "updated_at": "2020-10-20T06:05:05+00:00",
        "closed_at": "2020-10-20T06:05:05+00:00",
        "comments_count": [
            "mapingshuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 370,
        "title": "remove use_dali options in trainer",
        "body": "Currently, `FleetX` is using native `DataLoader` for training. When we are using Dali for data loader, lazy import is used.\r\nA better way is to write a wrapped `DataLoader` so that we can use dataloader.use_dali() to check whether we should do reset(). This will remove the `use_dali` in `trainer.fit`, `trainer.val` and `trainer.benchmark`.",
        "state": "closed",
        "user": "guru4elephant",
        "closed_by": "michaelowenliu",
        "created_at": "2020-10-01T03:00:45+00:00",
        "updated_at": "2024-03-06T06:23:16+00:00",
        "closed_at": "2024-03-06T06:23:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 377,
        "title": "Vgg demo model got 'nan':",
        "body": "Vgg demo model got 'nan':\r\n\r\n![image](https://user-images.githubusercontent.com/23031310/95703279-574e5d00-0c81-11eb-8691-b849104bdb77.png)\r\n\r\ncode:\r\n\r\n```\r\nimport fleetx as X\r\nimport paddle\r\nimport paddle.distributed.fleet as fleet\r\n# FleetX help users to focus more on learning to train a large scale model\r\n# if you want to learn how to write a model, FleetX is not for you\r\n# focus more on engineering staff in fleet-x\r\npaddle.enable_static()\r\nfleet.init(is_collective=True)\r\nconfigs = X.parse_train_configs()\r\n\r\nmodel = X.applications.VGG16()\r\ndownloader = X.utils.Downloader()\r\nlocal_path = downloader.download_from_bos(\r\n    fs_yaml='https://fleet.bj.bcebos.com/test/loader/small_imagenet.yaml',\r\n    local_path='./data')\r\nloader = model.get_train_dataloader(local_path, batch_size=32)\r\n\r\ndist_strategy = fleet.DistributedStrategy()\r\ndist_strategy.amp = True\r\n\r\noptimizer = paddle.fluid.optimizer.Momentum(\r\n    learning_rate=configs.lr,\r\n    momentum=configs.momentum,\r\n    regularization=paddle.fluid.regularizer.L2Decay(0.0001))\r\noptimizer = fleet.distributed_optimizer(optimizer, strategy=dist_strategy)\r\noptimizer.minimize(model.loss)\r\n\r\ntrainer = X.MultiGPUTrainer()\r\ntrainer.fit(model, loader, epoch=10)\r\n```",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "qjing666",
        "created_at": "2020-10-12T03:52:27+00:00",
        "updated_at": "2020-10-20T06:03:59+00:00",
        "closed_at": "2020-10-20T06:03:59+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 379,
        "title": "module 'fleetx.utils' has no attribute 'WMTDataDownloader'",
        "body": "https://github.com/PaddlePaddle/FleetX/blob/af6a76ef8aa0fd1becd788a07c6b3dc60ef75676/examples/transformer_app.py#L24\r\n\r\n![image](https://user-images.githubusercontent.com/23031310/95718940-b7ed9200-0ca1-11eb-8620-3d4efa4f303c.png)\r\n",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "qjing666",
        "created_at": "2020-10-12T07:43:51+00:00",
        "updated_at": "2020-10-21T10:46:28+00:00",
        "closed_at": "2020-10-21T10:46:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 363,
        "title": "error when using FleetX examples resnet_app",
        "body": "![image](https://user-images.githubusercontent.com/23031310/94656471-b54e7c80-0332-11eb-95ae-3db63854a564.png)\r\n",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "mapingshuo",
        "created_at": "2020-09-30T07:36:31+00:00",
        "updated_at": "2020-09-30T07:37:53+00:00",
        "closed_at": "2020-09-30T07:37:42+00:00",
        "comments_count": [
            "mapingshuo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 402,
        "title": "建议FleetX增加固定program seed的功能",
        "body": "添加方法为:\r\n\r\n```\r\n  for op in model.main_prog.global_block().ops:\r\n    if op.desc.has_attr('seed'):\r\n      op._set_attr('seed', 9000)\r\n\r\n  for op in model.startup_prog.global_block().ops:\r\n    if op.desc.has_attr('seed'):\r\n      op._set_attr('seed', 9000)\r\n```",
        "state": "closed",
        "user": "mapingshuo",
        "closed_by": "michaelowenliu",
        "created_at": "2020-10-24T03:37:15+00:00",
        "updated_at": "2024-03-06T06:23:23+00:00",
        "closed_at": "2024-03-06T06:23:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 405,
        "title": "load cifar10",
        "body": "无法使用fleetx中的vgg benchmark加载cifar10，可以给出一个加载cifar10的方法吗？",
        "state": "closed",
        "user": "lcylmhlcy",
        "closed_by": "michaelowenliu",
        "created_at": "2020-11-09T12:36:34+00:00",
        "updated_at": "2024-03-06T06:23:33+00:00",
        "closed_at": "2024-03-06T06:23:33+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 390,
        "title": "examples下的transformer和bert训练报错",
        "body": "server not ready, wait 3 sec to retry...\r\nnot ready endpoints:['127.0.0.1:42114']\r\n2020-10-15 04:49:07,933 - INFO - PUT localhost.localdomain/_WORKER/1\r\n2020-10-15 04:49:07,934 - INFO - GET localhost.localdomain/_WORKER/0 , key not found: 0\r\n2020-10-15 04:49:07,937 - INFO - PUT localhost.localdomain/_WORKER/0\r\n2020-10-15 04:49:07,937 - INFO - GET localhost.localdomain/_WORKER/1 , key found: 1\r\n2020-10-15 04:49:07,938 - INFO - GET localhost.localdomain/_WORKER/1 , key found: 1\r\n2020-10-15 04:49:07,944 - INFO - GET localhost.localdomain/_WORKER/0 , key found: 0\r\n2020-10-15 04:49:07,945 - INFO - GET localhost.localdomain/_WORKER/0 , key found: 0\r\n2020-10-15 04:49:07,952 - INFO - DELETE localhost.localdomain/_WORKER/1\r\n2020-10-15 04:49:07,952 - INFO - DELETE localhost.localdomain/_WORKER/0\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::SignalHandle(char const*, int)\r\n1   paddle::platform::GetCurrentTraceBackString()\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: A serious error (Termination signal) is detected by the operating system. (at /paddle/paddle/fluid/platform/init.cc:303)\r\n  [TimeInfo: *** Aborted at 1602737349 (unix time) try \"date -d @1602737349\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGTERM (@0x919b) received by PID 37368 (TID 0x7fb5de2b8700) from PID 37275 ***]",
        "state": "closed",
        "user": "gentelyang",
        "closed_by": "gentelyang",
        "created_at": "2020-10-15T04:51:16+00:00",
        "updated_at": "2022-07-01T12:54:19+00:00",
        "closed_at": "2020-11-02T04:57:45+00:00",
        "comments_count": [
            "gentelyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 406,
        "title": "文档代码在2.0rc不通过",
        "body": "文档地址：https://github.com/PaddlePaddle/FleetX/blob/develop/docs/source/paddle_fleet_rst/fleetrun_usage_cn.rst\r\n\r\n在2.0rc版本会报错：\r\nAttributeError: module 'paddle' has no attribute 'data'\r\n\r\nTypeError: fc() got an unexpected keyword argument 'input'\r\n\r\nTypeError: fc() got an unexpected keyword argument 'input'\r\n\r\nTypeError: fc() got an unexpected keyword argument 'act'\r\n\r\n经查证，发现需要修改成如下语句：\r\n\r\n\r\n\r\n> def mnist_on_mlp_model():\r\n\r\n    train_dataset = paddle.vision.datasets.MNIST(mode='train')\r\n    test_dataset = paddle.vision.datasets.MNIST(mode='test')\r\n    x = paddle.fluid.data(name=\"x\", shape=[64, 1, 28, 28], dtype='float32')\r\n    y = paddle.fluid.data(name=\"y\", shape=[64, 1], dtype='int64')\r\n    x_flatten = fluid.layers.reshape(x, [64, 784])\r\n    fc_1 = nn.fc(x=x_flatten, size=128, activation='tanh') \r\n    fc_2 = nn.fc(x=fc_1, size=128, activation='tanh') \r\n    prediction = nn.fc(x=[fc_2], size=10, activation='softmax') \r\n    cost = fluid.layers.cross_entropy(input=prediction, label=y)\r\n    acc_top1 = fluid.layers.accuracy(input=prediction, label=y, k=1)\r\n    avg_cost = fluid.layers.mean(x=cost)\r\n    return train_dataset, test_dataset, x, y, avg_cost, acc_top1\r\n\r\n\r\n也就是paddle.data 改成paddle.fluid.data\r\n\r\n\r\nfc_1 = nn.fc(input=x_flatten, size=128, act='tanh')\r\n改成\r\nfc_1 = nn.fc(x=x_flatten, size=128, activation='tanh')",
        "state": "closed",
        "user": "skywalk163",
        "closed_by": "michaelowenliu",
        "created_at": "2020-11-09T14:18:12+00:00",
        "updated_at": "2024-03-06T06:23:39+00:00",
        "closed_at": "2024-03-06T06:23:39+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 407,
        "title": "2.0 beta版 静态分布式单机多卡程序错误",
        "body": "### 错误：\r\n-----------  Configuration Arguments -----------\r\ngpus: 1,3\r\nips: 127.0.0.1\r\nlog_dir: log\r\nserver_num: None\r\nservers:\r\ntraining_script: test.py\r\ntraining_script_args: []\r\nworker_num: None\r\nworkers:\r\n------------------------------------------------\r\nINFO 2020-11-17 15:38:07,630 launch.py:411] Run collective gpu mode. gpu args:['--gpus'], cuda count:4\r\nINFO 2020-11-17 15:38:07,630 launch.py:207] get cluster from args:job_server:None pods:['rank:0 id:None addr:127.0.0.1 port:None visible_gpu:[] trainers:[\"gpu:[\\'1\\'] endpoint:127.0.0.1:47211 rank:0\", \"gpu:[\\'3\\'] endpoint:127.0.0.1:58254 rank:1\"] servers:[]             workers:[]'] job_stage_flag:None hdfs:None\r\nINFO 2020-11-17 15:38:07,631 launch_utils.py:380] start trainer proc:['/gpfs/share/home/2001111296/software/miniconda3/envs/pd-beta/bin/python', '-u', 'test.py'] env:{'FLAGS_selected_gpus': '1', 'PADDLE_TRAINER_ID': '0', 'PADDLE_CURRENT_ENDPOINT': '127.0.0.1:47211', 'PADDLE_TRAINERS_NUM': '2', 'PADDLE_TRAINER_ENDPOINTS': '127.0.0.1:47211,127.0.0.1:58254'}\r\nINFO 2020-11-17 15:38:07,670 launch_utils.py:380] start trainer proc:['/gpfs/share/home/2001111296/software/miniconda3/envs/pd-beta/bin/python', '-u', 'test.py'] env:{'FLAGS_selected_gpus': '3', 'PADDLE_TRAINER_ID': '1', 'PADDLE_CURRENT_ENDPOINT': '127.0.0.1:58254', 'PADDLE_TRAINERS_NUM': '2', 'PADDLE_TRAINER_ENDPOINTS': '127.0.0.1:47211,127.0.0.1:58254'}\r\nW1117 15:38:09.862329 54356 device_context.cc:320] Please NOTE: device: 1, CUDA Capability: 60, Driver API Version: 10.1, Runtime API Version: 10.0\r\nW1117 15:38:09.866822 54356 device_context.cc:328] device: 1, cuDNN Version: 7.5.\r\nW1117 15:38:12.084893 54356 device_context.h:193] WARNING: device: 1. The installed Paddle is compiled with CUDNN 7.6, but CUDNN version in your machine is 7.5, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\r\nW1117 15:38:20.937805 54356 fuse_all_reduce_op_pass.cc:75] Find all_reduce operators: 60. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 2.\r\n0 0 2.3934178 0.0 4.976986408233643\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 106, in <module>\r\n    feed=feeder.feed(data), fetch_list=[loss.name, acc.name])   #\r\nAttributeError: 'numpy.ndarray' object has no attribute 'name'\r\nINFO 2020-11-17 15:38:28,723 launch_utils.py:269] terminate all the procs\r\nERROR 2020-11-17 15:38:28,724 launch_utils.py:446] ABORT!!! Out of all 2 trainers, the trainer process with rank=[0, 1] was aborted. Please check its log.\r\nINFO 2020-11-17 15:38:31,725 launch_utils.py:269] terminate all the procs\r\n\r\n\r\n### 程序：\r\nimport paddle\r\nimport paddle.fluid as fluid\r\nimport paddle.distributed.fleet as fleet\r\nimport fleetx as X\r\nimport csv\r\nimport os\r\nimport numpy as np\r\nimport time\r\n\r\nimport vgg\r\nimport resnet\r\n\r\ndef vgg16(input):\r\n    def conv_block(ipt, num_filter, groups, dropouts):\r\n        return fluid.nets.img_conv_group(\r\n            input=ipt,\r\n            pool_size=2,\r\n            pool_stride=2,\r\n            conv_num_filter=[num_filter] * groups,\r\n            conv_filter_size=3,\r\n            conv_act='relu',\r\n            conv_with_batchnorm=True,\r\n            conv_batchnorm_drop_rate=dropouts,\r\n            pool_type='max')\r\n\r\n    conv1 = conv_block(input, 64, 2, [0.3, 0])\r\n    conv2 = conv_block(conv1, 128, 2, [0.4, 0])\r\n    conv3 = conv_block(conv2, 256, 3, [0.4, 0.4, 0])\r\n    conv4 = conv_block(conv3, 512, 3, [0.4, 0.4, 0])\r\n    conv5 = conv_block(conv4, 512, 3, [0.4, 0.4, 0])\r\n\r\n    drop = fluid.layers.dropout(x=conv5, dropout_prob=0.5)\r\n    fc1 = fluid.layers.fc(input=drop, size=512, act=None)\r\n    bn = fluid.layers.batch_norm(input=fc1, act='relu')\r\n    drop2 = fluid.layers.dropout(x=bn, dropout_prob=0.5)\r\n    fc2 = fluid.layers.fc(input=drop2, size=512, act=None)\r\n    predict = fluid.layers.fc(input=fc2, size=10, act='softmax')\r\n    return predict\r\n\r\npaddle.enable_static() # only after 2.0rc\r\nrole = fleet.base.role_maker.PaddleCloudRoleMaker(is_collective=True)\r\nfleet.init(role)\r\n# fleet.init(is_collective=True)\r\n# exec_strategy = fluid.ExecutionStrategy()\r\ndist_strategy = fleet.DistributedStrategy()\r\n# exec_strategy.num_threads = 2\r\n# exec_strategy.num_iteration_per_drop_scope = 100\r\n# dist_strategy.execution_strategy = exec_strategy\r\n# build_strategy = fluid.BuildStrategy()\r\n# build_strategy.enable_inplace = False\r\n# build_strategy.fuse_elewise_add_act_ops = True\r\n# build_strategy.fuse_bn_act_ops = True\r\n# dist_strategy.build_strategy = build_strategy\r\n# dist_strategy.nccl_comm_num = 1\r\nplace = fluid.CUDAPlace(int(os.environ.get('FLAGS_selected_gpus', 0)))\r\n\r\n# model = vgg.VGG16()\r\n# model = model.net\r\n\r\n\r\nBATCH_SIZE = 32\r\ntrain_reader = paddle.batch(\r\n    paddle.reader.shuffle(paddle.dataset.cifar.train10(), buf_size=50000),\r\n    batch_size=BATCH_SIZE)\r\ntest_reader = paddle.batch(\r\n    paddle.dataset.cifar.test10(), batch_size=BATCH_SIZE)\r\n\r\n\r\n# train_dataset = paddle.vision.datasets.Cifar10(mode='train')\r\n\r\n\r\n\r\ninput_x = fluid.layers.data(name=\"pixel\", shape=[3, 32, 32], dtype='float32')\r\ninput_y = fluid.layers.data(name=\"label\", shape=[1], dtype='int64')\r\npred = vgg16(input_x)\r\nloss = fluid.layers.mean(fluid.layers.cross_entropy(input=pred, label=input_y))\r\nacc = fluid.layers.accuracy(input=pred, label=input_y)\r\n\r\nlr = 0.0125\r\noptimizer = fluid.optimizer.SGD(learning_rate=lr)\r\noptimizer = fleet.distributed_optimizer(optimizer, strategy=dist_strategy)\r\noptimizer.minimize(loss)\r\n\r\n\r\nfeed_order = ['pixel', 'label']\r\nfeeder = fluid.DataFeeder(place=place, feed_list=feed_order)\r\n\r\n# train_reader = paddle.io.DataLoader(train_dataset, feed_order, places=place, \\\r\n#     batch_size=BATCH_SIZE, shuffle=True)\r\n\r\nexe = paddle.static.Executor(place)\r\nexe.run(paddle.static.default_startup_program())\r\n\r\n# compiled_prog = fluid.compiler.CompiledProgram(fluid.default_main_program())\r\ncompiled_prog = paddle.static.default_main_program()\r\n\r\nfor epoch_id in range(50):\r\n    total_time = 0\r\n    step = 0\r\n    start_time = time.time()\r\n    for data in train_reader():     \r\n        # print(loss.name, acc.name)      \r\n        # loss, acc = exe.run(compiled_prog, \\\r\n        #     feed=feeder.feed(data), fetch_list=[loss.name, acc.name], use_program_cache=True)   # \r\n        loss, acc = exe.run(compiled_prog, \\\r\n            feed=feeder.feed(data), fetch_list=[loss.name, acc.name])   # \r\n        end_time = time.time()\r\n        total_time += (end_time - start_time)\r\n        # print(fleet.worker_index())\r\n        # print(\r\n        #     \"epoch id: %d, step%d, train_loss: %f, train_acc: %f, total time cost = %f\"\r\n        #     % (epoch_id, step, loss, pass_acc, total_time))\r\n        print(epoch_id, step, loss[0], acc[0], total_time)\r\n        step += 1",
        "state": "closed",
        "user": "lcylmhlcy",
        "closed_by": "lcylmhlcy",
        "created_at": "2020-11-17T07:40:26+00:00",
        "updated_at": "2020-11-17T07:43:12+00:00",
        "closed_at": "2020-11-17T07:43:12+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 478,
        "title": "对于resnet101 如何设置checkpoints",
        "body": "https://fleet-x.readthedocs.io/en/latest/paddle_fleet_rst/collective/collective_mp/recomputation.html?highlight=checkpoints#recomputation\r\n参看链接中的resnet50,对于resnet101 也是采用同样的值吗",
        "state": "closed",
        "user": "paulpaul91",
        "closed_by": "michaelowenliu",
        "created_at": "2021-04-07T13:02:47+00:00",
        "updated_at": "2024-03-06T06:34:24+00:00",
        "closed_at": "2024-03-06T06:34:24+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 414,
        "title": "AttributeError: 'Fleet' object has no attribute 'DistributedStrategy'",
        "body": "当使用示例代码进行调试时报错：\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 17, in <module>\r\n    dist_strategy = fleet.DistributedStrategy()\r\nAttributeError: 'Fleet' object has no attribute 'DistributedStrategy'\r\n\r\n版本信息：\r\npaddlepaddle-gpu==2.0rc1，fleet-x==0.0.7\r\n\r\n请问这是什么原因呢？",
        "state": "closed",
        "user": "llzhaoshuo",
        "closed_by": "michaelowenliu",
        "created_at": "2020-12-30T02:12:06+00:00",
        "updated_at": "2024-03-06T06:34:18+00:00",
        "closed_at": "2024-03-06T06:34:18+00:00",
        "comments_count": [
            "gentelyang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 440,
        "title": "Example code cannot run",
        "body": "Environment: hub.baidubce.com/paddlepaddle/paddle:2.0.0rc1\r\n\r\nI tried to run example code in https://github.com/PaddlePaddle/FleetX/tree/develop/examples/wide_and_deep.\r\nGot the import error in `train.py`:\r\n```\r\nImportError: No module named 'paddle.distributed.fleet.utils.ps_util'\r\n```\r\n\r\nAm I supposed to run the code with 2.0.0rc1?\r\n\r\nAlso, the code is different from the code in the doc https://fleet-x.readthedocs.io/paddle_fleet_rst/parameter_server/ps_quick_start.html, but according to the doc, they should be the same. I have also tried to run the code in the doc, but it doesn't work with the `model.py` in the repo.",
        "state": "closed",
        "user": "Ruminateer",
        "closed_by": "Ruminateer",
        "created_at": "2021-01-20T03:58:48+00:00",
        "updated_at": "2021-03-17T07:35:21+00:00",
        "closed_at": "2021-03-17T07:35:21+00:00",
        "comments_count": [
            "gentelyang",
            "Ruminateer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 538,
        "title": "Slack Invite",
        "body": "Hi, how can I get invited to the slack channel?\r\n\r\nLink provided in the README.md leads to the sign in URL : https://fleetx.slack.com",
        "state": "closed",
        "user": "omar16100",
        "closed_by": "michaelowenliu",
        "created_at": "2021-09-10T06:53:48+00:00",
        "updated_at": "2024-03-06T06:34:46+00:00",
        "closed_at": "2024-03-06T06:34:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 509,
        "title": "request for demo (paddle.distributed.split) with several embeddings in model parallel",
        "body": "recently, when I use the FleetX to train large models with large embedding size(2000000 * 128) which is too large to fit GPU memory, when I use the demo provide by paddle using API(paddle.distributed.split), the demo runs smoothly, however, in my situation, I have several embedding need to split. so I modified the code like below. the process just stuck and no error. can someone help me solve this problem?\r\n\r\n**code with single distributed embedding demo.**\r\n\r\n```\r\nimport paddle\r\n\r\nfrom paddle.distributed import init_parallel_env\r\n\r\nfrom paddle.distributed import fleet\r\n\r\nfrom paddle import nn\r\n\r\n\r\n\r\npaddle.enable_static()\r\n\r\npaddle.set_device('gpu:%d'%paddle.distributed.ParallelEnv().dev_id)\r\n\r\nfleet.init(is_collective=True)\r\n\r\n\r\n\r\ndata = paddle.randint(0, 8, shape=[4,2])\r\n\r\n\r\n\r\nembed_init = nn.initializer.Uniform(low=-1.0, high=1.0)\r\n\r\nemb_attr = paddle.ParamAttr(initializer=embed_init, name=\"emb%s\" % paddle.distributed.ParallelEnv().dev_id)\r\n\r\nemb_out = paddle.distributed.split(\r\n\r\n        data,\r\n\r\n        (8, 8),\r\n\r\n        operation=\"embedding\",\r\n\r\n        num_partitions=2,\r\n\r\n        weight_attr=emb_attr,\r\n\r\n        )\r\n\r\nloss = paddle.mean(emb_out)\r\n\r\n\r\n\r\noptimizer = paddle.fluid.optimizer.Adam(0.1)\r\n\r\ndist_strategy = fleet.DistributedStrategy()\r\n\r\n\r\n\r\noptimizer = fleet.distributed_optimizer(optimizer, dist_strategy)\r\n\r\noptimizer.minimize(loss)\r\n\r\n\r\n\r\nplace = paddle.CUDAPlace(paddle.distributed.ParallelEnv().dev_id)\r\n\r\nexe = paddle.static.Executor(place)\r\n\r\nexe.run(paddle.static.default_startup_program())\r\n\r\nret = exe.run(paddle.static.default_main_program(), fetch_list=[loss.name])\r\n\r\nprint(ret)\r\n```\r\n\r\n\r\n**code with multiple distributed embedding demo.**\r\n\r\n```\r\nimport paddle\r\n\r\nfrom paddle.distributed import init_parallel_env\r\n\r\nfrom paddle.distributed import fleet\r\n\r\nfrom paddle import nn\r\n\r\npaddle.enable_static()\r\n\r\npaddle.set_device('gpu:%d'%paddle.distributed.ParallelEnv().dev_id)\r\n\r\nfleet.init(is_collective=True)\r\n\r\ndata = paddle.randint(0, 8, shape=[4,2])\r\n\r\nembed_init = nn.initializer.Uniform(low=-1.0, high=1.0)\r\n\r\nemb_attr1 = paddle.ParamAttr(initializer=embed_init, name=\"emb1%s\" % paddle.distributed.ParallelEnv().dev_id)\r\nemb_attr2 = paddle.ParamAttr(initializer=embed_init, name=\"emb2%s\" % paddle.distributed.ParallelEnv().dev_id)\r\n\r\nemb_out1 = paddle.distributed.split(\r\n\r\n        data,\r\n\r\n        (8, 8),\r\n\r\n        operation=\"embedding\",\r\n\r\n        num_partitions=2,\r\n\r\n        weight_attr=emb_attr1,\r\n\r\n        )\r\n\r\nemb_out2 = paddle.distributed.split(\r\n\r\n        data,\r\n\r\n        (8, 8),\r\n\r\n        operation=\"embedding\",\r\n\r\n        num_partitions=2,\r\n\r\n        weight_attr=emb_attr2,\r\n\r\n        )\r\n\r\nloss = paddle.mean(emb_out1) + paddle.mean(emb_out2)\r\n\r\n\r\n\r\noptimizer = paddle.fluid.optimizer.Adam(0.1)\r\n\r\ndist_strategy = fleet.DistributedStrategy()\r\n\r\n\r\n\r\noptimizer = fleet.distributed_optimizer(optimizer, dist_strategy)\r\n\r\noptimizer.minimize(loss)\r\n\r\n\r\n\r\nplace = paddle.CUDAPlace(paddle.distributed.ParallelEnv().dev_id)\r\n\r\nexe = paddle.static.Executor(place)\r\n\r\nexe.run(paddle.static.default_startup_program())\r\n\r\nret = exe.run(paddle.static.default_main_program(), fetch_list=[loss.name])\r\n\r\nprint(ret)\r\n\r\n```\r\n\r\n",
        "state": "closed",
        "user": "LiuHao-THU",
        "closed_by": "michaelowenliu",
        "created_at": "2021-06-15T02:57:25+00:00",
        "updated_at": "2024-03-06T06:34:34+00:00",
        "closed_at": "2024-03-06T06:34:34+00:00",
        "comments_count": [
            "sandyhouse",
            "LiuHao-THU",
            "LiuHao-THU"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 576,
        "title": "多机不训练",
        "body": "python3 -m paddle.distributed.launch --gpus=0 --ips=10.10.10.185,10.10.10.197 --host=10.10.10.197 train_fleet_static.py\r\n\r\n-----------  Configuration Arguments -----------\r\nbackend: auto\r\nelastic_server: None\r\nforce: False\r\ngpus: 0\r\nheter_devices: \r\nheter_worker_num: None\r\nheter_workers: \r\nhost: 10.10.10.197\r\nhttp_port: None\r\nips: 10.10.10.185,10.10.10.197\r\njob_id: None\r\nlog_dir: log\r\nnp: None\r\nnproc_per_node: None\r\nrun_mode: None\r\nscale: 0\r\nserver_num: None\r\nservers: \r\ntraining_script: train_fleet_static.py\r\ntraining_script_args: []\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nINFO 2021-12-14 10:47:17,483 launch.py:408] Run collective mode. gpu arguments:['--ips'], cuda count:1\r\nlaunch train in GPU mode!\r\nINFO 2021-12-14 10:47:17,484 launch_utils.py:525] Local start 1 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        1                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                10.10.10.197:6070              |\r\n    |                     PADDLE_TRAINERS_NUM                        2                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS       10.10.10.185:6070,10.10.10.197:6070     |\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                       0,0                     |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2021-12-14 10:47:17,484 launch_utils.py:530] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nlaunch proc_id:96795 idx:0\r\ntraining start\r\n/home/~/anaconda3/envs/paddle/lib/python3.9/site-packages/paddle/nn/layer/norm.py:652: UserWarning: When training, we now always track global mean and variance.\r\n  warnings.warn(\r\n/home/~/anaconda3/envs/paddle/lib/python3.9/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /home/~/anaconda3/envs/paddle/lib/python3.9/site-packages/paddle/vision/models/resnet.py:143\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nW1214 10:47:18.713200 96795 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.5, Runtime API Version: 10.2\r\nW1214 10:47:18.713238 96795 device_context.cc:465] device: 0, cuDNN Version: 8.1.\r\nI1214 10:47:20.225919 96795 gen_comm_id_helper.cc:190] Server listening on: 10.10.10.197:6070 successful.\r\n\r\n\r\n\r\npython3 -m paddle.distributed.launch --gpus=0 --ips=10.10.10.185,10.10.10.197 --host=10.10.10.185 train_fleet_static.py \r\n-----------  Configuration Arguments -----------\r\nbackend: auto\r\nelastic_server: None\r\nforce: False\r\ngpus: 0\r\nheter_worker_num: None\r\nheter_workers: \r\nhost: 10.10.10.185\r\nhttp_port: None\r\nips: 10.10.10.185,10.10.10.197\r\njob_id: None\r\nlog_dir: log\r\nnp: None\r\nnproc_per_node: None\r\nrun_mode: None\r\nscale: 0\r\nserver_num: None\r\nservers: \r\ntraining_script: train_fleet_static.py\r\ntraining_script_args: []\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nINFO:root:Run collective mode. gpu arguments:['--ips'], cuda count:1\r\nINFO 2021-12-14 10:47:08,221 launch.py:401] Run collective mode. gpu arguments:['--ips'], cuda count:1\r\nlaunch train in GPU mode!\r\nINFO:root:Local start 1 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                10.10.10.185:6070              |\r\n    |                     PADDLE_TRAINERS_NUM                        2                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS       10.10.10.185:6070,10.10.10.197:6070     |\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                       0,0                     |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2021-12-14 10:47:08,221 launch_utils.py:524] Local start 1 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                10.10.10.185:6070              |\r\n    |                     PADDLE_TRAINERS_NUM                        2                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS       10.10.10.185:6070,10.10.10.197:6070     |\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                       0,0                     |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO:root:details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nINFO 2021-12-14 10:47:08,221 launch_utils.py:529] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nlaunch proc_id:176862 idx:0\r\ntraining start\r\n/home/~/anaconda3/envs/paddle/lib/python3.9/site-packages/paddle/nn/layer/norm.py:652: UserWarning: When training, we now always track global mean and variance.\r\n  warnings.warn(\r\n/home/~/anaconda3/envs/paddle/lib/python3.9/site-packages/paddle/fluid/layers/math_op_patch.py:336: UserWarning: /home/~/anaconda3/envs/paddle/lib/python3.9/site-packages/paddle/vision/models/resnet.py:143\r\nThe behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\r\n  warnings.warn(\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['10.10.10.197:6070']\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['10.10.10.197:6070']\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['10.10.10.197:6070']\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['10.10.10.197:6070']\r\nW1214 10:47:21.061986 176862 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.5, Runtime API Version: 10.2\r\nW1214 10:47:21.062012 176862 device_context.cc:465] device: 0, cuDNN Version: 8.1.\r\n\r\n",
        "state": "closed",
        "user": "CunjunYin",
        "closed_by": "michaelowenliu",
        "created_at": "2021-12-14T02:54:29+00:00",
        "updated_at": "2024-03-06T06:35:09+00:00",
        "closed_at": "2024-03-06T06:35:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 539,
        "title": "分布式训练，单机多卡可以跑通，多机多卡可以建立通信但是不报错也不训练",
        "body": "### fleetrun --gpus=0,1 train_fleet_dygraph.py  正常运行\r\n\r\n-----------  Configuration Arguments -----------\r\ngpus: 0,1\r\nheter_worker_num: None\r\nheter_workers: \r\nhttp_port: None\r\nips: 127.0.0.1\r\nlog_dir: log\r\nnproc_per_node: None\r\nserver_num: None\r\nservers: \r\ntraining_script: train_fleet_dygraph.py\r\ntraining_script_args: []\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nWARNING 2021-09-18 15:33:48,326 launch.py:316] Not found distinct arguments and compiled with cuda. Default use collective mode\r\nlaunch train in GPU mode\r\nINFO 2021-09-18 15:33:48,328 launch_utils.py:471] Local start 2 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:25459               |\r\n    |                     PADDLE_TRAINERS_NUM                        2                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS         127.0.0.1:25459,127.0.0.1:61055       |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2021-09-18 15:33:48,328 launch_utils.py:475] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nI0918 15:33:49.541898 20096 nccl_context.cc:189] init nccl context nranks: 2 local rank: 0 gpu id: 0 ring id: 0\r\nW0918 15:33:50.633612 20096 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.2\r\nW0918 15:33:50.636582 20096 device_context.cc:372] device: 0, cuDNN Version: 8.0.\r\n[Epoch 0, batch 0] loss: 4.75578, acc1: 0.00000, acc5: 0.00000\r\n[Epoch 0, batch 5] loss: 25.66356, acc1: 0.03125, acc5: 0.06250\r\n[Epoch 0, batch 10] loss: 13.57118, acc1: 0.00000, acc5: 0.09375\r\n\r\n### fleetrun --ips=10.130.19.203,10.130.17.157 --gpus=0,1 train_fleet_dygraph.py  卡住不运行\r\n\r\n-----------  Configuration Arguments -----------\r\ngpus: 0,1\r\nheter_worker_num: None\r\nheter_workers: \r\nhttp_port: None\r\nips: 10.130.19.203,10.130.17.157\r\nlog_dir: log\r\nnproc_per_node: None\r\nserver_num: None\r\nservers: \r\ntraining_script: train_fleet_dygraph.py\r\ntraining_script_args: []\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nINFO 2021-09-18 15:41:49,243 launch.py:306] Run collective gpu mode. gpu arguments:['--ips'], cuda count:2\r\nlaunch train in GPU mode\r\nINFO 2021-09-18 15:41:49,245 launch_utils.py:471] Local start 2 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT               10.130.19.203:6070              |\r\n    |                     PADDLE_TRAINERS_NUM                        4                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS  ... 071,10.130.17.157:6070,10.130.17.157:6071|\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2021-09-18 15:41:49,245 launch_utils.py:475] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nW0918 15:41:50.323863 21635 nccl_context.cc:142] Socket connect worker 10.130.17.157:6070 failed, try again after 3 seconds.\r\nW0918 15:41:53.324177 21635 nccl_context.cc:142] Socket connect worker 10.130.17.157:6070 failed, try again after 6 seconds.\r\nW0918 15:41:59.324524 21635 nccl_context.cc:142] Socket connect worker 10.130.17.157:6070 failed, try again after 9 seconds.\r\nW0918 15:42:08.324882 21635 nccl_context.cc:142] Socket connect worker 10.130.17.157:6070 failed, try again after 12 seconds.\r\nI0918 15:42:20.325516 21635 nccl_context.cc:189] init nccl context nranks: 4 local rank: 0 gpu id: 0 ring id: 0\r\nW0918 15:42:21.382360 21635 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.2\r\nW0918 15:42:21.384966 21635 device_context.cc:372] device: 0, cuDNN Version: 8.0.",
        "state": "closed",
        "user": "jidlin",
        "closed_by": "michaelowenliu",
        "created_at": "2021-09-18T07:57:31+00:00",
        "updated_at": "2024-03-06T06:34:54+00:00",
        "closed_at": "2024-03-06T06:34:54+00:00",
        "comments_count": [
            "poetryben88"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 542,
        "title": "请问fleet的recompute目前支持动态图使用吗",
        "body": "paddle 2.1.2中也提供了动态图的recompute支持（from paddle.distributed.fleet.utils import recompute），不过在单机多卡环境下会报错，想请问下fleet支持动态图的recompute吗，谢谢。",
        "state": "closed",
        "user": "FesianXu",
        "closed_by": "FesianXu",
        "created_at": "2021-09-29T12:29:58+00:00",
        "updated_at": "2021-11-04T01:21:45+00:00",
        "closed_at": "2021-11-04T01:21:45+00:00",
        "comments_count": [
            "youth123"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 577,
        "title": "教程代码跑不起来cudaErrorNoKernelImageForDevice: no kernel image is available for execution on the device. (at /paddle/paddle/fluid/imperative/tracer.cc:221)",
        "body": "可能是我cuda版本不对？信息如下\r\n\r\npython -u /root/autodl-nas/BaseMP/FleetX-develop/examples/recompute/recompute_dygraph.py\r\nW0111 18:22:37.147157   515 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 10.2\r\nW0111 18:22:37.150291   515 device_context.cc:465] device: 0, cuDNN Version: 8.0.\r\n.....\r\n.....\r\n......\r\n......\r\n\r\nSystemError: (Fatal) Operator uniform_random raises an thrust::system::system_error exception.\r\nThe exception content is\r\n:parallel_for failed: cudaErrorNoKernelImageForDevice: no kernel image is available for execution on the device. (at /paddle/paddle/fluid/imperative/tracer.cc:221)\r\n",
        "state": "closed",
        "user": "FLYING37520",
        "closed_by": "FLYING37520",
        "created_at": "2022-01-11T10:25:09+00:00",
        "updated_at": "2022-01-11T10:38:48+00:00",
        "closed_at": "2022-01-11T10:38:48+00:00",
        "comments_count": [
            "FLYING37520"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 595,
        "title": "pipeline/train_fleet_pipeline.py  hang at one epoch finished ",
        "body": "https://github.com/PaddlePaddle/FleetX/blob/2817f4f641c5960f7a507a080ae48b642e0d8a45/examples/pipeline/train_fleet_pipeline.py#L99\r\n\r\nI run : python -m paddle.distributed.launch --gpus=\"0,1,2,3\" train_fleet_pipeline.py\r\n\r\n\r\n[Epoch 0, batch 5] loss: 48.88827, acc1: 0.06250, acc5: 0.09375\r\n[Epoch 0, batch 10] loss: 8.77979, acc1: 0.00000, acc5: 0.06250\r\n[Epoch 0, batch 15] loss: 19.01006, acc1: 0.00000, acc5: 0.12500\r\n[Epoch 0, batch 20] loss: 7.24177, acc1: 0.00000, acc5: 0.03125\r\n一个epoch运行完后会hang住.  卡住的位置应该是\r\n                if fleet.worker_index() == 3:\r\n                    loss, acc1, acc5 = exe.run(paddle.static.default_main_program(), fetch_list=[avg_cost, acc_top1, acc_top5])             \r\n                else:\r\n                    exe.run(paddle.static.default_main_program())       \r\nenv:\r\npaddle 2.3.0\r\ncuda 10.2\r\n Ubuntu x86_64 GNU/Linux\r\n\r\n",
        "state": "closed",
        "user": "LukeLIN-web",
        "closed_by": "michaelowenliu",
        "created_at": "2022-07-01T14:28:03+00:00",
        "updated_at": "2024-03-06T06:26:32+00:00",
        "closed_at": "2024-03-06T06:26:32+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 584,
        "title": "配置Sharding-hybrid-dp",
        "body": "Hi，在 [Sharding-hybrid-dp](https://fleet-x.readthedocs.io/en/latest/paddle_fleet_rst/collective/collective_mp/sharding.html#sharding-hybrid-dp) 文档介绍了能配置多机器间数据并行，机器内sharding并行，但是没有找到这部分的示例代码。我现在有4台机器，每台机器4张V100，那么我该如何配置这种混合并行方式？\r\n\r\n下面是配置sharding策略的部分，其中mp_degree和pp_degree都是1，sharding_degree和dp_degree都是4。\r\n\r\n```python\r\ndist_strategy = fleet.DistributedStrategy()\r\ndist_strategy.sharding = True\r\ndist_strategy.sharding_configs = {\r\n    \"segment_broadcast_MB\": 32,\r\n    \"sharding_degree\": args.sharding_degree,\r\n    \"mp_degree\": args.mp_degree,\r\n    \"pp_degree\": args.pp_degree,\r\n    \"dp_degree\": args.dp_degree,\r\n    \"optimize_offload\": False,\r\n}\r\n```\r\n\r\n开始训练后打印的分布式策略日志如下：\r\n\r\n```\r\n    +==============================================================================+\r\n    |                                                                              |\r\n    |                         DistributedStrategy Overview                         |\r\n    |                                                                              |\r\n    +==============================================================================+\r\n    |                           amp=True <-> amp_configs                           |\r\n    +------------------------------------------------------------------------------+\r\n    |                     init_loss_scaling                 32768.0                |\r\n    |                    incr_every_n_steps                   1000                 |\r\n    |               decr_every_n_nan_or_inf                    2                   |\r\n    |                            incr_ratio                   2.0                  |\r\n    |                            decr_ratio            0.800000011920929           |\r\n    |              use_dynamic_loss_scaling                   True                 |\r\n    |                     custom_white_list                 softmax                |\r\n    |                                                      layer_norm              |\r\n    |                                                         gelu                 |\r\n    |                     custom_black_list       c_softmax_with_cross_entropy     |\r\n    |                         use_pure_fp16                  False                 |\r\n    |                        use_fp16_guard                   True                 |\r\n    +==============================================================================+\r\n    |                      sharding=True <-> sharding_configs                      |\r\n    +------------------------------------------------------------------------------+\r\n    |             sharding_segment_strategy           segment_broadcast_MB         |\r\n    |                  segment_broadcast_MB                   32.0                 |\r\n    |                       sharding_degree                    4                   |\r\n    |                             mp_degree                    1                   |\r\n    |                             dp_degree                    4                   |\r\n    |                             hybrid_dp                  False                 |\r\n    |               gradient_merge_acc_step                    1                   |\r\n    |                      optimize_offload                  False                 |\r\n    |              pp_allreduce_in_optimize                  False                 |\r\n    |                             pp_degree                    1                   |\r\n    |                         optimize_cast                  False                 |\r\n    |             _dp_as_optimizer_sharding                  False                 |\r\n    +==============================================================================+\r\n    |                    Environment Flags, Communication Flags                    |\r\n    +------------------------------------------------------------------------------+\r\n    |                                  mode                    1                   |\r\n    |                               elastic                  False                 |\r\n    |                                  auto                  False                 |\r\n    |                   sync_nccl_allreduce                   True                 |\r\n    |                         nccl_comm_num                    2                   |\r\n    |            use_hierarchical_allreduce                  False                 |\r\n    |   hierarchical_allreduce_inter_nranks                    1                   |\r\n    |                       sync_batch_norm                  False                 |\r\n    |                   fuse_all_reduce_ops                   True                 |\r\n    |                  fuse_grad_size_in_MB                    32                  |\r\n    |              fuse_grad_size_in_TFLOPS                   50.0                 |\r\n    |               cudnn_exhaustive_search                  False                 |\r\n    |             conv_workspace_size_limit                   512                  |\r\n    |    cudnn_batchnorm_spatial_persistent                  False                 |\r\n    |                        fp16_allreduce                  False                 |\r\n    |               last_comm_group_size_MB                   1.0                  |\r\n    |                find_unused_parameters                  False                 |\r\n    |            without_graph_optimization                  False                 |\r\n    |                 fuse_grad_size_in_num                    8                   |\r\n    |                 calc_comm_same_stream                  False                 |\r\n    |                                   asp                  False                 |\r\n    |                       fuse_grad_merge                  False                 |\r\n    |                             semi_auto                  False                 |\r\n    +==============================================================================+\r\n    |                                Build Strategy                                |\r\n    +------------------------------------------------------------------------------+\r\n    |           enable_sequential_execution                  False                 |\r\n    |              fuse_elewise_add_act_ops                  False                 |\r\n    |                       fuse_bn_act_ops                  False                 |\r\n    |              fuse_relu_depthwise_conv                  False                 |\r\n    |                    fuse_broadcast_ops                  False                 |\r\n    |                fuse_all_optimizer_ops                  False                 |\r\n    |                        enable_inplace                  False                 |\r\n    |     enable_backward_optimizer_op_deps                   True                 |\r\n    |                 cache_runtime_context                  False                 |\r\n    |                   fuse_bn_add_act_ops                   True                 |\r\n    |                    enable_auto_fusion                  False                 |\r\n    |                          enable_addto                  False                 |\r\n    |                      fix_op_run_order                  False                 |\r\n    |              allow_cuda_graph_capture                  False                 |\r\n    +==============================================================================+\r\n    |                              Execution Strategy                              |\r\n    +------------------------------------------------------------------------------+\r\n    |                           num_threads                    2                   |\r\n    |          num_iteration_per_drop_scope                    1                   |\r\n    |                 num_iteration_per_run                    1                   |\r\n    |                    use_thread_barrier                  False                 |\r\n    +==============================================================================+\r\n\r\n```\r\n\r\n上面显示hybrid_dp为False，所以怀疑并没有启用Sharding-hybrid-dp。我现在遇到的问题是，多机并行的加速比太少了，4台机器大概是单台机器的1.4倍，所以怀疑是多机之间的sharding通信量限制了速度。\r\n",
        "state": "closed",
        "user": "HoratioJSY",
        "closed_by": "HoratioJSY",
        "created_at": "2022-03-18T03:50:01+00:00",
        "updated_at": "2022-03-30T07:40:25+00:00",
        "closed_at": "2022-03-30T07:40:24+00:00",
        "comments_count": [
            "HoratioJSY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 992,
        "title": "好像没有找到关于模型微调功能的部分，代码是还没有上库吗",
        "body": "如题，好像没有找到关于模型微调功能的部分，代码是还没有上库吗。我对这方面比较感兴趣。",
        "state": "closed",
        "user": "WeiChunyu-star",
        "closed_by": "michaelowenliu",
        "created_at": "2022-12-17T02:33:25+00:00",
        "updated_at": "2024-03-06T06:31:31+00:00",
        "closed_at": "2024-03-06T06:31:31+00:00",
        "comments_count": [
            "GuoxiaWang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1009,
        "title": "用pip拉取PaddleFleetX报错",
        "body": "![image](https://user-images.githubusercontent.com/52617714/210060189-1a2cfb98-cf01-433a-8967-85d3166b1756.png)\r\n",
        "state": "closed",
        "user": "boboboss-cmd",
        "closed_by": "michaelowenliu",
        "created_at": "2022-12-30T10:25:31+00:00",
        "updated_at": "2024-03-06T06:26:21+00:00",
        "closed_at": "2024-03-06T06:26:21+00:00",
        "comments_count": [
            "minghaoBD"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1010,
        "title": "平台是否含有python3.9的PaddleFleetX的docker容器",
        "body": null,
        "state": "closed",
        "user": "boboboss-cmd",
        "closed_by": "michaelowenliu",
        "created_at": "2023-01-03T01:42:20+00:00",
        "updated_at": "2024-03-06T06:35:34+00:00",
        "closed_at": "2024-03-06T06:35:34+00:00",
        "comments_count": [
            "kuizhiqing"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1026,
        "title": "分布式模式下，collective模型容器训练出现停滞问题",
        "body": "分布式模式下，采用collective训练模型，选取两个容器训练，一个容器训练完成后另一个容器就停止训练，该如何解决\r\n\r\n容器2已训练完成，模型参数已保存：\r\n![image](https://user-images.githubusercontent.com/52617714/215927927-59700ac9-97c9-46b9-a70e-4f811ba06f41.png)\r\n容器1停止训练：\r\n![image](https://user-images.githubusercontent.com/52617714/215928137-e5edfbc3-ba00-4e44-8765-77208d8010e8.png)\r\n监督容器界面为：\r\n![image](https://user-images.githubusercontent.com/52617714/215928260-45c38d4a-aea3-4e85-a58d-ab834ecd00c5.png)\r\n",
        "state": "closed",
        "user": "boboboss-cmd",
        "closed_by": "michaelowenliu",
        "created_at": "2023-02-01T02:12:08+00:00",
        "updated_at": "2024-03-06T06:36:21+00:00",
        "closed_at": "2024-03-06T06:36:21+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1016,
        "title": "在分布式情况下，使用paddle.save无法保存模型且未生成模型文件",
        "body": "![image](https://user-images.githubusercontent.com/52617714/210915119-6c1c2451-3f71-4e9e-bbc0-130156f1781b.png)\r\n![image](https://user-images.githubusercontent.com/52617714/210915320-4b4c5ee2-e447-49b2-9b8c-7d221efada93.png)\r\n",
        "state": "closed",
        "user": "boboboss-cmd",
        "closed_by": "michaelowenliu",
        "created_at": "2023-01-06T02:08:24+00:00",
        "updated_at": "2024-03-06T06:35:42+00:00",
        "closed_at": "2024-03-06T06:35:42+00:00",
        "comments_count": [
            "GuoxiaWang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1032,
        "title": "以参数服务器的模型进行多机多卡训练，有什么可参考的案例？",
        "body": null,
        "state": "closed",
        "user": "boboboss-cmd",
        "closed_by": "michaelowenliu",
        "created_at": "2023-02-08T06:40:01+00:00",
        "updated_at": "2024-03-06T06:35:52+00:00",
        "closed_at": "2024-03-06T06:35:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1019,
        "title": "在paddlefleet分布式模型训练的情况下，使用collective模型时，模型的保存和加载方式是如何实现的？",
        "body": null,
        "state": "closed",
        "user": "boboboss-cmd",
        "closed_by": "GuoxiaWang",
        "created_at": "2023-01-10T09:12:27+00:00",
        "updated_at": "2023-01-11T06:15:33+00:00",
        "closed_at": "2023-01-11T06:15:33+00:00",
        "comments_count": [
            "GuoxiaWang",
            "boboboss-cmd",
            "GuoxiaWang",
            "GuoxiaWang",
            "boboboss-cmd",
            "boboboss-cmd",
            "haohongxiang",
            "boboboss-cmd",
            "GuoxiaWang",
            "boboboss-cmd",
            "GuoxiaWang",
            "boboboss-cmd",
            "GuoxiaWang",
            "boboboss-cmd",
            "GuoxiaWang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1044,
        "title": "请问是否支持NPU多机多卡并行，包括数据并行、模型并行、pipline并行？",
        "body": null,
        "state": "closed",
        "user": "zws-2019",
        "closed_by": "michaelowenliu",
        "created_at": "2023-02-20T04:51:28+00:00",
        "updated_at": "2024-03-06T06:36:00+00:00",
        "closed_at": "2024-03-06T06:36:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1045,
        "title": "ModuleNotFoundError: No module named 'paddle.distributed.fleet.base.strategy_group'",
        "body": null,
        "state": "closed",
        "user": "zws-2019",
        "closed_by": "michaelowenliu",
        "created_at": "2023-02-20T07:53:47+00:00",
        "updated_at": "2024-03-06T06:36:06+00:00",
        "closed_at": "2024-03-06T06:36:06+00:00",
        "comments_count": [
            "USTCKAY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1057,
        "title": "paddle.fluid.fleet和paddle.distributed.fleet的差别是什么？在使用静态图的paddle.static.Executor时，运行时总是提醒“UserWarning: Standalone executor is not used for fleet”该如何解决？",
        "body": null,
        "state": "closed",
        "user": "boboboss-cmd",
        "closed_by": "michaelowenliu",
        "created_at": "2023-03-08T01:48:54+00:00",
        "updated_at": "2024-03-06T06:36:27+00:00",
        "closed_at": "2024-03-06T06:36:27+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1095,
        "title": "[DDP] Paddle的model parallel和Megatron的tensor parallel实现是否一致？",
        "body": "测试混合并行时发现：**在sharding_degree为1的情况下**（**disable sharding**），paddle的mp除了对参数进行切分，**也会优化器的状态进行切分**。\r\n\r\n根据megetraon的tensor parallel策略来看，其不会对优化器状态进行切分。\r\n\r\n请问：**paddle中的model parallel和megatron中的tensor parallel的策略是一致的吗？**",
        "state": "closed",
        "user": "BeingGod",
        "closed_by": "BeingGod",
        "created_at": "2023-08-07T08:34:36+00:00",
        "updated_at": "2023-08-07T10:08:37+00:00",
        "closed_at": "2023-08-07T10:08:37+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1054,
        "title": "多机多卡分布式训练卡住",
        "body": "### 请提出你的问题 Please ask your question\r\n\r\n我正在使用paddlepaddle进行分布式训练，单机多卡可以正常训练，多机多卡collective模式下，会在init nccl后卡住，无法进入下一步，没有任何报错信息，使用--log_level=debug也没有输出任何信息，日志信息如下：\r\n1. 第一个节点：使用命令`python -m paddle.distributed.launch --ips=172.16.13.74,172.16.13.87 train_with_fleet.py`\r\n``` shell\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nLAUNCH INFO 2023-03-02 02:01:33,781 -----------  Configuration  ----------------------\r\nLAUNCH INFO 2023-03-02 02:01:33,782 devices: None\r\nLAUNCH INFO 2023-03-02 02:01:33,782 elastic_level: -1\r\nLAUNCH INFO 2023-03-02 02:01:33,782 elastic_timeout: 30\r\nLAUNCH INFO 2023-03-02 02:01:33,782 gloo_port: 6767\r\nLAUNCH INFO 2023-03-02 02:01:33,782 host: None\r\nLAUNCH INFO 2023-03-02 02:01:33,782 job_id: default\r\nLAUNCH INFO 2023-03-02 02:01:33,782 legacy: False\r\nLAUNCH INFO 2023-03-02 02:01:33,782 log_dir: log\r\nLAUNCH INFO 2023-03-02 02:01:33,782 log_level: INFO\r\nLAUNCH INFO 2023-03-02 02:01:33,782 master: None\r\nLAUNCH INFO 2023-03-02 02:01:33,783 max_restart: 3\r\nLAUNCH INFO 2023-03-02 02:01:33,783 nnodes: 1\r\nLAUNCH INFO 2023-03-02 02:01:33,783 nproc_per_node: None\r\nLAUNCH INFO 2023-03-02 02:01:33,783 rank: -1\r\nLAUNCH INFO 2023-03-02 02:01:33,783 run_mode: collective\r\nLAUNCH INFO 2023-03-02 02:01:33,783 server_num: None\r\nLAUNCH INFO 2023-03-02 02:01:33,783 servers: \r\nLAUNCH INFO 2023-03-02 02:01:33,783 trainer_num: None\r\nLAUNCH INFO 2023-03-02 02:01:33,783 trainers: \r\nLAUNCH INFO 2023-03-02 02:01:33,783 training_script: train_with_fleet.py\r\nLAUNCH INFO 2023-03-02 02:01:33,784 training_script_args: []\r\nLAUNCH INFO 2023-03-02 02:01:33,784 with_gloo: 0\r\nLAUNCH INFO 2023-03-02 02:01:33,784 --------------------------------------------------\r\nLAUNCH WARNING 2023-03-02 02:01:33,784 Compatible mode enable with args ['--ips=172.16.13.74,172.16.13.87']\r\n-----------  Configuration Arguments -----------\r\nbackend: auto\r\ncluster_topo_path: None\r\nelastic_pre_hook: None\r\nelastic_server: None\r\nenable_auto_mapping: False\r\nforce: False\r\ngpus: None\r\nheter_devices: \r\nheter_worker_num: None\r\nheter_workers: \r\nhost: None\r\nhttp_port: None\r\nips: 172.16.13.74,172.16.13.87\r\njob_id: None\r\nlog_dir: log\r\nnp: None\r\nnproc_per_node: None\r\nrank_mapping_path: None\r\nrun_mode: None\r\nscale: 0\r\nserver_num: None\r\nservers: \r\ntraining_script: train_with_fleet.py\r\ntraining_script_args: []\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nINFO 2023-03-02 02:01:33,787 launch.py:504] Run collective mode. gpu arguments:['--ips'], cuda count:2\r\nINFO 2023-03-02 02:01:33,787 launch.py:504] Run collective mode. gpu arguments:['--ips'], cuda count:2\r\nlaunch train in GPU mode!\r\nINFO 2023-03-02 02:01:33,809 launch_utils.py:561] Local start 2 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        2                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                172.16.13.87:6070              |\r\n    |                     PADDLE_TRAINERS_NUM                        4                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS  ... :6071,172.16.13.87:6070,172.16.13.87:6071|\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                     0,1,0,1                   |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2023-03-02 02:01:33,809 launch_utils.py:561] Local start 2 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        2                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                172.16.13.87:6070              |\r\n    |                     PADDLE_TRAINERS_NUM                        4                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS  ... :6071,172.16.13.87:6070,172.16.13.87:6071|\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                     0,1,0,1                   |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2023-03-02 02:01:33,809 launch_utils.py:566] details about PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nINFO 2023-03-02 02:01:33,809 launch_utils.py:566] details about PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nlaunch proc_id:324 idx:0\r\nlaunch proc_id:329 idx:1\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nI0302 02:01:35.129714   324 gen_comm_id_helper.cc:205] Server listening on: 172.16.13.87:6070 successful.\r\nI0302 02:01:36.279278   324 nccl_context.cc:83] init nccl context nranks: 4 local rank: 2 gpu id: 0 ring id: 0\r\n```\r\n2. 第二个节点使用命令：`python -m paddle.distributed.launch --ips=172.16.13.74,172.16.13.87 train_with_fleet.py`\r\n``` shell\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nLAUNCH INFO 2023-03-02 02:01:22,936 -----------  Configuration  ----------------------\r\nLAUNCH INFO 2023-03-02 02:01:22,936 devices: None\r\nLAUNCH INFO 2023-03-02 02:01:22,936 elastic_level: -1\r\nLAUNCH INFO 2023-03-02 02:01:22,936 elastic_timeout: 30\r\nLAUNCH INFO 2023-03-02 02:01:22,936 gloo_port: 6767\r\nLAUNCH INFO 2023-03-02 02:01:22,936 host: None\r\nLAUNCH INFO 2023-03-02 02:01:22,936 job_id: default\r\nLAUNCH INFO 2023-03-02 02:01:22,936 legacy: False\r\nLAUNCH INFO 2023-03-02 02:01:22,936 log_dir: log\r\nLAUNCH INFO 2023-03-02 02:01:22,936 log_level: INFO\r\nLAUNCH INFO 2023-03-02 02:01:22,936 master: None\r\nLAUNCH INFO 2023-03-02 02:01:22,936 max_restart: 3\r\nLAUNCH INFO 2023-03-02 02:01:22,936 nnodes: 1\r\nLAUNCH INFO 2023-03-02 02:01:22,936 nproc_per_node: None\r\nLAUNCH INFO 2023-03-02 02:01:22,936 rank: -1\r\nLAUNCH INFO 2023-03-02 02:01:22,936 run_mode: collective\r\nLAUNCH INFO 2023-03-02 02:01:22,936 server_num: None\r\nLAUNCH INFO 2023-03-02 02:01:22,936 servers: \r\nLAUNCH INFO 2023-03-02 02:01:22,936 trainer_num: None\r\nLAUNCH INFO 2023-03-02 02:01:22,936 trainers: \r\nLAUNCH INFO 2023-03-02 02:01:22,936 training_script: train_with_fleet.py\r\nLAUNCH INFO 2023-03-02 02:01:22,936 training_script_args: []\r\nLAUNCH INFO 2023-03-02 02:01:22,937 with_gloo: 0\r\nLAUNCH INFO 2023-03-02 02:01:22,937 --------------------------------------------------\r\nLAUNCH WARNING 2023-03-02 02:01:22,937 Compatible mode enable with args ['--ips=172.16.13.74,172.16.13.87']\r\n-----------  Configuration Arguments -----------\r\nbackend: auto\r\ncluster_topo_path: None\r\nelastic_pre_hook: None\r\nelastic_server: None\r\nenable_auto_mapping: False\r\nforce: False\r\ngpus: None\r\nheter_devices: \r\nheter_worker_num: None\r\nheter_workers: \r\nhost: None\r\nhttp_port: None\r\nips: 172.16.13.74,172.16.13.87\r\njob_id: None\r\nlog_dir: log\r\nnp: None\r\nnproc_per_node: None\r\nrank_mapping_path: None\r\nrun_mode: None\r\nscale: 0\r\nserver_num: None\r\nservers: \r\ntraining_script: train_with_fleet.py\r\ntraining_script_args: []\r\nworker_num: None\r\nworkers: \r\n------------------------------------------------\r\nINFO 2023-03-02 02:01:22,938 launch.py:504] Run collective mode. gpu arguments:['--ips'], cuda count:2\r\nINFO 2023-03-02 02:01:22,938 launch.py:504] Run collective mode. gpu arguments:['--ips'], cuda count:2\r\nlaunch train in GPU mode!\r\nINFO 2023-03-02 02:01:22,939 launch_utils.py:561] Local start 2 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                172.16.13.74:6070              |\r\n    |                     PADDLE_TRAINERS_NUM                        4                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS  ... :6071,172.16.13.87:6070,172.16.13.87:6071|\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                     0,1,0,1                   |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2023-03-02 02:01:22,939 launch_utils.py:561] Local start 2 processes. First process distributed environment info (Only For Debug): \r\n    +=======================================================================================+\r\n    |                        Distributed Envs                      Value                    |\r\n    +---------------------------------------------------------------------------------------+\r\n    |                       PADDLE_TRAINER_ID                        0                      |\r\n    |                 PADDLE_CURRENT_ENDPOINT                172.16.13.74:6070              |\r\n    |                     PADDLE_TRAINERS_NUM                        4                      |\r\n    |                PADDLE_TRAINER_ENDPOINTS  ... :6071,172.16.13.87:6070,172.16.13.87:6071|\r\n    |                     PADDLE_RANK_IN_NODE                        0                      |\r\n    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\r\n    |                 PADDLE_WORLD_DEVICE_IDS                     0,1,0,1                   |\r\n    |                     FLAGS_selected_gpus                        0                      |\r\n    |             FLAGS_selected_accelerators                        0                      |\r\n    +=======================================================================================+\r\n\r\nINFO 2023-03-02 02:01:22,939 launch_utils.py:566] details about PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nINFO 2023-03-02 02:01:22,939 launch_utils.py:566] details about PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\r\nlaunch proc_id:31267 idx:0\r\nlaunch proc_id:31272 idx:1\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['172.16.13.74:6071', '172.16.13.87:6070', '172.16.13.87:6071']\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['172.16.13.87:6070', '172.16.13.87:6071']\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['172.16.13.87:6070', '172.16.13.87:6071']\r\nserver not ready, wait 3 sec to retry...\r\nnot ready endpoints:['172.16.13.87:6070', '172.16.13.87:6071']\r\nI0302 02:01:36.274989 31267 nccl_context.cc:83] init nccl context nranks: 4 local rank: 0 gpu id: 0 ring id: 0\r\n```\r\n发现两个节点都卡在了init nccl后，然后四个节点的endpoint log都已经检查过了，返回的信息都是\r\n``` shell\r\nI0302 02:01:36.274989 31267 nccl_context.cc:83] init nccl context nranks: 4 local rank: 0/1 gpu id: 0/1 ring id: 0/1\r\n```\r\n使用命令`nvidia-smi -l 10`查看GPU占用，一直是0，最长一次等过大概20分钟，还是一直卡在init nccl后。\r\n想请教一下具体的原因是什么。\r\n\r\npaddle版本：2.3.2\r\npython版本：3.7\r\ncuda版本：11.6",
        "state": "closed",
        "user": "Yiheng-Liu",
        "closed_by": "Yiheng-Liu",
        "created_at": "2023-03-03T01:59:06+00:00",
        "updated_at": "2023-03-07T09:58:04+00:00",
        "closed_at": "2023-03-07T09:58:04+00:00",
        "comments_count": [
            "Yiheng-Liu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1090,
        "title": "在使用CustomDevice单机双卡推理ernie模型，配置应当mp=2，为何运行log中似乎dp=2",
        "body": "```shell\r\n[2023-06-19 17:07:48,648] [    INFO] distributed_strategy.py:152 - distributed strategy initialized\r\nI0619 17:07:48.649518 3565096 tcp_utils.cc:181] The server starts to listen on IP_ANY:53537\r\nI0619 17:07:48.649669 3565096 tcp_utils.cc:130] Successfully connected to 127.0.1.1:53537\r\n[2023-06-19 17:07:53,079] [    INFO] topology.py:268 - Total 1 data comm group(s) create successfully!\r\n[2023-06-19 17:07:53,084] [    INFO] topology.py:268 - Total 2 model comm group(s) create successfully!\r\n[2023-06-19 17:07:53,088] [    INFO] topology.py:268 - Total 2 pipe comm group(s) create successfully!\r\n[2023-06-19 17:07:53,091] [    INFO] topology.py:268 - Total 2 sharding comm group(s) create successfully!\r\n[2023-06-19 17:07:53,096] [    INFO] topology.py:217 - HybridParallelInfo: rank_id: 0, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [0],  sharding_group: [0], pp_group: [0], dp_group: [0, 1], check/clip group: [0]\r\nargs.mp_degree= 2 _(脚本中手动打印的配置)_\r\nself.mp_degree 2 _(脚本中手动打印的配置)_\r\nI0619 17:07:53.134132 3565096 analysis_predictor.cc:1503] CustomDevice is enabled\r\n```\r\n0. 如上log应当表明建立了dp=2、mp=1的并行，是否正确？\r\n1. 请问可能的原因有哪些？比如缺失mp必需的算子？是否其中有fallback机制使得mp=2转为dp=2？\r\n2. 另，当前NPU实现了基于PaddleFleetX的模型并行、流水线并行了吗？",
        "state": "closed",
        "user": "jinyouzhi",
        "closed_by": "jinyouzhi",
        "created_at": "2023-06-19T09:12:08+00:00",
        "updated_at": "2023-08-29T07:17:51+00:00",
        "closed_at": "2023-08-29T07:17:51+00:00",
        "comments_count": [
            "GuoxiaWang",
            "jinyouzhi",
            "jinyouzhi",
            "GuoxiaWang",
            "ronny1996",
            "jinyouzhi",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1077,
        "title": "开启recompute后，单机四卡分组切分并行报错",
        "body": "不加入recompute，单机四卡分组切分并行可以正常训练\r\n但开启recompute后\r\n即在模型中：x = blk(x,H,W)\r\n改为：x = recompute(blk,x,H,W)\r\n训练完第一个epoch后报以下错误：\r\nepoch: 1, batch_id: 1, loss is: [2.6346893]\r\nTraceback (most recent call last):\r\nFile \"PVT-v2_distribute.py\", line 425, in\r\ntrain2()\r\nFile \"PVT-v2_distribute.py\", line 402, in train2\r\nscaler.scale(avg_loss).backward()\r\nFile \"\", line 2, in backward\r\nFile \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 26, in impl\r\nreturn wrapped_func(*args, **kwargs)\r\nFile \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 534, in impl\r\nreturn func(*args, **kwargs)\r\nFile \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 297, in backward\r\ncore.eager.run_backward([self], grad_tensor, retain_graph)\r\nOSError: (External) RuntimeError: (PreconditionNotMet) Error happened, when parameter[341][linear_79.b_0] has been ready before. Please set find_unused_parameters=True to traverse backward graph in each step to prepare reduce in advance. If you have set, there may be several reasons for this error: 1) In multiple reentrant backward phase, some parameters are reused.2) Using model parameters outside of forward function. Please make sure that model parameters are not shared in concurrent forward-backward passes.\r\n[Hint: Expected has_marked_unused_vars_ == false, but received has_marked_unused_vars_:1 != false:0.] (at /paddle/paddle/fluid/distributed/collective/reducer.cc:689)\r\n\r\nAt:\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/autograd/backward_mode.py(125): backward\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py(534): impl\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py(26): impl\r\n(2): backward\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/fleet/recompute/recompute.py(392): backward\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/autograd/py_layer.py(546): backward\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py(297): backward\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py(534): impl\r\n/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py(26): impl\r\n(2): backward\r\nPVT-v2_distribute.py(402): train2\r\nPVT-v2_distribute.py(425):\r\n(at /paddle/paddle/fluid/eager/pylayer/py_layer_node.cc:113)",
        "state": "closed",
        "user": "Nefefilibata",
        "closed_by": "michaelowenliu",
        "created_at": "2023-04-17T15:17:30+00:00",
        "updated_at": "2024-03-06T06:36:34+00:00",
        "closed_at": "2024-03-06T06:36:34+00:00",
        "comments_count": [
            "Nefefilibata",
            "GuoxiaWang",
            "Nefefilibata",
            "michaelowenliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1099,
        "title": "ernie模型是否能以动态图模型推理？",
        "body": "请问具体在PaddleFleetX下该功能具体怎么配置，如果没有怎么修改",
        "state": "closed",
        "user": "jinyouzhi",
        "closed_by": "jinyouzhi",
        "created_at": "2023-08-29T07:22:41+00:00",
        "updated_at": "2023-09-01T08:16:52+00:00",
        "closed_at": "2023-09-01T08:16:52+00:00",
        "comments_count": [
            "jinyouzhi"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1105
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1100,
        "title": "ernie base 6.7B mp4 infernece  在 cuda 上报错 ",
        "body": "报错信息\r\n\r\n```bash\r\nI0906 14:50:19.027952 3535380 task_node.cc:42] Constructing TaskNode for DistModelInf. The TaskNode's id is: 0. And the TaskNode's max_run_time and max_slot_num will be set to 1.\r\nI0906 14:50:19.038934 3535380 server.cpp:1107] Server[paddle::distributed::MessageServiceImpl] is serving on port=45436.\r\nI0906 14:50:19.038955 3535380 server.cpp:1110] Check out http://g0300:45436 in web browser.\r\nI0906 14:50:19.039060 3535380 message_bus.cc:202] Message bus's listen port thread starts successful.\r\nterminate called after throwing an instance of 'phi::enforce::EnforceNotMet'\r\n  what():  (External) CUBLAS error(13). \r\n  [Hint: 'CUBLAS_STATUS_EXECUTION_FAILED'.  The GPU program failed to execute. This is often caused by a launch failure of the kernel on the GPU, which can be caused by multiple reasons.  To correct: check that the hardware, an appropriate version of the driver, and the cuBLAS library are correctly installed. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:41)\r\n  [operator < fused_multi_transformer > error]\r\nLAUNCH INFO 2023-09-06 14:50:22,026 Exit code -6\r\n[2023-09-06 14:50:22,026] [    INFO] controller.py:149 - Exit code -6\r\n```",
        "state": "closed",
        "user": "KimBioInfoStudio",
        "closed_by": "michaelowenliu",
        "created_at": "2023-09-06T06:59:47+00:00",
        "updated_at": "2024-03-06T06:36:58+00:00",
        "closed_at": "2024-03-06T06:36:57+00:00",
        "comments_count": [
            "michaelowenliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1101,
        "title": "gpt13b训练 sharding stage3 + mp 报错",
        "body": "Traceback (most recent call last):\r\n  File \"tools/train.py\", line 74, in <module>\r\n    engine.fit(train_data_loader=train_data_loader,\r\n  File \"/mnt/qiaohan/PaddleFleetX-develop/ppfleetx/core/engine/eager_engine.py\", line 445, in fit\r\n    self._train_one_epoch(epoch_index, train_data_loader,\r\n  File \"/mnt/qiaohan/PaddleFleetX-develop/ppfleetx/core/engine/eager_engine.py\", line 351, in _train_one_epoch\r\n    loss = self._fit_impl(batch)\r\n  File \"/mnt/qiaohan/PaddleFleetX-develop/ppfleetx/core/engine/eager_engine.py\", line 519, in _fit_impl\r\n    self._optim_update_params()\r\n  File \"/mnt/qiaohan/PaddleFleetX-develop/ppfleetx/core/engine/eager_engine.py\", line 575, in _optim_update_params\r\n    self._scaler.step(self._optimizer)\r\n  File \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/amp/grad_scaler.py\", line 757, in step\r\n    self._unscale(optimizer)\r\n  File \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/distributed/fleet/meta_parallel/sharding/group_sharded_utils.py\", line 235, in unscale_method\r\n    optimizer.update_slice()\r\n  File \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/distributed/fleet/meta_parallel/sharding/group_sharded_stage3.py\", line 277, in _update_params_slice\r\n    update_list = self._update_params()\r\n  File \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/distributed/fleet/meta_parallel/sharding/group_sharded_stage3.py\", line 598, in _update_params\r\n    param.fw_storage = _TensorWrapper(param)\r\n  File \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/distributed/fleet/meta_parallel/sharding/group_sharded_stage3.py\", line 1086, in _TensorWrapper\r\n    shape=var.shape, dtype=var.dtype, name=\"slice@\" + param.name\r\nAttributeError: 'NoneType' object has no attribute 'shape'",
        "state": "closed",
        "user": "raining-dark",
        "closed_by": "michaelowenliu",
        "created_at": "2023-09-13T02:55:16+00:00",
        "updated_at": "2024-03-06T06:36:52+00:00",
        "closed_at": "2024-03-06T06:36:52+00:00",
        "comments_count": [
            "raining-dark",
            "raining-dark",
            "raining-dark",
            "raining-dark",
            "raining-dark",
            "michaelowenliu"
        ],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 1104
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1102,
        "title": "gpt模型 gpu 训练shard_stage3 + mp 出现bug",
        "body": null,
        "state": "closed",
        "user": "raining-dark",
        "closed_by": "michaelowenliu",
        "created_at": "2023-09-13T10:18:57+00:00",
        "updated_at": "2024-03-06T06:36:45+00:00",
        "closed_at": "2024-03-06T06:36:45+00:00",
        "comments_count": [
            "raining-dark",
            "michaelowenliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1103,
        "title": "gpt345M CUDA 在 shard_stage 3 + mp 配置下训练报错",
        "body": "RT. 参数配置，mp=2+shard degree=2（stage3），模型gpt345M\r\n\r\n```\r\n[2023-09-13 01:04:42,843] [INFO] - Data :\r\n[2023-09-13 01:04:42,843] [INFO] - Eval :\r\n[2023-09-13 01:04:42,843] [INFO] - dataset :\r\n[2023-09-13 01:04:42,844] [INFO] - input_dir : /mnt/qiaohan/large_training_data\r\n[2023-09-13 01:04:42,844] [INFO] - max_seq_len : 1024\r\n[2023-09-13 01:04:42,844] [INFO] - mode : Eval\r\n[2023-09-13 01:04:42,844] [INFO] - model_type : GPT\r\n[2023-09-13 01:04:42,844] [INFO] - name : GPTDataset\r\n[2023-09-13 01:04:42,844] [INFO] - num_samples : 240\r\n[2023-09-13 01:04:42,844] [INFO] - seed : 1024\r\n[2023-09-13 01:04:42,844] [INFO] - split : [969, 30, 1]\r\n[2023-09-13 01:04:42,844] [INFO] - loader :\r\n[2023-09-13 01:04:42,844] [INFO] - collate_fn : gpt_collate_fn\r\n[2023-09-13 01:04:42,844] [INFO] - num_workers : 1\r\n[2023-09-13 01:04:42,844] [INFO] - return_list : False\r\n[2023-09-13 01:04:42,844] [INFO] - sampler :\r\n[2023-09-13 01:04:42,844] [INFO] - batch_size : 4\r\n[2023-09-13 01:04:42,844] [INFO] - drop_last : True\r\n[2023-09-13 01:04:42,844] [INFO] - name : GPTBatchSampler\r\n[2023-09-13 01:04:42,844] [INFO] - shuffle : False\r\n[2023-09-13 01:04:42,844] [INFO] - Train :\r\n[2023-09-13 01:04:42,844] [INFO] - dataset :\r\n[2023-09-13 01:04:42,844] [INFO] - input_dir : /mnt/qiaohan/large_training_data\r\n[2023-09-13 01:04:42,844] [INFO] - max_seq_len : 1024\r\n[2023-09-13 01:04:42,844] [INFO] - mode : Train\r\n[2023-09-13 01:04:42,844] [INFO] - model_type : GPT\r\n[2023-09-13 01:04:42,845] [INFO] - name : GPTDataset\r\n[2023-09-13 01:04:42,845] [INFO] - num_samples : 80000\r\n[2023-09-13 01:04:42,845] [INFO] - seed : 1024\r\n[2023-09-13 01:04:42,845] [INFO] - split : [969, 30, 1]\r\n[2023-09-13 01:04:42,845] [INFO] - loader :\r\n[2023-09-13 01:04:42,845] [INFO] - collate_fn : gpt_collate_fn\r\n[2023-09-13 01:04:42,845] [INFO] - num_workers : 1\r\n[2023-09-13 01:04:42,845] [INFO] - return_list : False\r\n[2023-09-13 01:04:42,845] [INFO] - sampler :\r\n[2023-09-13 01:04:42,845] [INFO] - batch_size : 4\r\n[2023-09-13 01:04:42,845] [INFO] - drop_last : True\r\n[2023-09-13 01:04:42,845] [INFO] - name : GPTBatchSampler\r\n[2023-09-13 01:04:42,845] [INFO] - shuffle : False\r\n[2023-09-13 01:04:42,845] [INFO] - Distributed :\r\n[2023-09-13 01:04:42,845] [INFO] - dp_degree : 1\r\n[2023-09-13 01:04:42,845] [INFO] - fuse_sequence_parallel_allreduce : False\r\n[2023-09-13 01:04:42,845] [INFO] - hcg : HybridCommunicateGroup\r\n[2023-09-13 01:04:42,845] [INFO] - mp_degree : 2\r\n[2023-09-13 01:04:42,845] [INFO] - pp_degree : 1\r\n[2023-09-13 01:04:42,845] [INFO] - pp_recompute_interval : 1\r\n[2023-09-13 01:04:42,845] [INFO] - sharding :\r\n[2023-09-13 01:04:42,845] [INFO] - broadcast_overlap : False\r\n[2023-09-13 01:04:42,845] [INFO] - reduce_overlap : False\r\n[2023-09-13 01:04:42,846] [INFO] - sharding_degree : 2\r\n[2023-09-13 01:04:42,846] [INFO] - sharding_offload : False\r\n[2023-09-13 01:04:42,846] [INFO] - sharding_stage : 3\r\n[2023-09-13 01:04:42,846] [INFO] - Engine :\r\n[2023-09-13 01:04:42,846] [INFO] - accumulate_steps : 1\r\n[2023-09-13 01:04:42,846] [INFO] - eval_freq : 5000\r\n[2023-09-13 01:04:42,846] [INFO] - eval_iters : 10\r\n[2023-09-13 01:04:42,846] [INFO] - logging_freq : 1\r\n[2023-09-13 01:04:42,846] [INFO] - max_steps : 10000\r\n[2023-09-13 01:04:42,846] [INFO] - mix_precision :\r\n[2023-09-13 01:04:42,846] [INFO] - custom_black_list : ['layer_norm', 'reduce_sum', 'c_softmax_with_cross_entropy', 'elementwise_div']\r\n[2023-09-13 01:04:42,846] [INFO] - custom_white_list : ['lookup_table', 'lookup_table_v2']\r\n[2023-09-13 01:04:42,846] [INFO] - dtype : float16\r\n[2023-09-13 01:04:42,846] [INFO] - enable : True\r\n[2023-09-13 01:04:42,846] [INFO] - level : O1\r\n[2023-09-13 01:04:42,846] [INFO] - scale_loss : 65536.0\r\n[2023-09-13 01:04:42,846] [INFO] - num_train_epochs : 1\r\n[2023-09-13 01:04:42,846] [INFO] - save_load :\r\n[2023-09-13 01:04:42,846] [INFO] - ckpt_dir : None\r\n[2023-09-13 01:04:42,846] [INFO] - output_dir : ./output_mp\r\n[2023-09-13 01:04:42,846] [INFO] - save_epoch : 1\r\n[2023-09-13 01:04:42,846] [INFO] - save_steps : 1000\r\n[2023-09-13 01:04:42,846] [INFO] - test_iters : 100\r\n[2023-09-13 01:04:42,846] [INFO] - Global :\r\n[2023-09-13 01:04:42,847] [INFO] - device : gpu\r\n[2023-09-13 01:04:42,847] [INFO] - enable_partial_send_recv : True\r\n[2023-09-13 01:04:42,847] [INFO] - global_batch_size : 8\r\n[2023-09-13 01:04:42,847] [INFO] - local_batch_size : 4\r\n[2023-09-13 01:04:42,847] [INFO] - micro_batch_size : 4\r\n[2023-09-13 01:04:42,847] [INFO] - seed : 1024\r\n[2023-09-13 01:04:42,847] [INFO] - Model :\r\n[2023-09-13 01:04:42,847] [INFO] - attention_probs_dropout_prob : 0.0\r\n[2023-09-13 01:04:42,847] [INFO] - ffn_hidden_size : 4096\r\n[2023-09-13 01:04:42,847] [INFO] - fuse_attn_qkv : True\r\n[2023-09-13 01:04:42,847] [INFO] - fused_linear : False\r\n[2023-09-13 01:04:42,847] [INFO] - fused_softmax_with_triangular : False\r\n[2023-09-13 01:04:42,847] [INFO] - hidden_dropout_prob : 0.0\r\n[2023-09-13 01:04:42,847] [INFO] - hidden_size : 1024\r\n[2023-09-13 01:04:42,847] [INFO] - initializer_range : 0.02\r\n[2023-09-13 01:04:42,847] [INFO] - max_position_embeddings : 1024\r\n[2023-09-13 01:04:42,847] [INFO] - module : GPTModule\r\n[2023-09-13 01:04:42,847] [INFO] - name : GPT\r\n[2023-09-13 01:04:42,847] [INFO] - no_recompute_layers : []\r\n[2023-09-13 01:04:42,847] [INFO] - num_attention_heads : 16\r\n[2023-09-13 01:04:42,847] [INFO] - num_layers : 24\r\n[2023-09-13 01:04:42,847] [INFO] - recompute_granularity : full\r\n[2023-09-13 01:04:42,847] [INFO] - scale_qk_by_layer_num : True\r\n[2023-09-13 01:04:42,847] [INFO] - sequence_parallel : False\r\n[2023-09-13 01:04:42,848] [INFO] - type_vocab_size : 16\r\n[2023-09-13 01:04:42,848] [INFO] - use_flash_attn : False\r\n[2023-09-13 01:04:42,848] [INFO] - use_recompute : True\r\n[2023-09-13 01:04:42,848] [INFO] - vocab_size : 51200\r\n[2023-09-13 01:04:42,848] [INFO] - vocab_size_divisible_unit : 128\r\n[2023-09-13 01:04:42,848] [INFO] - Optimizer :\r\n[2023-09-13 01:04:42,848] [INFO] - beta1 : 0.9\r\n[2023-09-13 01:04:42,848] [INFO] - beta2 : 0.999\r\n[2023-09-13 01:04:42,848] [INFO] - epsilon : 1e-08\r\n[2023-09-13 01:04:42,848] [INFO] - grad_clip :\r\n[2023-09-13 01:04:42,848] [INFO] - clip_norm : 1.0\r\n[2023-09-13 01:04:42,848] [INFO] - name : ClipGradByGlobalNorm\r\n[2023-09-13 01:04:42,848] [INFO] - lr :\r\n[2023-09-13 01:04:42,848] [INFO] - decay_steps : 2880000\r\n[2023-09-13 01:04:42,848] [INFO] - max_lr : 5e-05\r\n[2023-09-13 01:04:42,848] [INFO] - min_lr : 1e-05\r\n[2023-09-13 01:04:42,848] [INFO] - name : CosineAnnealingWithWarmupDecay\r\n[2023-09-13 01:04:42,848] [INFO] - use_increments : True\r\n[2023-09-13 01:04:42,848] [INFO] - warmup_rate : 0.01\r\n[2023-09-13 01:04:42,848] [INFO] - multi_precision : True\r\n[2023-09-13 01:04:42,848] [INFO] - name : FusedAdamW\r\n[2023-09-13 01:04:42,848] [INFO] - tensor_fusion : False\r\n[2023-09-13 01:04:42,848] [INFO] - weight_decay : 0.01\r\n[2023-09-13 01:04:42,848] [INFO] - Profiler :\r\n[2023-09-13 01:04:42,849] [INFO] - detailed : False\r\n[2023-09-13 01:04:42,849] [INFO] - enable : False\r\n[2023-09-13 01:04:42,849] [INFO] - profiler_log : profiler_log\r\n[2023-09-13 01:04:42,849] [INFO] - scheduler : [1, 3]\r\n```\r\n\r\n报错信息：\r\n```\r\nTraceback (most recent call last):\r\nFile \"tools/train.py\", line 74, in\r\nengine.fit(train_data_loader=train_data_loader,\r\nFile \"/mnt/qiaohan/PaddleFleetX-develop/ppfleetx/core/engine/eager_engine.py\", line 445, in fit\r\nself._train_one_epoch(epoch_index, train_data_loader,\r\nFile \"/mnt/qiaohan/PaddleFleetX-develop/ppfleetx/core/engine/eager_engine.py\", line 351, in _train_one_epoch\r\nloss = self._fit_impl(batch)\r\nFile \"/mnt/qiaohan/PaddleFleetX-develop/ppfleetx/core/engine/eager_engine.py\", line 519, in _fit_impl\r\nself._optim_update_params()\r\nFile \"/mnt/qiaohan/PaddleFleetX-develop/ppfleetx/core/engine/eager_engine.py\", line 575, in _optim_update_params\r\nself._scaler.step(self._optimizer)\r\nFile \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/amp/grad_scaler.py\", line 757, in step\r\nself._unscale(optimizer)\r\nFile \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/distributed/fleet/meta_parallel/sharding/group_sharded_utils.py\", line 235, in unscale_method\r\noptimizer.update_slice()\r\nFile \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/distributed/fleet/meta_parallel/sharding/group_sharded_stage3.py\", line 277, in _update_params_slice\r\nupdate_list = self._update_params()\r\nFile \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/distributed/fleet/meta_parallel/sharding/group_sharded_stage3.py\", line 598, in _update_params\r\nparam.fw_storage = _TensorWrapper(param)\r\nFile \"/data/application/zhangtj/anaconda3/envs/paddle_gpt2/lib/python3.8/site-packages/paddle/distributed/fleet/meta_parallel/sharding/group_sharded_stage3.py\", line 1086, in _TensorWrapper\r\nshape=var.shape, dtype=var.dtype, name=\"slice@\" + param.name\r\nAttributeError: 'NoneType' object has no attribute 'shape'\r\n```\r\n\r\n注意到：[源码此处](https://github.com/PaddlePaddle/PaddleFleetX/blob/develop/ppfleetx/core/engine/eager_engine.py) check代码这里assert stage2 + mp\r\n![image](https://github.com/PaddlePaddle/PaddleFleetX/assets/127805199/edce5c2b-0e4b-45eb-a98e-6327a5007bb9)\r\n\r\n\r\n**请问：如果我修改该处，让gpt13b训练能够跑stage3 + mp请问这种做法支持吗？报错应该怎么排查**\r\n\r\n怀疑是保存模型的时候会有该报错，save_step设置小些更容易更快复现(比如设置1000步则1000步报出，500步则500步报出)\r\n\r\n",
        "state": "closed",
        "user": "tiandou-tangdou",
        "closed_by": "michaelowenliu",
        "created_at": "2023-09-13T11:54:11+00:00",
        "updated_at": "2024-03-06T06:23:55+00:00",
        "closed_at": "2024-03-06T06:23:55+00:00",
        "comments_count": [
            "michaelowenliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1111,
        "title": "怎么样能最快从自动驾驶感知算法工程师转到大模型算法工程师?",
        "body": "我的日常工作会涉及transformer。之前项目也有融合激光雷达和相机数据的，可以拿来学习。我日常工作也涉及一些模型小型化的工作，比如混合精度训练。另外，我也会用openmmlab的分布式训练。我怎么样能最快从自动驾驶算法工程师转到大模型算法工程师",
        "state": "open",
        "user": "yushengjiexy",
        "closed_by": null,
        "created_at": "2025-02-09T14:06:38+00:00",
        "updated_at": "2025-02-09T14:06:41+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1106,
        "title": "开发环境配置过程中问题频出",
        "body": "1. 这个项目有即开即用的 docker 环境\r\n\r\n当前出现的问题有：\r\n- ModuleNotFoundError: No module named 'paddle.fluid'\r\n- ImportError: libcudart.so.10.2: cannot open shared object file: No such file or directory\r\n- 其他一些包的不兼容或者安装失败，如\r\n```\r\n#7 74.65   ERROR: Command errored out with exit status 1:\r\n#7 74.65    command: /usr/bin/python /usr/local/lib/python3.7/dist-packages/pip-20.0.1-py3.7.egg/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-41peemij/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://mirror.baidu.com/pypi/simple -- 'setuptools>=64' wheel scikit-build 'setuptools_scm>=8'\r\n#7 74.65        cwd: None\r\n#7 74.65   Complete output (9 lines):\r\n#7 74.65   Looking in indexes: https://mirror.baidu.com/pypi/simple\r\n#7 74.65   Collecting setuptools>=64\r\n#7 74.65     Downloading https://mirror.baidu.com/pypi/packages/c7/42/be1c7bbdd83e1bfb160c94b9cafd8e25efc7400346cf7ccdbdb452c467fa/setuptools-68.0.0-py3-none-any.whl (804 kB)\r\n#7 74.65   Collecting wheel\r\n#7 74.65     Downloading https://mirror.baidu.com/pypi/packages/c7/c3/55076fc728723ef927521abaa1955213d094933dc36d4a2008d5101e1af5/wheel-0.42.0-py3-none-any.whl (65 kB)\r\n#7 74.65   Collecting scikit-build\r\n#7 74.65     Downloading https://mirror.baidu.com/pypi/packages/fa/af/b3ef8fe0bb96bf7308e1f9d196fc069f0c75d9c74cfaad851e418cc704f4/scikit_build-0.17.6-py3-none-any.whl (84 kB)\r\n#7 74.65   ERROR: Could not find a version that satisfies the requirement setuptools_scm>=8 (from versions: 1.0.0, 1.1.0, 1.2.0, 1.3.0, 1.4.0, 1.4.1, 1.5.0, 1.5.2, 1.5.3, 1.5.4, 1.5.5, 1.6.0, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.10.1, 1.11.0, 1.11.1, 1.13.0, 1.13.1, 1.14.0rc1, 1.14.0, 1.15.0rc1, 1.15.0, 1.15.1rc1, 1.15.4, 1.15.5, 1.15.6, 1.15.7, 1.16.0, 1.16.1, 1.16.2, 1.17.0, 2.0.0, 2.1.0, 3.0.0, 3.0.1, 3.0.2, 3.0.4, 3.0.5, 3.0.6, 3.1.0, 3.2.0, 3.3.1, 3.3.2, 3.3.3, 3.4.0, 3.4.1, 3.4.2, 3.4.3, 3.5.0, 4.0.0, 4.1.0, 4.1.1, 4.1.2, 5.0.0, 5.0.1, 5.0.2, 6.0.0, 6.0.1, 6.1.0.dev0, 6.1.0, 6.1.1, 6.2.0, 6.3.0, 6.3.1, 6.3.2, 6.4.0, 6.4.1, 6.4.2, 7.0.0, 7.0.1, 7.0.2, 7.0.3, 7.0.4, 7.0.5, 7.1.0)\r\n#7 74.65   ERROR: No matching distribution found for setuptools_scm>=8\r\n```\r\n\r\n2. 是不是paddlepaddle-gpu==0.0.0.post112 这个版本是随着时间变化的？有没有 PaddleFleetX 具体对应的 paddle 版本信息？\r\n\r\n",
        "state": "open",
        "user": "deepindeed2022",
        "closed_by": null,
        "created_at": "2024-03-09T12:55:06+00:00",
        "updated_at": "2024-03-15T10:22:17+00:00",
        "closed_at": null,
        "comments_count": [
            "deepindeed2022",
            "deepindeed2022",
            "michaelowenliu",
            "deepindeed2022",
            "michaelowenliu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleFleetX",
        "number": 1108,
        "title": "No module named 'ppfleetx'",
        "body": "Traceback (most recent call last):\r\n  File \"/remote-home/lzy/Helixfold/helixfold/run_helixfold.py\", line 37, in <module>\r\n    from utils.init_env import init_seed, init_distributed_env\r\n  File \"/remote-home/lzy/Helixfold/helixfold/utils/init_env.py\", line 19, in <module>\r\n    from ppfleetx.distributed.protein_folding import dp\r\nModuleNotFoundError: No module named 'ppfleetx'\r\n运行helixfold时候，按照gulide按照后，缺少ppfleetx，暂时没有找到合适的pip源来按照和下载。",
        "state": "open",
        "user": "Linzy19",
        "closed_by": null,
        "created_at": "2024-04-09T08:15:21+00:00",
        "updated_at": "2024-07-16T06:36:54+00:00",
        "closed_at": null,
        "comments_count": [
            "qfduli"
        ],
        "labels": []
    }
]