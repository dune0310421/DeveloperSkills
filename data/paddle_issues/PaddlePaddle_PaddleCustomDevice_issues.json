[
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 185,
        "title": "[NPU][ResNet50] Paddle 的 CrossEntroy 算子相比 Torch 存在冗余算子",
        "body": "**问题表现**：Paddle/Torch 单独跑 CrossEntroy 算子，Paddle 比 Torch 多了很多 cast, multiply, full 等算子的调用\r\n\r\n**代码定位和解决办法**：\r\n```bash\r\n# ./nn/functional/loss.py\r\ndef cross_entropy(... ...\r\n    if in_dygraph_mode():\r\n        if soft_label == False: # 这里根据算子定义，只有 weight != None 的时候才需要 valid_label，并不是所有计算都需要，可以跳过\r\n            valid_label = (\r\n                paddle.cast(label != ignore_index, dtype=label.dtype) * label\r\n            )\r\n# 否则很多时间都会耗费在 full 和 cast 算子计算上\r\n# 同时 npu 计算默认使用原有的 label 而不是 valid_label，以下这段代码是被 MLU 修改过\r\n# PR1: MLU 复用 NPU 代码 https://github.com/PaddlePaddle/Paddle/pull/39523\r\n# PR2：MLU 修改使用 valid_label https://github.com/PaddlePaddle/Paddle/pull/45201 ==> 和寒武纪确认中为啥要改？\r\n# 寒武纪回复：有的label里面有255的值，valid把255的值过滤掉，是在 deeplabv3 模型上遇到的，需要确认下“ignore index应该是会忽略某一个类别，但是255也同样被拿掉”？\r\n        if core.is_compiled_with_npu() or core.is_compiled_with_mlu():\r\n            if soft_label == False:\r\n                _, _, out = _legacy_C_ops.softmax_with_cross_entropy(\r\n                    input,\r\n                    valid_label, # 这里原先 NPU 使用的是 label，不需要 valid_label 的计算\r\n                    'soft_label',\r\n                    soft_label,\r\n                    'ignore_index',\r\n                    ignore_index,\r\n                    'numeric_stable_mode',\r\n                    True,\r\n                    'axis',\r\n                    axis,\r\n                    'use_softmax',\r\n                    use_softmax,\r\n                )\r\n \r\n # 将以下代码注释之后\r\n             valid_label = (\r\n                paddle.cast(label != ignore_index, dtype=label.dtype) * label\r\n            )\r\n```\r\n\r\n修复前后的 profiling 输出对比\r\n\r\n```bash\r\n# profiling 前后输出为\r\n ----------------------------------------------------------------Operator Summary---------------------\r\nTime unit: ms\r\n----------------------------------------------------  ------  ---------------------------------------- \r\nName                                                  Calls   CPU Total / Avg / Max / Min / Ratio(%) \r\n----------------------------------------------------  ------  ---------------------------------------- \r\n-----------------------------------------------------------Thread: All threads merged------------------\r\nfull dygraph                                          1       0.35 / 0.35 / 0.35 / 0.35 / 41.28\r\n  full infer_meta                                     1       0.00 / 0.00 / 0.00 / 0.00 / 0.81 \r\n  full compute                                        1       0.17 / 0.17 / 0.17 / 0.17 / 50.29\r\ncross_entropy_with_softmax dygraph                    1       0.17 / 0.17 / 0.17 / 0.17 / 20.35\r\n  cross_entropy_with_softmax infer_meta               1       0.00 / 0.00 / 0.00 / 0.00 / 1.10 \r\n  cross_entropy_with_softmax compute                  1       0.16 / 0.16 / 0.16 / 0.16 / 91.65\r\nnot_equal dygraph                                     1       0.09 / 0.09 / 0.09 / 0.09 / 10.28\r\n  not_equal infer_meta                                1       0.00 / 0.00 / 0.00 / 0.00 / 4.14 \r\n  not_equal compute                                   1       0.07 / 0.07 / 0.07 / 0.07 / 79.23\r\nmultiply dygraph                                      1       0.08 / 0.08 / 0.08 / 0.08 / 10.03\r\n  multiply infer_meta                                 1       0.00 / 0.00 / 0.00 / 0.00 / 3.14 \r\n  multiply compute                                    1       0.07 / 0.07 / 0.07 / 0.07 / 83.12\r\ncast dygraph                                          1       0.08 / 0.08 / 0.08 / 0.08 / 9.64 \r\n  cast infer_meta                                     1       0.00 / 0.00 / 0.00 / 0.00 / 1.96 \r\n  cast compute                                        1       0.07 / 0.07 / 0.07 / 0.07 / 83.00\r\nmean_all dygraph                                      1       0.07 / 0.07 / 0.07 / 0.07 / 8.42 \r\n  mean_all infer_meta                                 1       0.00 / 0.00 / 0.00 / 0.00 / 1.43 \r\n  mean_all compute                                    1       0.06 / 0.06 / 0.06 / 0.06 / 84.33\r\n----------------------------------------------------  ------  ---------------------------------------- \r\n\r\n# 前后对比，减少了大量算子在 full, cast 以及 multiply 算子上耗费的时间\r\n\r\n----------------------------------------------------------------Operator Summary-----------------------\r\nTime unit: ms\r\n----------------------------------------------------  ------  ---------------------------------------- \r\nName                                                  Calls   CPU Total / Avg / Max / Min / Ratio(%) \r\n----------------------------------------------------  ------  ---------------------------------------- \r\n-----------------------------------------------------------Thread: All threads merged------------------\r\ncross_entropy_with_softmax dygraph                    1       0.36 / 0.36 / 0.36 / 0.36 / 85.35\r\n  cross_entropy_with_softmax infer_meta               1       0.00 / 0.00 / 0.00 / 0.00 / 0.99 \r\n  cross_entropy_with_softmax compute                  1       0.21 / 0.21 / 0.21 / 0.21 / 58.29\r\nmean_all dygraph                                      1       0.06 / 0.06 / 0.06 / 0.06 / 14.65\r\n  mean_all infer_meta                                 1       0.00 / 0.00 / 0.00 / 0.00 / 1.67 \r\n  mean_all compute                                    1       0.05 / 0.05 / 0.05 / 0.05 / 83.78\r\n----------------------------------------------------  ------  ---------------------------------------- \r\n```\r\n",
        "state": "closed",
        "user": "qili93",
        "closed_by": "qili93",
        "created_at": "2022-11-07T04:30:51+00:00",
        "updated_at": "2024-02-05T10:39:46+00:00",
        "closed_at": "2024-02-05T10:39:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 53,
        "title": "[NPU Daily-CI] fail because Paddle commit",
        "body": "Daily CI: https://xly.bce.baidu.com/paddlepaddle/paddle-custom-device/newipipe/detail/6051767/job/16438707\r\nPaddle PR: https://github.com/PaddlePaddle/Paddle/pull/43878\r\n\r\n![image](https://user-images.githubusercontent.com/5997715/177900213-59c2d39a-335b-4da6-9d25-5c2f23f38dae.png)\r\n",
        "state": "closed",
        "user": "Aganlengzi",
        "closed_by": "Aganlengzi",
        "created_at": "2022-07-08T01:48:26+00:00",
        "updated_at": "2022-07-11T01:14:10+00:00",
        "closed_at": "2022-07-11T01:14:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 184,
        "title": "[NPU][ResNet50]  INT64 数据类型跑在 AI_CPU 上而不是 AI_Core 上",
        "body": "**表现：** Mul, Cast 等输入数据类型为 INT64 的算子跑在 AI_CPU 而不是 AI_CORE 上\r\n**原因：** 昇腾等系列国产硬件对 INT64 数据类型支持有问题，但是飞桨框架默认数据集的 Label 读取为 int64 类似\r\n**解决办法：** 修改套件代码，强制返回 Label 数据类型为 int32 类型\r\n**分析方法：** 模型中添加 acl profiler 接口获得性能分析结果\r\n\r\n**临时解决方案：**\r\n\r\n```bash\r\n# 模型代码中调用 mul, cast 等算子的代码为\r\ncost = nn.CrossEntropyLoss()\r\nloss = cost(outputs, labels) # 这里调用\r\n\r\n# 框架代码中调用 mul, cast 等算子的代码为\r\ndef cross_entropy(... ...\r\nvalid_label = paddle.multiply(paddle.cast(label != ignore_index, dtype=label.dtype), label)\r\n\r\n# 解决办法，修改 diff 如下，或者修改套件代码里面的 dataset 代码\r\ndiff --git a/python/paddle/vision/datasets/folder.py b/python/paddle/vision/datasets/folder.py\r\nindex 6ac0c4ca91..569396b482 100644\r\n--- a/python/paddle/vision/datasets/folder.py\r\n+++ b/python/paddle/vision/datasets/folder.py\r\n@@ -271,8 +271,10 @@ class DatasetFolder(Dataset):\r\n         sample = self.loader(path)\r\n         if self.transform is not None:\r\n             sample = self.transform(sample)\r\n+        import numpy as np\r\n+        return sample, np.array([target]).astype('int32')\r\n\r\n-        return sample, target\r\n+        #return sample, target\r\n\r\n     def __len__(self):\r\n         return len(self.samples)\r\n```\r\n \r\n\r\n",
        "state": "closed",
        "user": "qili93",
        "closed_by": "qili93",
        "created_at": "2022-11-07T04:27:48+00:00",
        "updated_at": "2024-02-05T10:39:36+00:00",
        "closed_at": "2024-02-05T10:39:36+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 191,
        "title": "[NPU][ResNet50] 支持 Storage Format 转化后 InferMeta 会失败",
        "body": "经过 storage dims 转化后，origin_format: NCHW, rigin_dims: 6 的 tensor 会转化为 storage_format: NC0HWC1, storage_dims: 1, 1, 1, 1, 16；实际这个 tensor 需要申请的 NPU显存大小就是16，因此调用 DenseTensor 的 ResizeAndAllocate 后，框架中默认存储的 DDim 也编程了 [1, 1, 1, 1, 16]，之后再对 BN 算子的 BatchNormInferMeta 进行输入的 dims 检查的时候会失败(失败原因是 BN 输入的 mean Tensor 的 dim.size 需要为1，但是 格式转化后的 dims.size 为 5， 因此导致检查失败)\r\n\r\n同时 InferMeta 获取得到的 output dims 的形状也是错误的\r\n\r\n```bash\r\nInput: x: format: NCHW, dims: [4, 1, 24, 24, 16], origin_format: 0, origin_dims: [4, 6, 24, 24], storage_format: 3, storage_dims: [4, 1, 24, 24, 16]\r\nInput: running_mean: format: NCHW, dims: [1, 1, 1, 1, 16], origin_format: 0, origin_dims: [6], storage_format: 3, storage_dims: [1, 1, 1, 1, 16]\r\nInput: running_var: format: NCHW, dims: [1, 1, 1, 1, 16], origin_format: 0, origin_dims: [6], storage_format: 3, storage_dims: [1, 1, 1, 1, 16]\r\nInput: scale: format: NCHW, dims: [1, 1, 1, 1, 16], origin_format: 0, origin_dims: [6], storage_format: 3, storage_dims: [1, 1, 1, 1, 16]\r\nInput: bias: format: NCHW, dims: [1, 1, 1, 1, 16], origin_format: 0, origin_dims: [6], storage_format: 3, storage_dims: [1, 1, 1, 1, 16]\r\nOutput: y: format: NCHW, dims: [4, 1, 24, 24, 16] ==> Not Initialized.\r\nOutput: mean_out: format: NCHW, dims: [1] ==> Not Initialized. # 这里应该是[C] = [6]，但是读取 Input: x 的 C 读到了 1 ，所以就错了\r\nOutput: variance_out: format: NCHW, dims: [1] ==> Not Initialized.\r\nOutput: saved_mean: format: NCHW, dims: [1] ==> Not Initialized.\r\nOutput: saved_variance: format: NCHW, dims: [1] ==> Not Initialized.\r\n```",
        "state": "closed",
        "user": "qili93",
        "closed_by": "qili93",
        "created_at": "2022-11-08T10:50:15+00:00",
        "updated_at": "2023-03-07T13:02:19+00:00",
        "closed_at": "2023-03-07T13:02:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 235,
        "title": "编译kernel报错：找不到paddle/fluid/platform/flags.h",
        "body": "### 问题\r\n编译时kernel部分报错：\r\nIn file included from ……python3.8/site-packages/paddle/include/paddle/phi/core/ddim.h:21,\r\n                 from ……python3.8/site-packages/paddle/include/paddle/phi/core/tensor_meta.h:22,\r\n                 from ……python3.8/site-packages/paddle/include/paddle/phi/core/compat/convert_utils.h:21,\r\n                 from ……python3.8/site-packages/paddle/include/paddle/phi/core/kernel_factory.h:26,\r\n                 from ……python3.8/site-packages/paddle/include/paddle/phi/core/custom_kernel.h:17,\r\n                 from ……python3.8/site-packages/paddle/include/paddle/phi/core/kernel_registry.h:24,\r\n                 from ……PaddleCustomDevice/backends/mlu/kernels/add_n_kernel.cc:21:\r\nfatal error: paddle/fluid/platform/flags.h: No such file or directory\r\n  101 | #include \"paddle/fluid/platform/flags.h\"\r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\nmake[2]: *** [CMakeFiles/paddle-custom-mlu.dir/build.make:76: CMakeFiles/paddle-custom-mlu.dir/kernels/add_n_kernel.cc.o] Error 1\r\n但该路径下有这一文件……请问该如何解决呢？\r\n\r\n### 基本信息\r\n- paddle为最新dev，Aarch64环境编译。\r\n- add_n_kernel.cc文件，实现仅有一条cout语句，include仅为#include \"paddle/phi/core/kernel_registry.h\"\r\n- 注册部分代码为\r\nPD_REGISTER_PLUGIN_KERNEL(add_n,\r\n                          CustomMLU,\r\n                          ALL_LAYOUT,\r\n                          custom_kernel::AddNKernel,\r\n                          float,\r\n                          phi::dtype::float16,\r\n                          double) {}\r\n\r\n\r\n",
        "state": "closed",
        "user": "adepp",
        "closed_by": "adepp",
        "created_at": "2022-11-26T10:44:13+00:00",
        "updated_at": "2022-11-27T16:16:46+00:00",
        "closed_at": "2022-11-27T16:16:46+00:00",
        "comments_count": [
            "adepp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 46,
        "title": "NPU RuntimeError: (Unavailable) AddCallback is not supported on ascend",
        "body": "For test_momentum_op_npu:\r\nctest -R test_momentum_op_npu, it reports:\r\n![image](https://user-images.githubusercontent.com/5997715/175205340-07be4060-1ca2-4dc0-8fc4-3a62ba7abf49.png)\r\n\r\n",
        "state": "closed",
        "user": "Aganlengzi",
        "closed_by": "Aganlengzi",
        "created_at": "2022-06-23T03:54:13+00:00",
        "updated_at": "2022-07-20T06:47:01+00:00",
        "closed_at": "2022-07-20T06:47:01+00:00",
        "comments_count": [
            "Aganlengzi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 197,
        "title": "如何判断注册是否成功？是否与paddle版本有关",
        "body": "## 当前问题\r\n1. 已按照《自定义新硬件接入指南》文档https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/dev_guides/custom_device_docs/index_cn.html基于custom_cpu代码完成了runtime部分接口的编写（其他部分仍为custom_cpu源代码，是否有影响？）\r\n2. 编译、pip成功后在执行paddle.device.get_all_custom_device_type()时返回值为空（[]）（如何判断是否注册成功？）\r\n\r\n## 环境\r\n1. 飞腾ARMCPU。从源码编译paddle时develop版编译失败，所以当前环境paddle版本为release版（非develop版是否对新硬件插件有影响？）",
        "state": "closed",
        "user": "adepp",
        "closed_by": "adepp",
        "created_at": "2022-11-11T06:57:03+00:00",
        "updated_at": "2022-11-16T07:55:06+00:00",
        "closed_at": "2022-11-16T07:55:06+00:00",
        "comments_count": [
            "ronny1996",
            "adepp",
            "ronny1996",
            "adepp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 42,
        "title": "paddle.jit.to_static fail with custom device",
        "body": "CustomDevice currently not support dygraph to static, reproduce steps as following.\r\n\r\n1. Install `paddle-custom-npu` based on [README](https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README.md)\r\n\r\n2. Run mnist_train.py on CPU succeeded:\r\n\r\n```python\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport shutil\r\nimport numpy as np\r\nimport paddle\r\nfrom paddle import nn\r\nimport paddle.nn.functional as F\r\n\r\nclass ConvBNLayer(nn.Layer):\r\n    def __init__(self,\r\n                 num_channels,\r\n                 num_filters,\r\n                 filter_size,\r\n                 stride,\r\n                 padding,\r\n                 num_groups=1):\r\n        super().__init__()\r\n\r\n        self.conv = nn.Conv2D(\r\n            in_channels=num_channels,\r\n            out_channels=num_filters,\r\n            kernel_size=filter_size,\r\n            stride=stride,\r\n            padding=padding,\r\n            groups=num_groups,\r\n            weight_attr=None,\r\n            bias_attr=False)\r\n        self.bn = nn.BatchNorm(num_filters)\r\n        self.relu = nn.ReLU()\r\n\r\n    def forward(self, x):\r\n        x = self.conv(x)\r\n        x = self.bn(x)\r\n        x = self.relu(x)\r\n        return x\r\n\r\nclass MNIST(nn.Layer):\r\n    def __init__(self):\r\n        super(MNIST, self).__init__()\r\n\r\n        self.conv0 = ConvBNLayer(\r\n                    num_channels=1,\r\n                    num_filters=4,\r\n                    filter_size=5,\r\n                    stride=1,\r\n                    padding=0,\r\n                    num_groups=1)\r\n        self.conv1 = ConvBNLayer(\r\n                    num_channels=4,\r\n                    num_filters=4,\r\n                    filter_size=1,\r\n                    stride=1,\r\n                    padding=0,\r\n                    num_groups=1)\r\n        self.max_pool = nn.MaxPool2D(kernel_size=4, stride=4, padding=0)\r\n        self.fc = nn.Linear(in_features=144, out_features=10)\r\n\r\n    @paddle.jit.to_static()\r\n    def forward(self, inputs, label=None):\r\n        x = self.conv0(inputs)\r\n        x1 = self.max_pool(x)\r\n        x2 = self.conv1(x1)\r\n        x = paddle.add(x=x1, y=x2)\r\n        x = paddle.flatten(x, start_axis=1, stop_axis=-1)\r\n        x = self.fc(x)\r\n        out = F.softmax(x)\r\n        if label is not None:\r\n            acc = paddle.metric.accuracy(input=x, label=label)\r\n            return out, acc\r\n        else:\r\n            return out\r\n\r\ndef test_mnist(test_reader, mnist_model):\r\n    acc_set = []\r\n    avg_loss_set = []\r\n\r\n    for batch_id, data in enumerate(test_reader()):\r\n        x_data = np.array([x[0].reshape(1, 28, 28) for x in data]).astype('float32')\r\n        y_data = np.array([x[1] for x in data]).astype('int64').reshape(-1, 1)\r\n\r\n        image = paddle.to_tensor(x_data)\r\n        label = paddle.to_tensor(y_data)\r\n\r\n        prediction, acc = mnist_model(image, label)\r\n        loss = F.cross_entropy(input=prediction, label=label)\r\n        avg_loss = paddle.mean(loss)\r\n\r\n        acc_set.append(float(acc.numpy()))\r\n        avg_loss_set.append(float(avg_loss.numpy()))\r\n\r\n    acc_val_mean = np.array(acc_set).mean()\r\n    avg_loss_val_mean = np.array(avg_loss_set).mean()\r\n    return avg_loss_val_mean, acc_val_mean\r\n\r\n\r\ndef train_mnist(num_epochs, save_dirname):\r\n    paddle.set_device('cpu')\r\n\r\n    mnist = MNIST()\r\n    adam = paddle.optimizer.Adam(learning_rate=0.001, parameters=mnist.parameters())\r\n\r\n    train_reader = paddle.batch(paddle.dataset.mnist.train(), batch_size=BATCH_SIZE, drop_last=True)\r\n    test_reader = paddle.batch(paddle.dataset.mnist.test(), batch_size=BATCH_SIZE, drop_last=True)\r\n\r\n    for epoch in range(num_epochs):\r\n        for batch_id, data in enumerate(train_reader()):\r\n            x_data = np.array([x[0].reshape(1, 28, 28) for x in data]).astype('float32')\r\n            y_data = np.array([x[1] for x in data]).astype('int64').reshape(-1, 1)\r\n\r\n            image = paddle.to_tensor(x_data)\r\n            label = paddle.to_tensor(y_data)\r\n\r\n            cost, acc = mnist(image, label)\r\n            loss = F.cross_entropy(cost, label)\r\n            avg_loss = paddle.mean(loss)\r\n\r\n            avg_loss.backward()\r\n            adam.minimize(avg_loss)\r\n            mnist.clear_gradients()\r\n\r\n            if batch_id % 100 == 0:\r\n                print(\"Loss at epoch {} step {}: {:}\".format(epoch, batch_id, avg_loss.numpy()))\r\n\r\n        mnist.eval()\r\n        test_cost, test_acc = test_mnist(test_reader, mnist)\r\n        mnist.train()\r\n        print(\"Loss at epoch {} , Test avg_loss is: {}, acc is: {}\".format(epoch, test_cost, test_acc))\r\n\r\n    # save inference model\r\n    if save_dirname is None:\r\n        return\r\n    # delete old model\r\n    if  os.path.exists(save_dirname):\r\n        shutil.rmtree(save_dirname)\r\n        os.makedirs(save_dirname)\r\n    # save inference model\r\n    mnist.eval()\r\n    model = paddle.jit.to_static(mnist, input_spec=[paddle.static.InputSpec([None, 1, 28, 28], 'float32', 'image')])\r\n    paddle.jit.save(model, save_dirname)\r\n\r\nif __name__ == '__main__':\r\n    BATCH_SIZE = 64\r\n    train_mnist(num_epochs=1, save_dirname='assets/mnist')\r\n```\r\n\r\n3. Change `paddle.set_device('cpu')` to `paddle.set_device('ascend')`, then fail with error as following:\r\n\r\n```bash\r\n(base) λ cann504 /workspace/my-demo-code/PaddlePaddle/mnistv2 {develop} python mnist_train.py\r\ngrep: warning: GREP_OPTIONS is deprecated; please use an alias or script\r\nI0618 05:08:42.379591 88034 init.cc:259] ENV [CUSTOM_DEVICE_ROOT]=/opt/conda/lib/python3.7/site-packages/paddle-plugins\r\nI0618 05:08:42.379639 88034 init.cc:147] Try loading custom device libs from: [/opt/conda/lib/python3.7/site-packages/paddle-plugins]\r\nI0618 05:08:42.832442 88034 custom_device.cc:712] Successed in loading custom runtime in lib: /opt/conda/lib/python3.7/site-packages/paddle-plugins/libpaddle-custom-npu.so\r\nI0618 05:08:42.834924 88034 custom_kernel.cc:70] Successed in loading 123 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0618 05:08:42.835026 88034 init.cc:159] Finished in LoadCustomDevice with libs_path: [/opt/conda/lib/python3.7/site-packages/paddle-plugins]\r\nI0618 05:08:42.835060 88034 init.cc:265] CustomDevice: ascend, visible devices count: 1\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 379, in __call__\r\n    return partial_program_layer(args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/partial_program.py\", line 349, in __call__\r\n    in_vars, out_vars = self._prepare(inputs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/partial_program.py\", line 443, in _prepare\r\n    expected_place):\r\nTypeError: _equals(): incompatible function arguments. The following argument types are supported:\r\n    1. (self: paddle.fluid.core_avx.Place, arg0: paddle.fluid.core_avx.Place) -> bool\r\n    2. (self: paddle.fluid.core_avx.Place, arg0: paddle.fluid.core_avx.CUDAPlace) -> bool\r\n    3. (self: paddle.fluid.core_avx.Place, arg0: paddle.fluid.core_avx.CPUPlace) -> bool\r\n    4. (self: paddle.fluid.core_avx.Place, arg0: paddle.fluid.core_avx.XPUPlace) -> bool\r\n    5. (self: paddle.fluid.core_avx.Place, arg0: paddle.fluid.core_avx.NPUPlace) -> bool\r\n    6. (self: paddle.fluid.core_avx.Place, arg0: paddle.fluid.core_avx.IPUPlace) -> bool\r\n    7. (self: paddle.fluid.core_avx.Place, arg0: paddle.fluid.core_avx.CUDAPinnedPlace) -> bool\r\n    8. (self: paddle.fluid.core_avx.Place, arg0: paddle.fluid.core_avx.MLUPlace) -> bool\r\n\r\nInvoked with: Place(ascend:0), Place(ascend:0)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"mnist_train.py\", line 158, in <module>\r\n    train_mnist(num_epochs=1, save_dirname='assets/mnist')\r\n  File \"mnist_train.py\", line 128, in train_mnist\r\n    cost, acc = mnist(image, label)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 929, in __call__\r\n    return self._dygraph_call_func(*inputs, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 914, in _dygraph_call_func\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py\", line 388, in __call__\r\n    error_data.raise_new_exception()\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/error.py\", line 328, in raise_new_exception\r\n    new_exception = self.create_exception()\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/error.py\", line 161, in create_exception\r\n    message = self.create_message()\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/error.py\", line 182, in create_message\r\n    self._simplify_error_value()\r\n  File \"/opt/conda/lib/python3.7/site-packages/paddle/fluid/dygraph/dygraph_to_static/error.py\", line 267, in _simplify_error_value\r\n    start_idx = error_value_lines_strip.index(start_trace)\r\nValueError: 'outputs = static_func(*inputs)' is not in list\r\n```\r\n",
        "state": "closed",
        "user": "qili93",
        "closed_by": "qili93",
        "created_at": "2022-06-17T13:09:39+00:00",
        "updated_at": "2024-02-04T06:44:14+00:00",
        "closed_at": "2024-02-04T06:44:14+00:00",
        "comments_count": [
            "qili93",
            "Aganlengzi",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 165,
        "title": "npu merged_momentum 问题讨论",
        "body": "参考npu的merged_momentum代码时，这块最后的接口可能会修改velocity_out_data，他用例里是用momentum kernel做标杆的，inplace模式下结果可能不对，能不能试试注释掉npu的momentum的kernel，用cpu的momentum做标杆跑下他们的merged_momentum用例看看结果是否正确？\r\n<img width=\"501\" alt=\"image\" src=\"https://user-images.githubusercontent.com/5997715/197159636-7a03dd5c-158f-454a-b5f0-078325726210.png\">\r\n\r\n@aalss\r\nrelated: https://github.com/PaddlePaddle/PaddleTecoBackend/pull/105",
        "state": "closed",
        "user": "Aganlengzi",
        "closed_by": "qili93",
        "created_at": "2022-10-21T09:13:24+00:00",
        "updated_at": "2023-05-30T09:00:13+00:00",
        "closed_at": "2023-05-30T09:00:13+00:00",
        "comments_count": [
            "aalss",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 244,
        "title": "[FAQ] 保证每次 DeviceContext.template Alloc(...) 调用 Plugin 注册的 DeviceAllocate 函数 / 关闭设备内存复用",
        "body": "### 问题\r\n`DeviceContext.template Alloc(...) ` 不会每次调用 Runtime API\r\n\r\n### 原因\r\npaddle 内部会管理设备内存\r\n\r\n### 解决办法\r\n1.设置环境变量\r\n```bash\r\nexport FLAGS_allocator_strategy=naive_best_fit\r\n```\r\n切换内存管理分配策略，paddle 默认策略为 auto_growth，该策略无法保证每次调用 runtime API 分配内存\r\n\r\n2.修改 Plugin 注册的 `device_max_chunk_size` 函数返回 0，该函数的作用是超过该尺寸，paddle 不会使用内部管理的内存，而直接调用 runtime API 分配，返回 0 表示始终使用 runtime API 分配\r\n\r\n即可关闭内存复用\r\n\r\n\r\n",
        "state": "closed",
        "user": "ronny1996",
        "closed_by": "ronny1996",
        "created_at": "2022-11-29T09:02:58+00:00",
        "updated_at": "2024-07-16T07:09:09+00:00",
        "closed_at": "2024-07-16T07:09:09+00:00",
        "comments_count": [
            "ronny1996",
            "engineer1109"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 296,
        "title": "是否支持注册全连接层kernel(linear_kernel)?",
        "body": "rt.",
        "state": "closed",
        "user": "adepp",
        "closed_by": "adepp",
        "created_at": "2022-12-15T07:45:36+00:00",
        "updated_at": "2023-02-09T08:22:48+00:00",
        "closed_at": "2023-02-09T08:22:48+00:00",
        "comments_count": [
            "ronny1996",
            "adepp",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 396,
        "title": "MLU zero-dim",
        "body": null,
        "state": "closed",
        "user": "ShawnNew",
        "closed_by": "qili93",
        "created_at": "2023-02-09T03:43:31+00:00",
        "updated_at": "2023-03-07T13:03:23+00:00",
        "closed_at": "2023-03-07T13:03:23+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 374,
        "title": "NPU插件与sklearn存在兼容性问题",
        "body": "按照教程安装paddle与paddle_custom_device，如果先import paddle，再import sklearn，就会报错：\r\n```\r\n>>> import paddle\r\nI0129 11:20:21.808104 11223 init.cc:266] ENV [CUSTOM_DEVICE_ROOT]=/opt/py37env/lib/python3.7/site-packages/paddle-plugins\r\nI0129 11:20:21.808182 11223 init.cc:150] Try loading custom device libs from: [/opt/py37env/lib/python3.7/site-packages/paddle-plugins]\r\nI0129 11:20:26.164170 11223 custom_device.cc:1040] Successed in loading custom runtime in lib: /opt/py37env/lib/python3.7/site-packages/paddle-plugins/libpaddle-custom-npu.so\r\nI0129 11:20:26.169677 11223 custom_kernel.cc:76] Successed in loading 296 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0129 11:20:26.169983 11223 init.cc:162] Finished in LoadCustomDevice with libs_path: [/opt/py37env/lib/python3.7/site-packages/paddle-plugins]\r\nI0129 11:20:26.170037 11223 init.cc:272] CustomDevice: npu, visible devices count: 8\r\n>>> import sklearn\r\nTraceback (most recent call last):\r\n  File \"/opt/py37env/lib/python3.7/site-packages/sklearn/__check_build/__init__.py\", line 48, in <module>\r\n    from ._check_build import check_build  # noqa\r\nImportError: /opt/py37env/lib/python3.7/site-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/opt/py37env/lib/python3.7/site-packages/sklearn/__init__.py\", line 81, in <module>\r\n    from . import __check_build  # noqa: F401\r\n  File \"/opt/py37env/lib/python3.7/site-packages/sklearn/__check_build/__init__.py\", line 50, in <module>\r\n    raise_build_error(e)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/sklearn/__check_build/__init__.py\", line 43, in raise_build_error\r\n    % (e, local_dir, \"\".join(dir_content).strip(), msg)\r\nImportError: /opt/py37env/lib/python3.7/site-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block\r\n___________________________________________________________________________\r\nContents of /opt/py37env/lib/python3.7/site-packages/sklearn/__check_build:\r\nsetup.py                  __pycache__               _check_build.cpython-37m-aarch64-linux-gnu.so\r\n__init__.py\r\n___________________________________________________________________________\r\nIt seems that scikit-learn has not been built correctly.\r\n\r\nIf you have installed scikit-learn from source, please do not forget\r\nto build the package before using it: run `python setup.py install` or\r\n`make` in the source directory.\r\n\r\nIf you have used an installer, please check that it is suited for your\r\nPython version, your operating system and your platform.\r\n```\r\n\r\n反之如果先import sklearn，则一切正常：\r\n```\r\n>>> import sklearn\r\n>>> import paddle\r\nI0129 11:20:43.997946 11705 init.cc:266] ENV [CUSTOM_DEVICE_ROOT]=/opt/py37env/lib/python3.7/site-packages/paddle-plugins\r\nI0129 11:20:43.998006 11705 init.cc:150] Try loading custom device libs from: [/opt/py37env/lib/python3.7/site-packages/paddle-plugins]\r\nI0129 11:20:48.402534 11705 custom_device.cc:1040] Successed in loading custom runtime in lib: /opt/py37env/lib/python3.7/site-packages/paddle-plugins/libpaddle-custom-npu.so\r\nI0129 11:20:48.407981 11705 custom_kernel.cc:76] Successed in loading 296 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0129 11:20:48.408267 11705 init.cc:162] Finished in LoadCustomDevice with libs_path: [/opt/py37env/lib/python3.7/site-packages/paddle-plugins]\r\nI0129 11:20:48.408321 11705 init.cc:272] CustomDevice: npu, visible devices count: 8\r\n```",
        "state": "closed",
        "user": "parap1uie-s",
        "closed_by": "qili93",
        "created_at": "2023-01-29T03:22:58+00:00",
        "updated_at": "2023-03-07T13:02:34+00:00",
        "closed_at": "2023-03-07T13:02:34+00:00",
        "comments_count": [
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 422,
        "title": "backend/npu编译出错",
        "body": null,
        "state": "closed",
        "user": "AspartameJ",
        "closed_by": "AspartameJ",
        "created_at": "2023-02-21T01:05:43+00:00",
        "updated_at": "2023-02-21T03:23:08+00:00",
        "closed_at": "2023-02-21T03:23:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 408,
        "title": "编译出错",
        "body": "+++ dirname tools/compile.sh\r\n++ cd tools/../\r\n++ pwd\r\n+ SOURCE_ROOT=/home/PaddleCustomDevice/backends/npu\r\n+ mkdir -p /home/PaddleCustomDevice/backends/npu/build\r\n+ cd /home/PaddleCustomDevice/backends/npu/build\r\n++ uname -i\r\n+ arch=x86_64\r\n+ '[' x86_64 == x86_64 ']'\r\n+ WITH_MKLDNN=ON\r\n+ WITH_ARM=OFF\r\n+ cat\r\n========================================\r\nConfiguring cmake in build ...\r\n    -DCMAKE_BUILD_TYPE=Release\r\n    -DWITH_KERNELS=ON\r\n    -DWITH_TESTING=OFF\r\n    -DWITH_MKLDNN=ON\r\n    -DWITH_ARM=OFF\r\n    -DON_INFER=OFF\r\n========================================\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_KERNELS=ON -DWITH_TESTING=OFF -DWITH_MKLDNN=ON -DWITH_ARM=OFF -DON_INFER=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\n-- Found PADDLE_CORE_LIB: /opt/py37env/lib/python3.7/site-packages/paddle/fluid/libpaddle.so\r\nCMake Error at cmake/generic.cmake:1:\r\n  Parse error.  Expected a command name, got unquoted argument with text\r\n  \"../../../Paddle/cmake/generic.cmake\".\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:8 (include)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7",
        "state": "closed",
        "user": "yubo105139",
        "closed_by": "qili93",
        "created_at": "2023-02-14T06:59:31+00:00",
        "updated_at": "2023-03-07T13:04:16+00:00",
        "closed_at": "2023-03-07T13:04:16+00:00",
        "comments_count": [
            "Suiyiaixiaoyu",
            "Suiyiaixiaoyu",
            "ronny1996",
            "AspartameJ"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 397,
        "title": "PaddlePaddle 分布式是否支持Linux下的新硬件",
        "body": "rt \r\n除了昆仑 XPU | 海光 DCU | 昇腾 NPU以外，自定义新硬件是否支持分布式训练？",
        "state": "closed",
        "user": "adepp",
        "closed_by": "qili93",
        "created_at": "2023-02-09T08:24:06+00:00",
        "updated_at": "2023-03-07T13:03:38+00:00",
        "closed_at": "2023-03-07T13:03:38+00:00",
        "comments_count": [
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 407,
        "title": "昇腾编译出错 symbol BIO_dgram_sctp_wait_for_dry version OPENSSL_1_1_0 not defined in file libcrypto.so.1.1 with link time reference",
        "body": "环境：eulerosv2r8；aarch64；cann5.1；Ascend910\r\n\r\n1. 未使用Docker，在环境中安装了https://paddle-device.bj.bcebos.com/develop/cpu/paddlepaddle-0.0.0-cp37-cp37m-linux_aarch64.whl\r\n2. 执行编译脚本\r\nbash tools/compile.sh\r\n\r\n报错：\r\n\r\n+++ dirname tools/compile.sh\r\n++ cd tools/../\r\n++ pwd\r\n+ SOURCE_ROOT=/home/ma-user/work/PaddleCustomDevice/backends/npu\r\n+ mkdir -p /home/ma-user/work/PaddleCustomDevice/backends/npu/build\r\n+ cd /home/ma-user/work/PaddleCustomDevice/backends/npu/build\r\n++ uname -i\r\n+ arch=aarch64\r\n+ '[' aarch64 == x86_64 ']'\r\n+ WITH_MKLDNN=OFF\r\n+ WITH_ARM=ON\r\n+ cat\r\n========================================\r\nConfiguring cmake in build ...\r\n    -DCMAKE_BUILD_TYPE=Release\r\n    -DWITH_KERNELS=ON\r\n    -DWITH_TESTING=ON\r\n    -DWITH_MKLDNN=OFF\r\n    -DWITH_ARM=ON\r\n    -DON_INFER=OFF\r\n========================================\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_KERNELS=ON -DWITH_TESTING=ON -DWITH_MKLDNN=OFF -DWITH_ARM=ON -DON_INFER=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\nError: Can not import paddle core while this file exists: /home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/libpaddle.so\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/core.py\", line 269, in <module>\r\n    from . import libpaddle\r\nImportError: /usr/lib64/libssl.so.1.1: symbol BIO_dgram_sctp_wait_for_dry version OPENSSL_1_1_0 not defined in file libcrypto.so.1.1 with link time reference\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/__init__.py\", line 27, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 33, in <module>\r\n    from . import core\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/core.py\", line 347, in <module>\r\n    if not avx_supported() and libpaddle.is_compiled_with_avx():\r\nNameError: name 'libpaddle' is not defined\r\nCMake Error at cmake/paddle.cmake:28 (message):\r\n  NO Installed Paddle Found in\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:7 (include)",
        "state": "closed",
        "user": "FlickerMi",
        "closed_by": "qili93",
        "created_at": "2023-02-13T15:28:51+00:00",
        "updated_at": "2023-03-21T16:14:01+00:00",
        "closed_at": "2023-03-07T13:03:56+00:00",
        "comments_count": [
            "ronny1996",
            "Randy-1009"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 411,
        "title": "NPU编译出错",
        "body": "+++ dirname tools/compile.sh\r\n++ cd tools/../\r\n++ pwd\r\n+ SOURCE_ROOT=/workspace/PaddleCustomDevice/backends/npu\r\n+ mkdir -p /workspace/PaddleCustomDevice/backends/npu/build\r\n+ cd /workspace/PaddleCustomDevice/backends/npu/build\r\n++ uname -i\r\n+ arch=aarch64\r\n+ '[' aarch64 == x86_64 ']'\r\n+ WITH_MKLDNN=OFF\r\n+ WITH_ARM=ON\r\n+ cat\r\n========================================\r\nConfiguring cmake in build ...\r\n    -DCMAKE_BUILD_TYPE=Release\r\n    -DWITH_KERNELS=ON\r\n    -DWITH_TESTING=OFF\r\n    -DWITH_MKLDNN=OFF\r\n    -DWITH_ARM=ON\r\n    -DON_INFER=OFF\r\n========================================\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_KERNELS=ON -DWITH_TESTING=OFF -DWITH_MKLDNN=OFF -DWITH_ARM=ON -DON_INFER=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\n-- Found PADDLE_CORE_LIB: /opt/py37env/lib/python3.7/site-packages/paddle/fluid/libpaddle.so\r\nCMake Error at CMakeLists.txt:8 (include):\r\n  include could not find load file:\r\n\r\n    generic\r\n\r\n\r\n-- FWKACLLIB_INC_DIR /usr/local/Ascend/ascend-toolkit/latest/fwkacllib/include\r\n-- ASCEND_CL_DIR /usr/local/Ascend/ascend-toolkit/latest/fwkacllib/lib64\r\n-- Current Ascend Toolkit version is 6.0.0\r\n-- Current Ascend Driver version is 22.0.4\r\n-- CXX compiler: /opt/compiler/gcc-8.2/bin/c++, version: GNU 8.2.0\r\n-- C compiler: /opt/compiler/gcc-8.2/bin/gcc, version: GNU 8.2.0\r\n-- AR tools: /usr/bin/ar\r\nCMake Error at cmake/third_party.cmake:25 (include):\r\n  include could not find load file:\r\n\r\n    external/gflags\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:62 (include)\r\n\r\n\r\nCMake Error at cmake/third_party.cmake:26 (include):\r\n  include could not find load file:\r\n\r\n    external/glog\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:62 (include)\r\n\r\n\r\nCMake Error at cmake/third_party.cmake:27 (include):\r\n  include could not find load file:\r\n\r\n    external/pybind11\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:62 (include)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/workspace/PaddleCustomDevice/backends/npu/build/CMakeFiles/CMakeOutput.log\".\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7\r\n",
        "state": "closed",
        "user": "Suiyiaixiaoyu",
        "closed_by": "qili93",
        "created_at": "2023-02-14T08:09:40+00:00",
        "updated_at": "2023-03-07T13:04:34+00:00",
        "closed_at": "2023-03-07T13:04:34+00:00",
        "comments_count": [
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 431,
        "title": "dataloader第三次数据在设备侧出错",
        "body": "在MLU设备上运行网络 [lstm](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_classification/rnn) 时，第三次dataloader给出的数据无效，导致网络的第一个算子出错。出错的数据可以参考下图\r\n\r\n![image](https://user-images.githubusercontent.com/21559339/222070361-ff4cd83b-f90a-43d0-bd3f-edef1f2c3fb7.png)\r\n",
        "state": "closed",
        "user": "ShawnNew",
        "closed_by": "ShawnNew",
        "created_at": "2023-03-01T07:19:19+00:00",
        "updated_at": "2024-03-21T12:28:16+00:00",
        "closed_at": "2024-03-21T12:28:16+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 429,
        "title": "ScatterUpdate 算子输出有误",
        "body": "input_tensor = [0, 0, 0, 0, 0, 0, 0, 0] \r\nindices = [[1], [3], [4], [7]]  或者 indices = [1,  3, 4, 7]\r\nupdates = [9, 10, 11, 12]\r\n\r\n执行完 output = [0, 0, 0, 0, 0, 0, 0, 0, ]，input_tensor = [0, 0, 0, 0, 0, 0, 0, 0] ，不符合预期，input_tensor应该是[0,9,10,11,0,0,12]。\r\n请问是我的输入数据有误还是？",
        "state": "closed",
        "user": "yangjianfengo1",
        "closed_by": "yangjianfengo1",
        "created_at": "2023-02-28T08:13:13+00:00",
        "updated_at": "2023-02-28T09:29:48+00:00",
        "closed_at": "2023-02-28T09:29:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 423,
        "title": "编译安装npu版成功，执行ppocr却报不是npu版本",
        "body": "如下图，编译安装npu版paddle成功，能识别卡信息，但是训练时失败，定位到是校验不通过。\r\npaddle-custom-npu     0.0.0\r\npaddleocr             2.6.1.0\r\npaddlepaddle          0.0.0\r\n\r\n![image](https://user-images.githubusercontent.com/110798296/220287169-256c02b4-1851-4df5-a8cb-c238c4a21bc1.png)\r\n\r\n![image](https://user-images.githubusercontent.com/110798296/220286868-8266fb47-a3b3-4661-bd3e-9701d04ed671.png)\r\n",
        "state": "closed",
        "user": "Wuguangnann",
        "closed_by": "qili93",
        "created_at": "2023-02-21T08:34:21+00:00",
        "updated_at": "2023-02-23T02:55:51+00:00",
        "closed_at": "2023-02-23T02:55:51+00:00",
        "comments_count": [
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 435,
        "title": "[Paddle] 主框架 Kernel output datatype 类型修改",
        "body": "相关 ISSUE 描述见：https://github.com/PaddlePaddle/Paddle/issues/51292\r\n\r\n**问题原因**：目前 PHI Kernel 存在部分算子输出 tensor 的数据类型不对，默认 output tensor datatype 与 kernel 注册的数据类型一致。比如 add kernel 本身是 FP16 的，那输出的 output tensor 的数据类型也是 FP16；但是存在90+算子是特殊情况，比如 top_k kernel 无论是什么数据类型，indices都是输出int64_t，和kernel类型不一致，所以需要显式指定。修改代码见 PR https://github.com/PaddlePaddle/Paddle/pull/51233\r\n\r\n**问题影响**：会导致部分静态图代码执行失败，动态图暂时不受影响。因为目前主要套件都跑动态图，影响可控。\r\n\r\n**修复计划**：\r\n1) 主框架会很快修改框架内部的CPU、GPU和XPU的kernel代码，但是 PaddleCustomDevice 的代码需要单独修改。\r\n2) 当前策略是随时关注Paddle主框架的Kernel代码变化，后续等主框架的90+算子修复完成之后，收集修改的90+的算子的PR list，然后统一对NPU和MLU代码进行修改。\r\n\r\n==== Update on 4/17 =====\r\n\r\n**最新状态**\r\n外部开发者ISSUE已完成 https://github.com/PaddlePaddle/Paddle/issues/51292\r\nPR List见  https://ku.baidu-int.com/d/9dfab610c5bc49 (需要补全输出标记的算子)\r\n\r\n**测试方法**\r\n开启`FLAGS_new_executor_static_build=1`下跑通单测即可，没有补全输出标记的算子开启此开关之后CI会挂。",
        "state": "closed",
        "user": "qili93",
        "closed_by": "qili93",
        "created_at": "2023-03-07T13:10:03+00:00",
        "updated_at": "2023-05-30T08:53:33+00:00",
        "closed_at": "2023-05-30T08:49:04+00:00",
        "comments_count": [
            "piDack",
            "qili93"
        ],
        "labels": [
            "paddle"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 443,
        "title": "subdmoudle update lead to all ut failed",
        "body": "@qili93  recently paddle repo merged https://github.com/PaddlePaddle/Paddle/pull/51033, which introduce a lot of change of paddle.fluid.layers.utils --> paddle.utils\r\n\r\n### Short Term Actions\r\n- [x] upgrade paddlecustomdevice's submodule paddle to newer one\r\n- [ ] link need .py file to paddlecustomdevice's  python/tests\r\n\r\n### Long Term Actions\r\n- [ ] move paddle test base to paddle wheel ",
        "state": "closed",
        "user": "KimBioInfoStudio",
        "closed_by": "USTCKAY",
        "created_at": "2023-03-14T02:42:02+00:00",
        "updated_at": "2023-03-21T04:09:08+00:00",
        "closed_at": "2023-03-21T04:09:08+00:00",
        "comments_count": [
            "USTCKAY",
            "KimBioInfoStudio"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 446,
        "title": "PaddleCustomDevice可以支持在NPU设备上部署PaddleOCR服务吗？",
        "body": "如题。",
        "state": "closed",
        "user": "minboo",
        "closed_by": "ronny1996",
        "created_at": "2023-03-17T08:19:27+00:00",
        "updated_at": "2023-03-27T02:07:36+00:00",
        "closed_at": "2023-03-27T02:07:36+00:00",
        "comments_count": [
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 448,
        "title": "如何注册paddle.static.nn.fc或paddle.nn.Linear算子",
        "body": "如题，应该注册哪个kernel？",
        "state": "closed",
        "user": "adepp",
        "closed_by": "adepp",
        "created_at": "2023-03-20T05:09:34+00:00",
        "updated_at": "2023-03-22T04:26:41+00:00",
        "closed_at": "2023-03-22T04:26:41+00:00",
        "comments_count": [
            "adepp"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 460,
        "title": "基于CustomDevice的分布式训练精度收敛差",
        "body": "* 基于CustomDevice训练vgg16，网络单卡训练精度收敛正常，分布式单机多卡训练精度收敛差。\r\n* 分布式训练网络性能是单卡的一半。\r\n\r\n问题如下图：\r\n<img width=\"1353\" alt=\"image\" src=\"https://user-images.githubusercontent.com/21559339/226796599-37edcb88-6f6b-44a6-b547-831f8bcbec72.png\">\r\n左边是单卡训练log，右边是4卡训练log",
        "state": "closed",
        "user": "ShawnNew",
        "closed_by": "ronny1996",
        "created_at": "2023-03-22T03:43:47+00:00",
        "updated_at": "2023-03-27T02:08:04+00:00",
        "closed_at": "2023-03-27T02:08:04+00:00",
        "comments_count": [
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 459,
        "title": "华为昇腾服务器上编译NPU版本报错",
        "body": "参考文档：https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md\r\n由于服务器环境原因，无法使用docker\r\n遇到的报错：\r\n![image](https://user-images.githubusercontent.com/46707940/226685990-eaa0c5d4-9610-4cb2-bff2-f75dfc6c0e05.png)\r\nPaddle安装后未找到，已经在文件中指定Paddle路径解决；\r\n相对路径找不到对应头文件，通过修改为绝对路径解决，路径为/home/ma-user/work/PaddleCustomDevice/Paddle/paddle/phi/api/profiler/trace_event.h和/home/ma-user/work/PaddleCustomDevice/Paddle/paddle/phi/api/profiler/trace_event_collector.h\r\n![image](https://user-images.githubusercontent.com/46707940/226686268-79aeaefc-3374-4b2d-bf0b-3dacd3b5eed9.png)\r\n完整报错信息如下：\r\n(MindSpore) [ma-user npu]$bash tools/compile.sh\r\n+++ dirname tools/compile.sh\r\n++ cd tools/../\r\n++ pwd\r\n+ SOURCE_ROOT=/home/ma-user/work/PaddleCustomDevice/backends/npu\r\n+ mkdir -p /home/ma-user/work/PaddleCustomDevice/backends/npu/build\r\n+ cd /home/ma-user/work/PaddleCustomDevice/backends/npu/build\r\n++ uname -i\r\n+ arch=aarch64\r\n+ '[' aarch64 == x86_64 ']'\r\n+ WITH_MKLDNN=OFF\r\n+ WITH_ARM=ON\r\n+ cat\r\n========================================\r\nConfiguring cmake in build ...\r\n    -DCMAKE_BUILD_TYPE=Release\r\n    -DWITH_KERNELS=ON\r\n    -DWITH_TESTING=OFF\r\n    -DWITH_MKLDNN=OFF\r\n    -DWITH_ARM=ON\r\n    -DON_INFER=OFF\r\n========================================\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_KERNELS=ON -DWITH_TESTING=OFF -DWITH_MKLDNN=OFF -DWITH_ARM=ON -DON_INFER=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\nError: Can not import paddle core while this file exists: /home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/libpaddle.so\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/core.py\", line 269, in <module>\r\n    from . import libpaddle\r\nImportError: /lib64/libssl.so.1.1: symbol BIO_dgram_sctp_wait_for_dry version OPENSSL_1_1_0 not defined in file libcrypto.so.1.1 with link time reference\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/__init__.py\", line 27, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/framework/random.py\", line 16, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\r\n    from . import framework\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 34, in <module>\r\n    from . import core\r\n  File \"/home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/core.py\", line 350, in <module>\r\n    if not avx_supported() and libpaddle.is_compiled_with_avx():\r\nNameError: name 'libpaddle' is not defined\r\n-- Found PADDLE_CORE_LIB: /home/ma-user/.local/lib/python3.7/site-packages/paddle/fluid/libpaddle.so\r\n-- FWKACLLIB_INC_DIR /usr/local/Ascend/ascend-toolkit/latest/fwkacllib/include\r\n-- ASCEND_CL_DIR /usr/local/Ascend/ascend-toolkit/latest/fwkacllib/lib64\r\n-- Current Ascend Toolkit version is 6.0.1\r\n-- Current Ascend Driver version is 22.0.0\r\n-- CXX compiler: /usr/bin/c++, version: GNU 7.3.0\r\n-- C compiler: /usr/bin/cc, version: GNU 7.3.0\r\n-- AR tools: /usr/bin/ar\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/ma-user/work/PaddleCustomDevice/backends/npu/build\r\n+ cmake_error=0\r\n+ '[' 0 '!=' 0 ']'\r\n+ '[' aarch64 == x86_64 ']'\r\n+ make TARGET=ARMV8 -j8\r\n[  1%] Built target ascend_cl\r\n[  6%] Built target extern_pybind\r\n[ 11%] Built target extern_gflags\r\n[ 16%] Built target extern_glog\r\n[ 16%] Built target third_party\r\nScanning dependencies of target paddle-custom-npu\r\n[ 17%] Building CXX object CMakeFiles/paddle-custom-npu.dir/runtime/runtime.cc.o\r\n[ 18%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/accuracy_kernel.cc.o\r\n[ 18%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/activation_kernel.cc.o\r\n[ 21%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/adagrad_kernel.cc.o\r\n[ 21%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/adam_kernel.cc.o\r\n[ 22%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/amp/check_finite_and_unscale_kernel.cc.o\r\n[ 22%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/add_n_kernel.cc.o\r\n[ 22%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/abs_kernel.cc.o\r\n[ 22%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/amp/update_loss_scaling_kernel.cc.o\r\n[ 23%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/arange_kernel.cc.o\r\n[ 24%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/arg_min_max_kernel.cc.o\r\n[ 24%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/argsort_grad_kernel.cc.o\r\n[ 25%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/argsort_kernel.cc.o\r\n[ 26%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/assign_kernel.cc.o\r\n[ 26%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/batch_norm_kernel.cc.o\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc: In function 'void custom_kernel::AssignValueKernel(const Context&, const std::vector<int>&, phi::DataType, const std::vector<paddle::experimental::ScalarBase<phi::DenseTensor> >&, phi::DenseTensor*)':\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:94:30: error: 'CppTypeToDataType' is not a member of 'phi'\r\n   auto template_dtype = phi::CppTypeToDataType<T>::Type();\r\n                              ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:94:30: note: suggested alternative: 'ProtoDataType'\r\n   auto template_dtype = phi::CppTypeToDataType<T>::Type();\r\n                              ^~~~~~~~~~~~~~~~~\r\n                              ProtoDataType\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:94:49: error: expected primary-expression before '>' token\r\n   auto template_dtype = phi::CppTypeToDataType<T>::Type();\r\n                                                 ^\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:94:52: error: '::Type' has not been declared\r\n   auto template_dtype = phi::CppTypeToDataType<T>::Type();\r\n                                                    ^~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:94:52: note: suggested alternative: 'dtype'\r\n   auto template_dtype = phi::CppTypeToDataType<T>::Type();\r\n                                                    ^~~~\r\n                                                    dtype\r\nIn file included from /home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/funcs/npu_enforce.h:21:0,\r\n                 from /home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/funcs/npu_funcs.h:19,\r\n                 from /home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:15:\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:431:48: error: '__TYPE2__' was not declared in this scope\r\n         ::phi::details::CommonType1<__TYPE1__, __TYPE2__>;              \\\r\n                                                ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:431:48: note: suggested alternative: '__TYPE1__'\r\n         ::phi::details::CommonType1<__TYPE1__, __TYPE2__>;              \\\r\n                                                ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:431:57: error: template argument 2 is invalid\r\n         ::phi::details::CommonType1<__TYPE1__, __TYPE2__>;              \\\r\n                                                         ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:433:57: error: type/value mismatch at argument 2 in template parameter list for 'template<class T1, class T2> using CommonType2 = typename std::add_lvalue_reference<typename std::add_const<typename phi::enforce::details::TypeConverter<T1, T2>::Type2>::type>::type'\r\n         ::phi::details::CommonType2<__TYPE1__, __TYPE2__>;              \\\r\n                                                         ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:433:57: note:   expected a type, got '__TYPE2__'\r\n         ::phi::details::CommonType2<__TYPE1__, __TYPE2__>;              \\\r\n                                                         ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:434:40: error: '__COMMON_TYPE1__' does not name a type; did you mean '__INTMAX_TYPE__'?\r\n     bool __is_not_error = (static_cast<__COMMON_TYPE1__>(__val1))__CMP( \\\r\n                                        ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:435:21: error: '__COMMON_TYPE2__' does not name a type; did you mean '__INTMAX_TYPE__'?\r\n         static_cast<__COMMON_TYPE2__>(__val2));                         \\\r\n                     ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:440:48: error: type/value mismatch at argument 1 in template parameter list for 'template<class T> struct phi::enforce::details::CanToString'\r\n           ::phi::details::CanToString<__TYPE2__>::kValue;               \\\r\n                                                ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:440:48: note:   expected a type, got '__TYPE2__'\r\n           ::phi::details::CanToString<__TYPE2__>::kValue;               \\\r\n                                                ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:448:15: error: the value of '__kCanToString__' is not usable in a constant expression\r\n               __kCanToString__>::Convert(#__VAL1, __val1),              \\\r\n               ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:448:31: error: the value of '__kCanToString__' is not usable in a constant expression\r\n               __kCanToString__>::Convert(#__VAL1, __val1),              \\\r\n                               ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:448:31: note: in template argument for type 'bool'\r\n               __kCanToString__>::Convert(#__VAL1, __val1),              \\\r\n                               ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:450:15: error: the value of '__kCanToString__' is not usable in a constant expression\r\n               __kCanToString__>::Convert(#__VAL2, __val2));             \\\r\n               ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:450:31: error: the value of '__kCanToString__' is not usable in a constant expression\r\n               __kCanToString__>::Convert(#__VAL2, __val2));             \\\r\n                               ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:450:31: note: in template argument for type 'bool'\r\n               __kCanToString__>::Convert(#__VAL2, __val2));             \\\r\n                               ^\r\n/home/ma-user/.local/lib/python3.7/site-packages/paddle/include/paddle/phi/core/enforce.h:457:3: note: in expansion of macro '__PADDLE_BINARY_COMPARE'\r\n   __PADDLE_BINARY_COMPARE(__VAL0, __VAL1, ==, !=, __VA_ARGS__)\r\n   ^~~~~~~~~~~~~~~~~~~~~~~\r\n/home/ma-user/work/PaddleCustomDevice/backends/npu/kernels/assign_kernel.cc:95:3: note: in expansion of macro 'PADDLE_ENFORCE_EQ'\r\n   PADDLE_ENFORCE_EQ(\r\n   ^~~~~~~~~~~~~~~~~\r\n[ 27%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/bce_loss_kernel.cc.o\r\n[ 28%] Building CXX object CMakeFiles/paddle-custom-npu.dir/kernels/bitwise_kernel.cc.o\r\nmake[2]: *** [CMakeFiles/paddle-custom-npu.dir/build.make:232: CMakeFiles/paddle-custom-npu.dir/kernels/assign_kernel.cc.o] Error 1\r\nmake[2]: *** Waiting for unfinished jobs....\r\nmake[1]: *** [CMakeFiles/Makefile2:75: CMakeFiles/paddle-custom-npu.dir/all] Error 2\r\nmake: *** [Makefile:84: all] Error 2\r\n+ make_error=2\r\n+ '[' 2 '!=' 0 ']'\r\n+ echo 'Make Error Found !!!'\r\nMake Error Found !!!\r\n+ exit 7\r\n\r\n\r\n",
        "state": "closed",
        "user": "Randy-1009",
        "closed_by": "ronny1996",
        "created_at": "2023-03-21T17:06:03+00:00",
        "updated_at": "2023-03-31T08:32:20+00:00",
        "closed_at": "2023-03-31T08:32:20+00:00",
        "comments_count": [
            "Randy-1009",
            "USTCKAY",
            "ghotiGYH",
            "YanhuiDua",
            "Randy-1009",
            "YanhuiDua",
            "ghotiGYH",
            "ronny1996",
            "Randy-1009",
            "USTCKAY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 467,
        "title": "is there any Intel dgpu runner on  BCS",
        "body": "@qili93 ",
        "state": "closed",
        "user": "KimBioInfoStudio",
        "closed_by": "KimBioInfoStudio",
        "created_at": "2023-03-26T15:38:23+00:00",
        "updated_at": "2023-08-15T02:12:09+00:00",
        "closed_at": "2023-08-15T02:12:09+00:00",
        "comments_count": [
            "KimBioInfoStudio",
            "qili93",
            "KimBioInfoStudio"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 553,
        "title": "NPU反向计算与CPU不一致，测试代码如下",
        "body": "```\r\nimport paddle\r\nimport paddle.nn as nn\r\nimport pdb\r\nfrom copy import deepcopy\r\nfrom paddle import ParamAttr\r\nimport paddle.fluid as fluid\r\nfrom paddle.fluid.dygraph.base import to_variable\r\nimport numpy as np\r\nimport math\r\n\r\npaddle.seed(123)\r\npaddle.set_device('npu:4')\r\n\r\ndef cosine_similarity(x, y):\r\n    x = x.numpy()\r\n    y = y.numpy()\r\n    x1 = x.flatten().astype(np.float64)\r\n    y1 = y.flatten().astype(np.float64)\r\n    dot = np.dot(x1, y1)\r\n    lx = np.linalg.norm(x1)\r\n    ly = np.linalg.norm(y1)\r\n    cos = dot / (lx * ly)\r\n    return cos\r\n\r\n\r\ndef get_bias_attr(k):\r\n    stdv = 1.0 / math.sqrt(k * 1.0)\r\n    initializer = paddle.nn.initializer.Uniform(-stdv, stdv)\r\n    bias_attr = ParamAttr(initializer=initializer)\r\n    return bias_attr\r\n\r\n# pdb.set_trace()\r\n\r\n# data [16, 64, 160, 160]\r\nxn = paddle.rand((16, 64, 160, 160))\r\nxn.stop_gradient=False\r\n\r\nxc = xn.cpu()\r\nxc.stop_gradient=False\r\n\r\nzn_grad = paddle.rand((16, 64, 320, 320))\r\nzc_grad = zn_grad.cpu()\r\n\r\n\r\n# model\r\nconv_n = nn.Conv2DTranspose(\r\n                 in_channels=64,\r\n                 out_channels=64,\r\n                 kernel_size=2,\r\n                 stride=2,\r\n                 weight_attr=ParamAttr(\r\n                     initializer=paddle.nn.initializer.KaimingUniform()),\r\n                 bias_attr=get_bias_attr(64)\r\n                 )\r\nbn_n = nn.BatchNorm(\r\n                 num_channels=64,\r\n                 param_attr=ParamAttr(\r\n                     initializer=paddle.nn.initializer.Constant(value=1.0)),\r\n                 bias_attr=ParamAttr(\r\n                     initializer=paddle.nn.initializer.Constant(value=1e-4)),\r\n                 act=\"relu\")\r\n\r\nconv_c = deepcopy(conv_n).to('cpu')\r\nbn_c = deepcopy(bn_n).to('cpu')\r\n\r\n# forward\r\nyn = conv_n(xn)\r\nyc = conv_c(xc)\r\n\r\nzn = bn_n(yn)\r\nzc = bn_c(yc)\r\n\r\nprint(\"[acc_forward]conv: \", cosine_similarity(yn, yc))\r\nprint(\"[acc_forward]bn: \", cosine_similarity(zn, zc))\r\n\r\nbreakpoint()\r\n# pdb.set_trace()\r\n# backward\r\nzn.backward(zn_grad)\r\nzc.backward(zc_grad)\r\n\r\nprint(\"[acc_backward]conv: \", cosine_similarity(conv_n.weight.grad, conv_c.weight.grad))\r\nprint(\"[acc_backward]bn: \", cosine_similarity(bn_n.weight.grad, bn_c.weight.grad))\r\n```",
        "state": "closed",
        "user": "max-niu",
        "closed_by": "ronny1996",
        "created_at": "2023-05-10T09:38:18+00:00",
        "updated_at": "2023-05-22T10:34:28+00:00",
        "closed_at": "2023-05-22T10:34:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 500,
        "title": "[TODO] 收集框架对于CustomDevice待优化项目",
        "body": "\r\nPaddle集成CustomDevice时，主要考虑对不同硬件通用，部分实现性能较低，这里收集硬件期望优化的代码",
        "state": "closed",
        "user": "ronny1996",
        "closed_by": "ronny1996",
        "created_at": "2023-04-14T03:45:26+00:00",
        "updated_at": "2024-07-16T07:09:03+00:00",
        "closed_at": "2024-07-16T07:09:03+00:00",
        "comments_count": [
            "ShawnNew",
            "ronny1996",
            "ronny1996",
            "YanhuiDua",
            "KimBioInfoStudio",
            "ronny1996",
            "ShawnNew",
            "YanhuiDua",
            "ShawnNew",
            "ronny1996",
            "jinyouzhi",
            "tiandou-tangdou",
            "tiandou-tangdou",
            "ronny1996",
            "tiandou-tangdou",
            "engineer1109",
            "qili93",
            "engineer1109",
            "engineer1109",
            "engineer1109"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 515,
        "title": "[Paddle] 0维Tensor推全",
        "body": "主框架相关背景和计划见：https://ku.baidu-int.com/knowledge/HFVrC7hq1Q/yKeL8Lljko/6UmOO2EkH2/Gv4bMvQxAw61WT\r\n\r\n**当前状态**：\r\n- 目前主repo的输入0D已经完成，输出0D完成50%，剩余正在升级中，见 [任务明细表 - 输出0D](https://ku.baidu-int.com/knowledge/HFVrC7hq1Q/yKeL8Lljko/6UmOO2EkH2/2dd3c096410d47)，预计会在4月合入\r\n- PaddleCustomDevice在主框架完成对所有0维Tensor的修改之后，需要参考主框架修改相应升级Kernel代码对0维Tensor的支持，并增加对0维Tensor的单测case\r\n\r\n**开发计划：**\r\n- 主框架4月底之前会完成所有0D的修改，到时候主框架提供修改后的PR List给到PaddleCustomDevice进行修改\r\n\r\n",
        "state": "closed",
        "user": "qili93",
        "closed_by": "qili93",
        "created_at": "2023-04-20T07:45:08+00:00",
        "updated_at": "2023-05-30T08:59:01+00:00",
        "closed_at": "2023-05-30T08:59:00+00:00",
        "comments_count": [
            "zhwesky2010",
            "YanhuiDua",
            "qili93"
        ],
        "labels": [
            "paddle"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 555,
        "title": "PaddleOCR DPNet模型使用NPU训练反向传播具有精度问题",
        "body": "抽取了DPNet模型中的场景进行测试，对比cpu和npu反向计算后的grad，精度对比指标为余弦相似度\r\n测试脚本：\r\n[test_DBFPN.py](https://gitee.com/max__niu/PaddleOCR/blob/release/2.6/test_npu_acc/test_DBFPN.py)\r\n[test_DBHead.py](https://gitee.com/max__niu/PaddleOCR/blob/release/2.6/test_npu_acc/test_DBHead.py)\r\n[test_ResidualUnit.py](https://gitee.com/max__niu/PaddleOCR/blob/release/2.6/test_npu_acc/test_ResidualUnit.py)\r\n\r\n精度结果：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/57517234/f66431a3-6dbf-4c2c-a7bc-e55d3e69aa66)\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/57517234/a3aa4339-61fd-4aeb-8f78-966c79b2ff89)\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/57517234/b5afea85-256e-4be2-ba61-c04137af8479)\r\n",
        "state": "closed",
        "user": "max-niu",
        "closed_by": "ronny1996",
        "created_at": "2023-05-11T09:11:36+00:00",
        "updated_at": "2023-05-22T10:34:15+00:00",
        "closed_at": "2023-05-22T10:34:15+00:00",
        "comments_count": [
            "YanhuiDua",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 564,
        "title": "[FAQ] 自定义 PASS + 自定义 OP 用于 Inference",
        "body": "自定义PASS\r\nhttps://github.com/PaddlePaddle/Paddle/pull/35602\r\nhttps://github.com/PaddlePaddle/Paddle/pull/36095\r\n自定义OP\r\nhttps://www.paddlepaddle.org.cn/documentation/docs/zh/guides/custom_op/index_cn.html#zidingyisuanzi\r\n\r\nmy_add_n.cc // 放到插件中一起编译成一个 so 文件\r\n```c++\r\n// Copyright (c) 2023 PaddlePaddle Authors. All Rights Reserved.\r\n//\r\n// Licensed under the Apache License, Version 2.0 (the \"License\");\r\n// you may not use this file except in compliance with the License.\r\n// You may obtain a copy of the License at\r\n//\r\n//     http://www.apache.org/licenses/LICENSE-2.0\r\n//\r\n// Unless required by applicable law or agreed to in writing, software\r\n// distributed under the License is distributed on an \"AS IS\" BASIS,\r\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n// See the License for the specific language governing permissions and\r\n// limitations under the License.\r\n\r\n#include <iostream>\r\n#include <vector>\r\n\r\n#include \"paddle/extension.h\"\r\n\r\nstd::vector<paddle::Tensor> MyAddNOp(const paddle::Tensor& x,\r\n                                     const paddle::Tensor& y,\r\n                                     const paddle::Tensor& z) {\r\n  return {paddle::add(x, y)};\r\n}\r\n\r\nstd::vector<std::vector<int64_t>> MyAddNOpInferShape(\r\n    const std::vector<int64_t>& x_shape,\r\n    const std::vector<int64_t>& y_shape,\r\n    const std::vector<int64_t>& z_shape) {\r\n  return {x_shape};\r\n}\r\n\r\nPD_BUILD_OP(my_add_n)\r\n    .Inputs({\"X\", \"Y\", \"Z\"})\r\n    .Outputs({\"Out\"})\r\n    .SetKernelFn(PD_KERNEL(MyAddNOp))\r\n    .SetInferShapeFn(PD_INFER_SHAPE(\r\n        MyAddNOpInferShape));  // neccessary if the op has muti_inputs\r\n\r\n```\r\n\r\nrun.py\r\n```python\r\nimport paddle\r\nimport numpy as np\r\n\r\npaddle.utils.cpp_extension.extension_utils.load_op_meta_info_and_register_op('/opt/py37env/lib/python3.7/site-packages/paddle_custom_device/libpaddle-custom-npu.so')\r\n\r\n@paddle.incubate.passes.ir.RegisterPass\r\ndef generate_add_n():\r\n    def pattern(x, y, z):\r\n        return paddle.add(paddle.add(x, y), z)\r\n\r\n    def replace(x, y, z):\r\n        return paddle.incubate.passes.ir.PassDesc.OP.my_add_n(X=x, Y=y, Z=z)\r\n\r\n    return pattern, replace\r\n\r\n@paddle.jit.to_static(input_spec=[paddle.static.InputSpec([None, 32], 'float32', 'x'),  paddle.static.InputSpec([None, 32], 'float32', 'y'),  paddle.static.InputSpec([None, 32], 'float32', 'z')])\r\ndef func(x, y, z):\r\n    return x + y + z\r\n\r\nmodel_file = './saved_models/func'\r\npaddle.jit.save(func, model_file)\r\n\r\n# inference\r\nconfig = paddle.inference.Config()\r\nconfig.set_prog_file(model_file + '.pdmodel')\r\nconfig.enable_memory_optim()\r\npass_builder = config.pass_builder()\r\npass_builder.append_pass('generate_add_n')\r\nprint(pass_builder.all_passes())\r\npredictor = paddle.inference.create_predictor(config)\r\n\r\ninput_names = predictor.get_input_names()\r\nfor i, name in enumerate(input_names):\r\n    input_tensor = predictor.get_input_handle(name)\r\n    input_tensor.copy_from_cpu(np.random.randn(2, 32).astype('float32'))\r\n\r\npredictor.run()\r\nresults = []\r\noutput_names = predictor.get_output_names()\r\nfor i, name in enumerate(output_names):\r\n    output_tensor = predictor.get_output_handle(name)\r\n    output_data = output_tensor.copy_to_cpu()\r\n    results.append(output_data)\r\nprint(results)\r\n\r\n```\r\n\r\nGLOG_v=10 python run.py\r\n\r\n```\r\nI0517 18:23:54.884903 94348 operator.cc:750] Place(cpu) Op(my_add_n), inputs:{X[x:float[2, 32]({})(Place(cpu))], Y[y:float[2, 32]({})(Place(cpu))], Z[z:float[2, 32]({})(Place(cpu))]}, outputs:{Out[tmp_1:[0]({})()]}.\r\nI0517 18:23:54.884943 94348 context_pool.cc:62] DeviceContextPool Get: Place(cpu)\r\nI0517 18:23:54.884971 94348 operator.cc:2130] op type:my_add_n, expected_kernel_key:{data_type[RAW(runtime decided type)]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}\r\nI0517 18:23:54.884994 94348 context_pool.cc:62] DeviceContextPool Get: Place(cpu)\r\nI0517 18:23:54.885025 94348 custom_operator.cc:424] Custom Operator: InferShape - get input ddim.\r\nI0517 18:23:54.885046 94348 custom_operator.cc:505] Custom Operator: InferShape - calc output ddim.\r\nI0517 18:23:54.885062 94348 custom_operator.cc:530] Custom Operator: InferShape - set output ddim: inplace_map.size() = 0, output_shapes.size() = 1\r\nI0517 18:23:54.885083 94348 custom_operator.cc:1160] Custom Operator: run custom kernel func in lambda.\r\nI0517 18:23:54.885099 94348 custom_operator.cc:64] Custom Operator: Start run KernelFunc.\r\nI0517 18:23:54.885111 94348 custom_operator.cc:68] Custom Operator: input name - X\r\nI0517 18:23:54.885135 94348 custom_operator.cc:68] Custom Operator: input name - Y\r\nI0517 18:23:54.885149 94348 custom_operator.cc:68] Custom Operator: input name - Z\r\nI0517 18:23:54.885154 94348 custom_operator.cc:185] Custom Operator: push outputs into CustomOpKernelContext.\r\nI0517 18:23:54.885172 94348 custom_operator.cc:268] Custom Operator: Run ComputeFunc.\r\nI0517 18:23:54.885187 94348 op_meta_info.cc:202] Custom opertor ConstructInplaceIndex no need to recompute.\r\nI0517 18:23:54.885202 94348 op_meta_info.cc:245] Custom opertor update plain outputs map successfully.\r\nI0517 18:23:54.885227 94348 api.cc:24106] add API kernel key: [CPU, NCHW, float32]\r\nI0517 18:23:54.885249 94348 custom_device_op_list.cc:46] Custom Device Black List: \r\nI0517 18:23:54.885263 94348 api.cc:24113] add kernel: {\"input\":[\"CPU, NCHW, float32\",\"CPU, NCHW, float32\"],\"output\":[\"CPU, NCHW, float32\"],\"attribute\":[]}\r\nI0517 18:23:54.885291 94348 context_pool.cc:62] DeviceContextPool Get: Place(cpu)\r\nI0517 18:23:54.885329 94348 dense_tensor.cc:139] Allocate data with bytes: 256\r\nI0517 18:23:54.885344 94348 stats.h:84] Update peak_value, after update, peak_value = 1024 , current value = 1024\r\nI0517 18:23:54.885383 94348 operator.cc:797] Place(cpu) Op(my_add_n), inputs:{X[x:float[2, 32]({})(Place(cpu))], Y[y:float[2, 32]({})(Place(cpu))], Z[z:float[2, 32]({})(Place(cpu))]}, outputs:{Out[tmp_1:float[2, 32]({})(Place(cpu))]}.\r\nI0517 18:23:54.885411 94348 helper.h:464] after run : [cpu current allocated memory: 0.000976562MB], [cpu current reserved memory: 0MB], [cpu peak allocated memory: 0.000976562MB], [cpu peak reserved memory: 0MB]\r\nI0517 18:23:54.885437 94348 reset_tensor_array.cc:45] Collect 0 arrays\r\n[array([[ 0.58247435,  0.826475  ,  0.6871278 ,  0.4126696 , -0.2559116 ,\r\n         0.65742874,  2.1384077 ,  0.24653143, -0.29847062, -2.2460418 ,\r\n        -1.1594441 , -1.5321505 ,  3.0779753 ,  1.3047652 ,  5.319272  ,\r\n        -3.2988782 ,  2.2765095 ,  0.8565507 , -3.34338   , -1.906771  ,\r\n        -1.3918409 , -0.9324397 , -0.14787453, -0.4925239 , -0.24697244,\r\n        -0.29773337, -2.2361014 , -2.4385114 ,  1.9175045 , -1.7525816 ,\r\n        -2.0501115 ,  2.8168874 ],\r\n       [-0.42592376, -1.5766194 ,  3.0644276 , -1.9179165 ,  2.8835368 ,\r\n         0.28963447,  0.4251368 ,  1.146347  , -0.45447612, -0.9540442 ,\r\n         1.8834621 ,  0.5726208 , -1.1495211 ,  2.1192973 , -0.1619632 ,\r\n         1.1780676 , -3.423511  ,  0.31345803,  2.212157  ,  2.284046  ,\r\n        -1.8597114 , -0.988636  ,  2.5586586 ,  0.6752815 , -0.8432386 ,\r\n        -1.5520113 , -0.93274736,  0.7499885 , -2.2453508 ,  1.2411486 ,\r\n         0.89078593,  0.02444351]], dtype=float32)]\r\nI0517 18:23:54.887071 94348 imperative.cc:2204] Tracer(0x3b7d92b0) set expected place Place(npu:0)\r\nI0517 18:23:54.887138 94348 mmap_allocator.cc:321] PID: 94348, MemoryMapFdSet: set size - 0\r\nI0517 18:23:54.889010 94348 mmap_allocator.cc:321] PID: 94348, MemoryMapFdSet: set size - 0\r\nI0517 18:23:55.128073 94348 mmap_allocator.cc:321] PID: 94348, MemoryMapFdSet: set size - 0\r\n```\r\n\r\nNPU DEMO: https://github.com/PaddlePaddle/PaddleCustomDevice/pull/578",
        "state": "closed",
        "user": "ronny1996",
        "closed_by": "qili93",
        "created_at": "2023-05-17T08:33:26+00:00",
        "updated_at": "2023-05-30T08:48:47+00:00",
        "closed_at": "2023-05-30T08:48:46+00:00",
        "comments_count": [
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 573,
        "title": "[NPU] 华为昇腾服务器Paddle训练问题，OSError: (External) ACL error, the error code is : 500002",
        "body": "系统环境/System Environment：EulerOS 2.0 (SP8) NPU 910APro\r\n版本号/Version：Paddle：2.4 PaddleOCR：2.6 问题相关组件/Related components：npu_op_runner.cc\r\n运行指令/Command Code：export FLAGS_selected_npus=3 然后 python3 tools/train.py -c ./configs/det/ch_ppocr_v2.0/ch_det_res18_db_v2.0.yml -o Global.use_npu=true Global.use_gpu=false\r\n完整报错/Complete Error Message：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/46707940/526f7aa3-499f-478c-be20-14d34d63db61)\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/46707940/7e1be0ca-ce10-4c83-8613-ed2b96477559)\r\n\r\n在华为NPU上已经编译成功了Paddle-2.4，PaddleDetection-2.4可以跑通目标检测Yolov3的训练，但是PaddleOCR在尝试训练文本检测模型ch_ppocr_server_v2.0_det时出现了以上报错，在报错之前模型已经成功加载到了卡上，占用了内存。\r\nPaddle的安装文档参考的是https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/hardware_support/npu_docs/paddle_install_cn.html\r\n训练文档参考的是https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/hardware_support/npu_docs/train_example_cn.html\r\n\r\n经过验证，在CPU上可以进行正常训练，在NPU上训练会报以上错误。\r\nCPU上训练过程截图：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/46707940/db7999f4-b0ad-41f9-bfa3-e1ba4fede036)\r\n\r\nNPU上训练截图：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/46707940/72c282dd-158c-4025-8a12-ea4f82bd1ead)\r\n\r\n目前Paddle已经尝试了2.4.0和2.4.1版本，都会出现上述报错。\r\n\r\nAscend训练日志中记录的报错为：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/46707940/0c4c3ea6-1695-4a93-acc2-5bd9470a4183)\r\n",
        "state": "closed",
        "user": "Randy-1009",
        "closed_by": "qili93",
        "created_at": "2023-05-22T09:24:42+00:00",
        "updated_at": "2024-02-05T08:54:06+00:00",
        "closed_at": "2024-02-05T08:54:06+00:00",
        "comments_count": [
            "ronny1996",
            "Randy-1009",
            "ronny1996"
        ],
        "labels": [
            "NPU"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 568,
        "title": "PaddleOCR CRNN模型使用NPU训练反向传播LSTM算子梯度全零",
        "body": "![BD576B32-3540-42E9-A361-39754F8DF53C](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/49392868/5b20206b-30e7-47a5-a6ed-5c51032b9562)\r\n1. 上图打印了CRNN的反向梯度，CRNN模型最后的模型结构是LSTM接FC层，FC层梯度正常，但是从LSTM开始梯度全零\r\n2. 原因是当前框架不支持LSTM反向在NPU上的计算\r\n3. Fallback到CPU上计算时，CPU计算的结果为全零",
        "state": "closed",
        "user": "zhuo97",
        "closed_by": "ronny1996",
        "created_at": "2023-05-18T03:12:45+00:00",
        "updated_at": "2023-05-22T09:15:08+00:00",
        "closed_at": "2023-05-22T09:15:08+00:00",
        "comments_count": [
            "ronny1996",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 579,
        "title": "[问题记录] MPS backend buffer 指针非法偏移引发错误",
        "body": "详情：MPS backend alloc得到MTLBuffer的handle。单独调用算子没有报错。跑模型时，handle以（void*) 传给主框架，主框架会在前64字节记录chunk信息，然后非法偏移64字节使用，引发错误。\r\n\r\n![9e2ed90ad3a1c09a817d18f549a94ed1](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/43111799/9d9d67de-9479-4a69-b131-112e7aacc843)\r\n",
        "state": "closed",
        "user": "lishicheng1996",
        "closed_by": "qili93",
        "created_at": "2023-05-24T10:52:55+00:00",
        "updated_at": "2024-02-05T10:40:03+00:00",
        "closed_at": "2024-02-05T10:40:03+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 571,
        "title": "[intel_gpu] 从 \"paddle/phi/capi/all.h\" 切换到 \"paddle/phi/extension.h\"",
        "body": "我们之前的实现参考 CustomDevice 文档，通过包含 \"paddle/phi/capi/all.h\" 实现 kernel。现在为了和其他 CustomDevice 的实现保持一致和一些开发需求，准备切换到 \"paddle/phi/extension.h\"。编译过后在执行\r\n```\r\npython -c \"import paddle\"\r\n```\r\n\r\n的时候会报以下错误：\r\n```\r\nI0522 14:07:09.374876 4179087 init.cc:231] ENV [CUSTOM_DEVICE_ROOT]=/home/youlei/miniconda3/envs/pd/lib/python3.10/site-packages/paddle_custom_device\r\nI0522 14:07:09.374919 4179087 init.cc:140] Try loading custom device libs from: [/home/youlei/miniconda3/envs/pd/lib/python3.10/site-packages/paddle_custom_device]\r\nfree(): invalid pointer\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::InitDevices()\r\n1   paddle::framework::InitDevices(std::vector<int, std::allocator<int> >)\r\n2   paddle::framework::LoadCustomDevice(std::string const&)\r\n3   phi::KernelRegistrar::KernelRegistrar(phi::RegType, char const*, char const*, phi::DataLayout, phi::DataType, void (*)(phi::KernelKey const&, phi::KernelArgsDef*), void (*)(phi::KernelKey const&, phi::Kernel*), std::function<void (phi::KernelContext*)>, void*)\r\n4   phi::KernelRegistrar::ConstructKernel(phi::RegType, char const*, char const*, phi::DataLayout, phi::DataType, void (*)(phi::KernelKey const&, phi::KernelArgsDef*), void (*)(phi::KernelKey const&, phi::Kernel*), std::function<void (phi::KernelContext*)>, void*)\r\n5   phi::CustomKernelMap::RegisterCustomKernel(std::string const&, phi::KernelKey const&, phi::Kernel const&)\r\n6   std::pair<paddle::detailv3::sherwood_v3_table<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > >, std::string, std::hash<std::string >, paddle::detailv3::KeyOrValueHasher<std::string, std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > >, std::hash<std::string > >, std::equal_to<std::string >, paddle::detailv3::KeyOrValueEquality<std::string, std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > >, std::equal_to<std::string > >, std::allocator<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > > >, std::allocator<paddle::detailv3::sherwood_v3_entry<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > > > > >::templated_iterator<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > > >, bool> paddle::detailv3::sherwood_v3_table<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > >, std::string, std::hash<std::string >, paddle::detailv3::KeyOrValueHasher<std::string, std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > >, std::hash<std::string > >, std::equal_to<std::string >, paddle::detailv3::KeyOrValueEquality<std::string, std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > >, std::equal_to<std::string > >, std::allocator<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > > >, std::allocator<paddle::detailv3::sherwood_v3_entry<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > > > > >::emplace_new_key<std::string const&, paddle::flat_hash_map<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > > > >::convertible_to_value>(signed char, paddle::detailv3::sherwood_v3_entry<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > > >*, std::string const&, paddle::flat_hash_map<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string, paddle::flat_hash_map<phi::KernelKey, phi::Kernel, phi::KernelKey::Hash, std::equal_to<phi::KernelKey>, std::allocator<std::pair<phi::KernelKey, phi::Kernel> > > > > >::convertible_to_value&&)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Process abort signal` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1684735629 (unix time) try \"date -d @1684735629\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGABRT (@0x3e9003fc48f) received by PID 4179087 (TID 0x7fa4a648c740) from PID 4179087 ***]\r\n\r\nAborted (core dumped)\r\n```\r\n\r\n目前所做的修改主要有：\r\n\r\n- 将所有的 #include \"paddle/phi/capi/all.h\" 改为 \"paddle/phi/extension.h\"；\r\n- 形如\r\n```\r\ntemplate <typename T>\r\nvoid Kernel(const phi::Context& dev_ctx, ...\r\n```\r\n的内容改为：\r\n```\r\ntemplate <typename T, typename Context>\r\nvoid AssignValueKernel(const Context& dev_ctx, ...\r\n```\r\n\r\n- `PD_BUILD_PHI_KERNEL` 改为 `PD_REGISTER_PLUGIN_KERNEL`;\r\n\r\n- 其他如 DDim、DataType 等相关的修改。\r\n\r\n一直找不到问题所在，请问是有哪里遗漏了吗？",
        "state": "closed",
        "user": "yangulei",
        "closed_by": "yangulei",
        "created_at": "2023-05-22T06:30:00+00:00",
        "updated_at": "2023-06-13T07:02:40+00:00",
        "closed_at": "2023-06-13T07:02:40+00:00",
        "comments_count": [
            "ronny1996",
            "KimBioInfoStudio",
            "yangulei",
            "ronny1996",
            "KimBioInfoStudio",
            "ronny1996",
            "KimBioInfoStudio",
            "KimBioInfoStudio",
            "yangulei"
        ],
        "labels": [
            "help wanted",
            "intel_gpu"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 592,
        "title": "[NPU]模型场景反向计算精度问题",
        "body": "```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport paddle\r\nfrom paddle import ParamAttr\r\nimport paddle.nn as nn\r\nimport paddle.nn.functional as F\r\n\r\nfrom paddle.vision.ops import DeformConv2D\r\nfrom paddle.regularizer import L2Decay\r\nfrom paddle.nn.initializer import Normal, Constant, XavierUniform\r\n\r\n\r\nimport os\r\nfrom copy import deepcopy\r\nimport numpy as np\r\npaddle.seed(123)\r\npaddle.set_device('npu:4')\r\n\r\ndef cosine_similarity(x, y):\r\n    #x = x.numpy()\r\n    #y = y.numpy()\r\n    x1 = x.flatten().astype(np.float64)\r\n    y1 = y.flatten().astype(np.float64)\r\n    dot = np.dot(x1, y1)\r\n    lx = np.linalg.norm(x1)\r\n    ly = np.linalg.norm(y1)\r\n    cos = dot / (lx * ly)\r\n    return cos\r\n    \r\n\r\nclass ConvBNLayer(nn.Layer):\r\n    def __init__(self,\r\n                 in_channels,\r\n                 out_channels,\r\n                 kernel_size,\r\n                 stride=1,\r\n                 groups=1,\r\n                 dcn_groups=1,\r\n                 is_vd_mode=False,\r\n                 act=None,\r\n                 is_dcn=False):\r\n        super(ConvBNLayer, self).__init__()\r\n\r\n        self.is_vd_mode = is_vd_mode\r\n        self._pool2d_avg = nn.AvgPool2D(\r\n            kernel_size=2, stride=2, padding=0, ceil_mode=True)\r\n        if not is_dcn:\r\n            self._conv = nn.Conv2D(\r\n                in_channels=in_channels,\r\n                out_channels=out_channels,\r\n                kernel_size=kernel_size,\r\n                stride=stride,\r\n                padding=(kernel_size - 1) // 2,\r\n                groups=groups,\r\n                bias_attr=False)\r\n        else:\r\n            self._conv = DeformableConvV2(\r\n                in_channels=in_channels,\r\n                out_channels=out_channels,\r\n                kernel_size=kernel_size,\r\n                stride=stride,\r\n                padding=(kernel_size - 1) // 2,\r\n                groups=dcn_groups,  #groups,\r\n                bias_attr=False)\r\n        self._batch_norm = nn.BatchNorm(out_channels, act=act)\r\n\r\n    def forward(self, inputs):\r\n        print(f\"forward:{inputs.shape}\")\r\n        if self.is_vd_mode:\r\n            inputs = self._pool2d_avg(inputs)\r\n        print(f\"forward:{inputs.shape}\")\r\n        y = self._conv(inputs)\r\n        y = self._batch_norm(y)\r\n        return y\r\n\r\n\r\n# data\r\nxn = paddle.rand((16, 512, 20, 20))\r\nxn.stop_gradient=False\r\n\r\nxc = xn.cpu()\r\nxc.stop_gradient=False\r\n\r\ngrad_n = paddle.rand((16, 2048, 10, 10))\r\ngrad_c = grad_n.cpu()\r\n\r\n# model\r\nmodel_n = ConvBNLayer(\r\n    in_channels=512,\r\n    out_channels=2048,\r\n    kernel_size=1,\r\n    stride=1,\r\n    groups=1,\r\n    dcn_groups=1,\r\n    is_vd_mode=True,\r\n    act=None,\r\n    is_dcn=False,\r\n)\r\n\r\nmodel_c = deepcopy(model_n).to('cpu')\r\n\r\nprint(model_c)\r\n# forward\r\nyn1 = model_n._pool2d_avg(xn)\r\nyn2 = model_n._conv(yn1)\r\nyn3 = model_n._batch_norm(yn2)\r\n\r\nyc1 = model_c._pool2d_avg(xc)\r\nyc2 = model_c._conv(yc1)\r\nyc3 = model_c._batch_norm(yc2)\r\n\r\n\r\nyn1.retain_grads()\r\nyn2.retain_grads()\r\nyn3.retain_grads()\r\n\r\nyc1.retain_grads()\r\nyc2.retain_grads()\r\nyc3.retain_grads()\r\n\r\n\r\nprint(\"[acc_forward]y1=\", cosine_similarity(yn1, yc1))\r\nprint(\"[acc_forward]y2=\", cosine_similarity(yn2, yc2))\r\nprint(\"[acc_forward]y3=\", cosine_similarity(yn3, yc3))\r\n\r\n# backward\r\ncase = 1\r\n\r\nif case == 1:\r\n    yn3.backward(grad_n)\r\n    yc3.backward(grad_c)\r\n    \r\nif case == 2:\r\n    yn3.backward()\r\n    yc3.backward()\r\n    \r\nif case == 3:\r\n    yn3.sum().backward()\r\n    yc3.sum().backward()    \r\n\r\nprint(\"[acc_backward]x.grad=\", cosine_similarity(xn.grad, xc.grad))\r\nprint(\"[acc_backward]y1.grad=\", cosine_similarity(yn1.grad, yc1.grad))\r\nprint(\"[acc_backward]y2.grad=\", cosine_similarity(yn2.grad, yc2.grad))\r\nprint(\"[acc_backward]y3.grad=\", cosine_similarity(yn3.grad, yc3.grad))\r\n\r\n\r\nprint(\"[acc_backward]model_c._conv.weight.grad=\", cosine_similarity(model_c._conv.weight.grad, model_n._conv.weight.grad))\r\nprint(\"[acc_backward]model_c._batch_norm.weight.grad=\", cosine_similarity(model_c._batch_norm.weight.grad, model_n._batch_norm.weight.grad))\r\n```\r\n\r\n测试脚本如上，在backward计算中测试了三个场景：\r\n\r\ncase == 1时  \r\n反向计算npu与cpu计算的grad精度一致。  \r\n\r\ncase == 2时  \r\n反向计算npu与cpu计算的grad精度不一致。  \r\n此时，增环境变量“export CUSTOM_DEVICE_BLACK_LIST=batch_norm,batch_norm_grad,conv2d,conv2d_grad,pool2d,pool2d_grad” 后，反向计算npu与cpu计算的grad精度一致。  \r\n\r\ncase == 3时  \r\n为模型中求loss后进行反向传播的使用场景，反向计算npu与cpu计算的grad精度不一致。 \r\n同样添加环境变量后精度一致。 \r\n\r\n疑问：\r\n1. case=1和case=2反向计算有什么区别。  \r\n2. case=3时为模型中loss.backward()实际场景，需要解决精度问题。",
        "state": "closed",
        "user": "max-niu",
        "closed_by": "qili93",
        "created_at": "2023-05-30T12:48:49+00:00",
        "updated_at": "2024-06-07T06:18:09+00:00",
        "closed_at": "2024-06-07T06:18:09+00:00",
        "comments_count": [
            "qili93",
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 593,
        "title": "使用PD_BUILD_PHI_KERNEL注册kernel失败",
        "body": "有两个问题想请教一下 ：\r\n\r\n1. PD_BUILD_PHI_KERNEL与PD_REGISTER_PLUGIN_KERNEL具体的区别是什么？\r\n2. 编译了 custom_cpu 的代码，里面使用PD_BUILD_PHI_KERNEL进行注册Kernel，运行时加载LOG显示`No custom kernel info found in loaded lib(s).`\r\n\r\n![2023-05-31_11-57](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/65210872/a5e229cd-5e2a-48b7-be0b-6d0e9f10949c)\r\n\r\n",
        "state": "closed",
        "user": "ccsuzzh",
        "closed_by": "ccsuzzh",
        "created_at": "2023-05-31T06:52:06+00:00",
        "updated_at": "2023-06-05T07:17:04+00:00",
        "closed_at": "2023-06-05T07:17:03+00:00",
        "comments_count": [
            "ronny1996",
            "ccsuzzh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 594,
        "title": "submodule更新异常",
        "body": "运行git submodule update --remote --init --recursive时，Paddle的第三方依赖 leveldb无法拉取\r\n\r\n```\r\n[***@*** PaddleCustomDevice]$ git submodule update --remote --init --recursive\r\nSubmodule 'Paddle' (https://github.com/PaddlePaddle/Paddle.git) registered for path 'Paddle'\r\nCloning into 'Paddle'...\r\nremote: Enumerating objects: 552541, done.\r\nremote: Counting objects: 100% (887/887), done.\r\nremote: Compressing objects: 100% (664/664), done.\r\nremote: Total 552541 (delta 408), reused 406 (delta 221), pack-reused 551654\r\nReceiving objects: 100% (552541/552541), 349.40 MiB | 335.00 KiB/s, done.\r\nResolving deltas: 100% (466820/466820), done.\r\nremote: Enumerating objects: 45, done.\r\nremote: Counting objects: 100% (45/45), done.\r\nremote: Compressing objects: 100% (21/21), done.\r\nremote: Total 24 (delta 22), reused 5 (delta 3), pack-reused 0\r\nUnpacking objects: 100% (24/24), done.\r\nFrom https://github.com/PaddlePaddle/Paddle\r\n   a195ef3..cbeff5f  develop    -> origin/develop\r\nSubmodule path 'Paddle': checked out 'cbeff5fc580672ff0882ca6bd9a1341fe8bef1fc'\r\nSubmodule 'third_party/dlpack' (https://github.com/dmlc/dlpack.git) registered for path 'third_party/dlpack'\r\nSubmodule 'third_party/eigen3' (https://gitlab.com/libeigen/eigen.git) registered for path 'third_party/eigen3'\r\nSubmodule 'third_party/gflags' (https://github.com/gflags/gflags.git) registered for path 'third_party/gflags'\r\nSubmodule 'third_party/glog' (https://github.com/google/glog.git) registered for path 'third_party/glog'\r\nSubmodule 'third_party/gloo' (https://github.com/ziyoujiyi/gloo.git) registered for path 'third_party/gloo'\r\nSubmodule 'third_party/leveldb' (https://github.com/google/leveldb) registered for path 'third_party/leveldb'\r\nSubmodule 'third_party/protobuf' (https://github.com/protocolbuffers/protobuf.git) registered for path 'third_party/protobuf'\r\nSubmodule 'third_party/threadpool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/threadpool'\r\nSubmodule 'third_party/utf8proc' (https://github.com/JuliaStrings/utf8proc.git) registered for path 'third_party/utf8proc'\r\nSubmodule 'third_party/warpctc' (https://github.com/baidu-research/warp-ctc.git) registered for path 'third_party/warpctc'\r\nSubmodule 'third_party/warprnnt' (https://github.com/PaddlePaddle/warp-transducer.git) registered for path 'third_party/warprnnt'\r\nSubmodule 'third_party/xxhash' (https://github.com/Cyan4973/xxHash.git) registered for path 'third_party/xxhash'\r\nSubmodule 'third_party/zlib' (https://github.com/madler/zlib.git) registered for path 'third_party/zlib'\r\nCloning into 'third_party/dlpack'...\r\nremote: Enumerating objects: 462, done.\r\nremote: Counting objects: 100% (99/99), done.\r\nremote: Compressing objects: 100% (40/40), done.\r\nremote: Total 462 (delta 74), reused 69 (delta 59), pack-reused 363\r\nReceiving objects: 100% (462/462), 1.70 MiB | 191.00 KiB/s, done.\r\nResolving deltas: 100% (162/162), done.\r\nSubmodule path 'Paddle/third_party/dlpack': checked out '3ec04430e89a6834e5a1b99471f415fa939bf642'\r\nCloning into 'third_party/eigen3'...\r\nremote: Enumerating objects: 119484, done.\r\nremote: Counting objects: 100% (1163/1163), done.\r\nremote: Compressing objects: 100% (375/375), done.\r\nremote: Total 119484 (delta 812), reused 1117 (delta 787), pack-reused 118321\r\nReceiving objects: 100% (119484/119484), 103.62 MiB | 10.13 MiB/s, done.\r\nResolving deltas: 100% (98647/98647), done.\r\nSubmodule path 'Paddle/third_party/eigen3': checked out '07e4604b1961a32bbe21841a1e97fc274b50c443'\r\nCloning into 'third_party/gflags'...\r\nremote: Enumerating objects: 2458, done.\r\nremote: Counting objects: 100% (71/71), done.\r\nremote: Compressing objects: 100% (46/46), done.\r\nremote: Total 2458 (delta 34), reused 52 (delta 25), pack-reused 2387\r\nReceiving objects: 100% (2458/2458), 1.53 MiB | 1.12 MiB/s, done.\r\nResolving deltas: 100% (1436/1436), done.\r\nSubmodule path 'Paddle/third_party/gflags': checked out 'a738fdf9338412f83ab3f26f31ac11ed3f3ec4bd'\r\nCloning into 'third_party/glog'...\r\nremote: Enumerating objects: 4005, done.\r\nremote: Counting objects: 100% (267/267), done.\r\nremote: Compressing objects: 100% (161/161), done.\r\nremote: Total 4005 (delta 153), reused 191 (delta 95), pack-reused 3738\r\nReceiving objects: 100% (4005/4005), 2.27 MiB | 237.00 KiB/s, done.\r\nResolving deltas: 100% (2755/2755), done.\r\nSubmodule path 'Paddle/third_party/glog': checked out '22491eb1236c8b5c1dcba2ed3a213c74ce699988'\r\nCloning into 'third_party/gloo'...\r\nremote: Enumerating objects: 3613, done.\r\nremote: Counting objects: 100% (7/7), done.\r\nremote: Compressing objects: 100% (7/7), done.\r\nremote: Total 3613 (delta 0), reused 1 (delta 0), pack-reused 3606\r\nReceiving objects: 100% (3613/3613), 1.07 MiB | 694.00 KiB/s, done.\r\nResolving deltas: 100% (2762/2762), done.\r\nSubmodule path 'Paddle/third_party/gloo': checked out '9877014465775fac31df9297e5425e599031be76'\r\nCloning into 'third_party/leveldb'...\r\nremote: Enumerating objects: 3525, done.\r\nremote: Counting objects: 100% (68/68), done.\r\nremote: Compressing objects: 100% (49/49), done.\r\nremote: Total 3525 (delta 29), reused 29 (delta 15), pack-reused 3457\r\nReceiving objects: 100% (3525/3525), 1.67 MiB | 173.00 KiB/s, done.\r\nResolving deltas: 100% (2460/2460), done.\r\nfatal: Needed a single revision\r\nUnable to find current origin/master revision in submodule path 'third_party/leveldb'\r\nFailed to recurse into submodule path 'Paddle'\r\n```",
        "state": "closed",
        "user": "parap1uie-s",
        "closed_by": "parap1uie-s",
        "created_at": "2023-05-31T07:27:25+00:00",
        "updated_at": "2023-07-12T09:38:30+00:00",
        "closed_at": "2023-07-12T09:38:30+00:00",
        "comments_count": [
            "KimBioInfoStudio",
            "USTCKAY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 598,
        "title": "PaddleNLP ChatGLM在NPU环境下运行异常",
        "body": "目前NPU似乎有kernel不支持fp16推理\r\n\r\n```\r\nimport paddlenlp\r\nfrom paddlenlp.transformers import ChatGLMForConditionalGeneration, ChatGLMTokenizer, ChatGLMConfig\r\n\r\nllm = 'THUDM/chatglm-6b'\r\nconfig = ChatGLMConfig.from_pretrained(llm)\r\nmodel = ChatGLMForConditionalGeneration.from_pretrained(llm, \r\n                            load_state_as_np=True, dtype=\"float16\", \r\n                            config=config)\r\nmodel_tokenizer = paddlenlp.transformers.AutoTokenizer.from_pretrained(llm)\r\n\r\ntext_input = '你好'\r\n\r\ninputs = model_tokenizer(text_input, return_tensors=\"pd\",\r\n            add_special_tokens=True,\r\n            padding=\"max_length\",\r\n            max_length=32,\r\n            truncation=True,\r\n            truncation_side=\"left\")\r\n\r\noutput1 = model.generate(max_length=64, decode_strategy='sampling', top_k=1, \r\n                        bos_token_id=model_tokenizer.bos_token_id, \r\n                        eos_token_id=model_tokenizer.end_token_id,\r\n                        pad_token_id=model_tokenizer.pad_token_id,\r\n                        **inputs)\r\n\r\npprint.pprint(model_tokenizer.batch_decode(output1[0].tolist()))\r\nprint(time.time() - t_start)\r\n```\r\n\r\n<img width=\"1049\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/23453851/ed267722-8f50-466f-9323-94eaf84285a9\">\r\n",
        "state": "closed",
        "user": "parap1uie-s",
        "closed_by": "YanhuiDua",
        "created_at": "2023-06-01T06:50:52+00:00",
        "updated_at": "2023-06-05T02:57:35+00:00",
        "closed_at": "2023-06-05T02:57:35+00:00",
        "comments_count": [
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 599,
        "title": "[intel_gpu] elementwise_sub op unittest failed",
        "body": "我把mlu目录下的test_elementwise_sub_op_mlu.py测试脚本移植到intel_gpu来，在以下几个测试用例中报错：\r\n1 TestElementwiseSubOp_broadcast_4\r\n2 TestElementwiseSubOp_commonuse_1\r\n3 TestElementwiseSubOp_commonuse_2\r\n报错的原因都是类似的，TestElementwiseSubOp_broadcast_4的错误信息如下：\r\n======================================================================\r\nERROR: test_check_grad_ingore_x (_main_.TestElementwiseSubOp_broadcast_4)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"test_elementwise_sub_op_intel_gpu.py\", line 65, in test_check_grad_ingore_x\r\n    self.place, [\"Y\"], \"Out\", max_relative_error=0.005, no_grad_set=set(\"X\")\r\n  File \"/home/tcl/master/frameworks.ai.paddle.gpu/python/tests/op_test.py\", line 2517, in check_grad_with_place\r\n    atol=atol,\r\n  File \"/home/tcl/master/frameworks.ai.paddle.gpu/python/tests/op_test.py\", line 2250, in _assert_is_close\r\n    diff_mat = np.abs(a - b) / abs_a\r\nValueError: operands could not be broadcast together with shapes (2,5,1,12) (2,5,12)\r\n\r\n======================================================================\r\nERROR: test_check_grad_normal (_main_.TestElementwiseSubOp_broadcast_4)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"test_elementwise_sub_op_intel_gpu.py\", line 61, in test_check_grad_normal\r\n    self.check_grad_with_place(self.place, [\"X\", \"Y\"], \"Out\")\r\n  File \"/home/tcl/master/frameworks.ai.paddle.gpu/python/tests/op_test.py\", line 2517, in check_grad_with_place\r\n    atol=atol,\r\n  File \"/home/tcl/master/frameworks.ai.paddle.gpu/python/tests/op_test.py\", line 2250, in _assert_is_close\r\n    diff_mat = np.abs(a - b) / abs_a\r\nValueError: operands could not be broadcast together with shapes (2,5,1,12) (2,5,12)\r\n\r\n----------------------------------------------------------------------",
        "state": "closed",
        "user": "ChengleiTian",
        "closed_by": "qili93",
        "created_at": "2023-06-02T08:48:53+00:00",
        "updated_at": "2024-06-07T06:18:14+00:00",
        "closed_at": "2024-06-07T06:18:14+00:00",
        "comments_count": [
            "qili93",
            "qili93",
            "qili93"
        ],
        "labels": [
            "intel_gpu"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 610,
        "title": "[intel_gpu] BN args on Place(cpu) in fleet training",
        "body": "我在测试通过 fleet 在 \"intel_gpu\" 单机多卡的机器上训练 DDP RN50。forward 正常，backward fail 在一个错误的 memcpy 上：\r\n```\r\nCopy 2048 Bytes from 0xffff8181ff0cc800(Place(cpu)) to 0x1ab0f000(Place(cpu))\r\n```\r\n这里的 src 显然是一个 device buffer，但是被错误地认为是 host buffer，导致了 segfault。\r\n通过日志发现有些 Tensor，如 `batch_norm2d_48.w_0` ，在最开始用 `full` 填充时还是在 `Place(intel_gpu:0)`，但是在调 BN kernel 时就变成了 `Place(cpu)`。请问这个问题要从哪些方向去找原因？\r\n所用 Paddle 版本为 （commit f55b387df0f473574f82c83da0c4c821829f35a7 (tag: v2.5.0-rc0, release/2.5)），所作的修改只有在 memcpy 日志中加上了指针。worker0 上精简后的 log 如下：\r\n``` log\r\n......\r\n\r\nI0605 17:04:43.523797 1570317 dygraph_functions.cc:39262] Finish AD API: gaussian\r\nI0605 17:04:43.523912 1570317 dygraph_functions.cc:39276] { Input: [],  \r\n Output: [ \r\n( out , [{Name: None, Initialized: 1, Ptr: 0x72edc60 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512, 512, 3, 3 ], ADInfo:[ None ]}]), ] } \r\nI0605 17:04:43.524639 1570317 eager.cc:653]  args_num: 5\r\nI0605 17:04:43.524663 1570317 eager.cc:823] Calling case2's initializer.\r\nI0605 17:04:43.524729 1570317 grad_node_info.cc:64] Construct GradNodeBase\r\nI0605 17:04:43.524763 1570317 accumulation_node.h:27] Construct GradNodeAccumulation\r\nI0605 17:04:43.524791 1570317 eager.cc:107] Tensor(batch_norm2d_48.w_0) have not GradNode, add GradNodeAccumulation0x85cdae0 for it.\r\nI0605 17:04:43.524863 1570317 eager_properties.cc:198] eager_properties 'Shape' method, layout autotune  desired_layout: Undefined(AnyLayout) default_layout: Undefined(AnyLayout) tensor layout: NCHW tensor's shape size is : 1\r\nI0605 17:04:43.524895 1570317 eager_op_function.cc:19529] Running Eager Final State API: full_\r\nI0605 17:04:43.524907 1570317 eager_op_function.cc:19531] args count: 2\r\nI0605 17:04:43.524927 1570317 eager_utils.cc:1424] type_name: str\r\nI0605 17:04:43.525002 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:04:43.525034 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:04:43.525020 1570317 eager_op_function.cc:19562] CurrentDeviceId: 0 from 0\r\nI0605 17:04:43.525058 1570317 dygraph_functions.cc:38666] Running AD API: full_\r\nI0605 17:04:43.525069 1570317 dygraph_functions.cc:38672]  No AMP for full__ad_func because it is a inplace or cast api. \r\nI0605 17:04:43.525080 1570317 dygraph_functions.cc:38692] Running C++ API: full_\r\nI0605 17:04:43.525146 1570317 dygraph_functions.cc:38703] { Input: [ \r\n( output , [{Name: batch_norm2d_48.w_0, Initialized: 0, Ptr: 0x72ed510 TensorInfo: [ Type: DenseTensor, Dtype: Unknown, Place: Unknown, Shape: Unknown ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ]} \r\nI0605 17:04:43.525171 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:04:43.525214 1570317 api.cc:26073] full_ API kernel key: [intel_gpu, NCHW, float32]\r\nI0605 17:04:43.525262 1570317 api.cc:26080] full kernel: {\"input\":[],\"output\":[\"intel_gpu, NCHW, float32\"],\"attribute\":[\"IntArray\",\"Scalar\",\"DataType\"]}\r\nI0605 17:04:43.525293 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:04:43.525385 1570317 full_kernel.cc:25] FullValue type=float\r\nI0605 17:04:43.525417 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:04:43.525431 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:04:43.525476 1570317 runtime.cc:234] request allocate size=2048 device=0\r\nI0605 17:04:43.525560 1570317 runtime.cc:258] allocate success size=2048 left=1765120799\r\nI0605 17:04:43.525624 1570317 auto_growth_best_fit_allocator.cc:118] Not found and reallocate 2048(0xffff8181fe020000), and remaining 0\r\nI0605 17:04:43.525640 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181fe020000\r\nI0605 17:04:43.525681 1570317 full_kernel.cc:29] FullValue size=512 sizeof(T)=4\r\nI0605 17:04:43.526175 1570317 dygraph_functions.cc:38717] Finish AD API: full_\r\nI0605 17:04:43.526319 1570317 dygraph_functions.cc:38734] { Input: [ \r\n( output , [{Name: batch_norm2d_48.w_0, Initialized: 1, Ptr: 0x72ed510 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ],  \r\n Output: [ \r\n( out , [{Name: batch_norm2d_48.w_0, Initialized: 1, Ptr: 0x72ed510 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ] } \r\n\r\n......\r\n\r\nI0605 17:04:46.935668 1570317 reducer.cc:101] var[conv2d_48.w_0] 's type is float32\r\nI0605 17:04:46.935672 1570317 reducer.cc:101] var[batch_norm2d_48.w_0] 's type is float32\r\nI0605 17:04:46.935675 1570317 reducer.cc:101] var[batch_norm2d_48.b_0] 's type is float32\r\nI0605 17:04:46.935679 1570317 reducer.cc:101] var[conv2d_49.w_0] 's type is float32\r\n\r\n......\r\n\r\nI0605 17:05:02.728678 1570317 eager_op_function.cc:16839] Running Eager Final State API: batch_norm\r\nI0605 17:05:02.728682 1570317 eager_op_function.cc:16841] args count: 5\r\nI0605 17:05:02.728744 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:02.728756 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:02.728751 1570317 eager_op_function.cc:16881] CurrentDeviceId: 0 from 0\r\nI0605 17:05:02.728763 1570317 dygraph_functions.cc:33987] Running AD API: batch_norm\r\nI0605 17:05:02.728767 1570317 dygraph_functions.cc:34050] Running C++ API: batch_norm\r\nI0605 17:05:02.728855 1570317 dygraph_functions.cc:34073] { Input: [ \r\n( x , [{Name: None, Initialized: 1, Ptr: 0x1a0755d0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [2]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1923ac40, ReluGradNode] },  ]SlotID: 1, StopGradients: 0, , Edges[  { [0, 0]: [0x72ed8a0, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( mean , [{Name: batch_norm2d_48.w_1, Initialized: 1, Ptr: 0x85cf840 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 1 ] ]}]),  \r\n( variance , [{Name: batch_norm2d_48.w_2, Initialized: 1, Ptr: 0x82d3300 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 1 ] ]}]),  \r\n( scale , [{Name: batch_norm2d_48.w_0, Initialized: 1, Ptr: 0x72ed510 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( bias , [{Name: batch_norm2d_48.b_0, Initialized: 1, Ptr: 0x85cec70 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ]} \r\nI0605 17:05:02.728883 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:02.728912 1570317 api.cc:22540] batch_norm API kernel key: [intel_gpu, NCHW, float32]\r\nI0605 17:05:02.728945 1570317 api.cc:22547] batch_norm kernel: {\"input\":[\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\"],\"output\":[\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\"],\"attribute\":[\"bool\",\"float\",\"float\",\"string\",\"bool\",\"bool\"]}\r\nI0605 17:05:02.728962 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:02.729009 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:02.729014 1570317 data_transform.cc:169] DeviceTransform in, src_place Place(cpu) dst_place: Place(intel_gpu:0)\r\nI0605 17:05:02.729025 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:02.729063 1570317 tensor_utils.cc:50] TensorCopy 512 from Place(cpu) to Place(intel_gpu:0)\r\nI0605 17:05:02.729077 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:02.729082 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:02.729099 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:02.729101 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0ca000\r\nI0605 17:05:02.729135 1570317 tensor_utils.cc:97] src:0x85e0000, dst:0xffff8181ff0ca000\r\nI0605 17:05:02.729149 1570317 memcpy.cc:66] memory::Copy 2048 Bytes from Place(cpu)(0x85e0000) to Place(intel_gpu:0)(0xffff8181ff0ca000), stream=0\r\nI0605 17:05:02.729158 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:02.729244 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:02.729259 1570317 runtime.cc:324] sync-stream devid=0\r\nI0605 17:05:02.729274 1570317 runtime.cc:374] memory-copy-h2d dst=0xffff8181ff0ca000 src=0x85e0000 size=2048\r\nI0605 17:05:02.729657 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:02.729671 1570317 data_transform.cc:169] DeviceTransform in, src_place Place(cpu) dst_place: Place(intel_gpu:0)\r\nI0605 17:05:02.729679 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:02.729691 1570317 tensor_utils.cc:50] TensorCopy 512 from Place(cpu) to Place(intel_gpu:0)\r\nI0605 17:05:02.729701 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:02.729704 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:02.729713 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:02.729717 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0ca800\r\nI0605 17:05:02.729736 1570317 tensor_utils.cc:97] src:0x8841000, dst:0xffff8181ff0ca800\r\nI0605 17:05:02.729748 1570317 memcpy.cc:66] memory::Copy 2048 Bytes from Place(cpu)(0x8841000) to Place(intel_gpu:0)(0xffff8181ff0ca800), stream=0\r\nI0605 17:05:02.729758 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:02.729801 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:02.729820 1570317 runtime.cc:324] sync-stream devid=0\r\nI0605 17:05:02.729831 1570317 runtime.cc:374] memory-copy-h2d dst=0xffff8181ff0ca800 src=0x8841000 size=2048\r\nI0605 17:05:02.730211 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:02.730233 1570317 data_transform.cc:169] DeviceTransform in, src_place Place(cpu) dst_place: Place(intel_gpu:0)\r\nI0605 17:05:02.730244 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:02.730258 1570317 tensor_utils.cc:50] TensorCopy 512 from Place(cpu) to Place(intel_gpu:0)\r\nI0605 17:05:02.730268 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:02.730271 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:02.730279 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:02.730283 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0cc000\r\nI0605 17:05:02.730296 1570317 tensor_utils.cc:97] src:0x7c1a000, dst:0xffff8181ff0cc000\r\nI0605 17:05:02.730306 1570317 memcpy.cc:66] memory::Copy 2048 Bytes from Place(cpu)(0x7c1a000) to Place(intel_gpu:0)(0xffff8181ff0cc000), stream=0\r\nI0605 17:05:02.730315 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:02.730357 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:02.730368 1570317 runtime.cc:324] sync-stream devid=0\r\nI0605 17:05:02.730379 1570317 runtime.cc:374] memory-copy-h2d dst=0xffff8181ff0cc000 src=0x7c1a000 size=2048\r\nI0605 17:05:02.730762 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:02.730785 1570317 data_transform.cc:169] DeviceTransform in, src_place Place(cpu) dst_place: Place(intel_gpu:0)\r\nI0605 17:05:02.730795 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:02.730809 1570317 tensor_utils.cc:50] TensorCopy 512 from Place(cpu) to Place(intel_gpu:0)\r\nI0605 17:05:02.730818 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:02.730823 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:02.730829 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:02.730832 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0cc800\r\nI0605 17:05:02.730845 1570317 tensor_utils.cc:97] src:0xe650000, dst:0xffff8181ff0cc800\r\nI0605 17:05:02.730856 1570317 memcpy.cc:66] memory::Copy 2048 Bytes from Place(cpu)(0xe650000) to Place(intel_gpu:0)(0xffff8181ff0cc800), stream=0\r\nI0605 17:05:02.730866 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:02.730907 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:02.730918 1570317 runtime.cc:324] sync-stream devid=0\r\nI0605 17:05:02.730928 1570317 runtime.cc:374] memory-copy-h2d dst=0xffff8181ff0cc800 src=0xe650000 size=2048\r\nI0605 17:05:02.731307 1570317 api.cc:22582] Perform View between Output and Input Tensor, share allocation and inplace version.\r\nI0605 17:05:02.731328 1570317 api.cc:22586] Perform View between Output and Input Tensor, share allocation and inplace version.\r\nI0605 17:05:02.731400 1570317 dense_tensor.cc:139] Allocate data with bytes: 3211264\r\nI0605 17:05:02.731405 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 3211264 bytes, aligned to 3211264\r\nI0605 17:05:02.731415 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 3211264 bytes from chunk size 4194304, remaining 983040\r\nI0605 17:05:02.731431 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 3211264 bytes, ptr = 0xffff81d5fdaf0000\r\nI0605 17:05:02.731453 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:02.731457 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:02.731462 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:02.731464 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0cd000\r\nI0605 17:05:02.731470 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:02.731473 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:02.731477 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:02.731479 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0cd800\r\nI0605 17:05:02.731565 1570317 dense_tensor.cc:139] Allocate data with bytes: 200832\r\nI0605 17:05:02.731571 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 200832 bytes, aligned to 200832\r\nI0605 17:05:02.731577 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 200832 bytes from chunk size 262144, remaining 61312\r\nI0605 17:05:02.731585 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 200832 bytes, ptr = 0xffff8181febeef80\r\nonednn_verbose,exec,gpu:0,batch_normalization,ocl:ref:any,forward_training,data_f32::blocked:abcd:f0 diff_undef::undef::,attr-scratchpad:user ,flags:CH,mb32ic512ih7iw7,0.275146\r\nI0605 17:05:02.732051 1570317 auto_growth_best_fit_allocator.cc:131] Free 200832 bytes, ptr = 0xffff8181febeef80\r\nI0605 17:05:02.732097 1570317 auto_growth_best_fit_allocator.cc:131] Free 2048 bytes, ptr = 0xffff8181ff0cc800\r\nI0605 17:05:02.732105 1570317 auto_growth_best_fit_allocator.cc:131] Free 2048 bytes, ptr = 0xffff8181ff0cc000\r\nI0605 17:05:02.732123 1570317 grad_node_info.cc:64] Construct GradNodeBase\r\nI0605 17:05:02.732144 1570317 grad_node_info.cc:238] Add Edges for slot: 0, the Edge is from BatchNormGradNode (addr: 0x198b7070)  to Conv2dGradNodeFinal (addr: 0x1a366ff0)\r\nI0605 17:05:02.732151 1570317 grad_node_info.h:77] Reseting Edge's Grad Node\r\nI0605 17:05:02.732168 1570317 grad_node_info.cc:238] Add Edges for slot: 3, the Edge is from BatchNormGradNode (addr: 0x198b7070)  to GradNodeAccumulation (addr: 0x85cdae0)\r\nI0605 17:05:02.732172 1570317 grad_node_info.h:77] Reseting Edge's Grad Node\r\nI0605 17:05:02.732177 1570317 grad_node_info.cc:238] Add Edges for slot: 4, the Edge is from BatchNormGradNode (addr: 0x198b7070)  to GradNodeAccumulation (addr: 0x85cf000)\r\nI0605 17:05:02.732182 1570317 grad_node_info.h:77] Reseting Edge's Grad Node\r\nI0605 17:05:02.732187 1570317 grad_node_info.cc:86] Set GradSlotMeta for Grad Inputs\r\nI0605 17:05:02.732193 1570317 grad_node_info.cc:86] Set GradSlotMeta for Grad Inputs\r\nI0605 17:05:02.732198 1570317 grad_node_info.cc:86] Set GradSlotMeta for Grad Inputs\r\nI0605 17:05:02.732203 1570317 grad_node_info.cc:86] Set GradSlotMeta for Grad Inputs\r\nI0605 17:05:02.732208 1570317 grad_node_info.cc:86] Set GradSlotMeta for Grad Inputs\r\nI0605 17:05:02.732213 1570317 grad_node_info.cc:86] Set GradSlotMeta for Grad Inputs\r\nI0605 17:05:02.732218 1570317 grad_node_info.cc:106] Skip Configuring GradSlotMeta for uninitialized GradInput Tensor\r\nI0605 17:05:02.732223 1570317 dygraph_functions.cc:34183] Finish AD API: batch_norm\r\nI0605 17:05:02.732421 1570317 dygraph_functions.cc:34224] { Input: [ \r\n( x , [{Name: None, Initialized: 1, Ptr: 0x1a0755d0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [2]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1923ac40, ReluGradNode] },  ]SlotID: 1, StopGradients: 0, , Edges[  { [0, 0]: [0x72ed8a0, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( mean , [{Name: batch_norm2d_48.w_1, Initialized: 1, Ptr: 0x85cf840 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 1 ] ]}]),  \r\n( variance , [{Name: batch_norm2d_48.w_2, Initialized: 1, Ptr: 0x82d3300 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 1 ] ]}]),  \r\n( scale , [{Name: batch_norm2d_48.w_0, Initialized: 1, Ptr: 0x72ed510 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( bias , [{Name: batch_norm2d_48.b_0, Initialized: 1, Ptr: 0x85cec70 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ],  \r\n Output: [ \r\n( out , [{Name: None, Initialized: 1, Ptr: 0x19561630 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( mean_out , [{Name: None, Initialized: 1, Ptr: 0x1a19dc90 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( variance_out , [{Name: None, Initialized: 1, Ptr: 0x18621490 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( saved_mean , [{Name: None, Initialized: 1, Ptr: 0x188de050 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( saved_variance , [{Name: None, Initialized: 1, Ptr: 0x19dce0f0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( reserve_space , [{Name: None, Initialized: 0, Ptr: 0x19f979d0 TensorInfo: [ Type: DenseTensor, Dtype: Unknown, Place: Unknown, Shape: Unknown ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ] } \r\nI0605 17:05:02.732524 1570317 eager_op_function.cc:11066] Running Eager Final State API: relu\r\n\r\n......\r\n\r\nI0605 17:05:07.889714 1570317 nodes.cc:14271] Finish AD API GRAD: relu_grad\r\nI0605 17:05:07.889755 1570317 nodes.cc:14288] { Input: [ \r\n( grad_out , [{Name: None, Initialized: 1, Ptr: 0x7cda990 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ None ], StopGradient: [ 0 ] ]}]),  \r\n( out , [{Name: @Saved, Initialized: 1, Ptr: 0x191d79d0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x198b7070, BatchNormGradNode] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ],  \r\n Output: [ \r\n ( grad_x , [{Name: None, Initialized: 1, Ptr: 0x19838cd0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ None ], StopGradient: [ 0 ] ]}]), ] } \r\nI0605 17:05:07.889763 1570317 backward.cc:283] retain_graph is false, need to clear the TensorWrapper of nodes.\r\nI0605 17:05:07.889771 1570317 auto_growth_best_fit_allocator.cc:131] Free 3211264 bytes, ptr = 0xffff81ac030c1ea0\r\nI0605 17:05:07.889791 1570317 backward.cc:312] Node: ReluGradNode addr:0x191da280, Found pending node: BatchNormGradNode addr: 0x198b7070\r\nI0605 17:05:07.889796 1570317 backward.cc:339] Get Edge and grad_output_tensor with slot: 0, rank: 0 's name is: \r\nI0605 17:05:07.889798 1570317 grad_tensor_holder.h:32] Init GradTensorHolder with meta size: 6\r\nI0605 17:05:07.889801 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.889804 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.889807 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.889809 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.889822 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.889824 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.889827 1570317 backward.cc:348] Construct GradTensorHolder for grad node: BatchNormGradNode\r\nI0605 17:05:07.889830 1570317 backward.cc:353] Sum or Move grad inputs for edge slot: 0, rank: 0\r\nI0605 17:05:07.889834 1570317 grad_tensor_holder.cc:132] Move Tensor for buffer_ slot: 0, size: 1\r\nI0605 17:05:07.889838 1570317 backward.cc:363] BatchNormGradNode ref_cnt is: 0\r\nI0605 17:05:07.889843 1570317 backward.cc:243] Preparing GradNode:BatchNormGradNode addr:0x198b7070\r\nI0605 17:05:07.889847 1570317 backward.cc:270] Run Backward Kernel with GradTensorHolder.\r\nI0605 17:05:07.889849 1570317 nodes.cc:23093] Running AD API GRAD: batch_norm_grad\r\nI0605 17:05:07.889856 1570317 grad_node_info.cc:43] float32 float32\r\nI0605 17:05:07.889863 1570317 tensor_wrapper.h:137] Recover tensor: @Saved for wrapper\r\nI0605 17:05:07.889868 1570317 tensor_wrapper.h:213]  The wrapper_version_snapshot of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889869 1570317 tensor_wrapper.h:216]  The tensor_version of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889873 1570317 tensor_wrapper.h:161] Recovered TensorWrapper with GradNode Conv2dGradNodeFinal addr: 0x1a366ff0\r\nI0605 17:05:07.889878 1570317 tensor_wrapper.h:137] Recover tensor: batch_norm2d_48.w_0@Saved for wrapper\r\nI0605 17:05:07.889880 1570317 tensor_wrapper.h:213]  The wrapper_version_snapshot of Tensor 'batch_norm2d_48.w_0@Saved' is [ 0 ]\r\nI0605 17:05:07.889883 1570317 tensor_wrapper.h:216]  The tensor_version of Tensor 'batch_norm2d_48.w_0@Saved' is [ 0 ]\r\nI0605 17:05:07.889886 1570317 tensor_wrapper.h:161] Recovered TensorWrapper with GradNode GradNodeAccumulation addr: 0x85cdae0\r\nI0605 17:05:07.889889 1570317 tensor_wrapper.h:137] Recover tensor: batch_norm2d_48.b_0@Saved for wrapper\r\nI0605 17:05:07.889895 1570317 tensor_wrapper.h:213]  The wrapper_version_snapshot of Tensor 'batch_norm2d_48.b_0@Saved' is [ 0 ]\r\nI0605 17:05:07.889899 1570317 tensor_wrapper.h:216]  The tensor_version of Tensor 'batch_norm2d_48.b_0@Saved' is [ 0 ]\r\nI0605 17:05:07.889901 1570317 tensor_wrapper.h:161] Recovered TensorWrapper with GradNode GradNodeAccumulation addr: 0x85cf000\r\nI0605 17:05:07.889904 1570317 tensor_wrapper.h:137] Recover tensor: @Saved for wrapper\r\nI0605 17:05:07.889907 1570317 tensor_wrapper.h:213]  The wrapper_version_snapshot of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889910 1570317 tensor_wrapper.h:216]  The tensor_version of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889914 1570317 tensor_wrapper.h:161] Recovered TensorWrapper with GradNode BatchNormGradNode addr: 0x198b7070\r\nI0605 17:05:07.889916 1570317 tensor_wrapper.h:137] Recover tensor: @Saved for wrapper\r\nI0605 17:05:07.889919 1570317 tensor_wrapper.h:213]  The wrapper_version_snapshot of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889922 1570317 tensor_wrapper.h:216]  The tensor_version of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889925 1570317 tensor_wrapper.h:161] Recovered TensorWrapper with GradNode BatchNormGradNode addr: 0x198b7070\r\nI0605 17:05:07.889928 1570317 tensor_wrapper.h:137] Recover tensor: @Saved for wrapper\r\nI0605 17:05:07.889930 1570317 tensor_wrapper.h:213]  The wrapper_version_snapshot of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889933 1570317 tensor_wrapper.h:216]  The tensor_version of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889936 1570317 tensor_wrapper.h:161] Recovered TensorWrapper with GradNode BatchNormGradNode addr: 0x198b7070\r\nI0605 17:05:07.889940 1570317 tensor_wrapper.h:137] Recover tensor: @Saved for wrapper\r\nI0605 17:05:07.889942 1570317 tensor_wrapper.h:213]  The wrapper_version_snapshot of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889945 1570317 tensor_wrapper.h:216]  The tensor_version of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889948 1570317 tensor_wrapper.h:161] Recovered TensorWrapper with GradNode BatchNormGradNode addr: 0x198b7070\r\nI0605 17:05:07.889951 1570317 tensor_wrapper.h:137] Recover tensor: @Saved for wrapper\r\nI0605 17:05:07.889953 1570317 tensor_wrapper.h:213]  The wrapper_version_snapshot of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889956 1570317 tensor_wrapper.h:216]  The tensor_version of Tensor '@Saved' is [ 0 ]\r\nI0605 17:05:07.889959 1570317 tensor_wrapper.h:161] Recovered TensorWrapper with GradNode BatchNormGradNode addr: 0x198b7070\r\nI0605 17:05:07.889963 1570317 nodes.cc:23146] Running C++ API: batch_norm_grad\r\nI0605 17:05:07.890098 1570317 nodes.cc:23181] { Input: [ \r\n( grad_out , [{Name: None, Initialized: 1, Ptr: 0x19838cd0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ None ], StopGradient: [ 0 ] ]}]),  \r\n( x , [{Name: @Saved, Initialized: 1, Ptr: 0x1a0755d0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [2]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1923ac40, ReluGradNode] },  ]SlotID: 1, StopGradients: 0, , Edges[  { [0, 0]: [0x72ed8a0, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( scale , [{Name: batch_norm2d_48.w_0@Saved, Initialized: 1, Ptr: 0x72ed510 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( bias , [{Name: batch_norm2d_48.b_0@Saved, Initialized: 1, Ptr: 0x85cec70 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( out_mean , [{Name: @Saved, Initialized: 1, Ptr: 0x1a19dc90 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( out_variance , [{Name: @Saved, Initialized: 1, Ptr: 0x18621490 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( saved_mean , [{Name: @Saved, Initialized: 1, Ptr: 0x188de050 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( saved_variance , [{Name: @Saved, Initialized: 1, Ptr: 0x19dce0f0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( reserve_space , [{Name: @Saved, Initialized: 0, Ptr: 0x19f979d0 TensorInfo: [ Type: DenseTensor, Dtype: Unknown, Place: Unknown, Shape: Unknown ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ]} \r\nI0605 17:05:07.890122 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:07.890137 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:07.890144 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:07.890151 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:07.890158 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:07.890165 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:07.890172 1570317 backward_api.cc:15475] batch_norm_grad API kernel key: [intel_gpu, NCHW, float32]\r\nI0605 17:05:07.890183 1570317 backward_api.cc:15482] batch_norm_grad kernel: {\"input\":[\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\"],\"output\":[\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\",\"intel_gpu, NCHW, float32\"],\"attribute\":[\"float\",\"float\",\"string\",\"bool\",\"bool\",\"bool\"]}\r\nI0605 17:05:07.890195 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:07.890215 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:07.890220 1570317 data_transform.cc:169] DeviceTransform in, src_place Place(cpu) dst_place: Place(intel_gpu:0)\r\nI0605 17:05:07.890228 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:07.890240 1570317 tensor_utils.cc:50] TensorCopy 512 from Place(cpu) to Place(intel_gpu:0)\r\nI0605 17:05:07.890247 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:07.890251 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:07.890259 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:07.890261 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181febde000\r\nI0605 17:05:07.890275 1570317 tensor_utils.cc:97] src:0x7c1a000, dst:0xffff8181febde000\r\nI0605 17:05:07.890283 1570317 memcpy.cc:66] memory::Copy 2048 Bytes from Place(cpu)(0x7c1a000) to Place(intel_gpu:0)(0xffff8181febde000), stream=0\r\nI0605 17:05:07.890290 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:07.890336 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:07.890345 1570317 runtime.cc:324] sync-stream devid=0\r\nI0605 17:05:07.890355 1570317 runtime.cc:374] memory-copy-h2d dst=0xffff8181febde000 src=0x7c1a000 size=2048\r\nI0605 17:05:07.890707 1570317 runtime.cc:128] get-device() : device->id=0\r\nI0605 17:05:07.890719 1570317 data_transform.cc:169] DeviceTransform in, src_place Place(cpu) dst_place: Place(intel_gpu:0)\r\nI0605 17:05:07.890733 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:07.890744 1570317 tensor_utils.cc:50] TensorCopy 512 from Place(cpu) to Place(intel_gpu:0)\r\nI0605 17:05:07.890753 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:07.890756 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:07.890764 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:07.890769 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0cc000\r\nI0605 17:05:07.890780 1570317 tensor_utils.cc:97] src:0xe650000, dst:0xffff8181ff0cc000\r\nI0605 17:05:07.890790 1570317 memcpy.cc:66] memory::Copy 2048 Bytes from Place(cpu)(0xe650000) to Place(intel_gpu:0)(0xffff8181ff0cc000), stream=0\r\nI0605 17:05:07.890800 1570317 runtime.cc:121] set-device : device->id=0\r\nI0605 17:05:07.890838 1570317 context_pool.cc:62] DeviceContextPool Get: Place(intel_gpu:0)\r\nI0605 17:05:07.890849 1570317 runtime.cc:324] sync-stream devid=0\r\nI0605 17:05:07.890857 1570317 runtime.cc:374] memory-copy-h2d dst=0xffff8181ff0cc000 src=0xe650000 size=2048\r\nI0605 17:05:07.891373 1570317 dense_tensor.cc:139] Allocate data with bytes: 3211264\r\nI0605 17:05:07.891391 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 3211264 bytes, aligned to 3211264\r\nI0605 17:05:07.891400 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 3211264 bytes from chunk size 4194304, remaining 983040\r\nI0605 17:05:07.891409 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 3211264 bytes, ptr = 0xffff81aca4530000\r\nI0605 17:05:07.891424 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:07.891427 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:07.891431 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:07.891434 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0cc800\r\nI0605 17:05:07.891439 1570317 dense_tensor.cc:139] Allocate data with bytes: 2048\r\nI0605 17:05:07.891443 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 2048 bytes, aligned to 2048\r\nI0605 17:05:07.891446 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 2048 bytes from chunk size 2048, remaining 0\r\nI0605 17:05:07.891449 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 2048 bytes, ptr = 0xffff8181ff0ce000\r\nI0605 17:05:07.891551 1570317 dense_tensor.cc:139] Allocate data with bytes: 200832\r\nI0605 17:05:07.891557 1570317 auto_growth_best_fit_allocator.cc:66] Allocate 200832 bytes, aligned to 200832\r\nI0605 17:05:07.891562 1570317 auto_growth_best_fit_allocator.cc:76] Allocate 200832 bytes from chunk size 262144, remaining 61312\r\nI0605 17:05:07.891569 1570317 auto_growth_best_fit_allocator.cc:123] Alloc 200832 bytes, ptr = 0xffff8181febeef80\r\nonednn_verbose,exec,gpu:0,batch_normalization,ocl:ref:any,backward,data_f32::blocked:abcd:f0 diff_f32::blocked:abcd:f0,attr-scratchpad:user ,flags:CH,mb32ic512ih7iw7,0.158936\r\nI0605 17:05:07.891780 1570317 auto_growth_best_fit_allocator.cc:131] Free 200832 bytes, ptr = 0xffff8181febeef80\r\nI0605 17:05:07.891819 1570317 auto_growth_best_fit_allocator.cc:131] Free 2048 bytes, ptr = 0xffff8181ff0cc000\r\nI0605 17:05:07.891827 1570317 auto_growth_best_fit_allocator.cc:131] Free 2048 bytes, ptr = 0xffff8181febde000\r\nI0605 17:05:07.891832 1570317 nodes.cc:23198] Fused api batch_norm_grad is called \r\nI0605 17:05:07.891839 1570317 nodes.cc:23285] Finish AD API GRAD: batch_norm_grad\r\nI0605 17:05:07.892006 1570317 nodes.cc:23329] { Input: [ \r\n( grad_out , [{Name: None, Initialized: 1, Ptr: 0x19838cd0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ None ], StopGradient: [ 0 ] ]}]),  \r\n( x , [{Name: @Saved, Initialized: 1, Ptr: 0x1a0755d0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [2]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1923ac40, ReluGradNode] },  ]SlotID: 1, StopGradients: 0, , Edges[  { [0, 0]: [0x72ed8a0, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( scale , [{Name: batch_norm2d_48.w_0@Saved, Initialized: 1, Ptr: 0x72ed510 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( bias , [{Name: batch_norm2d_48.b_0@Saved, Initialized: 1, Ptr: 0x85cec70 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(cpu), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [1]: SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( out_mean , [{Name: @Saved, Initialized: 1, Ptr: 0x1a19dc90 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( out_variance , [{Name: @Saved, Initialized: 1, Ptr: 0x18621490 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( saved_mean , [{Name: @Saved, Initialized: 1, Ptr: 0x188de050 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( saved_variance , [{Name: @Saved, Initialized: 1, Ptr: 0x19dce0f0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]),  \r\n( reserve_space , [{Name: @Saved, Initialized: 0, Ptr: 0x19f979d0 TensorInfo: [ Type: DenseTensor, Dtype: Unknown, Place: Unknown, Shape: Unknown ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ BackwardOutMeta: [  {SlotSize: [5]: SlotID: 0, StopGradients: 0, , Edges[  { [0, 0]: [0x1a366ff0, Conv2dGradNodeFinal] },  ]SlotID: 1, StopGradients: , Edges[  ]SlotID: 2, StopGradients: , Edges[  ]SlotID: 3, StopGradients: 0, , Edges[  { [0, 0]: [0x85cdae0, GradNodeAccumulation] },  ]SlotID: 4, StopGradients: 0, , Edges[  { [0, 0]: [0x85cf000, GradNodeAccumulation] },  ]}  ], BackwardInMeta: [  {SlotSize: [SlotID: 0, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 1, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 2, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 3, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 4, StopGradients: 0, , Edges[ { NULL Edge } ]SlotID: 5, StopGradients: 0, , Edges[ { NULL Edge } ]]:  ] ], StopGradient: [ 0 ] ]}]), ],  \r\n Output: [ \r\n ( grad_x , [{Name: None, Initialized: 1, Ptr: 0x6f3e3a0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 32, 512, 7, 7 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ None ], StopGradient: [ 0 ] ]}]),  \r\n ( grad_scale , [{Name: None, Initialized: 1, Ptr: 0x1a580460 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ None ], StopGradient: [ 0 ] ]}]),  \r\n ( grad_bias , [{Name: None, Initialized: 1, Ptr: 0x19ad40d0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ None ], StopGradient: [ 0 ] ]}]), ] } \r\nI0605 17:05:07.892024 1570317 backward.cc:283] retain_graph is false, need to clear the TensorWrapper of nodes.\r\nI0605 17:05:07.892030 1570317 auto_growth_best_fit_allocator.cc:131] Free 3211264 bytes, ptr = 0xffff81d5fcaf0000\r\nI0605 17:05:07.892040 1570317 auto_growth_best_fit_allocator.cc:131] Free 2048 bytes, ptr = 0xffff8181ff0ca000\r\nI0605 17:05:07.892047 1570317 auto_growth_best_fit_allocator.cc:131] Free 2048 bytes, ptr = 0xffff8181ff0ca800\r\nI0605 17:05:07.892052 1570317 auto_growth_best_fit_allocator.cc:131] Free 2048 bytes, ptr = 0xffff8181ff0cd000\r\nI0605 17:05:07.892058 1570317 auto_growth_best_fit_allocator.cc:131] Free 2048 bytes, ptr = 0xffff8181ff0cd800\r\nI0605 17:05:07.892067 1570317 backward.cc:312] Node: BatchNormGradNode addr:0x198b7070, Found pending node: Conv2dGradNodeFinal addr: 0x1a366ff0\r\nI0605 17:05:07.892071 1570317 backward.cc:339] Get Edge and grad_output_tensor with slot: 0, rank: 0 's name is: \r\nI0605 17:05:07.892074 1570317 grad_tensor_holder.h:32] Init GradTensorHolder with meta size: 1\r\nI0605 17:05:07.892076 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.892079 1570317 backward.cc:348] Construct GradTensorHolder for grad node: Conv2dGradNodeFinal\r\nI0605 17:05:07.892082 1570317 backward.cc:353] Sum or Move grad inputs for edge slot: 0, rank: 0\r\nI0605 17:05:07.892086 1570317 grad_tensor_holder.cc:132] Move Tensor for buffer_ slot: 0, size: 1\r\nI0605 17:05:07.892091 1570317 backward.cc:363] Conv2dGradNodeFinal ref_cnt is: 0\r\nI0605 17:05:07.892094 1570317 backward.cc:312] Node: BatchNormGradNode addr:0x198b7070, Found pending node: GradNodeAccumulation addr: 0x85cdae0\r\nI0605 17:05:07.892097 1570317 backward.cc:339] Get Edge and grad_output_tensor with slot: 3, rank: 0 's name is: \r\nI0605 17:05:07.892099 1570317 grad_tensor_holder.h:32] Init GradTensorHolder with meta size: 1\r\nI0605 17:05:07.892102 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.892104 1570317 backward.cc:348] Construct GradTensorHolder for grad node: GradNodeAccumulation\r\nI0605 17:05:07.892108 1570317 backward.cc:353] Sum or Move grad inputs for edge slot: 0, rank: 0\r\nI0605 17:05:07.892112 1570317 grad_tensor_holder.cc:132] Move Tensor for buffer_ slot: 0, size: 1\r\nI0605 17:05:07.892113 1570317 backward.cc:363] GradNodeAccumulation ref_cnt is: 0\r\nI0605 17:05:07.892117 1570317 backward.cc:312] Node: BatchNormGradNode addr:0x198b7070, Found pending node: GradNodeAccumulation addr: 0x85cf000\r\nI0605 17:05:07.892119 1570317 backward.cc:339] Get Edge and grad_output_tensor with slot: 4, rank: 0 's name is: \r\nI0605 17:05:07.892122 1570317 grad_tensor_holder.h:32] Init GradTensorHolder with meta size: 1\r\nI0605 17:05:07.892124 1570317 grad_tensor_holder.h:35] Init GradTensorHolder with meta rank: 1\r\nI0605 17:05:07.892127 1570317 backward.cc:348] Construct GradTensorHolder for grad node: GradNodeAccumulation\r\nI0605 17:05:07.892130 1570317 backward.cc:353] Sum or Move grad inputs for edge slot: 0, rank: 0\r\nI0605 17:05:07.892132 1570317 grad_tensor_holder.cc:132] Move Tensor for buffer_ slot: 0, size: 1\r\nI0605 17:05:07.892135 1570317 backward.cc:363] GradNodeAccumulation ref_cnt is: 0\r\nI0605 17:05:07.892140 1570317 auto_growth_best_fit_allocator.cc:131] Free 3211264 bytes, ptr = 0xffff81aca4a30000\r\nI0605 17:05:07.892148 1570317 backward.cc:243] Preparing GradNode:GradNodeAccumulation addr:0x85cf000\r\nI0605 17:05:07.892150 1570317 backward.cc:270] Run Backward Kernel with GradTensorHolder.\r\nI0605 17:05:07.892153 1570317 accumulation_node.cc:103] Running AD API Grad: GradNodeAccumulation\r\nI0605 17:05:07.892158 1570317 accumulation_node.cc:40] Move Tensor ptr: 0x19ad40d0\r\nI0605 17:05:07.892163 1570317 reducer.cc:762] Tensor[146] [batch_norm2d_48.b_0@Grad] arrived and triggered disthook\r\nI0605 17:05:07.892166 1570317 reducer.cc:778] Tensor[146][batch_norm2d_48.b_0] is marked ready.\r\nI0605 17:05:07.892175 1570317 accumulation_node.cc:135] Finish AD API Grad: GradNodeAccumulation\r\nI0605 17:05:07.892191 1570317 accumulation_node.cc:148] { Input: [], Output: [(grad_out, [{Name: None, Initialized: 1, Ptr: 0x19ad40d0 TensorInfo: [ Type: DenseTensor, Dtype: float32, Place: Place(intel_gpu:0), Shape: 512 ], ADInfo:[ Grad: [ {Name: None, Initialized: 0, Ptr: 0 TensorInfo: [ Unknown ], ADInfo:[ None ]} ],  GradNode: [ None ], StopGradient: [ 0 ] ]}]), ] } \r\nI0605 17:05:07.892197 1570317 backward.cc:283] retain_graph is false, need to clear the TensorWrapper of nodes.\r\nI0605 17:05:07.892201 1570317 accumulation_node.h:47] Do nothing here now\r\nI0605 17:05:07.892204 1570317 backward.cc:243] Preparing GradNode:GradNodeAccumulation addr:0x85cdae0\r\nI0605 17:05:07.892207 1570317 backward.cc:270] Run Backward Kernel with GradTensorHolder.\r\nI0605 17:05:07.892210 1570317 accumulation_node.cc:103] Running AD API Grad: GradNodeAccumulation\r\nI0605 17:05:07.892215 1570317 accumulation_node.cc:40] Move Tensor ptr: 0x1a580460\r\nI0605 17:05:07.892218 1570317 reducer.cc:762] Tensor[145] [batch_norm2d_48.w_0@Grad] arrived and triggered disthook\r\nI0605 17:05:07.892221 1570317 reducer.cc:778] Tensor[145][batch_norm2d_48.w_0] is marked ready.\r\nI0605 17:05:07.892226 1570317 reducer.cc:906] Group[0] is ready\r\nI0605 17:05:07.892230 1570317 reducer.cc:1045] group [0] start fused_allreduce.\r\nI0605 17:05:07.892242 1570317 api.cc:24921] empty API kernel key: [CPU, Undefined(AnyLayout), float32]\r\nI0605 17:05:07.892256 1570317 api.cc:24928] empty kernel: {\"input\":[],\"output\":[\"CPU, NCHW, float32\"],\"attribute\":[\"IntArray\",\"DataType\"]}\r\nI0605 17:05:07.892292 1570317 dense_tensor.cc:139] Allocate data with bytes: 30261152\r\nI0605 17:05:07.892329 1570317 context_pool.cc:62] DeviceContextPool Get: Place(cpu)\r\nI0605 17:05:07.892359 1570317 memcpy.cc:743] memory::Copy 2048 Bytes from 0xffff8181ff0cc800(Place(cpu)) to 0x1ab0f000(Place(cpu))\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   egr::Backward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool)\r\n1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)\r\n2   egr::GradNodeAccumulation::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)\r\n3   egr::GradNodeAccumulation::ApplyReduceHooks()\r\n4   paddle::distributed::EagerReducer::MarkVarReady(unsigned long, bool)\r\n5   paddle::distributed::EagerReducer::MarkGroupReady(unsigned long)\r\n6   paddle::distributed::EagerReducer::FusedAllReduceSchedule(paddle::distributed::EagerGroup*, int)\r\n7   paddle::distributed::EagerGroup::ConcatTensors(phi::Place const&)\r\n8   paddle::operators::math::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)\r\n9   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)\r\n10  phi::memory_utils::Copy(phi::Place const&, void*, phi::Place const&, void const*, unsigned long)\r\n11  phi::MemoryUtils::Copy(phi::Place const&, void*, phi::Place const&, void const*, unsigned long)\r\n12  void paddle::memory::Copy<phi::Place, phi::Place>(phi::Place, void*, phi::Place, void const*, unsigned long)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1685955907 (unix time) try \"date -d @1685955907\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0xffff8181ff0cc800) received by PID 1570317 (TID 0x7fa143155740) from PID 18446744073693612032 ***]\r\n\r\n```",
        "state": "closed",
        "user": "yangulei",
        "closed_by": "yangulei",
        "created_at": "2023-06-06T01:34:50+00:00",
        "updated_at": "2023-06-13T07:01:01+00:00",
        "closed_at": "2023-06-13T07:01:00+00:00",
        "comments_count": [
            "yangulei",
            "ronny1996",
            "yangulei",
            "ronny1996",
            "yangulei",
            "yangulei"
        ],
        "labels": [
            "help wanted",
            "intel_gpu"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 603,
        "title": "PaddleCustomDevice和paddlepaddle-npu的区别",
        "body": "我在官网上看到有一个[编译安装昇腾NPU版飞浆框架](https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/guides/hardware_support/npu_docs/paddle_install_cn.html)的文档，请问和这里的PaddleCustomDevice有什么区别？随便挑一种方式安装就行吗？",
        "state": "closed",
        "user": "AspartameJ",
        "closed_by": "AspartameJ",
        "created_at": "2023-06-05T03:21:36+00:00",
        "updated_at": "2023-06-13T08:30:04+00:00",
        "closed_at": "2023-06-13T07:01:00+00:00",
        "comments_count": [
            "parap1uie-s",
            "KimBioInfoStudio",
            "AspartameJ"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 615,
        "title": "The kernel with key (npu, Undefined(AnyLayout), float16) of kernel `silu` is not registered and fail to fallback to CPU one",
        "body": "在Ascend910 npu环境上训练，训练时加载数据后出现以下错误\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/61072437/96d4ff61-133e-4695-9807-5e6ff77191b7)\r\n\r\n\r\n[06/07 17:19:37] ppdet.data.source.coco INFO: Load [100625 samples valid, 0 samples invalid] in file /cache/train.json.\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/train.py\", line 188, in <module>\r\n    main()\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/train.py\", line 184, in main\r\n    run(FLAGS, cfg)\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/train.py\", line 137, in run\r\n    trainer.train(FLAGS.eval)\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/ppdet/engine/trainer.py\", line 414, in train\r\n    outputs = model(data)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-1.15.0/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/ppdet/modeling/architectures/meta_arch.py\", line 59, in forward\r\n    out = self.get_loss()\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/ppdet/modeling/architectures/yolov7.py\", line 95, in get_loss\r\n    return self._forward()\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/ppdet/modeling/architectures/yolov7.py\", line 73, in _forward\r\n    body_feats = self.backbone(self.inputs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-1.15.0/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/ppdet/modeling/backbones/yolov7_elannet.py\", line 592, in forward\r\n    x = self.stem(x)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-1.15.0/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-1.15.0/lib/python3.7/site-packages/paddle/nn/layer/container.py\", line 606, in forward\r\n    input = layer(input)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-1.15.0/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/ma-user/work/01.paddle_npu_20230603/01.PaddleYOLO-release-2.5-init/ppdet/modeling/backbones/csp_darknet.py\", line 87, in forward\r\n    y = self.act(x)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-1.15.0/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1254, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-1.15.0/lib/python3.7/site-packages/paddle/nn/layer/activation.py\", line 1163, in forward\r\n    return F.silu(x, self._name)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-1.15.0/lib/python3.7/site-packages/paddle/nn/functional/activation.py\", line 985, in silu\r\n    return _C_ops.silu(x)\r\nRuntimeError: (NotFound) The kernel with key (npu, Undefined(AnyLayout), float16) of kernel `silu` is not registered and fail to fallback to CPU one. Selected wrong Backend `npu`. Paddle support following Backends: CPU.\r\n  [Hint: Expected kernel_iter != iter->second.end(), but received kernel_iter == iter->second.end().] (at /paddle/paddle/phi/core/kernel_factory.cc:259)",
        "state": "closed",
        "user": "Daniel-deng-yi",
        "closed_by": "YanhuiDua",
        "created_at": "2023-06-07T09:54:36+00:00",
        "updated_at": "2023-06-09T02:20:51+00:00",
        "closed_at": "2023-06-09T02:20:51+00:00",
        "comments_count": [
            "onecatcn",
            "Daniel-deng-yi",
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 619,
        "title": "后端MLU是否支持单机多卡及多机多卡训练？",
        "body": "后端MLU是否支持单机多卡及多机多卡训练？该如何操作，是否有相应的支持文档？",
        "state": "closed",
        "user": "LC-Sunds",
        "closed_by": "ronny1996",
        "created_at": "2023-06-12T01:31:52+00:00",
        "updated_at": "2023-06-25T09:14:39+00:00",
        "closed_at": "2023-06-25T09:14:38+00:00",
        "comments_count": [
            "ronny1996",
            "LC-Sunds",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 661,
        "title": "[MLU] 请问paddlecustomdevice后端分布式训练是否只支持数据并行？",
        "body": "paddlecustomdevice后端分布式训练是否只支持数据并行？是否支持参数服务器的形式进行分布式训练？如果支持参数服务器的形式该如何启动？",
        "state": "closed",
        "user": "DeshuaiSun",
        "closed_by": "qili93",
        "created_at": "2023-07-05T02:22:25+00:00",
        "updated_at": "2024-02-27T07:57:57+00:00",
        "closed_at": "2024-02-27T07:57:56+00:00",
        "comments_count": [
            "ronny1996",
            "DeshuaiSun",
            "ronny1996",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 652,
        "title": "[NPU]编译选项ON_INFER打开后，用例执行失败",
        "body": "参考如下材料准备环境，编译前设置全局变量export ON_INFER=ON：\r\nhttps://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md\r\n\r\n问题一  找不到符号_ZN3fLB15FLAGS_set_to_1dE：\r\n(py37env) λ ascend /home/code/PaddleCustomDevice/backends/npu {develop} python3 tests/unittests/test_custom_pass_npu.py\r\nI0628 18:17:59.323984 44207 init.cc:239] ENV [CUSTOM_DEVICE_ROOT]=/home/code/PaddleCustomDevice/backends/npu/build\r\nI0628 18:17:59.324012 44207 init.cc:145] Try loading custom device libs from: [/home/code/PaddleCustomDevice/backends/npu/build]\r\nTraceback (most recent call last):\r\n  File \"tests/unittests/test_custom_pass_npu.py\", line 20, in <module>\r\n    import paddle\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/__init__.py\", line 31, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/framework/random.py\", line 17, in <module>\r\n    from paddle import fluid\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/fluid/__init__.py\", line 211, in <module>\r\n    __bootstrap__()\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/fluid/__init__.py\", line 203, in __bootstrap__\r\n    core.init_devices()\r\nValueError: (InvalidArgument) Fail to open library: /home/code/PaddleCustomDevice/backends/npu/build/libpaddle-custom-npu.so with error: /home/code/PaddleCustomDevice/backends/npu/build/libpaddle-custom-npu.so: undefined symbol: _ZN3fLB15FLAGS_set_to_1dE\r\n  [Hint: dso_handle should not be null.] (at /home/code/Paddle/paddle/fluid/platform/init.cc:152)\r\n\r\n问题二 规避问题一后：\r\n(py37env) λ ascend /home/code/PaddleCustomDevice/backends/npu {develop} python3 tests/unittests/test_custom_pass_npu.py\r\nI0628 18:22:27.276496 45602 init.cc:239] ENV [CUSTOM_DEVICE_ROOT]=/home/code/PaddleCustomDevice/backends/npu/build\r\nI0628 18:22:27.276530 45602 init.cc:145] Try loading custom device libs from: [/home/code/PaddleCustomDevice/backends/npu/build]\r\nI0628 18:22:27.876804 45602 custom_device.cc:1115] Successed in loading custom runtime in lib: /home/code/PaddleCustomDevice/backends/npu/build/libpaddle-custom-npu.so\r\nI0628 18:22:27.887941 45602 custom_kernel.cc:76] Successed in loading 316 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0628 18:22:27.888248 45602 init.cc:157] Finished in LoadCustomDevice with libs_path: [/home/code/PaddleCustomDevice/backends/npu/build]\r\nI0628 18:22:27.888275 45602 init.cc:245] CustomDevice: npu, visible devices count: 1\r\n/opt/py37env/lib/python3.7/site-packages/paddle/jit/api.py:945: UserWarning: What you save is a function, and `jit.save` will generate the name of the model file according to `path` you specify. When loading these files with `jit.load`, you get a `TranslatedLayer` whose inference result is the same as the inference result of the function you saved.\r\n  'What you save is a function, and `jit.save` will generate the name of the model file according to `path` you specify. When loading these files with `jit.load`, you get a `TranslatedLayer` whose inference result is the same as the inference result of the function you saved.'\r\n/opt/py37env/lib/python3.7/site-packages/paddle/static/io.py:994: UserWarning: no variable in your model, please ensure there are any variables in your model to save\r\n  \"no variable in your model, please ensure there are any variables in your model to save\"\r\n['generate_add_n']\r\nI0628 18:22:28.240198 45602 analysis_predictor.cc:1502] CustomDevice is enabled\r\n--- Running analysis [ir_graph_build_pass]\r\nI0628 18:22:28.240448 45602 executor.cc:187] Old Executor is Running.\r\nWARNING: Logging before InitGoogleLogging() is written to STDERR\r\nI0628 18:22:28.240542 45602 allocator_facade.cc:331] GetAllocator Place(cpu) 1\r\nI0628 18:22:28.240576 45602 allocator_facade.cc:331] GetAllocator Place(cpu) 1\r\nI0628 18:22:28.240581 45602 allocator_facade.cc:331] GetAllocator Place(cpu) 0\r\nI0628 18:22:28.240588 45602 allocator_facade.cc:331] GetAllocator Place(cpu) 0\r\n--- Running analysis [ir_analysis_pass]\r\n--- Running IR pass [generate_add_n]\r\nI0628 18:22:28.244626 45602 ir_analysis_pass.cc:46] argument has no fuse statis\r\n--- Running analysis [save_optimized_model_pass]\r\nW0628 18:22:28.244675 45602 save_optimized_model_pass.cc:28] save_optim_cache_model is turned off, skip save_optimized_model_pass\r\n--- Running analysis [ir_params_sync_among_devices_pass]\r\nI0628 18:22:28.244690 45602 ir_params_sync_among_devices_pass.cc:142] Sync params from CPU to npu:0\r\n--- Running analysis [adjust_cudnn_workspace_size_pass]\r\n--- Running analysis [inference_op_replace_pass]\r\n--- Running analysis [memory_optimize_pass]\r\nI0628 18:22:28.244761 45602 memory_optimize_pass.cc:118] The persistable params in main graph are : 0MB\r\nI0628 18:22:28.244805 45602 memory_optimize_pass.cc:246] Cluster name : y  size: 128\r\nI0628 18:22:28.244812 45602 memory_optimize_pass.cc:246] Cluster name : x  size: 128\r\nI0628 18:22:28.244814 45602 memory_optimize_pass.cc:246] Cluster name : z  size: 128\r\n--- Running analysis [ir_graph_to_program_pass]\r\nI0628 18:22:28.245867 45602 analysis_predictor.cc:1676] ======= optimize end =======\r\nI0628 18:22:28.245908 45602 naive_executor.cc:167] ---  skip [feed], feed -> z\r\nI0628 18:22:28.245914 45602 naive_executor.cc:167] ---  skip [feed], feed -> y\r\nI0628 18:22:28.245918 45602 naive_executor.cc:167] ---  skip [feed], feed -> x\r\nI0628 18:22:28.245944 45602 naive_executor.cc:167] ---  skip [tmp_1], fetch -> fetch\r\n\r\nE\r\n======================================================================\r\n\r\nERROR: test_my_add_n (__main__.TestCustomPass)\r\n\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"tests/unittests/test_custom_pass_npu.py\", line 77, in test_my_add_n\r\n    input_tensor.copy_from_cpu(np_inputs[i])\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/inference/wrapper.py\", line 46, in tensor_copy_from_cpu\r\n    self._copy_from_cpu_bind(data)\r\nRuntimeError: (NotFound) No allocator found for the place, Place(npu:0)\r\n  [Hint: Expected iter != allocators.end(), but received iter == allocators.end().] (at /home/code/Paddle/paddle/fluid/memory/allocation/allocator_facade.cc:338)\r\n\r\n\r\n----------------------------------------------------------------------\r\nRan 1 test in 0.086s\r\n\r\nFAILED (errors=1)\r\n",
        "state": "closed",
        "user": "MyAngelAyase",
        "closed_by": "qili93",
        "created_at": "2023-06-28T10:17:54+00:00",
        "updated_at": "2024-02-05T08:54:37+00:00",
        "closed_at": "2024-02-05T08:54:37+00:00",
        "comments_count": [
            "ronny1996",
            "MyAngelAyase",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 670,
        "title": "[intel_gpu] mem leak when runing RN50",
        "body": "we use GLOG_v=10 to run RN50 and found that paddle always allocate mem but w/o deallocate mem when lead out of mem\r\n\r\nRN50: https://github.com/PaddlePaddle/PaddleClas/tree/f820473d1d4d5174e57a5a6b08a42f672eb13390\r\ncmd: `python ./PaddleClas/tools/train.py -c ./PaddleClas/ppcls/configs/ImageNet/ResNet/ResNet50.yaml`",
        "state": "closed",
        "user": "KimBioInfoStudio",
        "closed_by": "KimBioInfoStudio",
        "created_at": "2023-07-07T08:10:08+00:00",
        "updated_at": "2024-05-23T02:53:34+00:00",
        "closed_at": "2024-05-23T02:47:49+00:00",
        "comments_count": [
            "ronny1996",
            "KimBioInfoStudio",
            "ronny1996",
            "KimBioInfoStudio",
            "ronny1996",
            "KimBioInfoStudio",
            "KimBioInfoStudio",
            "qili93",
            "KimBioInfoStudio"
        ],
        "labels": [
            "intel_gpu"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 687,
        "title": "[NPU]paddledetection 测试占用npu的hbm显存，但是不占用npu核，ips特别低",
        "body": "<img width=\"492\" alt=\"26b3bebbb69f35014beca2a1b2a675b\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/9717930/5198acfc-6015-4298-9ffc-0c90e14d174a\">\r\n\r\n编译好的paddle-aarch64 + paddle-npu 安装成功了，示例能跑通npu的训练，\r\n但是使用paddleDetectionv2.6.0的  python -u tools/train.py -c configs/yolov3/yolov3_darknet5_270e_roadsign.yml ，\r\n修改了配置文件：\r\nruntime.yml\r\nuse_gpu: false\r\nuse_xpu: false\r\nuse_mlu: false\r\nuse_npu: true\r\nlog_iter: 1\r\n现象是：占用npu的hbm显存，但是不占用npu核，ips特别低，单位时间处理的图片数0.0几，\r\n\r\n看过昇腾npu的官方示例是支持yolo的，测试过昇腾torch的可以使用npu跑yolo的，求助，谁能告诉下啥原因导致的npu核没有使用，怎么修改才能支持使用npu核参与训练啊\r\n",
        "state": "closed",
        "user": "535205856",
        "closed_by": "YanhuiDua",
        "created_at": "2023-07-13T08:49:23+00:00",
        "updated_at": "2023-07-19T11:26:04+00:00",
        "closed_at": "2023-07-19T11:26:04+00:00",
        "comments_count": [
            "535205856",
            "ronny1996",
            "535205856",
            "535205856"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 690,
        "title": "[NPU]PaddleSeg示例训练报错 OSError: (External)  ACL error, the error code is : 500002",
        "body": "编译好的paddle-aarch64 + paddle-npu 安装成功了，示例能跑通npu的训练，\r\n但是使用 python tools/train.py        --config configs/quick_start/bisene_optic_disc_512x512_1k.yml        --save_interval 5000        --save_dir output    --device npu\r\n\r\n现象是：\r\n卡住很久\r\n之后报错\r\n\r\n<img width=\"425\" alt=\"46faac1c049feede3f7b3ef3fd88717\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/9717930/18d543d4-39f3-4cca-aab2-6d635786d5e9\">\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/9717930/b524f976-deef-432a-8612-2cc79ef8cdb1)\r\n\r\n进入model(images) 时卡住的\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 269, in <module>\r\n    main(args)\r\n  File \"tools/train.py\", line 264, in main\r\n    to_static_training=cfg.to_static_training)\r\n  File \"/workspace/PaddleSeg/paddleseg/core/train.py\", line 214, in train\r\n    loss.backward()\r\n  File \"/opt/py37env/lib/python3.7/site-packages/decorator.py\", line 232, in fun\r\n    return caller(func, *(extras + args), **kw)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\r\n    return wrapped_func(*args, **kwargs)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 449, in __impl__\r\n    return func(*args, **kwargs)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/fluid/dygraph/tensor_patch_methods.py\", line 298, in backward\r\n    core.eager.run_backward([self], grad_tensor, retain_graph)\r\nOSError: (External)  ACL error, the error code is : 500002.  (at /workspace/PaddleCustomDevice/backends/npu/kernels/funcs/npu_op_runner.cc:619)\r\n\r\n\r\n\r\n宿主机机器环境是 昇腾910npu + 鲲鹏920 arm cpu 的 ubuntu 环境\r\n镜像使用是npu文档中的镜像 registry.baidubce.com/device/paddle-npu:cann601-ubuntu18-aarch64-gcc82\r\nPaddleSeg版本使用的是V2.7.0, Paddle使用的是develop分支编译的whl安装包安装的\r\n\r\n",
        "state": "closed",
        "user": "535205856",
        "closed_by": "YanhuiDua",
        "created_at": "2023-07-14T04:53:38+00:00",
        "updated_at": "2023-07-19T10:55:09+00:00",
        "closed_at": "2023-07-19T10:55:09+00:00",
        "comments_count": [
            "ronny1996",
            "YanhuiDua",
            "535205856",
            "535205856",
            "YanhuiDua",
            "535205856",
            "YanhuiDua",
            "535205856",
            "YanhuiDua",
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 694,
        "title": "[NPU] 单机多卡分布式训练提示RuntimeError: (NotFound) The kernel `sync_batch_norm` is not registered.",
        "body": "单机多卡报错\r\npython -m paddle.distributed.fleet.launch --run_mode=collective --npus=\"4,5,6,7\"  tools/train.py -c configs/yolov3/yolov3_darknet53_270e_roadsign.yml  -o use_npu=True\r\n\r\n单机单卡可以训练\r\n\r\n------------------------------------\r\n宿主机机器环境是 昇腾910npu + 鲲鹏920 arm cpu 的 ubuntu 环境\r\n镜像使用是npu文档中的镜像 registry.baidubce.com/device/paddle-npu:cann601-ubuntu18-aarch64-gcc82\r\n------------------------------------\r\n训练异常报错，\r\n\r\nTraceback (most recent call last):\r\n  File \"tools/train.py\", line 205, in <module>\r\n    main()\r\n  File \"tools/train.py\", line 201, in main\r\n    run(FLAGS, cfg)\r\n  File \"tools/train.py\", line 151, in run\r\n    trainer.train(FLAGS.eval)\r\n  File \"/workspace/PaddleDetection/ppdet/engine/trainer.py\", line 539, in train\r\n    outputs = model(data)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1253, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/distributed/parallel.py\", line 534, in forward\r\n    outputs = self._layers(*inputs, **kwargs)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1253, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/workspace/PaddleDetection/ppdet/modeling/architectures/meta_arch.py\", line 60, in forward\r\n    out = self.get_loss()\r\n  File \"/workspace/PaddleDetection/ppdet/modeling/architectures/yolo.py\", line 147, in get_loss\r\n    return self._forward()\r\n  File \"/workspace/PaddleDetection/ppdet/modeling/architectures/yolo.py\", line 81, in _forward\r\n    body_feats = self.backbone(self.inputs)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1253, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/workspace/PaddleDetection/ppdet/modeling/backbones/darknet.py\", line 330, in forward\r\n    out = self.conv0(x)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1253, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/workspace/PaddleDetection/ppdet/modeling/backbones/darknet.py\", line 77, in forward\r\n    out = self.batch_norm(out)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/nn/layer/layers.py\", line 1253, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/opt/py37env/lib/python3.7/site-packages/paddle/nn/layer/norm.py\", line 1557, in forward\r\n    False,\r\nRuntimeError: (NotFound) The kernel `sync_batch_norm` is not registered.\r\n  [Hint: Expected iter != kernels_.end(), but received iter == kernels_.end().] (at /paddle/paddle/phi/core/kernel_factory.cc:219)\r\n",
        "state": "closed",
        "user": "535205856",
        "closed_by": "YanhuiDua",
        "created_at": "2023-07-17T07:38:02+00:00",
        "updated_at": "2023-07-19T11:19:24+00:00",
        "closed_at": "2023-07-19T11:19:24+00:00",
        "comments_count": [
            "YanhuiDua",
            "535205856",
            "YanhuiDua",
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 706,
        "title": "[NPU] PaddleDetection的ppyolo_r50d_dcn网络模型训练半截报错退出",
        "body": "宿主机机器环境是 昇腾910npu + 鲲鹏920 arm cpu 的 ubuntu 环境\r\n镜像使用是npu文档中的镜像 registry.baidubce.com/device/paddle-npu:cann601-ubuntu18-aarch64-gcc82\r\npaddleDetection用的v2.6.0版本\r\n\r\n网络模型用的 ppyolo_r50d_dcn\r\n数据集用的 roadsign\r\n\r\npython tools/train.py -c configs/ppyolo/ppyolo_r50d_dcn_roadsign.yml -o use_npu=True\r\n\r\n训练半截报错\r\n\r\n--------------------------------------分割线   训练窗口的报错日志\r\n[07/20 21:41:52] ppdet.engine INFO: Epoch: [1] [19/58] learning_rate: 0.000064 loss_xy: 1.350998 loss_wh: 5.382170 loss_iou: 5.030044 loss_iou_aware: 0.926509 loss_obj: 4009.031738 loss_cls: 4.006392 loss: 4025.727783 eta: 45 days, 12:14:19 batch_cost: 0.6057 data_cost: 0.0006 ips: 19.8111 images/s\r\n[07/20 21:42:33] ppdet.engine INFO: Epoch: [1] [20/58] learning_rate: 0.000065 loss_xy: 3.250648 loss_wh: nan loss_iou: 7.106074 loss_iou_aware: nan loss_obj: nan loss_cls: nan loss: nan eta: 44 days, 22:28:24 batch_cost: 0.7804 data_cost: 0.0005 ips: 15.3774 images/s\r\nCall aclrtSynchronizeStream(reinterpret_cast<aclrtStream>(stream)) failed : 507015 at file /workspace/PaddleCustomDevice/backends/npu/runtime/runtime.cc line 408\r\nE10404: Output indexed [0] requires a 18446744073709551615 buffer, but 589856 (aligned) are allocated.\r\n        Solution: Check whether the data type, dimensions, and shape are correctly set. For details, see the aclGetTensorDescSize API description in AscendCL API Reference.\r\n        TraceBack (most recent call last):\r\n        [Exec][Op]Execute op failed. ge result = 145000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]\r\n        Output indexed [0] requires a 18446744073709551615 buffer, but 36896 (aligned) are allocated.\r\n        Output indexed [0] requires a 18446744073709551615 buffer, but 147488 (aligned) are allocated.\r\n        Output indexed [0] requires a 18446744073709551615 buffer, but 278816 (aligned) are allocated.\r\n        Output indexed [0] requires a 18446744073709551615 buffer, but 17472 (aligned) are allocated.\r\n\r\n\r\n\r\n\r\n----------------------------------------分割线   cann 错误日志\r\n[ERROR] ASCENDCL(1082179,python):2023-07-20-21:43:13.555.217 [stream.cpp:104]1082179 aclrtSynchronizeStream: [FINAL][FINAL]synchronize stream failed, runtime result = 507015\r\n[ERROR] RUNTIME(1082179,python):2023-07-20-21:43:13.561.365 [device_msg_handler.cc:156]1082179 HandleMsgInHostBuf:[FINAL][FINAL]\r\nDEVICE[0] PID[1082179]:\r\nEXCEPTION STREAM:\r\n  Exception info:TGID=1421543, model id=65535, stream id=2, stream phase=3\r\n  Message info[0]:stream sq's task full(1024), head=714 tail=713 pid=1421543\r\n    Other info[0]:time=2023-07-20-11:11:46.148.823, function=put_sq_cmd_to_stream_sq, line=1710, error code=0x94\r\nEXCEPTION STREAM:\r\n  Exception info:TGID=1421543, model id=65535, stream id=2, stream phase=3\r\n  Message info[0]:stream sq's task full(1024), head=714 tail=713 pid=1421543\r\n    Other info[0]:time=2023-07-2\r\n[ERROR] RUNTIME(1082179,python):2023-07-20-21:43:13.561.374 [device_msg_handler.cc:156]1082179 HandleMsgInHostBuf:[FINAL][FINAL]0-11:11:46.148.857, function=put_sq_cmd_to_stream_sq, line=1710, error code=0x94\r\nEXCEPTION STREAM:\r\n  Exception info:TGID=1421543, model id=65535, stream id=2, stream phase=3\r\n  Message info[0]:stream sq's task full(1024), head=714 tail=713 pid=1421543\r\n    Other info[0]:time=2023-07-20-11:11:46.148.867, function=put_sq_cmd_to_stream_sq, line=1710, error code=0x94\r\nEXCEPTION STREAM:\r\n  Exception info:TGID=1421543, model id=65535, stream id=2, stream phase=3\r\n  Message info[0]:stream sq's task full(1024), head=7",
        "state": "closed",
        "user": "535205856",
        "closed_by": "qili93",
        "created_at": "2023-07-21T01:53:36+00:00",
        "updated_at": "2024-06-07T06:18:06+00:00",
        "closed_at": "2024-06-07T06:18:06+00:00",
        "comments_count": [
            "YanhuiDua",
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 717,
        "title": "[BUG] nearest interpolate 单测 bug",
        "body": "1. TestNearestInterpOp_attr_tensor\r\n<img width=\"754\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/31957460/b7e9db3a-52c3-4ed9-810e-58aff1ac067c\">\r\n\r\n432-433行会覆盖`self.init_test_case()`中变量\r\n\r\n2. TestNearestInterpOp\r\n<img width=\"646\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/31957460/04a8bf61-1308-4f9a-8854-f764e601b8b7\">\r\n\r\n167行会覆盖`self.init_test_case()`中变量\r\n\r\n关联PR：https://github.com/PaddlePaddle/PaddleCustomDevice/pull/716",
        "state": "closed",
        "user": "BeingGod",
        "closed_by": "YanhuiDua",
        "created_at": "2023-07-24T09:40:39+00:00",
        "updated_at": "2023-07-25T06:50:17+00:00",
        "closed_at": "2023-07-25T06:50:17+00:00",
        "comments_count": [
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 718,
        "title": "【NPU】【Pass】split算子的输出是多个的情况下怎么得到每个输出？",
        "body": "# 问题\r\n在写pass 匹配split 算子的时候，split算子有多个输出，怎么得到每个输出？比如下图的网络：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/22309864/186b61f4-30a4-4b6b-8dfb-279c65efc8bc)\r\n\r\n# 我目前的尝试\r\n```python \r\ndef pattern(reshape_result):\r\n    split_op = ir.PassDesc.OP.split\r\n    split_op.SetAttr(\"num\", 3)\r\n    split_op.SetOutputs(\"Out\", paddle.Tensor(shape=[3, None, None, None, None]))  # 这里报错\r\n    split_result = split_op(X=reshape_result)._outputs[\"Out\"]\r\n    \r\n    print(f\"split_result type = {type(split_result)}\")\r\n    print(f\"split result = {(split_result)}\")\r\n    q, k, v = split_result[0], split_result[1], split_result[2]  # 想拿到q , k , v \r\n```",
        "state": "closed",
        "user": "linboyang",
        "closed_by": "linboyang",
        "created_at": "2023-07-24T12:13:48+00:00",
        "updated_at": "2023-08-09T08:25:20+00:00",
        "closed_at": "2023-08-09T08:25:20+00:00",
        "comments_count": [
            "linboyang",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 724,
        "title": "[NPU][Pass] 同样的网络结构，如果加入了while算子，那么Patter函数就匹配不上了",
        "body": "## 问题：\r\n1. 同样的网络结构，加上while算子之后，pattern没匹配上\r\n2. while 算子内部的结构也未匹配上。\r\n## 复现的代码如下：\r\n```python\r\nimport paddle\r\nimport numpy as np\r\nfrom paddle.incubate.passes import ir\r\n\r\n@paddle.incubate.passes.ir.RegisterPass\r\ndef generate_add_n():\r\n    def pattern(x, y, cache):\r\n        cached_y = ir.PassDesc.OP.concat(X=[cache, y])\r\n        matmul_result = ir.PassDesc.OP.matmul_v2(X=x, Y=cached_y)   \r\n        return matmul_result, cached_y  # 代码更新\r\n\r\n    def replace(x, y, cache):\r\n        return paddle.incubate.passes.ir.PassDesc.OP.my_add_n(X=x, Y=y, Z=cache)\r\n    return pattern, replace\r\n\r\n@paddle.jit.to_static(input_spec=[paddle.static.InputSpec([2, 2], 'float32', 'x'),  paddle.static.InputSpec([2, 2], 'float32', 'y'), paddle.static.InputSpec([1, 1], 'int32', 'loop_cnt')])\r\ndef func(x, y, loop_cnt):\r\n    \r\n    cache_ = paddle.to_tensor([[1.0, 2.0],[1.0, 2.0]], dtype=\"float32\")\r\n    y = paddle.tensor.concat([cache_, y], axis=-1)\r\n    result = paddle.matmul(x, y)\r\n\r\n    i = paddle.to_tensor([0], dtype=\"int32\")\r\n    while i < paddle.squeeze(loop_cnt, 1):\r\n        if cache_ is not None:\r\n            y = paddle.tensor.concat([cache_, y], axis=-1)\r\n        result = paddle.matmul(x, y)\r\n        # cache_ = paddle.assign(y)\r\n        cache_ = y\r\n        paddle.increment(i)\r\n    return result\r\n\r\n# 如果使用如下函数，那么pass可以匹配。\r\n@paddle.jit.to_static(input_spec=[paddle.static.InputSpec([2, 2], 'float32', 'x'),  paddle.static.InputSpec([2, 2], 'float32', 'y')])\r\ndef func_without_while(x, y):\r\n    cache_ = paddle.to_tensor([[1.0, 2.0],[1.0, 2.0]], dtype=\"float32\")\r\n    y = paddle.tensor.concat([cache_, y], axis=-1)\r\n    result = paddle.matmul(x, y)\r\n    return result\r\n\r\npaddle.utils.cpp_extension.extension_utils.load_op_meta_info_and_register_op('/opt/py37env/lib/python3.7/site-packages/paddle_custom_device/libpaddle-custom-npu.so')\r\nprint(func.concrete_program.main_program)\r\nmodel_file = './saved_models/func'\r\npaddle.jit.save(func, model_file)\r\n\r\n# inference\r\nconfig = paddle.inference.Config()\r\nconfig.set_prog_file(model_file + '.pdmodel')\r\nconfig.enable_custom_device('npu')\r\nconfig.enable_memory_optim()\r\npass_builder = config.pass_builder()\r\npass_builder.append_pass('generate_add_n')\r\npaddle.fluid.core.register_subgraph_pass(\"generate_add_n\")\r\npass_builder.turn_on_debug()\r\n\r\nprint(pass_builder.all_passes())\r\npredictor = paddle.inference.create_predictor(config)\r\nnp_inputs = [\r\n            np.ones((2, 2)).astype(\"float32\"),\r\n            np.ones((2, 2)).astype(\"float32\"),\r\n            np.ones((1, 1)).astype(\"int32\"),\r\n        ]\r\ninput_names = predictor.get_input_names()\r\nfor i, name in enumerate(input_names):\r\n    input_tensor = predictor.get_input_handle(name)\r\n    input_tensor.copy_from_cpu(np_inputs[i])\r\n# input_names = predictor.get_input_names()\r\n# for i, name in enumerate(input_names):\r\n#     input_tensor = predictor.get_input_handle(name)\r\n#     input_tensor.copy_from_cpu(np.random.randn(2, 2).astype('float32'))\r\n\r\npredictor.run()\r\nresults = []\r\noutput_names = predictor.get_output_names()\r\nfor i, name in enumerate(output_names):\r\n    output_tensor = predictor.get_output_handle(name)\r\n    output_data = output_tensor.copy_to_cpu()\r\n    results.append(output_data)\r\nprint(results)\r\n```",
        "state": "closed",
        "user": "linboyang",
        "closed_by": "linboyang",
        "created_at": "2023-07-25T15:00:29+00:00",
        "updated_at": "2023-08-09T08:28:15+00:00",
        "closed_at": "2023-08-09T08:28:15+00:00",
        "comments_count": [
            "linboyang",
            "linboyang",
            "ronny1996",
            "linboyang",
            "linboyang",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 731,
        "title": "[NPU] [CustomOp] 请问自定义OP有多个输出的情况下，怎么拿到多个输出？",
        "body": "## 如题。cpp代码为定义的OP，python 为测试文件\r\n```cpp\r\n\r\n#include <iostream>\r\n#include <vector>\r\n\r\n#include \"kernels/funcs/npu_op_runner.h\"\r\n#include \"paddle/extension.h\"\r\n\r\nstd::vector<paddle::Tensor> MyAddNThreeOutOp(const paddle::Tensor& x,\r\n                                     const paddle::Tensor& y,\r\n                                     const paddle::Tensor& q,\r\n                                     const paddle::Tensor& k) {\r\n  std::cout << \"in MyAddNThreeOutOp\" << std::endl;\r\n  auto dev_ctx = static_cast<const phi::CustomContext*>(\r\n      paddle::experimental::DeviceContextPool::Instance().Get(x.place()));\r\n  auto stream = static_cast<aclrtStream>(dev_ctx->stream());\r\n\r\n  auto x_tensor = static_cast<const phi::DenseTensor*>(x.impl().get());\r\n  auto y_tensor = static_cast<const phi::DenseTensor*>(y.impl().get());\r\n  auto q_tensor = static_cast<const phi::DenseTensor*>(q.impl().get());\r\n  auto k_tensor = static_cast<const phi::DenseTensor*>(k.impl().get());\r\n\r\n\r\n  std::shared_ptr<phi::DenseTensor> out1_tensor =\r\n      std::make_shared<phi::DenseTensor>();\r\n  out1_tensor->Resize(x_tensor->dims());\r\n  dev_ctx->Alloc(out1_tensor.get(), x_tensor->dtype());\r\n\r\n  std::shared_ptr<phi::DenseTensor> out2_tensor =\r\n      std::make_shared<phi::DenseTensor>();\r\n  out2_tensor->Resize(x_tensor->dims());\r\n  dev_ctx->Alloc(out2_tensor.get(), x_tensor->dtype());\r\n\r\n  std::shared_ptr<phi::DenseTensor> out3_tensor =\r\n      std::make_shared<phi::DenseTensor>();\r\n  out3_tensor->Resize(x_tensor->dims());\r\n  dev_ctx->Alloc(out3_tensor.get(), x_tensor->dtype());\r\n\r\n  const auto& add_runner1 =\r\n      NpuOpRunner(\"Add\", {*x_tensor, *y_tensor}, {*out1_tensor}, {});\r\n  add_runner1.Run(stream);\r\n  const auto& add_runner2 =\r\n      NpuOpRunner(\"Add\", {*q_tensor, *k_tensor}, {*out2_tensor}, {});\r\n  add_runner2.Run(stream);\r\n\r\n  const auto& add_runner3 =\r\n      NpuOpRunner(\"Add\", {*q_tensor, *x_tensor}, {*out3_tensor}, {});\r\n  add_runner3.Run(stream);\r\n\r\n  return {paddle::Tensor(out1_tensor), paddle::Tensor(out2_tensor), paddle::Tensor(out3_tensor)};\r\n}\r\n\r\nstd::vector<std::vector<int64_t>> MyAddNThreeOutOpInferShape(\r\n    const std::vector<int64_t>& x_shape,\r\n    const std::vector<int64_t>& y_shape,\r\n    const std::vector<int64_t>& q_shape,\r\n    const std::vector<int64_t>& k_shape) {\r\n  return {x_shape};\r\n}\r\n\r\nPD_BUILD_OP(my_add_n_three_out)\r\n    .Inputs({\"X\", \"Y\", \"Q\", \"K\"})\r\n    .Outputs({\"Out1\", \"Out2\", \"Out3\"})\r\n    .SetKernelFn(PD_KERNEL(MyAddNThreeOutOp))\r\n    .SetInferShapeFn(PD_INFER_SHAPE(\r\n        MyAddNThreeOutOpInferShape));  // neccessary if the op has muti_inputs\r\n\r\n```\r\n## 测试文件为：\r\n```python\r\nimport paddle \r\nimport paddle.nn as nn\r\nimport numpy as np\r\n\r\nfrom paddle.incubate.passes import ir\r\n\r\n\r\n@paddle.incubate.passes.ir.RegisterPass\r\ndef gen_fuse_res_add():\r\n    def pattern(x, y, q, k):\r\n        #resadd\r\n        out1, out2, out3 = ir.PassDesc.OP.my_add_n_three_out(X=x, Y=y, Q=q, K=k)\r\n        return out1, out2, out3\r\n\r\n    def replace(x, y, q, k):\r\n        out1 = ir.PassDesc.OP.my_add_n(X=x, Y=y, Z=y)\r\n        out2 = ir.PassDesc.OP.my_add_n(X=out1, Y=y, Z=y)\r\n        return out1, out2, out_2\r\n\r\n    return pattern, replace\r\n\r\n\r\n@paddle.jit.to_static(input_spec=[paddle.static.InputSpec([2, 2], 'float32', 'x'),  paddle.static.InputSpec([2, 2], 'float32', 'y'), \r\n                        paddle.static.InputSpec([2, 2], 'float32', 'q'), paddle.static.InputSpec([2, 2], 'float32', 'k')])\r\ndef func(x, y, q, k):\r\n    ou1, out2, out3 = ir.PassDesc.OP.my_add_n_three_out(X=x, Y=y, Q=q, K=k)  # 这里想拿到out1 2 3\r\n    return out1, out2, out3\r\n\r\npaddle.utils.cpp_extension.extension_utils.load_op_meta_info_and_register_op('/opt/py37env/lib/python3.7/site-packages/paddle_custom_device/libpaddle-custom-npu.so')\r\nprint(func.concrete_program.main_program)\r\nmodel_file = './saved_models/func'\r\npaddle.jit.save(func, model_file)\r\n\r\n# inference\r\nconfig = paddle.inference.Config()\r\nconfig.set_prog_file(model_file + '.pdmodel')\r\nconfig.enable_custom_device('npu')\r\nconfig.enable_memory_optim()\r\npass_builder = config.pass_builder()\r\npass_builder.append_pass('gen_fuse_res_add')\r\npaddle.fluid.core.register_subgraph_pass(\"gen_fuse_res_add\")\r\npass_builder.turn_on_debug()\r\n\r\nprint(pass_builder.all_passes())\r\npredictor = paddle.inference.create_predictor(config)\r\nnp_inputs = [\r\n            np.ones((2, 2)).astype(\"float32\"),\r\n            np.ones((2, 2)).astype(\"float32\"),\r\n        ]\r\ninput_names = predictor.get_input_names()\r\nfor i, name in enumerate(input_names):\r\n    input_tensor = predictor.get_input_handle(name)\r\n    input_tensor.copy_from_cpu(np_inputs[i])\r\n# input_names = predictor.get_input_names()\r\n# for i, name in enumerate(input_names):\r\n#     input_tensor = predictor.get_input_handle(name)\r\n#     input_tensor.copy_from_cpu(np.random.randn(2, 2).astype('float32'))\r\n\r\npredictor.run()\r\nresults = []\r\noutput_names = predictor.get_output_names()\r\nfor i, name in enumerate(output_names):\r\n    output_tensor = predictor.get_output_handle(name)\r\n    output_data = output_tensor.copy_to_cpu()\r\n    results.append(output_data)\r\nprint(results)\r\n```\r\n## 运行测试文件的报错：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/22309864/6ffe8786-41ae-4ac1-9051-7d4ca41e9c42)\r\n\r\n",
        "state": "closed",
        "user": "linboyang",
        "closed_by": "linboyang",
        "created_at": "2023-07-27T08:38:29+00:00",
        "updated_at": "2023-08-09T08:28:48+00:00",
        "closed_at": "2023-08-09T08:28:47+00:00",
        "comments_count": [
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 733,
        "title": "build failed on pybind11 patch step",
        "body": "```\r\nerror: pathspec 'v2.10.3' did not match any file(s) known to git\r\ngmake[2]: *** [CMakeFiles/extern_pybind.dir/build.make:116: third_party/pybind/src/extern_pybind-stamp/extern_pybind-patch] Error 1\r\ngmake[1]: *** [CMakeFiles/Makefile2:149: CMakeFiles/extern_pybind.dir/all] Error 2\r\ngmake[1]: *** Waiting for unfinished jobs....\r\n```\r\n\r\n",
        "state": "closed",
        "user": "KimBioInfoStudio",
        "closed_by": "KimBioInfoStudio",
        "created_at": "2023-07-28T04:25:49+00:00",
        "updated_at": "2024-04-23T07:12:48+00:00",
        "closed_at": "2024-04-23T07:12:48+00:00",
        "comments_count": [
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 740,
        "title": "昇腾910按照文档在编译步骤时遇到错误",
        "body": "(python39) [ma-user npu]$bash tools/compile.sh\r\n+++ dirname tools/compile.sh\r\n++ cd tools/../\r\n++ pwd\r\n+ SOURCE_ROOT=/home/ma-user/work/PaddleCustomDevice/backends/npu\r\n+ mkdir -p /home/ma-user/work/PaddleCustomDevice/backends/npu/build\r\n+ cd /home/ma-user/work/PaddleCustomDevice/backends/npu/build\r\n++ uname -i\r\n+ arch=aarch64\r\n+ '[' aarch64 == x86_64 ']'\r\n+ WITH_MKLDNN=OFF\r\n+ WITH_ARM=ON\r\n+ cat\r\n========================================\r\nConfiguring cmake in build ...\r\n    -DCMAKE_BUILD_TYPE=Release\r\n    -DWITH_TESTING=OFF\r\n    -DWITH_MKLDNN=OFF\r\n    -DWITH_ARM=ON\r\n    -DON_INFER=OFF\r\n========================================\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_TESTING=OFF -DWITH_MKLDNN=OFF -DWITH_ARM=ON -DON_INFER=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\nCMake Error at cmake/paddle.cmake:1:\r\n  Parse error.  Expected a command name, got unquoted argument with text\r\n  \"../../../cmake/paddle.cmake\".\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:22 (include)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7\r\n\r\n环境：python3.9\r\n           conda环境\r\n           一张昇腾910",
        "state": "closed",
        "user": "Wall-cn",
        "closed_by": "Wall-cn",
        "created_at": "2023-08-02T03:40:28+00:00",
        "updated_at": "2023-08-03T06:24:50+00:00",
        "closed_at": "2023-08-03T06:24:50+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 741,
        "title": "请问如何在华为ModelArts平台上编译？",
        "body": null,
        "state": "closed",
        "user": "Wall-cn",
        "closed_by": "Wall-cn",
        "created_at": "2023-08-03T06:24:30+00:00",
        "updated_at": "2023-08-13T04:53:08+00:00",
        "closed_at": "2023-08-13T04:53:08+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 734,
        "title": "[MLU][BUG] fix rsqrt ut",
        "body": "<img width=\"547\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/31957460/de9fac1b-94db-4f5d-92a4-7165b893c2e6\">\r\n\r\n\r\n关联PR：https://github.com/PaddlePaddle/PaddleCustomDevice/pull/726",
        "state": "closed",
        "user": "BeingGod",
        "closed_by": "qili93",
        "created_at": "2023-07-28T09:08:35+00:00",
        "updated_at": "2024-04-15T04:49:56+00:00",
        "closed_at": "2024-04-15T04:49:55+00:00",
        "comments_count": [
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 735,
        "title": "[MLU][NPU][BUG] fix nearest_interp_v2 case & add 2D sacle tensor case",
        "body": "1. `set_align_corners `没有调用，导致`TestNearestInterpWithoutCorners`测例未覆盖\r\n<img width=\"599\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/31957460/fc001fd9-bab7-4473-9429-d71825cdd696\">\r\n\r\n\r\n2. 增加`scale_by_2Dtensor `的case，覆盖kernel中scale tensor size > 1的情况\r\n<img width=\"1096\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/31957460/ce7d9b71-5f41-482b-bc7c-64de79a15e2b\">\r\n\r\n",
        "state": "closed",
        "user": "BeingGod",
        "closed_by": "YanhuiDua",
        "created_at": "2023-07-28T09:11:51+00:00",
        "updated_at": "2024-04-23T08:01:13+00:00",
        "closed_at": "2024-04-23T08:01:13+00:00",
        "comments_count": [
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 736,
        "title": "[MLU] bloom-560M训练爆显存",
        "body": "相关版本：\r\n\r\n- python -m pip install paddlepaddle==0.0.0 -f https://www.paddlepaddle.org.cn/whl/linux/cpu-mkl/develop.html\r\n- PaddleCustomDevice-develop分支\r\n\r\n执行步骤：\r\nhttps://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/bloom#%E6%A8%A1%E5%9E%8B-finetune",
        "state": "closed",
        "user": "ShawnNew",
        "closed_by": "ShawnNew",
        "created_at": "2023-07-28T09:32:12+00:00",
        "updated_at": "2024-03-21T12:28:28+00:00",
        "closed_at": "2024-03-21T12:28:28+00:00",
        "comments_count": [
            "YanhuiDua",
            "Ivorfeng"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 742,
        "title": "自定义PASS Pattern中包含dropout算子，无法实现算子替换",
        "body": "HI， 我在开发自定义PASS，去实现推理时的算子融合，我发现如果模型中包含有dropout，PASS执行就会失败，无法成功替换为融合后的算子。下面是我简化后的代码，请问一下dropout有什么特殊之处吗？同样的代码如果换成Normalize就可以很好的工作。\r\n# limitations under the License.\r\n\r\nfrom __future__ import print_function, division\r\n\r\nimport os\r\nimport numpy as np\r\nimport unittest\r\nimport paddle\r\n\r\npaddle.enable_static()\r\n\r\n\r\n@paddle.incubate.passes.ir.RegisterPass\r\ndef generate_my_dropout():\r\n    def pattern(x):\r\n        return paddle.nn.functional.dropout(x)\r\n\r\n    def replace(x):\r\n        return paddle.incubate.passes.ir.PassDesc.OP.my_dropout(X=x)\r\n\r\n    return pattern, replace\r\n\r\n\r\n@paddle.jit.to_static(\r\n    input_spec=[\r\n        paddle.static.InputSpec([None, 32], \"float32\", \"x\"),\r\n    ]\r\n)\r\ndef func(x):\r\n    return paddle.nn.functional.dropout(x)\r\n\r\nMODLE_FILE = \"./saved_dropout_model\"\r\n\r\n\r\nclass TestCustomPass(unittest.TestCase):\r\n    def setUp(self):\r\n        for lib in os.listdir(os.getenv(\"CUSTOM_DEVICE_ROOT\")):\r\n            if lib.endswith(\".so\"):\r\n                paddle.utils.cpp_extension.extension_utils.load_op_meta_info_and_register_op(\r\n                    lib\r\n                )\r\n        paddle.jit.save(func, MODLE_FILE)\r\n\r\n    def test_my_dropout(self):\r\n        config = paddle.inference.Config()\r\n        config.set_prog_file(MODLE_FILE + \".pdmodel\")\r\n        config.enable_memory_optim()\r\n        config.enable_custom_device(\"intel_gpu\")\r\n        pass_builder = config.pass_builder()\r\n        pass_builder.append_pass(\"generate_my_dropout\")\r\n        print(pass_builder.all_passes())\r\n        predictor = paddle.inference.create_predictor(config)\r\n\r\n        np_inputs = [\r\n            np.random.randn(3, 32, 32).astype(\"float32\"),\r\n        ]\r\n        input_names = predictor.get_input_names()\r\n        for i, name in enumerate(input_names):\r\n            input_tensor = predictor.get_input_handle(name)\r\n            input_tensor.copy_from_cpu(np_inputs[i])\r\n\r\n        predictor.run()\r\n        results = []\r\n        output_names = predictor.get_output_names()\r\n        for i, name in enumerate(output_names):\r\n            output_tensor = predictor.get_output_handle(name)\r\n            output_data = output_tensor.copy_to_cpu()\r\n            results.append(output_data)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    unittest.main()\r\n",
        "state": "closed",
        "user": "ChengleiTian",
        "closed_by": "ChengleiTian",
        "created_at": "2023-08-04T00:48:56+00:00",
        "updated_at": "2023-08-11T01:40:24+00:00",
        "closed_at": "2023-08-11T01:40:24+00:00",
        "comments_count": [
            "ronny1996",
            "ChengleiTian"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 744,
        "title": "[Bug]: AttributeError: 'paddle.fluid.libpaddle.AnalysisConfig' object has no attribute 'enable_npu'",
        "body": "### 软件环境\r\n\r\n```Markdown\r\npaddle-custom-npu   0.0.0\r\npaddle2onnx         1.0.5\r\npaddlefsl           1.1.0\r\npaddlenlp           2.5.2\r\npaddlepaddle        0.0.0\r\n```\r\n\r\n\r\n### 重复问题\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### 错误描述\r\n\r\n```Markdown\r\n我在昇腾环境按照https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md\r\n编译了paddle，并安装了paddlenlp\r\n执行Taskflow API报了以下错误\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddlenlp/taskflow/taskflow.py\", line 837, in __init__\r\n    self.task_instance = task_class(\r\n  File \"/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddlenlp/taskflow/information_extraction.py\", line 536, in __init__\r\n    self._get_inference_model()\r\n  File \"/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddlenlp/taskflow/task.py\", line 366, in _get_inference_model\r\n    self._prepare_static_mode()\r\n  File \"/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddlenlp/taskflow/task.py\", line 199, in _prepare_static_mode\r\n    self._config.enable_npu(self.kwargs[\"device_id\"])\r\nAttributeError: 'paddle.fluid.libpaddle.AnalysisConfig' object has no attribute 'enable_npu'\r\n>>> client_loop: send disconnect: Broken pipe\r\n```\r\n\r\n\r\n### 稳定复现步骤 & 代码\r\n\r\n```\r\nschema = ['时间', '选手', '赛事名称']\r\nfrom paddlenlp import Taskflow\r\nie = Taskflow('information_extraction', schema=schema)\r\n```\r\n完整输出\r\n```\r\n(.venv) [ma-user npu]$python\r\nPython 3.9.17 (main, Jul 31 2023, 14:08:44)\r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> ^[[A^[[A^[[A^C\r\nKeyboardInterrupt\r\n>>> schema = ['时间', '选手', '赛事名称']\r\n>>> from paddlenlp import Taskflow\r\nI0805 01:51:40.542229 24803 init.cc:239] ENV [CUSTOM_DEVICE_ROOT]=/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddle_custom_device\r\nI0805 01:51:40.542289 24803 init.cc:145] Try loading custom device libs from: [/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddle_custom_device]\r\nI0805 01:51:41.062960 24803 custom_device.cc:1112] Successed in loading custom runtime in lib: /home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI0805 01:51:41.069720 24803 custom_kernel.cc:76] Successed in loading 325 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0805 01:51:41.069873 24803 init.cc:157] Finished in LoadCustomDevice with libs_path: [/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddle_custom_device]\r\nI0805 01:51:41.069908 24803 init.cc:245] CustomDevice: npu, visible devices count: 1\r\n>>> ie = Taskflow('information_extraction', schema=schema)\r\n[2023-08-05 01:51:54,462] [    INFO] - Downloading model_state.pdparams from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base_v1.1/model_state.pdparams\r\n100%|████████████████████████████████████████████████████████████████████████| 450M/450M [00:16<00:00, 28.3MB/s]\r\n[2023-08-05 01:52:13,069] [    INFO] - Downloading config.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base/config.json\r\n100%|██████████████████████████████████████████████████████████████████████████| 610/610 [00:00<00:00, 3.34MB/s]\r\n[2023-08-05 01:52:13,251] [    INFO] - Downloading vocab.txt from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base/vocab.txt\r\n100%|█████████████████████████████████████████████████████████████████████████| 182k/182k [00:00<00:00, 889kB/s]\r\n[2023-08-05 01:52:13,725] [    INFO] - Downloading special_tokens_map.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base/special_tokens_map.json\r\n100%|███████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 556kB/s]\r\n[2023-08-05 01:52:13,911] [    INFO] - Downloading tokenizer_config.json from https://bj.bcebos.com/paddlenlp/taskflow/information_extraction/uie_base/tokenizer_config.json\r\n100%|███████████████████████████████████████████████████████████████████████████| 172/172 [00:00<00:00, 933kB/s]\r\n[2023-08-05 01:52:14,141] [    INFO] - loading configuration file /home/ma-user/.paddlenlp/taskflow/information_extraction/uie-base/config.json\r\n[2023-08-05 01:52:14,143] [    INFO] - Model config ErnieConfig {\r\n  \"architectures\": [\r\n    \"UIE\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"dtype\": \"float32\",\r\n  \"enable_recompute\": false,\r\n  \"fuse\": false,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 768,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 3072,\r\n  \"layer_norm_eps\": 1e-12,\r\n  \"max_position_embeddings\": 2048,\r\n  \"model_type\": \"ernie\",\r\n  \"num_attention_heads\": 12,\r\n  \"num_hidden_layers\": 12,\r\n  \"pad_token_id\": 0,\r\n  \"paddlenlp_version\": null,\r\n  \"pool_act\": \"tanh\",\r\n  \"task_id\": 0,\r\n  \"task_type_vocab_size\": 3,\r\n  \"type_vocab_size\": 4,\r\n  \"use_task_id\": true,\r\n  \"vocab_size\": 40000\r\n}\r\n\r\n[2023-08-05 01:53:05,058] [    INFO] - All model checkpoint weights were used when initializing UIE.\r\n\r\n[2023-08-05 01:53:05,059] [    INFO] - All the weights of UIE were initialized from the model checkpoint at /home/ma-user/.paddlenlp/taskflow/information_extraction/uie-base.\r\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use UIE for predictions without further training.\r\n[2023-08-05 01:53:05,062] [    INFO] - Converting to the inference model cost a little time.\r\nI0805 01:53:09.457243 24803 program_interpreter.cc:173] New Executor is Running.\r\n[2023-08-05 01:53:15,365] [    INFO] - The inference model save in the path:/home/ma-user/.paddlenlp/taskflow/information_extraction/uie-base/static/inference\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddlenlp/taskflow/taskflow.py\", line 837, in __init__\r\n    self.task_instance = task_class(\r\n  File \"/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddlenlp/taskflow/information_extraction.py\", line 536, in __init__\r\n    self._get_inference_model()\r\n  File \"/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddlenlp/taskflow/task.py\", line 366, in _get_inference_model\r\n    self._prepare_static_mode()\r\n  File \"/home/ma-user/work/PaddleCustomDevice/backends/npu/.venv/lib/python3.9/site-packages/paddlenlp/taskflow/task.py\", line 199, in _prepare_static_mode\r\n    self._config.enable_npu(self.kwargs[\"device_id\"])\r\nAttributeError: 'paddle.fluid.libpaddle.AnalysisConfig' object has no attribute 'enable_npu'\r\n```",
        "state": "closed",
        "user": "BrightXiaoHan",
        "closed_by": "BrightXiaoHan",
        "created_at": "2023-08-05T00:30:50+00:00",
        "updated_at": "2023-08-06T14:18:31+00:00",
        "closed_at": "2023-08-06T14:18:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "error": "'NoneType' object has no attribute 'repository'",
        "issue_number": 782
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 750,
        "title": "自定义Pass中，无法提取被融合算子的权重",
        "body": "你好，在我下面的例子里面, 会将MyTest的forward替换为my_ln, LayerNorm中的属性值epsilon，可以通过MappedPattern获取到，\r\n但是无法获取到LayerNorm算子的Bias和Scale, 请问有什么办法可以得到被融合算子的可学习参数张量？\r\n\r\n```\r\n@paddle.incubate.passes.ir.RegisterPass\r\ndef generate_my_ln():\r\n    def pattern(x):\r\n        ln_op = IR.PassDesc.OP.layer_norm\r\n        ln_op._outputs.pop(\"Mean\")\r\n        ln_op._outputs.pop(\"Variance\")\r\n        ln_out = ln_op(X=x)\r\n\r\n        return ln_out\r\n\r\n    def replace(x):\r\n        fuse_op = IR.PassDesc.OP.my_ln(X=x, Y=x)\r\n        fuse_op.Attr(\"epsilon\").MappedPattern(\r\n            op=\"layer_norm\", name=\"epsilon\"\r\n        )\r\n        fuse_op.SetAttr(\"transpose_x\", True)\r\n        fuse_op.SetAttr(\"transpose_y\", False)\r\n\r\n        return fuse_op\r\n\r\n    return pattern, replace\r\n\r\n\r\nclass MyTest(paddle.nn.Layer):\r\n    def __init__(\r\n        self\r\n    ):\r\n        super().__init__()\r\n        self.ln_op = paddle.nn.LayerNorm(2, epsilon=0.000345, weight_attr=True, bias_attr=True)\r\n\r\n    def forward(self, x):\r\n        ln_out = self.ln_op(x)\r\n        return ln_out\r\n```",
        "state": "closed",
        "user": "ChengleiTian",
        "closed_by": "qili93",
        "created_at": "2023-08-10T06:34:21+00:00",
        "updated_at": "2024-05-23T07:55:24+00:00",
        "closed_at": "2024-05-23T07:55:23+00:00",
        "comments_count": [
            "ronny1996",
            "ChengleiTian",
            "qili93",
            "qili93",
            "ChengleiTian",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 756,
        "title": "昇腾npu编译paddle时报错",
        "body": "电脑端下载zip放到服务器端按文档编译报错\r\n-- Run 'git submodule update --init Paddle' in /usr/local/Ascend/PaddleCustomDevice\r\nerror: pathspec 'Paddle' did not match any file(s) known to git.\r\nCMake Error at cmake/paddle.cmake:68 (message):\r\n  Failed to get submodule Paddle', please check your network !\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:22 (include)\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/usr/local/Ascend/PaddleCustomDevice/backends/npu/build/CMakeFiles/CMakeOutput.log\".\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7",
        "state": "closed",
        "user": "Sam-papa",
        "closed_by": "Sam-papa",
        "created_at": "2023-08-11T10:40:32+00:00",
        "updated_at": "2023-08-11T11:38:28+00:00",
        "closed_at": "2023-08-11T11:38:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 767,
        "title": "NPU上每个device显示有重复的进程id",
        "body": "NPU上每个device显示有重复的进程id，只占用少量显存，类似僵尸进程\r\n\r\n\r\n",
        "state": "closed",
        "user": "zhjc",
        "closed_by": "ronny1996",
        "created_at": "2023-08-22T12:06:32+00:00",
        "updated_at": "2023-08-25T05:52:22+00:00",
        "closed_at": "2023-08-25T05:52:22+00:00",
        "comments_count": [
            "zhjc",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 759,
        "title": "[Paddle]请问当前反向算子的实现是否有像pytorch那样的autograd计算机制?",
        "body": "- 例如：div_grad\r\n- 在pytorch中div_grad调用div_tensor_self_backward实现，div_tensor_self_backward调用其他算子实现，具体怎么实现是框架自己的逻辑，paddle中是否有相应的机制？",
        "state": "closed",
        "user": "DeshuaiSun",
        "closed_by": "qili93",
        "created_at": "2023-08-15T11:00:55+00:00",
        "updated_at": "2024-02-27T07:48:56+00:00",
        "closed_at": "2024-02-27T07:48:56+00:00",
        "comments_count": [
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 770,
        "title": "Paddle PR-CI-Py3流水线对custom-cpu的测试用例有随机挂现象",
        "body": "https://xly.bce.baidu.com/paddlepaddle/paddle/newipipe/detail/9016046/job/23646338\r\n以此（实际上在此流水线相邻的测试中也出现了类似的现象）为例，31544行出现空指针，能否帮忙排查一下该问题。",
        "state": "closed",
        "user": "jinyouzhi",
        "closed_by": "jinyouzhi",
        "created_at": "2023-08-24T14:00:53+00:00",
        "updated_at": "2023-08-25T02:06:05+00:00",
        "closed_at": "2023-08-25T02:06:05+00:00",
        "comments_count": [
            "ronny1996",
            "jinyouzhi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 783,
        "title": "[NPU]PaddleCustomDevice编译安装后import paddle失败",
        "body": "Paddle版本：7c8c9b7d87b51838ae6ed379ac9bc3d5685b7bee\r\nPaddleCustomDevice版本：0a9d29c7839277447b78138c62ec928f17926ef8\r\n\r\nPaddle编译命令：\r\n```\r\ncmake .. -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DPY_VERSION=3.7 -DPYTHON_EXECUTABLE=`which python3` -DWITH_TESTING=OFF -DON_INFER=ON -DWITH_CUSTOM_DEVICE=ON -DWITH_DISTRIBUTE=ON -DWITH_PSCORE=ON -DWITH_XBYAK=OFF -DWITH_ARM=ON\r\n\r\nmake TARGET=ARMV8 -j64\r\n```\r\n\r\nPaddleCustomDevice命令：\r\n```\r\ncd backends/npu\r\nbash tools/compile.sh\r\n```\r\n\r\n生成的两个whl包使用pip安装后，执行`import paddle`，报错如下：\r\n```\r\n>>> import paddle\r\nI0907 16:59:06.533313 39583 init.cc:237] ENV [CUSTOM_DEVICE_ROOT]=/opt/py37env/lib/python3.7/site-packages/paddle_custom_device\r\nI0907 16:59:06.533385 39583 init.cc:146] Try loading custom device libs from: [/opt/py37env/lib/python3.7/site-packages/paddle_custom_device]\r\npaddle flags error: illegal RegisterFlag, flag \"devices\" has been defined in /home/xxx/paddle/fluid/inference/io.cc (at /home/xxx/paddle/utils/flags_native.cc:301)\r\n\r\n```",
        "state": "closed",
        "user": "zhjc",
        "closed_by": "ronny1996",
        "created_at": "2023-09-06T09:00:07+00:00",
        "updated_at": "2023-09-08T02:20:39+00:00",
        "closed_at": "2023-09-08T02:20:39+00:00",
        "comments_count": [
            "zhjc",
            "ronny1996",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 808,
        "title": "[NPU]aclrtDestroyEvent替换为aclrtResetEvent后，代码运行卡住",
        "body": "如下为替换的代码\r\n``` cpp\r\nstatic std::mutex events_mutext;\r\nstatic std::list<aclrtEvent> idle_events, busy_events;\r\nstatic std::unordered_map<aclrtEvent, aclrtStream> event_stream_map;\r\n\r\nC_Status CreateEvent(const C_Device device, C_Event *event) {\r\n  std::cout << \"Run In CreateEvent\" << std::endl;\r\n  std::lock_guard<std::mutex> lock(events_mutext);\r\n  aclrtEvent aclrt_event;\r\n  if (idle_events.empty()) {\r\n    ACL_CHECK(aclrtCreateEvent(&aclrt_event));\r\n  } else {\r\n    aclrt_event = idle_events.front();\r\n    idle_events.pop_front();\r\n  }\r\n  busy_events.push_back(aclrt_event);\r\n  *event = reinterpret_cast<C_Event>(aclrt_event);\r\n  std::cout << \"Run Out CreateEvent: \" << aclrt_event << std::endl;\r\n  return C_SUCCESS;\r\n}\r\n\r\nC_Status RecordEvent(const C_Device device, C_Stream stream, C_Event event) {\r\n  std::cout << \"Run In RecordEvent\" << std::endl;\r\n  std::lock_guard<std::mutex> lock(events_mutext);\r\n  ACL_CHECK(aclrtRecordEvent(reinterpret_cast<aclrtEvent *>(event),\r\n                             reinterpret_cast<aclrtStream>(stream)));\r\n  event_stream_map[event] = stream;\r\n  std::cout << \"Run Out RecordEvent: \" << event << std::endl;\r\n  return C_SUCCESS;\r\n}\r\n\r\nC_Status QueryEvent(const C_Device device, C_Event event) {\r\n  std::cout << \"Run In QueryEvent\" << std::endl;\r\n  aclrtEventRecordedStatus status = ACL_EVENT_RECORDED_STATUS_COMPLETE;\r\n  ACL_CHECK(aclrtQueryEventStatus(event, &status));\r\n  std::cout << \"Run Out QueryEvent: \" << event << \" status: \" << status << std::endl;\r\n  return status == ACL_EVENT_RECORDED_STATUS_COMPLETE ? C_SUCCESS : C_FAILED;\r\n}\r\n\r\nC_Status DestroyEvent(const C_Device device, C_Event event) {\r\n  std::cout << \"Run In DestroyEvent: \" << event << std::endl;\r\n  std::lock_guard<std::mutex> lock(events_mutext);\r\n  auto it = event_stream_map.find(reinterpret_cast<aclrtEvent>(event));\r\n  auto busy_event_it = std::find(busy_events.begin(), busy_events.end(), reinterpret_cast<aclrtEvent>(event));\r\n  if (it != event_stream_map.end()) {\r\n    std::cout << \"ResetEvent: \" << event << std::endl;\r\n    ACL_CHECK(aclrtResetEvent(it->first, it->second));\r\n    event_stream_map.erase(it);\r\n  }\r\n  if (busy_event_it != busy_events.end()) {\r\n    idle_events.push_back(reinterpret_cast<aclrtEvent>(event));\r\n    busy_events.erase(busy_event_it);\r\n  }\r\n  std::cout << \"Run Out DestroyEvent\" << std::endl;\r\n  return C_SUCCESS;\r\n}\r\n```\r\n\r\n### 运行CustomDevice测试用例  “ctest -I 26 -V” 也会出现卡住的现象。\r\n",
        "state": "closed",
        "user": "bmers",
        "closed_by": "bmers",
        "created_at": "2023-10-08T14:27:59+00:00",
        "updated_at": "2023-11-30T13:01:06+00:00",
        "closed_at": "2023-11-30T13:01:06+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 785,
        "title": "[NPU]执行import paddle语句后程序释放时执行时间长",
        "body": "Paddle commit id：12301bc5337fa3bc2d07050d240fbac3689fa9ce\r\nPaddleCustomDevice最新develop分支，编译代码安装whl包\r\n\r\n执行一条语句`import paddle`，进程退出时间较长，通过`npu-smi info`查看是八张卡，顺序的在每张卡出现一个进程，所有卡上进程消除后程序退出，示例如下：\r\n+===========================+===============+====================================================+\r\n| No running processes found in NPU 0                                                            |\r\n+===========================+===============+====================================================+\r\n| No running processes found in NPU 1                                                            |\r\n+===========================+===============+====================================================+\r\n| No running processes found in NPU 2                                                            |\r\n+===========================+===============+====================================================+\r\n| No running processes found in NPU 3                                                            |\r\n+===========================+===============+====================================================+\r\n| 4       0                 | 4729          | python                   | 65                      |\r\n+===========================+===============+====================================================+\r\n| No running processes found in NPU 5                                                            |\r\n+===========================+===============+====================================================+\r\n| No running processes found in NPU 6                                                            |\r\n+===========================+===============+====================================================+\r\n| No running processes found in NPU 7                                                            |\r\n+===========================+===============+====================================================+\r\n",
        "state": "closed",
        "user": "zhjc",
        "closed_by": "qili93",
        "created_at": "2023-09-07T08:16:55+00:00",
        "updated_at": "2024-05-22T02:18:24+00:00",
        "closed_at": "2024-05-22T02:18:24+00:00",
        "comments_count": [
            "qili93",
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 788,
        "title": "[NPU]llama模型报错lookup_table_v2找不到",
        "body": "算子注册信息如下：\r\n```\r\npython -c \"import paddle;[print(x) for x in paddle.fluid.core._get_all_register_op_kernels()['lookup_table_v2']]\"\r\nI0909 10:56:59.667981 137882 init.cc:237] ENV [CUSTOM_DEVICE_ROOT]=/opt/py39/lib/python3.9/site-packages/paddle_custom_device\r\nI0909 10:56:59.668047 137882 init.cc:146] Try loading custom device libs from: [/opt/py39/lib/python3.9/site-packages/paddle_custom_device]\r\nI0909 10:57:00.375885 137882 custom_device.cc:1108] Successed in loading custom runtime in lib: /opt/py39/lib/python3.9/site-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI0909 10:57:00.394555 137882 custom_kernel.cc:63] Successed in loading 325 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0909 10:57:00.394879 137882 init.cc:158] Finished in LoadCustomDevice with libs_path: [/opt/py39/lib/python3.9/site-packages/paddle_custom_device]\r\nI0909 10:57:00.395005 137882 init.cc:243] CustomDevice: npu, visible devices count: 8\r\n{data_type[int8_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}\r\n{data_type[::paddle::platform::bfloat16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}\r\n{data_type[::paddle::platform::float16]; data_layout[Undefined(AnyLayout)]; place[Place(npu:0)]; library_type[PLAIN]}\r\n{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}\r\n{data_type[double]; data_layout[Undefined(AnyLayout)]; place[Place(npu:0)]; library_type[PLAIN]}\r\n{data_type[int]; data_layout[Undefined(AnyLayout)]; place[Place(npu:0)]; library_type[PLAIN]}\r\n{data_type[double]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}\r\n{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(npu:0)]; library_type[PLAIN]}\r\n\r\n```",
        "state": "closed",
        "user": "zhjc",
        "closed_by": "ronny1996",
        "created_at": "2023-09-08T03:03:20+00:00",
        "updated_at": "2023-09-15T09:23:04+00:00",
        "closed_at": "2023-09-12T02:17:10+00:00",
        "comments_count": [
            "max-niu",
            "max-niu",
            "max-niu",
            "max-niu",
            "max-niu",
            "max-niu",
            "bmers",
            "max-niu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 810,
        "title": "[MLU] 自动混合精度规约算子特化处理问题",
        "body": "当前MLU实现中规约算子是否已支持自动混合精度的特化处理？根据[自动混合精度训练（AMP）](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/performance_improving/amp_cn.html)中的介绍，当前paddle框架已支持MLU的混合精度训练，但根据[低精度算子支持开发规范](https://www.paddlepaddle.org.cn/documentation/docs/zh/dev_guides/amp_precision/amp_op_dev_guide_cn.html)中的介绍当前规约算子及部分数学函数计算并无特化处理，请问当前MLU支持自动混合精度采用了哪种方案？",
        "state": "closed",
        "user": "DeshuaiSun",
        "closed_by": "DeshuaiSun",
        "created_at": "2023-10-09T08:45:55+00:00",
        "updated_at": "2024-03-19T06:36:30+00:00",
        "closed_at": "2024-03-19T06:36:30+00:00",
        "comments_count": [
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 811,
        "title": "FusedAllReduce使用Concat和Split算子？",
        "body": "当前实现中，concat和split使用memcpy实现，是否考虑使用concat和split算子实现？",
        "state": "closed",
        "user": "tiandou-tangdou",
        "closed_by": "qili93",
        "created_at": "2023-10-09T12:06:14+00:00",
        "updated_at": "2024-04-15T02:15:32+00:00",
        "closed_at": "2024-04-15T02:15:32+00:00",
        "comments_count": [
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 834,
        "title": "昇腾910B和CANN7.0.RC1出现错误",
        "body": "参考文档：https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md\r\n环境信息：官网EulerOs系统的Dockerfile修改成CANN7.0.RC1，python=3.9，gcc82\r\n出错命令：python tests/test_LeNet_MNIST.py\r\n完整的错误信息：python tests/test_LeNet_MNIST.py\r\nI1108 08:56:44.854535 114008 init.cc:233] ENV [CUSTOM_DEVICE_ROOT]=/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle_custom_device\r\nI1108 08:56:44.854583 114008 init.cc:142] Try loading custom device libs from: [/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle_custom_device]\r\nI1108 08:56:45.166314 114008 custom_device.cc:1108] Successed in loading custom runtime in lib: /root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI1108 08:56:45.168068 114008 custom_kernel.cc:63] Successed in loading 326 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI1108 08:56:45.168195 114008 init.cc:154] Finished in LoadCustomDevice with libs_path: [/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle_custom_device]\r\nI1108 08:56:45.168227 114008 init.cc:239] CustomDevice: npu, visible devices count: 8\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nERROR: Unexpected BUS error encountered in DataLoader worker. This might be caused by insufficient shared memory (shm), please check whether use_shared_memory is set and storage space in /dev/shm is enough\r\nTraceback (most recent call last):\r\n  File \"/work/PaddleCustomDevice/backends/npu/tests/test_LeNet_MNIST.py\", line 261, in <module>\r\n    main(args)\r\n  File \"/work/PaddleCustomDevice/backends/npu/tests/test_LeNet_MNIST.py\", line 162, in main\r\n    outputs = model(images)\r\n  File \"/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1343, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle/vision/models/lenet.py\", line 67, in forward\r\n    x = self.features(inputs)\r\n  File \"/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1343, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle/nn/layer/container.py\", line 614, in forward\r\n    input = layer(input)\r\n  File \"/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1343, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle/nn/layer/conv.py\", line 715, in forward\r\n    out = F.conv._conv_nd(\r\n  File \"/root/miniconda3/envs/paddle-npu/lib/python3.9/site-packages/paddle/nn/functional/conv.py\", line 128, in _conv_nd\r\n    pre_bias = _C_ops.conv2d(\r\nOSError: (External)  ACL error, the error code is : 500001.  (at /work/PaddleCustomDevice/backends/npu/kernels/funcs/npu_op_runner.cc:422)\r\n请问能解决吗？目前在国产化项目中之前都是基于910A的，该怎么做呢？目前项目比较急。",
        "state": "closed",
        "user": "Wall-cn",
        "closed_by": "Wall-cn",
        "created_at": "2023-11-08T09:11:11+00:00",
        "updated_at": "2023-11-09T08:20:03+00:00",
        "closed_at": "2023-11-09T08:19:37+00:00",
        "comments_count": [
            "Wall-cn",
            "YanhuiDua",
            "Wall-cn",
            "Wall-cn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 820,
        "title": "[MLU] 安装不成功",
        "body": "MLU安装后，import paddle不成功，哪位大佬可以提供安装的docker镜像和安装包呢？",
        "state": "closed",
        "user": "baominghelly",
        "closed_by": "qili93",
        "created_at": "2023-10-13T13:52:02+00:00",
        "updated_at": "2024-02-27T07:48:35+00:00",
        "closed_at": "2024-02-27T07:48:35+00:00",
        "comments_count": [
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 836,
        "title": "昇腾910B上训练厂内VIMER-UFO大模型，几个epoch后稳定报错",
        "body": "<img width=\"1385\" alt=\"7aee8fe238ed06109fee9fac53dee2c2\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/45171399/783534ab-eebf-4cbe-8b09-9d5670f85499\">\r\n使用昇腾910B训练VIMER-UFO大模型，在训练几个epoch后会稳定报这个错，如何解决？\r\n如流联系：lvfeng02",
        "state": "closed",
        "user": "Jeremy-lf",
        "closed_by": "qili93",
        "created_at": "2023-11-15T03:21:15+00:00",
        "updated_at": "2024-06-07T06:18:17+00:00",
        "closed_at": "2024-06-07T06:18:17+00:00",
        "comments_count": [
            "YanhuiDua",
            "Jeremy-lf",
            "YanhuiDua",
            "Jeremy-lf",
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 844,
        "title": "Llama65B静态batch复现步骤",
        "body": "## 一、相关代码仓：\r\nPaddle：https://github.com/MyAngelAyase/Paddle\r\nPaddleCustomDevice：https://github.com/MyAngelAyase/PaddleCustomDevice\r\nPaddleNLP：https://github.com/MyAngelAyase/PaddleNLP\r\n\r\n## 二、安装编译\r\n\r\n```bash\r\n# 安装最新加速库Run包\r\nsource /usr/local/Ascend/atb/set_env.sh\r\n\r\n# Paddle (5832764483 2023-10-13)\r\ngit clone https://github.com/MyAngelAyase/Paddle.git -b develop\r\ncmake .. -DPY_VERSION=3.9 -DPYTHON_EXECUTABLE=`which python3` -DWITH_ARM=OFF -DWITH_TESTING=OFF -DCMAKE_BUILD_TYPE=Release -DON_INFER=ON -DWITH_XBYAK=OFF -DWITH_CUSTOM_DEVICE=ON -DWITH_DISTRIBUTE=ON -DWITH_PSCORE=ON\r\nmake -j$(nproc)\r\n\r\n# PaddleCustomDevice (a800ff7)\r\ngit clone. https://github.com/MyAngelAyase/PaddleCustomDevice.git -b develop\r\nexport WITH_ASCEND_TRANSFORMER_ACC=ON\r\nbash tools/compile.sh\r\n\r\n# PaddleNLP (913d569)\r\ngit clone https://github.com/MyAngelAyase/PaddleNLP.git -b develop\r\ncd PaddleNLP && pip install -e .\r\n\r\n# 后处理自定义算子 \r\nwget xxxx/paddle_post_processALL.zip\r\n```\r\n修改paddle_post_processALL/src/ops/ascendc/op_kernel/set_mask_value.cpp:30\r\n（因为当前在PaddleNLP将(attention mask - 1)*1e4操作提出到predictor处理，见[#pr74](https://github.com/MyAngelAyase/PaddleCustomDevice/pull/74)和[#pr17](https://github.com/MyAngelAyase/PaddleNLP/pull/17)，故在setmaskvalue需要适配将赋1修改为赋0，业务模型无类似操作可不需要。）\r\n\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/29788896/8ae15708-1084-4a35-ba2f-64429cbbc648)\r\n```bash\r\ncd build && bash build_ops.sh\r\nbash  aie_ops.run --extract=/workspace # 目录下会生成vendors目录\r\n# 设置算子库路径\r\nexport ASCEND_CUSTOM_OPP_PATH=/workspace/vendors/aie_ascendc\r\n```\r\n\r\n## 三、模型导出\r\n\r\n```bash\r\n# 切权重\r\n词表横切会使用多个小算子组成embedding，为避免造成显存碎片，暂时先暴力的不切词表权重（后续考虑竖切），接入Llama65B加速库embedding。\r\n```\r\n对应PaddleNLP修改见[#pr21](https://github.com/MyAngelAyase/PaddleNLP/pull/21)\r\n脚本内容：\r\n```python\r\n\"\"\"\r\nAuthor(Zhengzekang):\r\n\r\nIf we use PaddleNLP to export distributed model by using dy2static directly, \r\neach device will read full model which easily cause OOM. \r\n\r\nThis script only use single device to read full model and split model by assigned NRANKS\r\n\r\n\"\"\"\r\n\r\nimport paddle \r\nimport os \r\nimport json \r\n\r\n# Define Weight Name List. \r\nLLAMA_COLUMN_SPLIT_WEIGHT_LIST = [\r\n    \"self_attn.q_proj.weight\",\r\n    \"self_attn.k_proj.weight\",\r\n    \"self_attn.v_proj.weight\",\r\n    \"mlp.gate_proj.weight\",\r\n    \"mlp.up_proj.weight\",\r\n]\r\n\r\nLLAMA_ROW_SPLIT_WEIGHT_LIST = [\r\n    \"self_attn.o_proj.weight\",\r\n    \"mlp.down_proj.weight\"\r\n]\r\n\r\nLLAMA_NO_SPLIT_WEIGHT_LIST = [\r\n    \"input_layernorm.weight\",\r\n    \"post_attention_layernorm.weight\",\r\n]\r\n\r\nLM_HEAD_COLUMN_SPLIT_WEIGHT_LIST = [\r\n    \"lm_head.weight\"\r\n]\r\n\r\nEMBEDDING_ROW_SPLIT_WEIGHT_LIST = [\r\n    \"llama.embed_tokens.weight\"\r\n]\r\n\r\nFINAL_NORM_WEIGHT_LSIT = [\r\n    \"llama.norm.weight\"\r\n]\r\n\r\ndef parse_arguments():\r\n    import argparse\r\n\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--model_dir\", required=True, help=\"The directory of model.\")\r\n    parser.add_argument(\"--output_model_dir\", required=True, help=\"The directory of model.\")\r\n    parser.add_argument(\"--nranks\", type=int, default=\"1\", help=\"The number of distributed model num. \")\r\n    return parser.parse_args()\r\n\r\ndef col_split(weight, nranks): \r\n    return paddle.split(paddle.to_tensor(weight, place=paddle.CPUPlace()), axis=1, num_or_sections=nranks)\r\n\r\ndef row_split(weight, nranks): \r\n    return paddle.split(paddle.to_tensor(weight, place=paddle.CPUPlace()), axis=0, num_or_sections=nranks)\r\n\r\ndef split_model_weight(model_dir, nranks, output_model_path): \r\n    model_state_path = os.path.join(model_dir, \"model_state.pdparams\")\r\n    origin_model = paddle.load(model_state_path, return_numpy=True)\r\n    config = None \r\n    with open(os.path.join(model_dir, \"config.json\"), \"r\") as f: \r\n        config = json.load(f) \r\n\r\n    for rank_id in range(nranks): \r\n        print(\"Now process rank: \", rank_id)\r\n        split_state_dict = dict()\r\n        col_split_lm_head_weight = col_split(origin_model[LM_HEAD_COLUMN_SPLIT_WEIGHT_LIST[0]], nranks)[rank_id]\r\n        #row_split_embed_token_weight = row_split(origin_model[EMBEDDING_ROW_SPLIT_WEIGHT_LIST[0]], nranks)[rank_id]\r\n        split_state_dict[LM_HEAD_COLUMN_SPLIT_WEIGHT_LIST[0]] = col_split_lm_head_weight\r\n        #split_state_dict[EMBEDDING_ROW_SPLIT_WEIGHT_LIST[0]] = row_split_embed_token_weight\r\n        split_state_dict[EMBEDDING_ROW_SPLIT_WEIGHT_LIST[0]] = paddle.to_tensor(origin_model[EMBEDDING_ROW_SPLIT_WEIGHT_LIST[0]], place=paddle.CPUPlace())\r\n\r\n        print(split_state_dict)\r\n        for layer_id in range(config[\"num_hidden_layers\"]): \r\n            print(\"Now process LayerIdx: \", layer_id)\r\n            for column_split_weight_name in LLAMA_COLUMN_SPLIT_WEIGHT_LIST: \r\n                full_column_split_weight_name = \"llama.layers.{}.\".format(layer_id) + column_split_weight_name\r\n                column_split_weight = col_split(origin_model[full_column_split_weight_name], nranks)[rank_id]\r\n                split_state_dict[full_column_split_weight_name] = column_split_weight\r\n\r\n            for row_split_weight_name in LLAMA_ROW_SPLIT_WEIGHT_LIST: \r\n                full_row_split_weight_name = \"llama.layers.{}.\".format(layer_id) + row_split_weight_name\r\n                row_split_weight = row_split(origin_model[full_row_split_weight_name], nranks)[rank_id]\r\n                split_state_dict[full_row_split_weight_name] = row_split_weight\r\n\r\n            for no_split_weight_name in LLAMA_NO_SPLIT_WEIGHT_LIST: \r\n                full_no_split_weight_name = \"llama.layers.{}.\".format(layer_id) + no_split_weight_name\r\n                split_state_dict[full_no_split_weight_name] = paddle.to_tensor(origin_model[full_no_split_weight_name], place=paddle.CPUPlace())\r\n\r\n        last_norm_weight_name = FINAL_NORM_WEIGHT_LSIT[0]\r\n        split_state_dict[last_norm_weight_name] = paddle.to_tensor(origin_model[last_norm_weight_name], place=paddle.CPUPlace())\r\n        paddle.save(split_state_dict, os.path.join(output_model_path, \"model_state.tp0{}.pdparams\".format(rank_id)))\r\n\r\nif __name__ == \"__main__\": \r\n    args = parse_arguments()\r\n    split_model_weight(args.model_dir, \r\n                       args.nranks, \r\n                       args.output_model_dir)\r\n\r\n```\r\n```bash\r\n# Npu下导出8卡推理模型，PaddleNLP\r\ncd PaddleNLP/llm\r\npython -m paddle.distributed.launch --devices \"0,1,2,3,4,5,6,7\" export_model.py \\\r\n    --model_name_or_path facebook/llama-65b \\\r\n    --output_path ./export_llama65b_fp16_mp8 \\\r\n    --dtype float16 \\\r\n    --inference_model\r\n```\r\n确保less_than 前的 reduce_sum 算子的 (后续在NPU上推理有问题，必须要求reduce_all=True)\r\n运行以下程序输出readable code显示模型中reduce_sum算子的attr。\r\n```python\r\nimport paddle\r\n\r\npaddle.enable_static()\r\nexe = paddle.static.Executor(paddle.CPUPlace())\r\n\r\n# load inference model  \r\n[infer_program, feed_target_names, fetch_targets] = paddle.static.load_inference_model(\"./export_llama65b_fp16_mp8/rank_0/model\", exe)\r\n\r\n# dump readable_code of global block\r\nwith open ('readable_code_global_block.log', 'w') as file:\r\n  global_block = infer_program.global_block()\r\n  file.write(global_block._to_readable_code())\r\n```\r\n在输入出日志中grep reduce_sum 算子，获得结果如下\r\n```\r\ngrep \"\\ less_than\" readable_code_global_block.log\r\ngrep \"\\ reduce_sum\" readable_code_global_block.log\r\n# 期望得到的输出结果如下\r\n{Out=['sum_1.tmp_0']} = reduce_sum(inputs={X=['cast_2.tmp_0']}, dim = [], in_dtype = -1, keep_dim = False, op_device = , op_namescope = /, op_role = 0, op_role_var = [], out_dtype = -1, reduce_all = True)\r\n{Out=['sum_2.tmp_0']} = reduce_sum(inputs={X=['cast_3.tmp_0']}, dim = [], in_dtype = -1, keep_dim = False, op_device = , op_namescope = /, op_role = 0, op_role_var = [], out_dtype = -1, reduce_all = True)\r\n```\r\n## 四、模型预测\r\n```bash\r\n修改 infer_llama_npu.sh 中的 model_dir，\r\n```",
        "state": "open",
        "user": "bmers",
        "closed_by": null,
        "created_at": "2023-11-30T13:46:13+00:00",
        "updated_at": "2023-12-01T02:46:15+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 839,
        "title": "动态batch脚本，重新进入时报错",
        "body": "```c\r\n##@@(ZeroCopyRun START)(1700108135978080)\r\nterminate called after throwing an instance of 'phi::enforce::EnforceNotMet'\r\n  what():  In user code:\r\n\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/llm/export_model.py\", line 111, in <module>\r\n      main()\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/llm/export_model.py\", line 99, in main\r\n      predictor.model.to_static(\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/paddlenlp/experimental/transformers/generation_utils.py\", line 118, in to_static\r\n      paddle.jit.save(\r\n    File \"/opt/py39/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/api.py\", line 795, in wrapper\r\n      func(layer, path, input_spec, **configs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/dygraph/base.py\", line 76, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/api.py\", line 1136, in save\r\n      static_func.concrete_program_specify_input_spec(\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/dy2static/program_translator.py\", line 969, in concrete_program_specify_input_spec\r\n      concrete_program, _ = self.get_concrete_program(\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/dy2static/program_translator.py\", line 859, in get_concrete_program\r\n      concrete_program, partial_program_layer = self._program_cache[\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/dy2static/program_translator.py\", line 1452, in __getitem__\r\n      self._caches[item_id] = self._build_once(item)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/dy2static/program_translator.py\", line 1396, in _build_once\r\n      concrete_program = ConcreteProgram.from_func_spec(\r\n    File \"/opt/py39/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/wrapped_decorator.py\", line 25, in __impl__\r\n      return wrapped_func(*args, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/dygraph/base.py\", line 76, in __impl__\r\n      return func(*args, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/dy2static/program_translator.py\", line 1220, in from_func_spec\r\n      outputs = static_func(*inputs)\r\n    File \"/root/.cache/paddle/to_static_tmp/2118847/generate_5x70ftd.py\", line 38, in generate\r\n      return _jst.Ld(_decoedby_no_grad)(_jst.Ld(self), _jst.Ld(input_ids), _jst.Ld(attention_mask), _jst.Ld(position_ids), _jst.Ld(penalty_score), _jst.Ld(frequency_score), _jst.Ld(presence_score), _jst.Ld(min_length), _jst.Ld(max_length), _jst.Ld(temperature), _jst.Ld(top_p), _jst.Ld(eos_token_id), _jst.Ld(seq_len_encoder), _jst.Ld(seq_len_decoder), _jst.Ld(step_idx), _jst.Ld(stop_flags), _jst.Ld(tgt_ids), _jst.Ld(tgt_pos), _jst.Ld(tgt_generation_mask), _jst.Ld(pre_ids), _jst.Ld(stop_nums), _jst.Ld(cache_kvs), _jst.Ld(inputs_embeds), _jst.Ld(logits_processors), _jst.Ld(pre_caches))\r\n    File \"/opt/py39/lib/python3.9/site-packages/decorator.py\", line 232, in fun\r\n      return caller(func, *(extras + args), **kw)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/dygraph/base.py\", line 349, in _decorate_function\r\n      return func(*args, **kwargs)\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/paddlenlp/experimental/transformers/generation_utils.py\", line 183, in generate\r\n      ret = self.sample(\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/paddlenlp/experimental/transformers/generation_utils.py\", line 351, in sample\r\n      outputs = _forward_(**model_kwargs)\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/paddlenlp/experimental/transformers/generation_utils.py\", line 289, in _forward_\r\n      return self(**model_inputs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1350, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1329, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/paddlenlp/experimental/transformers/llama/modeling.py\", line 524, in forward\r\n      outputs = self.llama(\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1350, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1329, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/paddlenlp/experimental/transformers/llama/modeling.py\", line 271, in forward\r\n      if inputs_embeds is None:\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/dy2static/convert_operators.py\", line 371, in convert_ifelse\r\n      out = _run_py_ifelse(\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/jit/dy2static/convert_operators.py\", line 453, in _run_py_ifelse\r\n      py_outs = true_fn() if pred else false_fn()\r\n    File \"/home/yuanwei/new_test/PaddleNLP_NoBatchMask/paddlenlp/experimental/transformers/llama/modeling.py\", line 272, in forward\r\n      inputs_embeds = self.embed_tokens(ids_remove_padding)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1350, in __call__\r\n      return self._dygraph_call_func(*inputs, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1329, in _dygraph_call_func\r\n      outputs = self.forward(*inputs, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/distributed/fleet/layers/mpu/mp_layers.py\", line 159, in forward\r\n      output_parallel = mp_ops._c_lookup_table(\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/distributed/fleet/layers/mpu/mp_ops.py\", line 357, in _c_lookup_table\r\n      helper.append_op(\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/layer_helper.py\", line 45, in append_op\r\n      return self.main_program.current_block().append_op(*args, **kwargs)\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/framework.py\", line 4368, in append_op\r\n      op = Operator(\r\n    File \"/opt/py39/lib/python3.9/site-packages/paddle/base/framework.py\", line 2906, in __init__\r\n      for frame in traceback.extract_stack():\r\n\r\n    PreconditionNotMetError: The meta data must be valid when call the mutable data function.\r\n      [Hint: Expected valid() == true, but received valid():0 != true:1.] (at /workspace/Paddle/paddle/phi/core/dense_tensor.cc:126)\r\n      [operator < c_embedding > error]\r\n\r\n```",
        "state": "closed",
        "user": "bmers",
        "closed_by": "bmers",
        "created_at": "2023-11-16T04:18:02+00:00",
        "updated_at": "2023-11-30T13:00:50+00:00",
        "closed_at": "2023-11-30T13:00:50+00:00",
        "comments_count": [
            "bmers",
            "bmers"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 840,
        "title": "昇腾910B训练PaddleDetection框架中的检测报错",
        "body": "![717db6e972750f30eb3a8960e27a43a9](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/45171399/e97cc87d-cd60-4b43-afc1-4ff9dd4291b9)\r\n\r\nvitbase+dino检测head，paddledet版本是2.6，如何解决",
        "state": "closed",
        "user": "Jeremy-lf",
        "closed_by": "qili93",
        "created_at": "2023-11-21T08:02:52+00:00",
        "updated_at": "2024-02-28T10:52:25+00:00",
        "closed_at": "2024-02-28T10:52:25+00:00",
        "comments_count": [
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 846,
        "title": "Paddle官方有提供cann7.0版本的镜像环境吗？",
        "body": "https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md，官方链接只有cann6.0.1",
        "state": "closed",
        "user": "ben1017-maker",
        "closed_by": "qili93",
        "created_at": "2023-12-05T01:57:59+00:00",
        "updated_at": "2024-02-05T08:53:14+00:00",
        "closed_at": "2024-02-05T08:53:14+00:00",
        "comments_count": [
            "BrightXiaoHan",
            "BrightXiaoHan",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 849,
        "title": "编译验证：ValueError: (InvalidArgument) The kernel arange_tensor is not ready for custom kernel registering. (at /paddle/paddle/phi/core/custom_kernel.cc:53)",
        "body": "安装这个指导https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md编译了安装包，在验证时报错。\r\n(py39) λ bms-98e4 /workspace/PaddleCustomDevice/backends/npu {develop} python -c \"import paddle; print(paddle.device.get_all_custom_device_type())\"\r\nI1009 17:56:38.029748  5132 init.cc:232] ENV [CUSTOM_DEVICE_ROOT]=/opt/py39/lib/python3.9/site-packages/paddle_custom_device\r\nI1009 17:56:38.029801  5132 init.cc:141] Try loading custom device libs from: [/opt/py39/lib/python3.9/site-packages/paddle_custom_device]\r\nI1009 17:56:42.466187  5132 custom_device.cc:1042] Successed in loading custom runtime in lib: /opt/py39/lib/python3.9/site-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/opt/py39/lib/python3.9/site-packages/paddle/__init__.py\", line 31, in <module>\r\n    from .framework import monkey_patch_variable\r\n  File \"/opt/py39/lib/python3.9/site-packages/paddle/framework/__init__.py\", line 17, in <module>\r\n    from . import random  # noqa: F401\r\n  File \"/opt/py39/lib/python3.9/site-packages/paddle/framework/random.py\", line 17, in <module>\r\n    from paddle import fluid\r\n  File \"/opt/py39/lib/python3.9/site-packages/paddle/fluid/__init__.py\", line 211, in <module>\r\n    __bootstrap__()\r\n  File \"/opt/py39/lib/python3.9/site-packages/paddle/fluid/__init__.py\", line 203, in __bootstrap__\r\n    core.init_devices()\r\nValueError: (InvalidArgument) The kernel arange_tensor is not ready for custom kernel registering. (at /paddle/paddle/phi/core/custom_kernel.cc:53)\r\n",
        "state": "closed",
        "user": "shirwy",
        "closed_by": "shirwy",
        "created_at": "2023-12-07T09:59:54+00:00",
        "updated_at": "2023-12-08T02:22:56+00:00",
        "closed_at": "2023-12-08T02:22:56+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 852,
        "title": "set_value算子bool类型报错",
        "body": "```c\r\nI1215 11:13:47.706383 259168 message_bus.cc:202] Message bus's listen port thread starts successful.\r\n/home/yuanwei/Page_PaddleNLP/PaddleNLP/paddlenlp/transformers/tokenizer_utils_base.py:1925: UserWarning: Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\r\n  warnings.warn(\r\nlength:  134\r\n-\r\nTraceback (most recent call last):\r\n  File \"/home/yuanwei/Page_PaddleNLP/PaddleNLP/llm/predictor.py\", line 1555, in <module>\r\n    predict()\r\n  File \"/home/yuanwei/Page_PaddleNLP/PaddleNLP/llm/predictor.py\", line 1497, in predict\r\n    outputs = predictor.predict(batch_source_text)\r\n  File \"/home/yuanwei/Page_PaddleNLP/PaddleNLP/llm/predictor.py\", line 1133, in predict\r\n    self._preprocess(input_texts)\r\n  File \"/home/yuanwei/Page_PaddleNLP/PaddleNLP/llm/predictor.py\", line 1174, in _preprocess\r\n    self.inputs[\"stop_flags\"][i : i + 1] = False\r\n  File \"/opt/py39/lib/python3.9/site-packages/paddle/base/dygraph/tensor_patch_methods.py\", line 797, in __setitem__\r\n    return self.__setitem_eager_tensor__(item, value)\r\nOSError: \r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   set_value__dygraph_function(paddle::Tensor&, paddle::Tensor const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::framework::AttributeMap const&)\r\n1   paddle::imperative::Tracer::TraceOp(std::string const&, paddle::imperative::NameTensorMap const&, paddle::imperative::NameTensorMap const&, paddle::framework::AttributeMap&, phi::Place const&, paddle::framework::AttributeMap*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)\r\n2   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::framework::AttributeMap&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, paddle::framework::AttributeMap*, bool)\r\n3   paddle::imperative::PreparedOp::Run(paddle::imperative::NameTensorMap const&, paddle::imperative::NameTensorMap const&, paddle::framework::AttributeMap const&, paddle::framework::AttributeMap const&)\r\n4   phi::KernelImpl<void (*)(phi::CustomContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<paddle::experimental::ScalarBase<phi::DenseTensor>, std::allocator<paddle::experimental::ScalarBase<phi::DenseTensor> > > const&, phi::DenseTensor*), &(void custom_kernel::SetValueNPUKernel<bool, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<paddle::experimental::ScalarBase<phi::DenseTensor>, std::allocator<paddle::experimental::ScalarBase<phi::DenseTensor> > > const&, phi::DenseTensor*))>::Compute(phi::KernelContext*)\r\n5   void custom_kernel::SetValueNPUKernel<bool, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<paddle::experimental::ScalarBase<phi::DenseTensor>, std::allocator<paddle::experimental::ScalarBase<phi::DenseTensor> > > const&, phi::DenseTensor*)\r\n6   void custom_kernel::SetTensorValueNPUKernel<bool, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)\r\n7   void custom_kernel::SetTensorValueNPUImplKernel<bool, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)\r\n8   NpuOpRunner::Run(void*, bool) const\r\n9   phi::enforce::EnforceNotMet::EnforceNotMet(phi::ErrorSummary const&, char const*, int)\r\n10  phi::enforce::GetCurrentTraceBackString[abi:cxx11](bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nExternalError:  ACL error, the error code is : 500002.  (at /home/yuanwei/PaddleCustomDevice/backends/npu/kernels/funcs/npu_op_runner.cc:628)\r\n  [operator < set_value > error]\r\nI1215 11:13:53.572939 259168 server.cpp:1167] Server[paddle::distributed::MessageServiceImpl] is going to quit\r\nLAUNCH INFO 2023-12-15 11:13:58,683 Pod failed\r\nLAUNCH ERROR 2023-12-15 11:13:58,683 Container failed !!!\r\nContainer rank 0 status failed cmd ['/opt/py39/bin/python', '-u', 'predictor.py', '--model_name_or_path', '/home/yuanwei/Page_PaddleNLP/PaddleNLP/llm/inference_model/llama_ptq_ckpts_smooth_all_shift_13b_mp2', '--dtype', 'float16', '--src_length', '1430', '--max_length', '330', '--output_file', 'infer.json', '--mode', 'static', '--batch_size', '10', '--block_size', '64', '--block_attn', '--inference_model'] code -11 log mp8/workerlog.0 \r\nenv {'GREP_COLOR': '1;31', 'ASDOPS_LOG_TO_BOOST_TYPE': 'atb', 'LC_ALL': 'en_US.UTF-8', 'LD_LIBRARY_PATH': '/opt/py39/lib/python3.9/site-packages/cv2/../../lib64:/home/yuanwei/gxh_atb/ascend-transformer-boost/output/atb/lib:/home/yuanwei/gxh_atb/ascend-transformer-boost/output/atb/examples:/usr/local/Ascend/atb/latest/atb/lib:/usr/local/Ascend/atb/latest/atb/examples:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/nnengine:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/opskernel:/usr/local/Ascend/ascend-toolkit/latest/lib64:/usr/local/Ascend/driver/lib64/driver:/usr/local/Ascend/driver/lib64/common:/usr/local/Ascend/driver/lib64:/opt/compiler/gcc-8.2/lib:/opt/compiler/gcc-8.2/lib64:', 'ASDOPS_TILING_PARSE_CACHE_DISABLE': '0', 'ASDOPS_OPS_PATH': '/home/yuanwei/gxh_atb/ascend-transformer-boost/output/atb/ops', 'TOOLCHAIN_HOME': '/usr/local/Ascend/ascend-toolkit/latest/toolkit', 'HCCL_WHITELIST_DISABLE': '1', 'ATB_OPSRUNNER_KERNEL_CACHE_LOCAL_COUNT': '1', 'ATB_OPSRUNNER_SETUP_CACHE_ENABLE': '1', 'LANG': 'en_US.UTF-8', 'ASCEND_GLOBAL_LOG_LEVEL': '3', 'HOSTNAME': 'localhost.localdomain', 'OLDPWD': '/home/yuanwei/PaddleCustomDevice/backends/npu', 'ASDOPS_LOG_TO_FILE_FLUSH': '0', 'FLAGS_allocator_strategy': 'naive_best_fit', 'FLAGS_control_flow_use_new_executor': '1', 'ATB_OPSRUNNER_KERNEL_CACHE_TILING_SIZE': '10240', 'ASDOPS_MATMUL_PP_FLAG': '1', 'PADDLE_XCCL_BACKEND': 'npu', 'ASDOPS_LOG_LEVEL': 'FATAL', 'ASCEND_AICPU_PATH': '/usr/local/Ascend/ascend-toolkit/latest', 'VIRTUAL_ENV': '/opt/py39', 'GLOG_logtostderr': 'true', 'ATB_HOST_TILING_BUFFER_BLOCK_NUM': '128', 'FLAGS_call_stack_level': '2', 'HCCL_SECURITY_MODE': '1', 'ASDOPS_LOG_TO_STDOUT': '0', 'ATB_LOG_TO_STDOUT': '0', 'PWD': '/home/yuanwei/Page_PaddleNLP/PaddleNLP/llm', 'HOME': '/root', 'ATB_SAVE_TENSOR_END': '1', 'CLICOLOR': '1', 'LCCL_ENABLE_FALLBACK': '1', 'WITH_ASCEND_TRANSFORMER_ACC': 'ON', 'ASDOPS_HOME_PATH': '/home/yuanwei/gxh_atb/ascend-transformer-boost/output/atb', 'FLAGS_fraction_of_gpu_memory_to_use': '0.92', 'ATB_WORKSPACE_MEM_ALLOC_GLOBAL': '0', 'ATB_LOG_TO_FILE': '0', 'GLOG_v': '0', 'FLAGS_npu_storage_format': '1', 'ATB_SAVE_TENSOR_RUNNER': '', 'ATB_STREAM_SYNC_EVERY_KERNEL_ENABLE': '0', 'FLAGS_new_executor_serial_run': '1', 'ATB_OPSRUNNER_KERNEL_CACHE_GLOABL_COUNT': '5', 'TERM': 'xterm', 'ASCEND_OPP_PATH': '/usr/local/Ascend/ascend-toolkit/latest/opp', 'ASCEND_CUSTOM_OPP_PATH': '/home/yuanwei/paddle_post_processALL_1025/build/pkg/vendors/aie_ascendc', 'HCCL_CONNECT_TIMEOUT': '7200', 'ASCEND_HOME_PATH': '/usr/local/Ascend/ascend-toolkit/latest', 'ATB_COMPARE_TILING_EVERY_KERNEL': '0', 'ATB_LOG_LEVEL': 'FATAL', 'ATB_SAVE_TENSOR_START': '0', 'SHLVL': '2', 'LANGUAGE': 'en_US.UTF-8', 'PYTHONPATH': '/home/yuanwei/Page_PaddleNLP/PaddleNLP:/usr/local/Ascend/ascend-toolkit/latest/opp/built-in/op_impl/ai_core/tbe:/usr/local/Ascend/ascend-toolkit/latest/python/site-packages:', 'ATB_SAVE_TENSOR': '0', 'ASCEND_RT_VISIBLE_DEVICES': '8,9', 'ATB_OPSRUNNER_KERNEL_CACHE_TYPE': '3', 'ATB_HOME_PATH': '/home/yuanwei/gxh_atb/ascend-transformer-boost/output/atb', 'ASCEND_SLOG_PRINT_TO_STDOUT': '0', 'ATB_WORKSPACE_MEM_ALLOC_ALG_TYPE': '1', 'ASDOPS_LOG_TO_FILE': '0', 'ATB_STREAM_SYNC_EVERY_OPERATION_ENABLE': '0', 'PATH': '/home/yuanwei/gxh_atb/ascend-transformer-boost/output/atb/bin:/usr/local/Ascend/atb/latest/atb/bin:/opt/py39/bin:/usr/local/Ascend/ascend-toolkit/latest/compiler/ccec_compiler/bin:/usr/local/Ascend/ascend-toolkit/latest/bin::/opt/py39/bin:/opt/cmake-3.19/bin:/opt/compiler/gcc-8.2/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'ATB_STREAM_SYNC_EVERY_RUNNER_ENABLE': '0', 'ATB_PROFILING_ENABLE': '0', '_': '/opt/py39/bin/python', 'CUSTOM_DEVICE_ROOT': '/opt/py39/lib/python3.9/site-packages/paddle_custom_device', 'OMP_NUM_THREADS': '1', 'QT_QPA_PLATFORM_PLUGIN_PATH': '/opt/py39/lib/python3.9/site-packages/cv2/qt/plugins', 'QT_QPA_FONTDIR': '/opt/py39/lib/python3.9/site-packages/cv2/qt/fonts', 'POD_NAME': 'mkapvs', 'PADDLE_MASTER': '127.0.0.1:39043', 'PADDLE_GLOBAL_SIZE': '2', 'PADDLE_LOCAL_SIZE': '2', 'PADDLE_GLOBAL_RANK': '0', 'PADDLE_LOCAL_RANK': '0', 'PADDLE_NNODES': '1', 'PADDLE_CURRENT_ENDPOINT': '127.0.0.1:39044', 'PADDLE_TRAINER_ID': '0', 'PADDLE_TRAINERS_NUM': '2', 'PADDLE_RANK_IN_NODE': '0', 'PADDLE_TRAINER_ENDPOINTS': '127.0.0.1:39044,127.0.0.1:39045', 'PADDLE_DISTRI_BACKEND': 'xccl', 'FLAGS_selected_npus': '0', 'PADDLE_LOG_DIR': '/home/yuanwei/Page_PaddleNLP/PaddleNLP/llm/mp8'}\r\nLAUNCH INFO 2023-12-15 11:13:58,683 ------------------------- ERROR LOG DETAIL -------------------------\r\nstd::allocator<paddle::experimental::ScalarBase<phi::DenseTensor> > > const&, phi::DenseTensor*), &(void custom_kernel::SetValueNPUKernel<bool, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<paddle::experimental::ScalarBase<phi::DenseTensor>, std::allocator<paddle::experimental::ScalarBase<phi::DenseTensor> > > const&, phi::DenseTensor*))>::Compute(phi::KernelContext*)\r\n5   void custom_kernel::SetValueNPUKernel<bool, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<paddle::experimental::ScalarBase<phi::DenseTensor>, std::allocator<paddle::experimental::ScalarBase<phi::DenseTensor> > > const&, phi::DenseTensor*)\r\n6   void custom_kernel::SetTensorValueNPUKernel<bool, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)\r\n7   void custom_kernel::SetTensorValueNPUImplKernel<bool, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)\r\n8   NpuOpRunner::Run(void*, bool) const\r\n9   phi::enforce::EnforceNotMet::EnforceNotMet(phi::ErrorSummary const&, char const*, int)\r\n10  phi::enforce::GetCurrentTraceBackString[abi:cxx11](bool)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nExternalError:  ACL error, the error code is : 500002.  (at /home/yuanwei/PaddleCustomDevice/backends/npu/kernels/funcs/npu_op_runner.cc:628)\r\n  [operator < set_value > error]\r\nI1215 11:13:53.572939 259168 server.cpp:1167] Server[paddle::distributed::MessageServiceImpl] is going to quit\r\nLAUNCH INFO 2023-12-15 11:13:58,683 Exit code -11\r\n\r\n```",
        "state": "closed",
        "user": "bmers",
        "closed_by": "bmers",
        "created_at": "2023-12-15T03:22:15+00:00",
        "updated_at": "2023-12-20T12:47:26+00:00",
        "closed_at": "2023-12-20T12:47:26+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 850,
        "title": "npu编译报错：error: ‘StringToDataLayout’ is not a member of ‘phi’",
        "body": "按照https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md\r\n指导编译时报错\r\n/workspace/PaddleCustomDevice/backends/npu/kernels/batch_norm_kernel.cc: In function ‘void custom_kernel::BatchNormKernel(const Context&, const phi::DenseTensor&, const phi::DenseTensor&, const phi::DenseTensor&, const paddle::optional<phi::DenseTensor>&, const paddle::optional<phi::DenseTensor>&, bool, float, float, const string&, bool, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)’:\r\n/workspace/PaddleCustomDevice/backends/npu/kernels/batch_norm_kernel.cc:64:33: error: ‘StringToDataLayout’ is not a member of ‘phi’\r\n   const auto data_layout = phi::StringToDataLayout(data_layout_str);\r\n                                 ^~~~~~~~~~~~~~~~~~\r\n/workspace/PaddleCustomDevice/backends/npu/kernels/batch_norm_kernel.cc:64:33: note: suggested alternative: ‘DataLayout’\r\n   const auto data_layout = phi::StringToDataLayout(data_layout_str);\r\n                                 ^~~~~~~~~~~~~~~~~~\r\n                                 DataLayout\r\n/workspace/PaddleCustomDevice/backends/npu/kernels/batch_norm_kernel.cc: In function ‘void custom_kernel::BatchNormGradKernel(const Context&, const phi::DenseTensor&, const paddle::optional<phi::DenseTensor>&, const paddle::optional<phi::DenseTensor>&, const paddle::optional<phi::DenseTensor>&, const paddle::optional<phi::DenseTensor>&, const phi::DenseTensor&, const phi::DenseTensor&, const paddle::optional<phi::DenseTensor>&, const phi::DenseTensor&, float, float, const string&, bool, bool, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)’:\r\n/workspace/PaddleCustomDevice/backends/npu/kernels/batch_norm_kernel.cc:311:33: error: ‘StringToDataLayout’ is not a member of ‘phi’\r\n   const auto data_layout = phi::StringToDataLayout(data_layout_str);\r\n                                 ^~~~~~~~~~~~~~~~~~\r\n/workspace/PaddleCustomDevice/backends/npu/kernels/batch_norm_kernel.cc:311:33: note: suggested alternative: ‘DataLayout’\r\n   const auto data_layout = phi::StringToDataLayout(data_layout_str);\r\n                                 ^~~~~~~~~~~~~~~~~~\r\n                                 DataLayout\r\nCMakeFiles/paddle-custom-npu.dir/build.make:276: recipe for target 'CMakeFiles/paddle-custom-npu.dir/kernels/batch_norm_kernel.cc.o' failed\r\nmake[2]: *** [CMakeFiles/paddle-custom-npu.dir/kernels/batch_norm_kernel.cc.o] Error 1\r\nmake[2]: *** Waiting for unfinished jobs....\r\nCMakeFiles/Makefile2:109: recipe for target 'CMakeFiles/paddle-custom-npu.dir/all' failed\r\nmake[1]: *** [CMakeFiles/paddle-custom-npu.dir/all] Error 2\r\nMakefile:102: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n+ make_error=2\r\n+ '[' 2 '!=' 0 ']'\r\n+ echo 'Make Error Found !!!'\r\nMake Error Found !!!\r\n+ exit 7\r\n",
        "state": "closed",
        "user": "shirwy",
        "closed_by": "qili93",
        "created_at": "2023-12-08T02:24:11+00:00",
        "updated_at": "2024-02-04T06:32:30+00:00",
        "closed_at": "2024-02-04T06:32:30+00:00",
        "comments_count": [
            "duyongtju",
            "duyongtju",
            "study-hard-forever",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 856,
        "title": "求助算子属性不会跟随输入改变",
        "body": "rebuild_padding_v2算子中，有一个max_input_length属性，图中值为1430\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/29788896/de7d2daa-c145-4ffb-9b61-b8437e9ef196)\r\n该1430具体是，从参数kwargs[\"max_input_length\"]读取到的，具体与export静态图时设置的输入长度src_length有关。\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/29788896/182dfc77-396f-42bb-9122-478ef0dde53a)\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/29788896/f238fb8b-21cb-40ba-9128-7ed8eb7f97eb)\r\n\r\n实际使用这个静态图运行时，如果给src_length与导出export时设置的不一样，这个max_input_length属性并不会跟随输入改变，还是1430。\r\n如果我将组网代码修改一下，尝试从input_ids的shape中获取max_input_length信息时，导出模型又会报错。\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/29788896/f3eef19b-48d2-485f-b120-e4edf29b0dfc)\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/29788896/b57f2702-538a-47b0-8fbd-99bf7e208480)\r\n\r\n",
        "state": "closed",
        "user": "bmers",
        "closed_by": "qili93",
        "created_at": "2023-12-20T13:06:36+00:00",
        "updated_at": "2024-04-15T02:13:51+00:00",
        "closed_at": "2024-04-15T02:13:50+00:00",
        "comments_count": [
            "bmers",
            "bmers",
            "bmers",
            "bmers",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 882,
        "title": "如何限制进程npu最大内存占用量",
        "body": "现在加载一个模型默认会把一个npu的内存占满。mindspore中可以通过设置\r\n```\r\nimport mindspore as ms\r\nms.set_context(max_device_memory=\"1GB\")\r\n```\r\n进行限制，paddle中是否可以进行类似的设置？",
        "state": "closed",
        "user": "BrightXiaoHan",
        "closed_by": "BrightXiaoHan",
        "created_at": "2024-01-08T15:08:41+00:00",
        "updated_at": "2024-01-09T01:44:58+00:00",
        "closed_at": "2024-01-08T16:17:38+00:00",
        "comments_count": [
            "BrightXiaoHan",
            "BrightXiaoHan"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 878,
        "title": "paddle-npu编译镜像device/paddle-npu:cann700-910B-ubuntu18-aarch64无法下载",
        "body": "文档地址：https://github.com/PaddlePaddle/PaddleCustomDevice/tree/develop/backends/npu\r\n镜像地址：registry.baidubce.com/device/paddle-npu:cann700-910B-ubuntu18-aarch64\r\n无法下载，报错信息：\r\nError response from daemon: manifest for registry.baidubce.com/device/paddle-npu:cann700-910B-ubuntu18-aarch64 not found: manifest unknown: manifest unknown\r\n\r\n",
        "state": "closed",
        "user": "2022WPJ",
        "closed_by": "qili93",
        "created_at": "2024-01-05T05:15:39+00:00",
        "updated_at": "2024-02-05T08:53:24+00:00",
        "closed_at": "2024-02-05T08:53:24+00:00",
        "comments_count": [
            "BrightXiaoHan",
            "2022WPJ",
            "BrightXiaoHan",
            "qili93",
            "2022WPJ",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 920,
        "title": "registry.baidubce.com/device/paddle-npu:cann700-910B-ubuntu18-aarch64 镜像不存在",
        "body": "docker pull registry.baidubce.com/device/paddle-npu:cann700-910B-ubuntu18-aarch64\r\n\r\n镜像不存在！！！！！！\r\nError response from daemon: manifest for registry.baidubce.com/device/paddle-npu:cann700-910B-ubuntu18-aarch64 not found: manifest unknown: manifest unknown",
        "state": "closed",
        "user": "bigbosskai",
        "closed_by": "qili93",
        "created_at": "2024-01-26T05:36:34+00:00",
        "updated_at": "2024-02-05T08:53:32+00:00",
        "closed_at": "2024-02-05T08:53:32+00:00",
        "comments_count": [
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 922,
        "title": "PaddleCustomDevice仓自定义融合算子的Infershape函数问题",
        "body": "Hi，请教一下，当前想在推理场景下实现一些自定义的融合算子，但是在写Infershape时有点Confuse，不知道该如何定义Infershape函数，因为需要知道每个算子的属性、输入shape才能进行推导。在CustomDevice仓只看到了一个my_add_n的自定义算子推导，不是很详细，有没有更详细一点的示例供参考，谢谢！\r\n",
        "state": "closed",
        "user": "wanx7130",
        "closed_by": "qili93",
        "created_at": "2024-01-29T02:50:44+00:00",
        "updated_at": "2024-02-22T03:01:03+00:00",
        "closed_at": "2024-02-22T03:01:03+00:00",
        "comments_count": [
            "ronny1996",
            "wanx7130",
            "wanx7130",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 958,
        "title": "notebook import paddle报错",
        "body": "在控制台 /opt/py39/bin/python -c \"import paddle\" 能正确执行",
        "state": "closed",
        "user": "bigbosskai",
        "closed_by": "bigbosskai",
        "created_at": "2024-02-19T07:07:37+00:00",
        "updated_at": "2024-02-19T07:08:12+00:00",
        "closed_at": "2024-02-19T07:08:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 923,
        "title": "paddle custom device中接入multiclass_nms3时，custom_device在静态图执行器下无法正确识别输出tensor数据",
        "body": "paddle custom device中接入multiclass_nms3时，主框架UT中有一个[NoOutput测例](https://github.com/PaddlePaddle/Paddle/blob/develop/test/legacy_test/test_multiclass_nms_op.py#L792)，自定义算子接入UT时加上这个测例时，无法成功识别output和index的数据，识别为None。\r\n\r\n自定义算子输出信息：\r\n<img width=\"520\" alt=\"ef3643ca92a76703861ae65e260a6aa2\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/87294783/18015c1e-9bc8-4d2f-923a-d03cb617123e\">\r\n\r\nCPU算子输出信息：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/87294783/31a7cf38-e46e-4d67-829c-7416519f5043)\r\n\r\n\r\n打开GLOG_V=10，两者主框架侧输出信息tensor信息如下：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/87294783/cc732c41-59fe-4e03-b146-b13bcdc85102)\r\n\r\n最小复现代码，可以直接在multiclass_nms3_kernel.cc自定义注册算子中：\r\n```\r\nout->Resize({0, 6});\r\nctx.template Alloc<T>(out);\r\n\r\nindex->Resize({0, 1});\r\nctx.template Alloc<int>(index);\r\n```\r\n\r\n",
        "state": "closed",
        "user": "zepingWww",
        "closed_by": "qili93",
        "created_at": "2024-01-29T07:43:00+00:00",
        "updated_at": "2024-03-01T02:39:30+00:00",
        "closed_at": "2024-02-22T03:01:33+00:00",
        "comments_count": [
            "ronny1996",
            "zepingWww",
            "ronny1996",
            "qili93",
            "zepingWww",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 959,
        "title": "【NPU】notebook import paddle 报错",
        "body": "在控制台 /opt/py39/bin/python -c \"import paddle\" 能正确执行\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/27066989/3aa0b605-0131-4299-b452-b10999ffa45e)\r\n但是在notebook中\r\nimport paddle就 不行了\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/27066989/b7cf2df6-3946-4e17-b789-48752bb51a7c)\r\n\r\nPATH\r\nLD_LIBRARY_PATH\r\n等环境变量，notebook和控制台都是一致的",
        "state": "closed",
        "user": "bigbosskai",
        "closed_by": "qili93",
        "created_at": "2024-02-19T07:10:53+00:00",
        "updated_at": "2024-02-26T09:59:09+00:00",
        "closed_at": "2024-02-26T09:59:09+00:00",
        "comments_count": [
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 965,
        "title": "昇腾310上对PaddlePaddle进行编译失败",
        "body": "是否支持在昇腾310上对PaddlePaddle进行编译？CANN版本应该怎么选？是否有对应的编译环境镜像",
        "state": "closed",
        "user": "wuys1",
        "closed_by": "qili93",
        "created_at": "2024-02-22T03:58:35+00:00",
        "updated_at": "2024-08-23T08:58:38+00:00",
        "closed_at": "2024-03-21T12:22:36+00:00",
        "comments_count": [
            "qili93",
            "qili93",
            "wuys1",
            "qili93",
            "dianziMAN"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1176,
        "title": "拉取镜像失败！docker pull registry.baidubce.com/device/paddle-npu:cann80T2-910A-ubuntu18-aarch64",
        "body": "Error response from daemon: manifest for registry.baidubce.com/device/paddle-npu:cann80T2-910A-ubuntu18-aarch64 not found: manifest unknown: manifest unknown",
        "state": "closed",
        "user": "Jakin-huang",
        "closed_by": "Jakin-huang",
        "created_at": "2024-04-24T04:20:50+00:00",
        "updated_at": "2024-04-24T05:47:40+00:00",
        "closed_at": "2024-04-24T05:47:40+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 994,
        "title": "PaddleSeg模型跑训练报错，OSError:(External)ACL error,the error code is:500002",
        "body": "## 1，环境\r\n昇腾910b\r\ncann7.0\r\n官方镜像registry.baidubce.com/device/paddle-npu:cann701-910B-ubuntu18-aarch64\r\npaddleseg版本2.9\r\n## 2，训练启动命令\r\ncd ./contrib/PP-HumanSeg\r\npython ../../tools/train.py --config configs/human_pp_humansegv2_lite.yml --save_dir output/human_pp_humansegv2_lite --save_interval 100 --do_eval --use_vdl  --device npu\r\n## 3，问题\r\n![5cdc13966a3f2799ef716faa1b340a2](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/88080704/5d75a881-d4b0-442a-ad87-9d9e35dc0c72)\r\n报错OSError:(External)ACL error,the error code is:500002\r\n",
        "state": "closed",
        "user": "PlayerJian",
        "closed_by": "YanhuiDua",
        "created_at": "2024-03-11T03:06:12+00:00",
        "updated_at": "2024-04-01T11:51:04+00:00",
        "closed_at": "2024-04-01T11:51:04+00:00",
        "comments_count": [
            "YanhuiDua",
            "YanhuiDua",
            "qili93",
            "PlayerJian",
            "PlayerJian",
            "PlayerJian",
            "PlayerJian",
            "YanhuiDua",
            "PlayerJian",
            "YanhuiDua",
            "PlayerJian",
            "YanhuiDua",
            "YanhuiDua",
            "PlayerJian",
            "YanhuiDua",
            "PlayerJian",
            "YanhuiDua",
            "PlayerJian",
            "YanhuiDua",
            "PlayerJian",
            "YanhuiDua",
            "PlayerJian",
            "YanhuiDua",
            "PlayerJian",
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1030,
        "title": "unittests 报错 No module named 'tests.op_test'",
        "body": "执行命令：\r\ncd PaddleCustomDevice/backends/mlu\r\nbash tools/compile.sh\r\ncd build && ctest -R test_arg_max_op_mlu -V\r\n\r\n报错：\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/135964669/669aecc0-61d4-4386-9f83-01866cbe409d)\r\n\r\n请问怎么解决？",
        "state": "closed",
        "user": "PeiyuLau",
        "closed_by": "YanhuiDua",
        "created_at": "2024-03-20T03:26:35+00:00",
        "updated_at": "2024-03-29T08:49:05+00:00",
        "closed_at": "2024-03-29T08:49:05+00:00",
        "comments_count": [
            "qili93",
            "PeiyuLau"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1035,
        "title": "Apple M2 环境CMake 构建失败",
        "body": "环境：macbook air m2\r\nPython 版本：3.10.13\r\n参考[教程](https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/mps/README.md)执行，构建失败，报错日志如下：\r\n```\r\n-- Found Python: /opt/miniconda3/envs/wiring/bin/python3.10 (found suitable version \"3.10.13\", required range is \"3.10...<3.11\") found components: Interpreter Development Development.Module Development.Embed\r\nWANRINGCannot find core_avx.so, using core_noavx.so instead.\r\nFATALcore_noavx.so NOT found in /opt/miniconda3/envs/wiring/lib/python3.10/site-packages/paddle/fluid/\r\nCMake Error at build/third_party/gflags/tmp/extern_gflags-mkdirs.cmake:6 (file):\r\n  file failed to create directory:\r\n\r\n    /third_party/gflags\r\n\r\n  because: No such file or directory\r\nCall Stack (most recent call first):\r\n  /opt/homebrew/Cellar/cmake/3.28.3/share/cmake/Modules/ExternalProject.cmake:1790 (include)\r\n  /opt/homebrew/Cellar/cmake/3.28.3/share/cmake/Modules/ExternalProject.cmake:4354 (_ep_set_directories)\r\n  cmake/external/gflags.cmake:64 (ExternalProject_Add)\r\n  cmake/third_party.cmake:27 (include)\r\n  CMakeLists.txt:69 (include)\r\n\r\n\r\nCMake Error at /opt/homebrew/Cellar/cmake/3.28.3/share/cmake/Modules/ExternalProject.cmake:3235 (message):\r\n  No download info given for 'extern_gflags' and its source directory:\r\n\r\n   /third_party/gflags\r\n\r\n  is not an existing non-empty directory.  Please specify one of:\r\n\r\n   * SOURCE_DIR with an existing non-empty directory\r\n   * DOWNLOAD_COMMAND\r\n   * URL\r\n   * GIT_REPOSITORY\r\n   * SVN_REPOSITORY\r\n   * HG_REPOSITORY\r\n   * CVS_REPOSITORY and CVS_MODULE\r\nCall Stack (most recent call first):\r\n  /opt/homebrew/Cellar/cmake/3.28.3/share/cmake/Modules/ExternalProject.cmake:4418 (_ep_add_download_command)\r\n  cmake/external/gflags.cmake:64 (ExternalProject_Add)\r\n  cmake/third_party.cmake:27 (include)\r\n  CMakeLists.txt:69 (include)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\n```",
        "state": "closed",
        "user": "tongda",
        "closed_by": "qili93",
        "created_at": "2024-03-21T06:53:15+00:00",
        "updated_at": "2024-04-15T02:10:38+00:00",
        "closed_at": "2024-04-15T02:10:38+00:00",
        "comments_count": [
            "qili93",
            "lishicheng1996",
            "tongda",
            "ronny1996",
            "ronny1996",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1118,
        "title": "[NPU]paddle适配昇腾910B推理没有cpu快",
        "body": "paddle相关库版本如下：\r\n![截屏2024-04-08 12 45 50](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/64243381/dd110bb0-ab92-48b1-bc36-3b55c56b1470)\r\n\r\nnpu-smi信息如下：\r\n![截屏2024-04-08 12 51 06](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/64243381/dd9f97ed-f7a9-42f5-90ce-bffc8455f945)\r\n\r\n如题，相同的代码，使用npu启动，推理延时很高，比cpu启动的时候还要高。并且输入新的文本信息进行推理时，就如同第一次推理一样，需要30-50s。\r\n\r\n下面是我用npu启动，推理的一些延时截图\r\n![npu](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/64243381/8247d6bc-150f-49da-803a-b4fa7ea334d1)\r\n\r\n\r\n下图是cpu启动的推理延时截图\r\n![cpu](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/64243381/ca8622e9-4e33-4ae9-90de-052df2308322)\r\n\r\n\r\n下面是我使用paddle.inference.Config设置npu的截图\r\n![截屏2024-04-08 12 42 48](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/64243381/df9043da-77cd-409b-9bd5-e6e52e95aa86)\r\n\r\n\r\n求懂paddle-npu的大佬帮忙看看是哪里不对劲吧！！！\r\n\r\n",
        "state": "closed",
        "user": "wietisson",
        "closed_by": "qili93",
        "created_at": "2024-04-08T05:01:14+00:00",
        "updated_at": "2024-05-30T10:08:16+00:00",
        "closed_at": "2024-05-09T03:15:09+00:00",
        "comments_count": [
            "qili93",
            "wietisson",
            "qili93",
            "HeChangHaoGary",
            "qili93",
            "HeChangHaoGary",
            "qili93",
            "danyXu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1135,
        "title": "[mlu]训练transformer时直接系统卡死，cpu softlock",
        "body": "![微信截图_20240411174040](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/60912796/8be9ba5d-5daf-416f-97bc-ac10aca6eba2)\r\n",
        "state": "closed",
        "user": "robvoid",
        "closed_by": "robvoid",
        "created_at": "2024-04-11T09:42:23+00:00",
        "updated_at": "2024-05-23T07:02:57+00:00",
        "closed_at": "2024-05-23T07:02:08+00:00",
        "comments_count": [
            "qili93",
            "robvoid",
            "qili93",
            "robvoid",
            "robvoid",
            "robvoid",
            "qili93",
            "ShawnNew",
            "qili93",
            "robvoid",
            "qili93",
            "robvoid",
            "robvoid"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1177,
        "title": "华为910A 编译报错：include \"unsupported/Eigen/CXX11/Tensor",
        "body": "/opt/py39/lib/python3.9/site-packages/paddle/include/paddle/phi/kernels/funcs/eigen/extensions.h:23:10: fatal error: unsupported/Eigen/CXX11/Tensor: No such file or directory\r\n #include \"unsupported/Eigen/CXX11/Tensor\"\r\n          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\nCMakeFiles/paddle-custom-npu.dir/build.make:257: recipe for target 'CMakeFiles/paddle-custom-npu.dir/kernels/argsort_kernel.cc.o' failed\r\nmake[2]: *** [CMakeFiles/paddle-custom-npu.dir/kernels/argsort_kernel.cc.o] Error 1\r\nCMakeFiles/paddle-custom-npu.dir/build.make:453: recipe for target 'CMakeFiles/paddle-custom-npu.dir/kernels/contiguous_kernel.cc.o' failed\r\nmake[2]: *** [CMakeFiles/paddle-custom-npu.dir/kernels/contiguous_kernel.cc.o] Error 1\r\nCMakeFiles/paddle-custom-npu.dir/build.make:439: recipe for target 'CMakeFiles/paddle-custom-npu.dir/kernels/concat_kernel.cc.o' failed\r\nmake[2]: *** [CMakeFiles/paddle-custom-npu.dir/kernels/concat_kernel.cc.o] Error 1\r\nCMakeFiles/paddle-custom-npu.dir/build.make:173: recipe for target 'CMakeFiles/paddle-custom-npu.dir/kernels/add_n_kernel.cc.o' failed\r\nmake[2]: *** [CMakeFiles/paddle-custom-npu.dir/kernels/add_n_kernel.cc.o] Error 1\r\nCMakeFiles/paddle-custom-npu.dir/build.make:411: recipe for target 'CMakeFiles/paddle-custom-npu.dir/kernels/coalesce_tensor_kernel.cc.o' failed\r\nmake[2]: *** [CMakeFiles/paddle-custom-npu.dir/kernels/coalesce_tensor_kernel.cc.o] Error 1\r\nCMakeFiles/Makefile2:159: recipe for target 'CMakeFiles/paddle-custom-npu.dir/all' failed\r\nmake[1]: *** [CMakeFiles/paddle-custom-npu.dir/all] Error 2\r\nMakefile:100: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n+ make_error=2\r\n+ '[' 2 '!=' 0 ']'\r\n+ echo 'Make Error Found !!!'\r\nMake Error Found !!!\r\n+ exit 7",
        "state": "closed",
        "user": "Jakin-huang",
        "closed_by": "qili93",
        "created_at": "2024-04-24T06:56:37+00:00",
        "updated_at": "2024-05-20T07:42:57+00:00",
        "closed_at": "2024-05-20T07:42:57+00:00",
        "comments_count": [
            "Jakin-huang",
            "YanhuiDua",
            "parap1uie-s",
            "YanhuiDua",
            "parap1uie-s",
            "YanhuiDua",
            "Jakin-huang",
            "YanhuiDua",
            "YanhuiDua",
            "parap1uie-s",
            "YanhuiDua",
            "parap1uie-s",
            "YanhuiDua",
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1178,
        "title": "能否在readme中提供有效、稳定、可使用的镜像仓库地址，以及不同设备的不同驱动镜像列表（以：npu为例不同驱动版本的镜像列表）。",
        "body": "docker pull registry.baidubce.com/device/paddle-npu:cann700-910A-ubuntu18-aarch64 拉取镜像失败\r\n![image](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/17819399/304669c1-687f-46f6-a338-55b3338af072)\r\n",
        "state": "closed",
        "user": "Jakin-huang",
        "closed_by": "qili93",
        "created_at": "2024-04-25T01:03:27+00:00",
        "updated_at": "2024-05-22T02:19:37+00:00",
        "closed_at": "2024-05-22T02:19:37+00:00",
        "comments_count": [
            "YanhuiDua",
            "YanhuiDua",
            "Jakin-huang",
            "YanhuiDua",
            "Jakin-huang",
            "YanhuiDua",
            "qili93",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1213,
        "title": "[NPU] paddlespeech 报错 ACL error, the error code is : 500002",
        "body": "Name: paddlepaddle\r\nVersion: 2.5.2\r\nPaddleCustomDevice版本：2.5/release\r\npaddlespeech版本：1.4.1\r\nNPU版本\r\n<img width=\"1270\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/11511900/ee81d820-ae29-40be-9d95-b42de45b57a3\">\r\n\r\n\r\npaddle不用最新版本因为paddlespeech在高版本会有如下问题 https://github.com/PaddlePaddle/PaddleSpeech/issues/3665\r\n\r\n调用 paddlespeech 生成\r\npaddlespeech tts --input \"你好，欢迎使用百度飞桨深度学习框架！\" --output output.wav\r\nI0508 10:08:12.738766 81469 init.cc:232] ENV [CUSTOM_DEVICE_ROOT]=/ssddata/data1/hbr/pp/lib/python3.9/site-packages/paddle_custom_device\r\nI0508 10:08:12.738832 81469 init.cc:141] Try loading custom device libs from: [/ssddata/data1/hbr/pp/lib/python3.9/site-packages/paddle_custom_device]\r\nI0508 10:08:13.713307 81469 custom_device.cc:1042] Successed in loading custom runtime in lib: /ssddata/data1/hbr/pp/lib/python3.9/site-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI0508 10:08:13.724445 81469 custom_kernel.cc:76] Successed in loading 294 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0508 10:08:13.724625 81469 init.cc:153] Finished in LoadCustomDevice with libs_path: [/ssddata/data1/hbr/pp/lib/python3.9/site-packages/paddle_custom_device]\r\nI0508 10:08:13.724697 81469 init.cc:238] CustomDevice: npu, visible devices count: 1\r\n/ssddata/data1/hbr/pp/lib/python3.9/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\r\n  warnings.warn(\"Setuptools is replacing distutils.\")\r\nOSError: (External)  ACL error, the error code is : 500002.  (at /ssddata/data1/hbr/PaddleCustomDevice/backends/npu/kernels/funcs/npu_op_runner.cc:646)\r\n  [operator < set_value > error]",
        "state": "closed",
        "user": "cynicgit",
        "closed_by": "ronny1996",
        "created_at": "2024-05-08T02:23:26+00:00",
        "updated_at": "2024-05-17T05:20:50+00:00",
        "closed_at": "2024-05-17T05:20:50+00:00",
        "comments_count": [
            "cynicgit",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1214,
        "title": "[NPU] 昇腾910B arm, run_check时报  ACL error, the error code is : 500001",
        "body": "<img width=\"1305\" alt=\"image\" src=\"https://github.com/PaddlePaddle/PaddleCustomDevice/assets/11511900/481f1c1b-fce5-4595-96e7-e563d88e1f27\">\r\npaddlepaddle 和 PaddleCustomDevice都是develop分支版本",
        "state": "closed",
        "user": "cynicgit",
        "closed_by": "ronny1996",
        "created_at": "2024-05-08T02:32:18+00:00",
        "updated_at": "2024-05-17T05:20:32+00:00",
        "closed_at": "2024-05-17T05:20:32+00:00",
        "comments_count": [
            "ronny1996",
            "cynicgit",
            "ronny1996",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1271,
        "title": "执行编译时报错",
        "body": "+++ dirname tools/compile.sh\r\n++ cd tools/../\r\n++ pwd\r\n+ SOURCE_ROOT=/Work/PaddleCustomDevice/backends/npu\r\n+ mkdir -p /Work/PaddleCustomDevice/backends/npu/build\r\n+ cd /Work/PaddleCustomDevice/backends/npu/build\r\n++ uname -i\r\n+ arch=aarch64\r\n+ '[' aarch64 == x86_64 ']'\r\n+ WITH_MKL=OFF\r\n+ WITH_ARM=ON\r\n+ WITH_ATB=OFF\r\n+ '[' -n '' ']'\r\n+ cat\r\n========================================\r\nConfiguring cmake in build ...\r\n    -DCMAKE_BUILD_TYPE=Release\r\n    -DWITH_TESTING=OFF\r\n    -DWITH_MKL=OFF\r\n    -DWITH_ARM=ON\r\n    -DWITH_ATB=OFF\r\n    -DON_INFER=OFF\r\n    -DWITH_COVERAGE=OFF\r\n========================================\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_TESTING=OFF -DWITH_MKL=OFF -DWITH_ARM=ON -DWITH_ATB=OFF -DON_INFER=OFF -DWITH_COVERAGE=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\nWANRINGCannot find core_avx.so, using core_noavx.so instead.\r\nFATALcore_noavx.so NOT found in /usr/local/python3.7.5/lib/python3.7/site-packages/paddle/base/\r\n-- Run 'git submodule update --init Paddle' in /Work/PaddleCustomDevice\r\n-- PADDLE_SOURCE_DIR=/Work/PaddleCustomDevice/Paddle\r\n-- Paddle version is 0.0.0\r\n-- FWKACLLIB_INC_DIR /usr/local/Ascend/ascend-toolkit/latest/fwkacllib/include\r\n-- ASCEND_CL_DIR /usr/local/Ascend/ascend-toolkit/latest/fwkacllib/lib64\r\n-- ATB_INC_DIR /usr/local/Ascend/atb/latest/atb/include\r\n-- Current Ascend Toolkit version is 5.1.RC2\r\n-- Current Ascend Driver version is 20.1.0\r\n-- CXX compiler: /usr/bin/c++, version: GNU 7.5.0\r\n-- C compiler: /usr/bin/cc, version: GNU 7.5.0\r\n-- AR tools: /usr/bin/ar\r\n-- CMAKE_CXX_FLAGS:  -Wno-narrowing -Wno-terminate -Wno-write-strings -Wno-return-type -D_GLIBCXX_USE_CXX11_ABI=1\r\n-- CUSTOM_OPERATOR_SRCS=custom_op/fused_allgather_mm.cc;custom_op/fused_attention_npu.cc;custom_op/fused_mm_allreduce.cc;custom_op/fused_mm_reduce_scatter.cc;custom_op/fused_rms_norm_npu.cc;custom_op/fused_rope_npu.cc;custom_op/llama_infer/atb_ops/atb_layers/fused_blha_layer.cc;custom_op/llama_infer/atb_ops/atb_layers/fused_lm_head_layer.cc;custom_op/llama_infer/atb_ops/atb_layers/linear.cc;custom_op/llama_infer/atb_ops/atb_layers/mixed_gate_up_act.cc;custom_op/llama_infer/atb_ops/atb_layers/qkv_split.cc;custom_op/llama_infer/atb_ops/atb_layers/runner.cc;custom_op/llama_infer/atb_ops/atb_layers/smooth_quant.cc;custom_op/llama_infer/atb_ops/fused_blha_layer_op.cc;custom_op/llama_infer/atb_ops/fused_blha_layer_op_utils.cc;custom_op/llama_infer/atb_ops/fused_lm_head_op.cc;custom_op/llama_infer/atb_ops/remove_padding_op.cc;custom_op/llama_infer/dequant_int8.cc;custom_op/llama_infer/encode_rotary_qk.cc;custom_op/llama_infer/fused_get_rope.cc;custom_op/llama_infer/get_output.cc;custom_op/llama_infer/get_padding_offset.cc;custom_op/llama_infer/get_padding_offset_v2.cc;custom_op/llama_infer/qkv_transpose_split.cc;custom_op/llama_infer/quant_int8.cc;custom_op/llama_infer/rebuild_padding.cc;custom_op/llama_infer/rebuild_padding_v2.cc;custom_op/llama_infer/save_with_output.cc;custom_op/llama_infer/save_with_output_msg.cc;custom_op/llama_infer/set_value_by_flags.cc;custom_op/llama_infer/set_value_by_flags_v2.cc;custom_op/llama_infer/step.cc;custom_op/llama_infer/stop_generation_multi_ends.cc;custom_op/llama_infer/stop_generation_multi_ends_v2.cc;custom_op/llama_infer/token_penalty_multi_scores.cc;custom_op/llama_infer/token_penalty_multi_scores_v2.cc;custom_op/llama_infer/transpose_removing_padding.cc;custom_op/llama_infer/update_inputs.cc;custom_op/llama_infer/write_cache_kv.cc;custom_op/llama_infer/write_int8_cache_kv.cc;custom_op/my_add_n_op.cc\r\n-- Run 'git submodule update --init gflags' in /Work/PaddleCustomDevice/Paddle/third_party\r\n-- Run 'git submodule update --init glog' in /Work/PaddleCustomDevice/Paddle/third_party\r\n-- Run 'git submodule update --init pybind' in /Work/PaddleCustomDevice/Paddle/third_party\r\n-- Git commit id is: 9d318133d512a963550aa31f92efc7bf9e2fc469\r\n-- Custom op git commit id is: 9d318133d512a963550aa31f92efc7bf9e2fc469\r\n-- Configuring done (0.5s)\r\nCMake Error: The following variables are used in this project, but they are set to NOTFOUND.\r\nPlease set them or make sure they are set and tested correctly in the CMake files:\r\nPADDLE_CORE_LIB\r\n    linked by target \"paddle-custom-npu\" in directory /Work/PaddleCustomDevice/backends/npu\r\n\r\n-- Generating done (0.1s)\r\nCMake Generate step failed.  Build files cannot be regenerated correctly.\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7\r\n",
        "state": "closed",
        "user": "Piterang",
        "closed_by": "qili93",
        "created_at": "2024-05-30T08:27:43+00:00",
        "updated_at": "2024-06-18T11:42:19+00:00",
        "closed_at": "2024-06-18T11:42:19+00:00",
        "comments_count": [
            "YanhuiDua",
            "Piterang",
            "YanhuiDua",
            "YanhuiDua",
            "Piterang",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1276,
        "title": "编译安装paddle-custom-npu-0.0.0后使用paddleocr贴别慢",
        "body": "基础功能检查 没有问题。但是在paddleocr预测时：\r\n\r\n\r\nI0531 15:46:17.706218 112503 init.cc:236] ENV [CUSTOM_DEVICE_ROOT]=/usr/local/lib/python3.10/dist-packages/paddle_custom_device\r\nI0531 15:46:17.706283 112503 init.cc:145] Try loading custom device libs from: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\r\nI0531 15:46:18.313715 112503 custom_device.cc:1099] Succeed in loading custom runtime in lib: /usr/local/lib/python3.10/dist-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI0531 15:46:18.319205 112503 custom_kernel.cc:63] Succeed in loading 350 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0531 15:46:18.319399 112503 init.cc:157] Finished in LoadCustomDevice with libs_path: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\r\nI0531 15:46:18.319448 112503 init.cc:242] CustomDevice: npu, visible devices count: 8\r\n[2024/05/31 15:46:19] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=True, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id='0,1,2,3', image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/ch/ch_PP-OCRv4_det_infer', det_limit_side_len=680, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=True, total_process_num=1, process_id=0, benchmark=True, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\r\nload finish\r\n\r\nI0531 15:46:21.097870 113010 init.cc:236] ENV [CUSTOM_DEVICE_ROOT]=/usr/local/lib/python3.10/dist-packages/paddle_custom_device\r\nI0531 15:46:21.097935 113010 init.cc:145] Try loading custom device libs from: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\r\nI0531 15:46:21.287110 113251 init.cc:236] ENV [CUSTOM_DEVICE_ROOT]=/usr/local/lib/python3.10/dist-packages/paddle_custom_device\r\nI0531 15:46:21.287169 113251 init.cc:145] Try loading custom device libs from: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\r\nI0531 15:46:21.682519 113010 custom_device.cc:1099] Succeed in loading custom runtime in lib: /usr/local/lib/python3.10/dist-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI0531 15:46:21.687526 113010 custom_kernel.cc:63] Succeed in loading 350 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0531 15:46:21.687721 113010 init.cc:157] Finished in LoadCustomDevice with libs_path: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\r\nI0531 15:46:21.687773 113010 init.cc:242] CustomDevice: npu, visible devices count: 8\r\nI0531 15:46:21.876283 113251 custom_device.cc:1099] Succeed in loading custom runtime in lib: /usr/local/lib/python3.10/dist-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI0531 15:46:21.879951 113251 custom_kernel.cc:63] Succeed in loading 350 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0531 15:46:21.880151 113251 init.cc:157] Finished in LoadCustomDevice with libs_path: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\r\nI0531 15:46:21.880192 113251 init.cc:242] CustomDevice: npu, visible devices count: 8\r\n\r\n\r\n[2024/05/31 15:49:47] ppocr DEBUG: dt_boxes num : 3, elapsed : 32.64580488204956\r\n[2024/05/31 15:49:47] ppocr DEBUG: cls num  : 3, elapsed : 0.022808074951171875\r\nWarning: tiling offset out of range, index: 32\r\nWarning: tiling offset out of range, index: 32\r\nWarning: tiling offset out of range, index: 32\r\n[2024/05/31 15:50:49] ppocr DEBUG: rec_res num  : 3, elapsed : 62.09084606170654\r\n[8.0, 7.0] [752.0, 7.0] [752.0, 25.0] [8.0, 25.0] 如果想要使用om模型进行推理，就需要使用华为acl的特定的Api，关于atc的api具体可查看他们 0.9951098561286926\r\n[9.0, 35.0] [742.0, 35.0] [742.0, 53.0] [9.0, 53.0] 的官网的api说明，其实如果说学过CUDA的话，就会发现，它的Api和CUDA其实蛮像的，比如 0.9868237972259521\r\n[8.0, 62.0] [331.0, 61.0] [331.0, 80.0] [8.0, 81.0] cudamemorymalloc对应acl.rt.malloc等 0.9853638410568237\r\n###############ocr_test1.png is ok###########\r\n[2024/05/31 15:51:24] ppocr DEBUG: dt_boxes num : 6, elapsed : 35.48471665382385\r\n[2024/05/31 15:51:55] ppocr DEBUG: cls num  : 6, elapsed : 30.283159494400024\r\nWarning: tiling offset out of range, index: 32\r\nWarning: tiling offset out of range, index: 32\r\nWarning: tiling offset out of range, index: 32\r\n[2024/05/31 15:53:00] ppocr DEBUG: rec_res num  : 6, elapsed : 65.58153176307678\r\n[32.0, 9.0] [379.0, 9.0] [379.0, 24.0] [32.0, 24.0] 1.npu加载.om模型，并将模型转移到NPU上 0.9712381362915039\r\n[31.0, 38.0] [279.0, 38.0] [279.0, 53.0] [31.0, 53.0] 2.NPU上分配模型的输入和输出 0.9975005388259888\r\n[29.0, 64.0] [278.0, 64.0] [278.0, 83.0] [29.0, 83.0] 3.CPU加载图片，从硬盘到内存 0.9993540644645691\r\n[29.0, 91.0] [280.0, 91.0] [280.0, 110.0] [29.0, 110.0] 4.输入数据拷贝，从内存到NPU 0.9980849027633667\r\n[29.0, 120.0] [158.0, 120.0] [158.0, 139.0] [29.0, 139.0] 5.NPU执行推理 0.9916012287139893\r\n[30.0, 149.0] [280.0, 149.0] [280.0, 164.0] [30.0, 164.0] 6.输出数据拷贝，从NPU到内存 0.9904201030731201\r\n###############ocr_test2.png is ok###########\r\n\r\n预测的时间都在 一分钟以上，而且NPU 能跑满60G（这个很奇怪），\r\n",
        "state": "closed",
        "user": "fallbernana123456",
        "closed_by": "YanhuiDua",
        "created_at": "2024-05-31T04:06:07+00:00",
        "updated_at": "2024-06-28T03:41:19+00:00",
        "closed_at": "2024-06-28T03:41:19+00:00",
        "comments_count": [
            "YanhuiDua",
            "fallbernana123456",
            "YanhuiDua",
            "fallbernana123456",
            "fallbernana123456",
            "YanhuiDua",
            "qili93",
            "fallbernana123456",
            "fallbernana123456",
            "YanhuiDua",
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1293,
        "title": "训练出错OSError: (External)  ACL error, the error code is : 500002.  (at /home/ma-user/work/ascend/PaddleCustomDevice/backends/npu/kernels/funcs/npu_op_runner.cc:626)",
        "body": "版本是 paddle2.6.1   cann=7.0.0  910PremiumA   \r\n验证环境都成功，无报错\r\n![1717749367448_CD8001EB-2DC3-4cce-B6DB-AEA24559A155](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/63270520/d0eb383c-a377-42ea-9573-23a47a26c13d)\r\n**https://github.com/lyuwenyu/RT-DETR**  源代码\r\n但训练rtdetr官方代码报错\r\n下面是报错日志\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/work/rtdetr_paddle/tools/train.py\", line 183, in <module>\r\n    main()\r\n  File \"/home/ma-user/work/rtdetr_paddle/tools/train.py\", line 179, in main\r\n    run(FLAGS, cfg)\r\n  File \"/home/ma-user/work/rtdetr_paddle/tools/train.py\", line 135, in run\r\n    trainer.train(FLAGS.eval)\r\n  File \"/home/ma-user/work/rtdetr_paddle/ppdet/engine/trainer.py\", line 377, in train\r\n    outputs = model(data)\r\n  File \"/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/ma-user/work/rtdetr_paddle/ppdet/modeling/architectures/meta_arch.py\", line 60, in forward\r\n    out = self.get_loss()\r\n  File \"/home/ma-user/work/rtdetr_paddle/ppdet/modeling/architectures/detr.py\", line 113, in get_loss\r\n    return self._forward()\r\n  File \"/home/ma-user/work/rtdetr_paddle/ppdet/modeling/architectures/detr.py\", line 87, in _forward\r\n    out_transformer = self.transformer(body_feats, pad_mask, self.inputs)\r\n  File \"/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/paddle/nn/layer/layers.py\", line 1429, in __call__\r\n    return self.forward(*inputs, **kwargs)\r\n  File \"/home/ma-user/work/rtdetr_paddle/ppdet/modeling/transformers/rtdetr_transformer.py\", line 419, in forward\r\n    get_contrastive_denoising_training_group(gt_meta,\r\n  File \"/home/ma-user/work/rtdetr_paddle/ppdet/modeling/transformers/utils.py\", line 337, in get_contrastive_denoising_training_group\r\n    attn_mask[num_denoising:, :num_denoising] = True\r\n  File \"/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/paddle/base/dygraph/tensor_patch_methods.py\", line 897, in __setitem__\r\n    return self._setitem_dygraph(item, value)\r\nOSError: (External)  ACL error, the error code is : 500002.  (at /home/ma-user/work/ascend/PaddleCustomDevice/backends/npu/kernels/funcs/npu_op_runner.cc:626)",
        "state": "closed",
        "user": "wenshuaishuai123",
        "closed_by": "qili93",
        "created_at": "2024-06-07T10:20:21+00:00",
        "updated_at": "2024-06-21T05:38:04+00:00",
        "closed_at": "2024-06-21T05:38:04+00:00",
        "comments_count": [
            "qili93",
            "wenshuaishuai123",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1298,
        "title": "NPU后端 nightly-build版本增加cp310",
        "body": "官网上的安装指引，https://www.paddlepaddle.org.cn/packages/nightly/npu/ 链接下目前只有cp39的nightly-build",
        "state": "closed",
        "user": "parap1uie-s",
        "closed_by": "ronny1996",
        "created_at": "2024-06-17T02:08:40+00:00",
        "updated_at": "2024-06-18T06:21:24+00:00",
        "closed_at": "2024-06-18T06:21:24+00:00",
        "comments_count": [
            "ronny1996",
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1258,
        "title": "使用昇腾910显卡进行编译时出错",
        "body": "(paddle) [jiboyang@bms-3c50 npu]$ bash tools/compile.sh\r\n+++ dirname tools/compile.sh\r\n++ cd tools/../\r\n++ pwd\r\n+ SOURCE_ROOT=/home/jiboyang/paddlepaddle/PaddleCustomDevice/backends/npu\r\n+ mkdir -p /home/jiboyang/paddlepaddle/PaddleCustomDevice/backends/npu/build\r\n+ cd /home/jiboyang/paddlepaddle/PaddleCustomDevice/backends/npu/build\r\n++ uname -i\r\n+ arch=aarch64\r\n+ '[' aarch64 == x86_64 ']'\r\n+ WITH_MKL=OFF\r\n+ WITH_ARM=ON\r\n+ WITH_ATB=OFF\r\n+ '[' -n '' ']'\r\n+ cat\r\n========================================\r\nConfiguring cmake in build ...\r\n    -DCMAKE_BUILD_TYPE=Release\r\n    -DWITH_TESTING=ON\r\n    -DWITH_MKL=OFF\r\n    -DWITH_ARM=ON\r\n    -DWITH_ATB=OFF\r\n    -DON_INFER=OFF\r\n    -DWITH_COVERAGE=OFF\r\n========================================\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_TESTING=ON -DWITH_MKL=OFF -DWITH_ARM=ON -DWITH_ATB=OFF -DON_INFER=OFF -DWITH_COVERAGE=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'paddle'\r\nCMake Error at cmake/paddle.cmake:31 (message):\r\n  NO Installed Paddle Found in\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:22 (include)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7",
        "state": "closed",
        "user": "ABBoyangCD",
        "closed_by": "qili93",
        "created_at": "2024-05-22T08:28:26+00:00",
        "updated_at": "2024-06-28T07:58:08+00:00",
        "closed_at": "2024-06-28T07:58:08+00:00",
        "comments_count": [
            "qili93",
            "ABBoyangCD",
            "qili93",
            "qili93",
            "ABBoyangCD",
            "qili93",
            "ABBoyangCD",
            "ABBoyangCD",
            "qili93",
            "ABBoyangCD",
            "qili93",
            "qili93",
            "ABBoyangCD",
            "qili93",
            "wujf147",
            "qili93",
            "wujf147",
            "wujf147",
            "qili93",
            "wujf147",
            "qili93",
            "wujf147",
            "qili93",
            "wujf147",
            "wujf147",
            "qili93",
            "wujf147",
            "wujf147",
            "YanhuiDua",
            "YanhuiDua",
            "qili93"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1314,
        "title": "怎么利用寒武纪mlu卡进行paddleocr检测和识别",
        "body": "各位老师好，我已按照官网流程进行paddle安装和编译，利用test_lenet_minst.py测试也没有问题；后续我安装了paddleocr想进行检测和识别，但是显示只能使用cpu版本的进行推理，请问怎么使用寒武纪的显卡进行检测和识别呢，需要修改哪些东西？另外在使用docker run时如果使用gpu可以指定--gpus all,类似的在寒武纪mlu可以指定显卡设备吗？paddleocr推理如下所示：\r\n![git_issue1](https://github.com/PaddlePaddle/PaddleCustomDevice/assets/172480266/01b685c1-a8bc-4af2-8dc6-0a9d46a01594)\r\n",
        "state": "closed",
        "user": "wujf147",
        "closed_by": "paddle-bot[bot]",
        "created_at": "2024-06-25T08:59:27+00:00",
        "updated_at": "2025-07-01T06:49:12+00:00",
        "closed_at": "2025-07-01T06:49:12+00:00",
        "comments_count": [
            "YanhuiDua",
            "wujf147",
            "YanhuiDua",
            "wujf147",
            "wujf147",
            "YanhuiDua",
            "YanhuiDua",
            "wujf147",
            "YanhuiDua",
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1321,
        "title": "使用昇腾卡910B时编译安装报错",
        "body": "-- PADDLE_CORE_LIB: /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/paddle/base/libpaddle.so\r\n-- Run 'git submodule update --init Paddle' in /home/ma-user/work/evaluation-sh/dulin_OCR/task3/layoutxlm_infer/PaddleCustomDevice-develop\r\nfatal: not a git repository (or any parent up to mount point /home/ma-user)\r\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\nCMake Error at cmake/paddle.cmake:72 (message):\r\n  Failed to get submodule Paddle', please check your network !\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:22 (include)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7\r\n这个 -submodule是指的什么？因为有网关的原因无法通过外网下载，该如何规避这个问题?",
        "state": "open",
        "user": "GenerallyCovetous",
        "closed_by": null,
        "created_at": "2024-06-27T03:42:20+00:00",
        "updated_at": "2024-07-24T06:59:00+00:00",
        "closed_at": null,
        "comments_count": [
            "YanhuiDua",
            "GenerallyCovetous",
            "YanhuiDua",
            "GenerallyCovetous",
            "YanhuiDua",
            "GenerallyCovetous",
            "GenerallyCovetous",
            "GenerallyCovetous",
            "YanhuiDua",
            "GenerallyCovetous",
            "YanhuiDua",
            "GenerallyCovetous",
            "GenerallyCovetous",
            "YanhuiDua",
            "GenerallyCovetous",
            "GenerallyCovetous",
            "qili93",
            "GenerallyCovetous",
            "YanhuiDua",
            "GenerallyCovetous",
            "YanhuiDua",
            "Irisnotiris"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1331,
        "title": "寒武纪mlu 如何对PaddleCustomDevice的mlu进行源码编译？",
        "body": "由于python版本要求使用3.8版本，不能直接使用安装python3.10版本的wheel包\r\npaddle_custom_mlu.whl\r\n可以给出paddlecustomdevice源码编译的步骤和命令么？谢谢！\r\n@YanhuiDua",
        "state": "open",
        "user": "wangzy0327",
        "closed_by": null,
        "created_at": "2024-07-02T09:30:10+00:00",
        "updated_at": "2024-09-19T01:27:38+00:00",
        "closed_at": null,
        "comments_count": [
            "YanhuiDua",
            "wangzy0327",
            "YanhuiDua",
            "wangzy0327",
            "qili93",
            "wangzy0327"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1355,
        "title": "昇腾 910B 推理缓慢+预热效能不符预期",
        "body": "基于 https://github.com/PaddlePaddle/PaddleCustomDevice/issues/1118 提问者的场景，有一些补充。\r\n\r\n前提：\r\n按 develop 分支 07.15 左右最新的 commit(bcc47be2979e36b4d1a726fbdb9253a1530b7ff4) 执行编译，并通过了[“基础功能检查”](https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md)\r\n![image](https://github.com/user-attachments/assets/9766804c-859a-4726-ab79-2205bfb44e9d)\r\n\r\n1.预热尝试一\r\n  手里有 5500+ 完全不同的query token\r\n  预热阶段，每个 length 的 query 只取1个，分别执行query，当作预热\r\n  剩下的5000+个query，大部分都能在较短的延时(30ms+)推理出结果，但仍有少部分仍需更长延时\r\n\r\n2.预热尝试二，基于尝试一中length无法覆盖用例最大512长度token的生产要求\r\n    构建中文汉字1000个+英文字符+中英文标点符号+数字的字符集\r\n    每次query从中随机选取指定数量的字符拼凑成整句\r\n    整句长度从1一直到512，也就是执行512次query\r\n    这样的操作，显存会逐渐增涨，把910B单卡64GB显存撑爆。\r\n\r\n3.预热尝试三，基于尝试二，将最大长度由512降至256（用于验证可行性）\r\n    预热完成后，显存占用16GB\r\n    然后再使用之前5000+query进行query测试（这些query都在256长度范围内）\r\n    结论是之前的预热仿佛没有任何作用\r\n\r\n4.另外，推理时路径下有生成kernel_meta_xxx数据，但kernel_meta_xxx数据无法复用，这意味着每次都需要走较长时间的预热流程。\r\n        第一次启动docker，执行5000+query，生成kernel_meta目录，将该目录中的数据导出至宿主机\r\n        第二次启动docker，使用-v挂载路径，再次启动进程，之前已经warm up的请求仍然耗时达30s+\r\n\r\n5.然后尝试探究问题进行性能采样，数据如下，但不太明确\r\n[PROF_000001_20240720102832085_QKLFOOPJMINELEIC.zip](https://github.com/user-attachments/files/16328236/PROF_000001_20240720102832085_QKLFOOPJMINELEIC.zip)\r\n\r\n基于以上，我的问题是：\r\n1.预热操作是否有执行标准？或者更好的建议？\r\n2.问题关键还是推理耗时过久，所以麻烦看看采样数据中是否有值得关注的点，能指出模型/paddle框架需要完善的点？\r\n\r\n",
        "state": "open",
        "user": "HighGee",
        "closed_by": null,
        "created_at": "2024-07-22T05:28:10+00:00",
        "updated_at": "2024-07-22T08:08:34+00:00",
        "closed_at": null,
        "comments_count": [
            "HighGee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1356,
        "title": "昇腾300I DUO卡不支持",
        "body": "[root@localhost dist]# python3 -c \"import paddle; paddle.utils.run_check()\"\r\nI0722 12:18:07.275084 1318483 init.cc:236] ENV [CUSTOM_DEVICE_ROOT]=/usr/local/python310/lib/python3.10/site-packages/paddle_custom_device\r\nI0722 12:18:07.275131 1318483 init.cc:145] Try loading custom device libs from: [/usr/local/python310/lib/python3.10/site-packages/paddle_custom_device]\r\nI0722 12:18:07.746173 1318483 custom_device.cc:1099] Succeed in loading custom runtime in lib: /usr/local/python310/lib/python3.10/site-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI0722 12:18:07.749110 1318483 custom_kernel.cc:63] Succeed in loading 355 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI0722 12:18:07.749258 1318483 init.cc:157] Finished in LoadCustomDevice with libs_path: [/usr/local/python310/lib/python3.10/site-packages/paddle_custom_device]\r\nI0722 12:18:07.749292 1318483 init.cc:242] CustomDevice: npu, visible devices count: 4\r\nRunning verify PaddlePaddle program ... \r\nI0722 12:18:08.663375 1318483 program_interpreter.cc:243] New Executor is Running.\r\n\r\n\r\n--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::StandaloneExecutor::Run(std::vector<std::string, std::allocator<std::string > > const&, bool)\r\n1   paddle::framework::InterpreterCore::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)\r\n2   paddle::framework::ProgramInterpreter::Run(std::vector<std::string, std::allocator<std::string > > const&, bool, bool, bool, bool)\r\n3   paddle::framework::ProgramInterpreter::Build(std::vector<std::string, std::allocator<std::string > > const&, std::vector<paddle::framework::OpFuncNode, std::allocator<paddle::framework::OpFuncNode> >*, bool)\r\n4   paddle::framework::interpreter::BuildOpFuncList(phi::Place const&, paddle::framework::BlockDesc const&, std::set<std::string, std::less<std::string >, std::allocator<std::string > > const&, std::vector<paddle::framework::OpFuncNode, std::allocator<paddle::framework::OpFuncNode> >*, paddle::framework::VariableScope*, paddle::framework::interpreter::ExecutionConfig const&, std::vector<std::function<void (paddle::framework::OperatorBase*, paddle::framework::Scope*)>, std::allocator<std::function<void (paddle::framework::OperatorBase*, paddle::framework::Scope*)> > > const&, std::vector<std::function<void (paddle::framework::OperatorBase*, paddle::framework::Scope*)>, std::allocator<std::function<void (paddle::framework::OperatorBase*, paddle::framework::Scope*)> > > const&, bool, bool)\r\n5   void custom_kernel::MatmulKernel<float, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, phi::DenseTensor const&, bool, bool, phi::DenseTensor*)\r\n6   aclnnMatmul\r\n7   InitL2Phase2Context(char*, aclOpExecutor*)\r\n8   GetOpExecCacheFromExecutor(aclOpExecutor*)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: `Segmentation fault` is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1721621889 (unix time) try \"date -d @1721621889\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x141e53) received by PID 1318483 (TID 0xfffef55e5980) from PID 1318483 ***]\r\n\r\n段错误 (核心已转储)\r\n",
        "state": "open",
        "user": "tomjimi2019",
        "closed_by": null,
        "created_at": "2024-07-22T08:47:27+00:00",
        "updated_at": "2024-07-24T00:56:52+00:00",
        "closed_at": null,
        "comments_count": [
            "cleansely",
            "tomjimi2019"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1367,
        "title": "[bug]openi容器中编译报错",
        "body": "[root@i02b565b66d24833aa365f540872143f-task0-0 npu]# bash tools/compile.sh+++ dirname tools/compile.sh\r\n++ cd tools/../\r\n++ pwd\r\n+ SOURCE_ROOT=/home/ma-user/PaddleCustomDevice/backends/npu\r\n+ mkdir -p /home/ma-user/PaddleCustomDevice/backends/npu/build\r\n+ cd /home/ma-user/PaddleCustomDevice/backends/npu/build\r\n++ uname -i\r\n+ arch=aarch64\r\n+ '[' aarch64 == x86_64 ']'\r\n+ WITH_MKL=OFF\r\n+ WITH_ARM=ON\r\n+ WITH_ATB=OFF\r\n+ '[' -n '' ']'\r\n+ cat\r\n========================================\r\nConfiguring cmake in build ...\r\n    -DCMAKE_BUILD_TYPE=Release\r\n    -DWITH_TESTING=ON\r\n    -DWITH_MKL=OFF\r\n    -DWITH_ARM=ON\r\n    -DWITH_ATB=OFF\r\n    -DON_INFER=OFF\r\n    -DWITH_COVERAGE=OFF\r\n========================================\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_TESTING=ON -DWITH_MKL=OFF -DWITH_ARM=ON -DWITH_ATB=OFF -DON_INFER=OFF -DWITH_COVERAGE=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\nCMake Error at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:137 (message):\r\n  Could NOT find Python (missing: Python_LIBRARY Python_INCLUDE_DIR\r\n  Development) (found version \"2.7.15\")\r\nCall Stack (most recent call first):\r\n  /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE)\r\n  /usr/share/cmake/Modules/FindPython.cmake:169 (find_package_handle_standard_args)\r\n  cmake/paddle.cmake:15 (find_package)\r\n  CMakeLists.txt:22 (include)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/ma-user/PaddleCustomDevice/backends/npu/build/CMakeFiles/CMakeOutput.log\".\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7\r\n\r\n\r\n环境\r\npython 3.9\r\ngcc 7.3\r\nNPU: 1*Ascend-D910B, CPU: 20, 显存: 32GB, 内存: 60GB\r\n\r\n[root@i02b565b66d24833aa365f540872143f-task0-0 npu]# npu-smi info\r\n+------------------------------------------------------------------------------------------------+\r\n| npu-smi 23.0.rc2.2               Version: 23.0.0                                               |\r\n+---------------------------+---------------+----------------------------------------------------+\r\n| NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|\r\n| Chip                      | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |\r\n+===========================+===============+====================================================+\r\n| 0     910B                | OK            | 68.5        32                0    / 0             |\r\n| 0                         | 0000:C1:00.0  | 0           1280 / 13553      0    / 32768         |\r\n+===========================+===============+====================================================+\r\n+---------------------------+---------------+----------------------------------------------------+\r\n| NPU     Chip              | Process id    | Process name             | Process memory(MB)      |\r\n+===========================+===============+====================================================+\r\n| No running processes found in NPU 0                                                            |\r\n+===========================+===============+====================================================+\r\n\r\n\r\n[root@i02b565b66d24833aa365f540872143f-task0-0 npu]# cat /usr/local/Ascend/ascend-toolkit/latest/version.cfg \r\n# version: 1.0\r\nruntime_running_version=[7.2.0.1.235:8.0.RC1]\r\ncompiler_running_version=[7.2.0.1.235:8.0.RC1]\r\nhccl_running_version=[7.2.0.1.235:8.0.RC1]\r\nopp_running_version=[7.2.0.1.235:8.0.RC1]\r\ntoolkit_running_version=[7.2.0.1.235:8.0.RC1]\r\naoe_running_version=[7.2.0.1.235:8.0.RC1]\r\nncs_running_version=[7.2.0.1.235:8.0.RC1]\r\nopp_kernel_running_version=[7.2.0.1.235:8.0.RC1]\r\nruntime_upgrade_version=[7.2.0.1.235:8.0.RC1]\r\ncompiler_upgrade_version=[7.2.0.1.235:8.0.RC1]\r\nopp_upgrade_version=[7.2.0.1.235:8.0.RC1]\r\ntoolkit_upgrade_version=[7.2.0.1.235:8.0.RC1]\r\naoe_upgrade_version=[7.2.0.1.235:8.0.RC1]\r\nncs_upgrade_version=[7.2.0.1.235:8.0.RC1]\r\nhccl_upgrade_version=[7.2.0.1.235:8.0.RC1]\r\nopp_kernel_upgrade_version=[7.2.0.1.235:8.0.RC1]\r\nruntime_installed_version=[7.0.0.5.242:7.0.RC1][7.2.0.1.235:8.0.RC1]\r\ncompiler_installed_version=[7.0.0.5.242:7.0.RC1][7.2.0.1.235:8.0.RC1]\r\nopp_installed_version=[7.0.0.5.242:7.0.RC1][7.2.0.1.235:8.0.RC1]\r\ntoolkit_installed_version=[7.0.0.5.242:7.0.RC1][7.2.0.1.235:8.0.RC1]\r\naoe_installed_version=[7.0.0.5.242:7.0.RC1][7.2.0.1.235:8.0.RC1]\r\nncs_installed_version=[7.0.0.5.242:7.0.RC1][7.2.0.1.235:8.0.RC1]\r\nhccl_installed_version=[7.2.0.1.235:8.0.RC1]\r\nopp_kernel_installed_version=[7.2.0.1.235:8.0.RC1]\r\n\r\n\r\n[root@i02b565b66d24833aa365f540872143f-task0-0 npu]# cat /usr/local/Ascend/driver/version.info \r\nVersion=23.0.rc2.2\r\nascendhal_version=7.25.6\r\naicpu_version=1.0\r\ntdt_version=1.0\r\nlog_version=1.0\r\nprof_version=2.0\r\ndvppkernels_version=1.1\r\ntsfw_version=1.0\r\nInnerversion=V100R001C30SPC002B220\r\ncompatible_version=[V100R001C30]\r\ncompatible_version_fw=[6.4.0,6.4.99]\r\npackage_version=23.0.rc2.2",
        "state": "open",
        "user": "bltcn",
        "closed_by": null,
        "created_at": "2024-08-02T10:03:40+00:00",
        "updated_at": "2024-08-06T04:02:26+00:00",
        "closed_at": null,
        "comments_count": [
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1397,
        "title": "开发者请到Paddle主仓提问",
        "body": "亲爱的开发者朋友们，\r\n\r\n如果您对新硬件上飞桨的使用有问题，欢迎去飞桨主仓issue区提问：\r\nhttps://github.com/PaddlePaddle/Paddle/issues\r\n\r\nPaddleCustomDevice作为飞桨与厂商技术合作的代码仓库，issue区将聚焦框架与硬件厂商的技术交流，不再处理开发者的框架使用问题。\r\n\r\n过去的时间中，我们在PaddleCustomDevice的issue区，看到了很多开发者对飞桨的关注，其中也看到一些非常有意思的分析。你们的反馈，也是我们工作前进的动力。例如，开发者反馈的关于昇腾推理硬件的问题，我们启动了Paddle-ONNX-OM的验证工作，安排了ONNX算子补齐。然后，我们也观察到，新硬件的问题散落在主仓与CustomDevice两个代码仓库的issue区，导致需要维护2套值班机制，信息共享不便利。\r\n\r\n未来，开发者问题纳入主仓统一管理，共享主仓的值班机制，硬件支持方面也梳理各个方向负责人去支持主仓，希望如此以更高的效率去支持开发者的使用。\r\n\r\n主仓见！",
        "state": "open",
        "user": "onecatcn",
        "closed_by": null,
        "created_at": "2024-09-11T03:20:31+00:00",
        "updated_at": "2024-09-11T07:47:06+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1368,
        "title": "昇腾910B编译后基础检查run_check报错",
        "body": "910B arm，CANN 7.0.1\r\npaddlepaddle和paddle custom device版本是2.6.1\r\n运行paddle.utils.run_check()报错ACL error, the error code is : 500001\r\n![image](https://github.com/user-attachments/assets/00b0da51-2ba6-48ae-8e29-2bdad3a18c4d)\r\n![image](https://github.com/user-attachments/assets/5c70957b-cf70-423d-a223-1c95b480a9d0)\r\n\r\n检查安装版本输出如下：\r\n![image](https://github.com/user-attachments/assets/e630c784-c1f8-450f-a9e1-56e8b261c75e)\r\n\r\n 试了`export FLAGS_npu_jit_compile=false`没用，除了更换cann8.0的镜像是否有其他解决办法？\r\n#1214",
        "state": "open",
        "user": "Irisnotiris",
        "closed_by": null,
        "created_at": "2024-08-04T07:03:12+00:00",
        "updated_at": "2024-08-14T04:02:34+00:00",
        "closed_at": null,
        "comments_count": [
            "YanhuiDua",
            "wbz5087",
            "YanhuiDua"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1383,
        "title": "在Npu环境上并没有使用npu进行推理",
        "body": "每个图片第一次被推理的时候速度都非常慢（10~100秒），第二次被推理时正常（0.5s）。并且第一次推理AICore利用率为0.\r\n代码为PaddleOCR代码，运行ppstructure/predict_system.py。\r\n![image](https://github.com/user-attachments/assets/8db3b143-3783-4963-ba76-d68db7da8d44)\r\n![image](https://github.com/user-attachments/assets/17882aaa-52e1-44f0-9229-0b8ac89d7e78)\r\n",
        "state": "open",
        "user": "liujiachang",
        "closed_by": null,
        "created_at": "2024-08-22T06:59:48+00:00",
        "updated_at": "2024-08-22T09:36:13+00:00",
        "closed_at": null,
        "comments_count": [
            "YanhuiDua",
            "liujiachang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1370,
        "title": "使用昇腾卡910A时编译安装报错，cann7.01-arm镜像 & paddle 2.6.1",
        "body": "910A arm，CANN 7.0.1\r\npaddlepaddle和paddle custom device版本是2.6.1\r\n![图片](https://github.com/user-attachments/assets/c1f7378e-f57c-4c86-a185-f339f6e3b910)\r\n![图片](https://github.com/user-attachments/assets/4eb2e6c6-5667-4e22-8f99-579e3a855ac4)\r\n![图片](https://github.com/user-attachments/assets/e2577b92-7c42-47e2-8cfa-84442ff913b3)\r\n执行编译脚本时报错如下：\r\n![企业微信截图_17231209919168](https://github.com/user-attachments/assets/9cd0b6f1-8f6e-43e9-92a5-63ef0c5aa835)\r\n提示的cmake报错行如下：\r\n",
        "state": "open",
        "user": "CanJie",
        "closed_by": null,
        "created_at": "2024-08-08T12:57:51+00:00",
        "updated_at": "2024-09-11T07:51:06+00:00",
        "closed_at": null,
        "comments_count": [
            "CanJie",
            "CanJie",
            "CanJie",
            "CanJie",
            "onecatcn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1421,
        "title": "910b运行paddlex报NameError: name 'libpaddle' is not defined",
        "body": "硬件：昇腾910b\r\n环境：\r\n使用容器镜像registry.baidubce.com/device/paddle-npu:cann80RC1-ubuntu20-aarch64-gcc84-py39\r\n飞浆版本：paddlepaddle-3.0.0.dev20241010-cp39-cp39-linux_aarch64\r\npaddle_custom_device: 3.0.0.dev20241010\r\n\r\n运行命令：paddlex --pipeline OCR --input /work/test.png --device npu:0\r\n报错：\r\n![image](https://github.com/user-attachments/assets/9dd11e3a-aece-409f-8a6d-ca833b1a110d)\r\n![image](https://github.com/user-attachments/assets/11c86fb7-8bf8-4802-93eb-9c818d65ba2e)\r\n\r\n\r\n",
        "state": "open",
        "user": "boreassun",
        "closed_by": null,
        "created_at": "2024-10-11T08:18:53+00:00",
        "updated_at": "2024-11-25T01:54:21+00:00",
        "closed_at": null,
        "comments_count": [
            "YanhuiDua",
            "onecatcn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1430,
        "title": "910b上编译安装之后，运行检查程序，还是报错",
        "body": "λ master-1 /work/PaddleCustomDevice/backends/npu {develop} python -c \"import paddle; paddle.utils.run_check()\"\r\nI1022 11:56:13.547047  6141 init.cc:236] ENV [CUSTOM_DEVICE_ROOT]=/usr/local/lib/python3.9/dist-packages/paddle_custom_device\r\nI1022 11:56:13.547103  6141 init.cc:145] Try loading custom device libs from: [/usr/local/lib/python3.9/dist-packages/paddle_custom_device]\r\nI1022 11:56:14.248243  6141 custom_device.cc:1099] Succeed in loading custom runtime in lib: /usr/local/lib/python3.9/dist-packages/paddle_custom_device/libpaddle-custom-npu.so\r\nI1022 11:56:14.256450  6141 custom_kernel.cc:63] Succeed in loading 357 custom kernel(s) from loaded lib(s), will be used like native ones.\r\nI1022 11:56:14.256623  6141 init.cc:157] Finished in LoadCustomDevice with libs_path: [/usr/local/lib/python3.9/dist-packages/paddle_custom_device]\r\nI1022 11:56:14.256670  6141 init.cc:242] CustomDevice: npu, visible devices count: 1\r\nRunning verify PaddlePaddle program ... \r\nCall aclrtSetDevice(device->id) failed : 507033 at file /work/PaddleCustomDevice/backends/npu/runtime/runtime.cc line 430\r\nEL0002: 2024-10-22-11:56:14.885.664 The device ID is invalid.\r\n        TraceBack (most recent call last):\r\n        Failed to open device, retCode=0x7020013, deviceId=0.[FUNC:InitRawDriver][FILE:device.cc][LINE:278]\r\n        Failed to init RawDriver, device_id=0, retCode=0x7020013[FUNC:Init][FILE:device.cc][LINE:322]\r\n        Check param failed, dev can not be NULL![FUNC:DeviceRetain][FILE:runtime.cc][LINE:3709]\r\n        Check param failed, dev can not be NULL![FUNC:PrimaryContextRetain][FILE:runtime.cc][LINE:3447]\r\n        Check param failed, ctx can not be NULL![FUNC:PrimaryContextRetain][FILE:runtime.cc][LINE:3474]\r\n        Check param failed, context can not be null.[FUNC:NewDevice][FILE:api_impl.cc][LINE:2179]\r\n        New device failed, retCode=0x7010006[FUNC:SetDevice][FILE:api_impl.cc][LINE:2201]\r\n        rtSetDevice execute failed, reason=[device retain error][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]\r\n        open device 0 failed, runtime result = 507033.[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]\r\n        ctx is NULL![FUNC:GetDevErrMsg][FILE:api_impl.cc][LINE:4692]\r\n        The argument is invalid.Reason: rtGetDevMsg execute failed, reason=[context pointer null]",
        "state": "closed",
        "user": "boss-yang702",
        "closed_by": "ronny1996",
        "created_at": "2024-10-22T03:57:26+00:00",
        "updated_at": "2024-10-22T05:35:34+00:00",
        "closed_at": "2024-10-22T05:35:34+00:00",
        "comments_count": [
            "ronny1996"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1463,
        "title": "运行python -c \"import paddle; paddle.utils.run_check()\"出错",
        "body": "--------------------------------------\r\nC++ Traceback (most recent call last):\r\n--------------------------------------\r\n0   paddle::framework::ThreadPoolTempl<paddle::framework::StlThreadEnvironment>::WorkerLoop(int)\r\n1   paddle::framework::PirInterpreter::RunInstructionBaseAsync(unsigned long)\r\n2   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)\r\n3   paddle::framework::PhiKernelInstruction::Run()\r\n4   void custom_kernel::MatmulKernel<float, phi::CustomContext>(phi::CustomContext const&, phi::DenseTensor const&, phi::DenseTensor const&, bool, bool, phi::DenseTensor*)\r\n5   aclnnMatmul\r\n6   InitL2Phase2Context(char*, aclOpExecutor*)\r\n7   GetOpExecCacheFromExecutor(aclOpExecutor*)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nFatalError: Segmentation fault is detected by the operating system.\r\n  [TimeInfo: *** Aborted at 1731662312 (unix time) try \"date -d @1731662312\" if you are using GNU date ***]\r\n  [SignalInfo: *** SIGSEGV (@0x158c) received by PID 5516 (TID 0xfffd88ef5160) from PID 5516 ***]\r\n  报错内容如上，是什么原因呢？",
        "state": "open",
        "user": "yuluzhong",
        "closed_by": null,
        "created_at": "2024-11-15T09:24:05+00:00",
        "updated_at": "2024-12-03T11:51:18+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1440,
        "title": "在910B arm架构机器上源码编译PaddleCustomDevice报错",
        "body": "报错截图\r\n![image](https://github.com/user-attachments/assets/ff48cfbf-987c-4f21-81ad-e519078e9b4b)\r\n\r\n![7cbb0906f92509471693748b269627fc](https://github.com/user-attachments/assets/5491f578-52fb-41cd-b84d-5133c52c4f94)\r\n\r\n报错代码：\r\n+ set +e\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_TESTING=ON -DWITH_MKL=OFF -DWITH_ARM=ON -DWITH_ATB=ON -DON_INFER=OFF -DWITH_COVERAGE=OFF -DPYTHON_VERSION= -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\r\n-- The CXX compiler identification is GNU 8.4.0\r\n-- The C compiler identification is GNU 8.4.0\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Check for working C compiler: /usr/bin/cc - skipped\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\nCMake Error at cmake/paddle.cmake:1:\r\n  Parse error.  Expected a command name, got unquoted argument with text\r\n  \"../../../cmake/paddle.cmake\".\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:22 (include)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\n+ cmake_error=1\r\n+ '[' 1 '!=' 0 ']'\r\n+ echo 'CMake Error Found !!!'\r\nCMake Error Found !!!\r\n+ exit 7\r\n\r\n\r\n我是根据https://www.paddlepaddle.org.cn/documentation/docs/zh/develop//guides/hardware_support/npu/install_cn.html#%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BA%8C%EF%BC%9A%E6%BA%90%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85\r\n中的关于arm源码编译安装PaddleCustomDevice的操作执行的，执行到bash tools/compile.sh的时候报了如上的错误，请问如何解决？\r\n",
        "state": "closed",
        "user": "Tyx-main",
        "closed_by": "Tyx-main",
        "created_at": "2024-11-01T09:41:44+00:00",
        "updated_at": "2024-11-27T07:37:40+00:00",
        "closed_at": "2024-11-27T07:37:40+00:00",
        "comments_count": [
            "Tyx-main",
            "ronny1996",
            "Tyx-main",
            "ronny1996",
            "onecatcn",
            "Tyx-main"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1453,
        "title": "昇腾910b上，使用paddleocr读取表格，耗时达到6s左右",
        "body": "## 在昇腾910b上，使用paddleocr读取表格，耗时达到6s左右, n卡只需0.8s\r\n\r\n### 物理环境： cann80RC1-ubuntu20-paddleocr2.7.3-paddlepaddle(3.0.0.dev20240527)\r\n#### 环境变量：\r\n`ENV FLAGS_npu_jit_compile=False\r\nENV FLAGS_npu_scale_aclnn=True\r\nENV CUSTOM_DEVICE_BLACK_LIST=\"set_value,set_value_with_tensor\"`\r\n\r\n### 复现方式：\r\n\r\n#### 命令行方式：\r\n`paddleocr --image_dir tts --use_npu true --type=structure`\r\ntts 目录中2个图片，都包含表格\r\n\r\n![image](https://github.com/user-attachments/assets/2d4d1680-bba2-4c92-8fd8-fb759495e237)\r\n\r\n\r\n#### 代码：\r\n`table_engine = NewPPStructure(show_log=True, lang='ch', recovery=False, det_limit_side_len=1920, use_npu=is_use_npu(),\r\n                              det_model_dir='ch_PP-OCRv4_det_infer',\r\n                              rec_model_dir='ch_PP-OCRv4_rec_infer',\r\n                              layout_model_dir='picodet_lcnet_x1_0_fgd_layout_cdla_infer',\r\n                              layout_dict_path='/opt/anaconda3/envs/paddle_env/lib/python3.8/site-packages/paddleocr/ppocr/utils/dict/layout_dict/layout_cdla_dict.txt',\r\n                              # table_char_dict_path='table_structure_dict_ch.txt',\r\n                              table_model_dir='ch_ppstructure_mobile_v2.0_SLANet_infer',\r\n                              layout_score_threshold=0.25,\r\n                              layout_nms_threshold=0.5)\r\n\r\n提取table信息\r\n        table_extract_num = 0\r\n        for b in final_layouts:\r\n            if str(b.type).lower() == \"table\":\r\n                x1,y1,x2,y2 = b.block.x_1, b.block.y_1, b.block.x_2, b.block.y_2\r\n                res, table_time_dict = self.table_system(\r\n                    ori_im[y1:y2, x1:x2].copy(), return_ocr_result_in_table)\r\n                b.text = res['html']\r\n                ori_im[y1:y2, x1:x2] = np.ones((y2-y1, x2-x1, 3), dtype=np.uint8)*255\r\n                table_extract_num += 1\r\n            else:\r\n                b.text = []\r\n\r\n        get_logger().info(\"extract table nums:{}\".format(table_extract_num))\r\n`\r\n![image](https://github.com/user-attachments/assets/53057803-e7da-482a-bdb6-f4166ae25dc7)\r\n\r\n\r\nprofiling\r\n执行了一次profiling，日志数据可以提供，profiling数据较大，可以留言发送\r\n[paddleocr_6.log](https://github.com/user-attachments/files/17632518/paddleocr_6.log)\r\n\r\n",
        "state": "open",
        "user": "danyXu",
        "closed_by": null,
        "created_at": "2024-11-05T12:33:23+00:00",
        "updated_at": "2024-11-19T11:14:22+00:00",
        "closed_at": null,
        "comments_count": [
            "ronny1996",
            "danyXu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1454,
        "title": "请问这个问题怎么解决呢？",
        "body": "CMake Error at cmake/paddle.cmake:90 (message):\r\n  Failed to get submodule Paddle', please check your network !\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:22 (include)\r\n",
        "state": "open",
        "user": "yuluzhong",
        "closed_by": null,
        "created_at": "2024-11-08T08:26:07+00:00",
        "updated_at": "2024-11-13T02:02:55+00:00",
        "closed_at": null,
        "comments_count": [
            "yuluzhong",
            "yuluzhong",
            "cmcamdy",
            "yuluzhong"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1478,
        "title": "昇腾910B，容器内运行mind Vsion推理报错",
        "body": "- 环境配置\r\n MINDX SDK  6.0.RC3\r\n CANN 8.0.RC1\r\n- 报错日志\r\nBegin to initialize Log.\r\nThe output directory of logs file exist.\r\nWARNING: Logging before InitGoogleLogging() is written to STDERR\r\nI20241122 10:02:56.407680 281462569663328 FileUtils.cpp:339] The input file is empty\r\nI20241122 10:02:56.407710 281462569663328 FileUtils.cpp:495] Check Other group permission: Current permission is 4, but required no greater than 0.\r\nSave logs information to specified directory.\r\nE20241122 10:02:57.047970 281462569663328 ImageProcessorDptr.hpp:819] Failed to recognize Ascend chip. (Code = -1, Message = \"ACL: general failure\") \r\nE20241122 10:02:57.048184 281462569663328 ImageProcessorDptr.hpp:879] Get predict size failed. (Code = -1, Message = \"ACL: general failure\") \r\nE20241122 10:02:57.048208 281462569663328 ImageProcessorDptr.hpp:530] ImageProcessor: Fail to predict output image data size. (Code = -1, Message = \"ACL: general failure\") \r\nE20241122 10:02:57.048230 281462569663328 PyDvpp.cpp:36] ImageProcessor decode failed. (Code = -1, Message = \"ACL: general failure\") \r\nTraceback (most recent call last):\r\n  File \"/home/HwHiAiUser/app/main.py\", line 21, in <module>\r\n    decoded_image = imageProcessor.decode(image_path, base.nv12)\r\nRuntimeError: [-1][ACL: general failure] ",
        "state": "open",
        "user": "bsl1997",
        "closed_by": null,
        "created_at": "2024-11-22T10:09:15+00:00",
        "updated_at": "2024-11-27T08:53:34+00:00",
        "closed_at": null,
        "comments_count": [
            "bsl1997",
            "onecatcn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1460,
        "title": "undefined symbol问题",
        "body": "ValueError: (InvalidArgument) Fail to open library: /home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/paddle_custom_device/libpaddle-custom-npu.so with error: /home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/paddle_custom_device/libpaddle-custom-npu.so: undefined symbol: _ZN13custom_kernel14GatherNdKernelIbN3phi13CustomContextEEEvRKT0_RKNS1_11DenseTensorES8_PS6_\r\n  [Hint: dso_handle should not be null.] (at /paddle/paddle/fluid/platform/init.cc:152)\r\n  请问这个问题怎么解决呢",
        "state": "open",
        "user": "yuluzhong",
        "closed_by": null,
        "created_at": "2024-11-14T08:42:00+00:00",
        "updated_at": "2024-11-28T01:43:08+00:00",
        "closed_at": null,
        "comments_count": [
            "onecatcn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1495,
        "title": "E1203 08:43:48.414558 27598 analysis_config.cc:163] Please use PaddlePaddle with GPU version.",
        "body": "出现这个提示，我不确定出现这个提示是会真正运行在了NPU上，是否有影响。\r\n\r\n期待解答\r\n\r\n会连续出现三个：\r\nE1203 08:43:48.096444 27598 analysis_config.cc:163] Please use PaddlePaddle with GPU version.\r\nE1203 08:43:48.414558 27598 analysis_config.cc:163] Please use PaddlePaddle with GPU version.\r\nE1203 08:43:48.896029 27598 analysis_config.cc:163] Please use PaddlePaddle with GPU version.\r\n\r\n",
        "state": "open",
        "user": "wenxinmomo",
        "closed_by": null,
        "created_at": "2024-12-03T08:49:46+00:00",
        "updated_at": "2024-12-09T06:19:29+00:00",
        "closed_at": null,
        "comments_count": [
            "wenxinmomo",
            "onecatcn",
            "wenxinmomo",
            "wenxinmomo",
            "wenxinmomo",
            "xuanyuanminzheng",
            "wenxinmomo",
            "xuanyuanminzheng",
            "wenxinmomo",
            "xiaoguoguo626807",
            "wenxinmomo",
            "wenxinmomo",
            "wangna11BD",
            "wenxinmomo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1518,
        "title": "I have searched the PaddleOCR Issues and found no similar bug report.",
        "body": null,
        "state": "closed",
        "user": "yongqiangma",
        "closed_by": "yongqiangma",
        "created_at": "2024-12-12T06:42:20+00:00",
        "updated_at": "2024-12-12T06:43:10+00:00",
        "closed_at": "2024-12-12T06:43:10+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1503,
        "title": "请问一下paddlepaddle==3.0.0b2和paddle-custom-npu==3.0.0b2应该使用那个版本的paddleocr以及paddleclas",
        "body": "请问一下我在昇腾NPU 910b上想使用paddleocr，我的paddlepaddle==3.0.0b2 -i [https://www.paddlepaddle.org.cn/packages/stable/cpu/，以及paddle-custom-npu==3.0.0b2](https://www.paddlepaddle.org.cn/packages/stable/cpu/%EF%BC%8C%E4%BB%A5%E5%8F%8Apaddle-custom-npu==3.0.0b2) -i https://www.paddlepaddle.org.cn/packages/stable/npu/ 是上述版本的，我需要安装paddleocr和paddleclas，应该安装什么版本的，我目前安装的是\"paddleocr=2.9.1\"，paddleclas=2.6.0，在这个版本下一但加载paddleOcr，把use_npu=True这个参数加上，就会在加载的时候报错，我的报错记录在图片里，以及我加载模型的方式，希望大佬们解答一下\r\n![20241205-160820](https://github.com/user-attachments/assets/53386080-2706-4f6d-9622-82e7e588069d)\r\n![20241205-160824](https://github.com/user-attachments/assets/32a7ee1f-e722-403f-ae7b-f222a61cd588)\r\n当我把use_npu=True 去掉的时候，是可以正常运行的，但是ocr一张图片耗时要39s左右，所以我不确定是否在npu上运行了，\r\n当我执行这段代码的时候python -c \"import paddle_custom_device; paddle_custom_device.npu.version()\"\r\n是正常的返回，如下图\r\n![image](https://github.com/user-attachments/assets/af9a0dbf-6369-4d56-87b3-f745791473b1)\r\n",
        "state": "open",
        "user": "Stefan3Zz",
        "closed_by": null,
        "created_at": "2024-12-05T08:33:00+00:00",
        "updated_at": "2024-12-07T14:58:12+00:00",
        "closed_at": null,
        "comments_count": [
            "Stefan3Zz",
            "onecatcn",
            "Stefan3Zz",
            "onecatcn",
            "onecatcn"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1497,
        "title": "昇腾NPU上运行text_detector速度慢",
        "body": "### 🔎 Search before asking\n\n- [x] I have searched the PaddleOCR [Docs](https://paddlepaddle.github.io/PaddleOCR/) and found no similar bug report.\n- [x] #1518\n- [X] I have searched the PaddleOCR [Discussions](https://github.com/PaddlePaddle/PaddleOCR/discussions) and found no similar bug report.\n\n### 🐛 Bug (问题描述)\n\n在ARM架构，910B的环境下。\r\n执行`PaddleOCR.text_detector()`，速度比CPU还慢。\r\nCPU一张图片大概0.5s\r\nNPU一张图片，2s-1s左右\r\n\r\n已经使用环境变量：` export FLAGS_npu_jit_compile=0`\r\n\r\n请问这种情况下，`text_detector`如何进行加速。\r\n\r\n注：`text_recognizer`很快。\n\n### 🏃‍♂️ Environment (运行环境)\n\nCPU：ARM\r\nNPU：910B\r\nCANN：8.0.RC2\n\n### 🌰 Minimal Reproducible Example (最小可复现问题的Demo)\n\n使用PaddleOCR中的text_detector函数",
        "state": "open",
        "user": "wenxinmomo",
        "closed_by": null,
        "created_at": "2024-12-03T10:57:47+00:00",
        "updated_at": "2024-12-12T06:44:31+00:00",
        "closed_at": null,
        "comments_count": [
            "wenxinmomo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1548,
        "title": "请问如何设置CUSTOM_DEVICE_BLACK_LIST ，让nn.SimpleRNN算子执行在CPU上，其余跑在加速器上？",
        "body": "![image](https://github.com/user-attachments/assets/49c2acc1-110d-4d3e-94da-f79f4678287c)\r\n我这里脚本设置后，所有算子操作均跑在CPU上了",
        "state": "open",
        "user": "wangzy0327",
        "closed_by": null,
        "created_at": "2025-01-08T06:38:22+00:00",
        "updated_at": "2025-01-13T02:07:26+00:00",
        "closed_at": null,
        "comments_count": [
            "xiaoguoguo626807",
            "wangzy0327"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1541,
        "title": "请问PaddleCustom-mlu 哪个版本支持rnn，lstm",
        "body": "ValueError: (InvalidArgument) MLU only support LSTM mode now, current mode is RNN_TANH\r\n  [Hint: Expected mode == \"LSTM\", but received mode:RNN_TANH != \"LSTM\":LSTM.] (at /paddle/backends/mlu/kernels/rnn_kernel.cc:127)\r\n\r\n\r\nValueError: (InvalidArgument) MLU only support 1 num_layers, current num_layers is 3\r\n  [Hint: Expected num_layers == 1, but received num_layers:3 != 1:1.] (at /paddle/backends/mlu/kernels/rnn_kernel.cc:133)",
        "state": "open",
        "user": "wangzy0327",
        "closed_by": null,
        "created_at": "2025-01-02T07:16:37+00:00",
        "updated_at": "2025-01-06T07:37:54+00:00",
        "closed_at": null,
        "comments_count": [
            "PeiyuLau",
            "wangzy0327"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1592,
        "title": "昇腾镜像编译完成后，运行环境校验，结果不知是否正确",
        "body": "![Image](https://github.com/user-attachments/assets/cddf134b-a6e8-4047-b47a-36ff0300fbfc)\n您好，进行校验的时候，明明有一张npu，但是却没有发现，然后我看到kernel库没有找到\n![Image](https://github.com/user-attachments/assets/eb5bf550-1047-4889-a817-4208340741ae)\n这个反馈正常吗？谢谢！\n\n\n![Image](https://github.com/user-attachments/assets/0e7e767c-19d0-4f99-bf22-02f0300d3dbd)\n\n这个命令执行失败了\n\n![Image](https://github.com/user-attachments/assets/5605a5d7-fe58-420d-895a-48db50b015d8)",
        "state": "closed",
        "user": "whwususu",
        "closed_by": "whwususu",
        "created_at": "2025-03-07T05:56:17+00:00",
        "updated_at": "2025-03-10T01:21:14+00:00",
        "closed_at": "2025-03-10T01:21:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1591,
        "title": "昇腾镜像打包成功后，执行验证命令，出现以下错误",
        "body": "![Image](https://github.com/user-attachments/assets/2d936f3c-9ac4-4cd4-a9af-5187bb00c5ad) \n我是不是要自己手动设置环境变量，谢谢！",
        "state": "closed",
        "user": "whwususu",
        "closed_by": "whwususu",
        "created_at": "2025-03-07T05:32:03+00:00",
        "updated_at": "2025-03-07T05:53:31+00:00",
        "closed_at": "2025-03-07T05:53:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1593,
        "title": "昇腾910b,镜像打包成功，运行正常，但是npu-smi info报错",
        "body": "![Image](https://github.com/user-attachments/assets/a850b9c2-c9d1-4242-8d77-bbdbc9ea3a41)\n\n不知道缺少了什么库，谢谢！\n\n![Image](https://github.com/user-attachments/assets/2536ed85-0706-4061-8675-f0b355e79958)\n\n![Image](https://github.com/user-attachments/assets/b3746ac7-d5e3-497b-b724-d33517b58a62)",
        "state": "closed",
        "user": "whwususu",
        "closed_by": "whwususu",
        "created_at": "2025-03-10T01:30:30+00:00",
        "updated_at": "2025-03-10T08:16:25+00:00",
        "closed_at": "2025-03-10T08:16:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1554,
        "title": "最后一步进行模型训练和推理测试的时候出现Cannot open file output/model.pdmodel",
        "body": "训练完成后没有查找到模型权重文件，导致报错。\r\n/usr/local/lib/python3.10/dist-packages/paddle/jit/dy2static/program_translator.py:770: UserWarning: full_graph=False don't support input_spec arguments. It will not produce any effect.\r\nYou can set full_graph=True, then you can assign input spec.\r\n\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"/mnt/nvme/yiqidata/paddle-npu/PaddleCustomDevice/backends/npu/build/tests/test_LeNet_MNIST.py\", line 261, in <module>\r\n    main(args)\r\n  File \"/mnt/nvme/yiqidata/paddle-npu/PaddleCustomDevice/backends/npu/build/tests/test_LeNet_MNIST.py\", line 209, in main\r\n    infer(\"output\")\r\n  File \"/mnt/nvme/yiqidata/paddle-npu/PaddleCustomDevice/backends/npu/build/tests/test_LeNet_MNIST.py\", line 76, in infer\r\n    config = paddle_infer.Config(model_file, params_file)\r\nRuntimeError: (NotFound) Cannot open file output/model.pdmodel, please confirm whether the file is normal.\r\n  [Hint: Expected paddle::inference::IsFileExists(prog_file_) == true, but received paddle::inference::IsFileExists(prog_file_):0 != true:1.] (at /paddle/paddle/fluid/inference/api/analysis_config.cc:117)  检查确实没有输出output/model.pdmodel文件。",
        "state": "open",
        "user": "champaignhgx",
        "closed_by": null,
        "created_at": "2025-01-10T00:42:19+00:00",
        "updated_at": "2025-01-15T14:57:51+00:00",
        "closed_at": null,
        "comments_count": [
            "yongqiangma",
            "champaignhgx",
            "yongqiangma",
            "champaignhgx",
            "yongqiangma"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1598,
        "title": "test",
        "body": "test",
        "state": "closed",
        "user": "onecatcn",
        "closed_by": "onecatcn",
        "created_at": "2025-03-11T07:30:02+00:00",
        "updated_at": "2025-03-11T07:31:00+00:00",
        "closed_at": "2025-03-11T07:31:00+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1599,
        "title": "测试",
        "body": "提交",
        "state": "closed",
        "user": "Bobbybobo0621",
        "closed_by": "Bobbybobo0621",
        "created_at": "2025-03-11T07:33:00+00:00",
        "updated_at": "2025-03-11T07:33:25+00:00",
        "closed_at": "2025-03-11T07:33:25+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1601,
        "title": "寒武纪MLU370-X4，运行paddlepaddle3.0-rc报错，找不到libmluops.so.1",
        "body": "MLU370已安装驱动，CNMON可用\n\n\n- 安装PaddlePaddle。\n\n```\npython -m pip install paddlepaddle==3.0.0rc1 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/\n```\n\n\n\n- 安装CustomDevice。\n\n```\npython -m pip install paddle-custom-mlu==3.0.0rc1 -i https://www.paddlepaddle.org.cn/packages/stable/mlu/\n```\n\n验证\n```\npython -c \"import paddle; paddle.utils.run_check()\"\n```\n\n报错\nI0311 14:58:41.198390   193 [[init.cc:235](http://init.cc:235/)](http://init.cc:235/)] ENV [CUSTOM_DEVICE_ROOT]=/usr/local/lib/python3.10/dist-packages/paddle_custom_device\nI0311 14:58:41.198410   193 [[init.cc:144](http://init.cc:144/)](http://init.cc:144/)] Try loading custom device libs from: [/usr/local/lib/python3.10/dist-packages/paddle_custom_device]\nTraceback (most recent call last):\nFile \"<string>\", line 1, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/paddle/**init**.py\", line 38, in <module>\nfrom .base import core  # noqa: F401\nFile \"/usr/local/lib/python3.10/dist-packages/paddle/base/**init**.py\", line 204, in <module>\n**bootstrap**()\nFile \"/usr/local/lib/python3.10/dist-packages/paddle/base/**init**.py\", line 196, in **bootstrap**\ncore.init_devices()\nValueError: (InvalidArgument) Fail to open library: /usr/local/lib/python3.10/dist-packages/paddle_custom_device/libpaddle-custom-mlu.so with error: libmluops.so.1: cannot open shared object file: No such file or directory\n[Hint: dso_handle should not be null.] (at /paddle/paddle/fluid/platform/init.cc:151)",
        "state": "closed",
        "user": "raodez",
        "closed_by": "raodez",
        "created_at": "2025-03-11T07:45:14+00:00",
        "updated_at": "2025-03-11T09:15:38+00:00",
        "closed_at": "2025-03-11T09:15:37+00:00",
        "comments_count": [
            "onecatcn",
            "raodez",
            "raodez",
            "a31413510",
            "raodez"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1640,
        "title": "GetDevice 返回只应该是deviceid",
        "body": "https://github.com/PaddlePaddle/PaddleCustomDevice/blob/eb6a7c2652d87d2f54e3a230e2ff5451c2f8c91f/backends/mlu/runtime/runtime.cc#L432",
        "state": "open",
        "user": "yongqiangma",
        "closed_by": null,
        "created_at": "2025-03-26T11:41:40+00:00",
        "updated_at": "2025-03-26T11:41:44+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1665,
        "title": "docker build 基础镜像找不到",
        "body": "ERROR: failed to solve: registry.baidubce.com/device/paddle-cpu:ubuntu20-npu-base-aarch64-gcc84: registry.baidubce.com/device/paddle-cpu:ubuntu20-npu-base-aarch64-gcc84: not found",
        "state": "open",
        "user": "yuemengrui",
        "closed_by": null,
        "created_at": "2025-04-09T08:54:34+00:00",
        "updated_at": "2025-05-28T02:59:36+00:00",
        "closed_at": null,
        "comments_count": [
            "chenli20190213"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1658,
        "title": "使用Npu训练完模型转换为静态图没有.pdmodel文件",
        "body": "使用昇腾910B，paddlenlp训练完模型之后，使用paddle.jit.to_static以及paddle.jit.save函数，保存模型之后没有.pdmodel文件，只有.pdiparams文件和一个.json文件，我该如何使用paddle_infer.Config这个函数呢",
        "state": "open",
        "user": "OvO616",
        "closed_by": null,
        "created_at": "2025-04-03T06:49:49+00:00",
        "updated_at": "2025-04-07T00:49:59+00:00",
        "closed_at": null,
        "comments_count": [
            "OvO616"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1811,
        "title": "Nightly Update: Paddle Submodule",
        "body": "Automated PR to update Paddle submodule to the latest commit.",
        "state": "open",
        "user": "github-actions[bot]",
        "closed_by": null,
        "created_at": "2025-07-08T16:30:27+00:00",
        "updated_at": "2025-07-08T16:30:33+00:00",
        "closed_at": null,
        "comments_count": [
            "paddle-bot[bot]"
        ],
        "labels": [
            "automated",
            "submodule"
        ]
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1713,
        "title": "manifest for registry.baidubce.com/device/paddle-cpu:ubuntu20-npu-base-aarch64-gcc84 not found",
        "body": "参照https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/tools/dockerfile/build-image.sh构建适配310p的镜像，构建过程中提示：manifest for registry.baidubce.com/device/paddle-cpu:ubuntu20-npu-base-aarch64-gcc84 not found。请问基础镜像名称是否有误，请给出正确的在310p构建的基础镜像名称，谢谢！！",
        "state": "open",
        "user": "chenli20190213",
        "closed_by": null,
        "created_at": "2025-05-27T08:27:07+00:00",
        "updated_at": "2025-06-04T09:35:44+00:00",
        "closed_at": null,
        "comments_count": [
            "onecatcn",
            "intjun"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaddleCustomDevice",
        "number": 1812,
        "title": "[NPU] Fix slice op on NPU",
        "body": "当 starts = -1 时，aclnnSliceV2 与 paddle.slice 结果 size 不一致，导致 NPU 上多个模型推理异常。\r\n\r\n修复方案是传入标准化过的切片。",
        "state": "open",
        "user": "LittleHeroZZZX",
        "closed_by": null,
        "created_at": "2025-07-08T17:05:23+00:00",
        "updated_at": "2025-07-08T17:05:30+00:00",
        "closed_at": null,
        "comments_count": [
            "paddle-bot[bot]"
        ],
        "labels": [
            "contributor"
        ]
    }
]