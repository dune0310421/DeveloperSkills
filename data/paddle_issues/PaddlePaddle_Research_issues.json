[
    {
        "repo": "PaddlePaddle/Research",
        "number": 29,
        "title": "关于序列标注策略的疑惑",
        "body": "![image](https://user-images.githubusercontent.com/23302810/78389347-2aa3f380-7615-11ea-8925-645f6bca5682.png)\r\n为什么“王”字，所对应的标签被划分到两个类中，这两个类分别是什么，希望得到解答，谢谢",
        "state": "closed",
        "user": "szxSpark",
        "closed_by": "szxSpark",
        "created_at": "2020-04-03T17:41:03+00:00",
        "updated_at": "2020-04-03T18:01:48+00:00",
        "closed_at": "2020-04-03T18:01:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 28,
        "title": "推荐式对话的baseline未上传",
        "body": "",
        "state": "closed",
        "user": "DesmonDay",
        "closed_by": "DesmonDay",
        "created_at": "2020-04-03T07:29:59+00:00",
        "updated_at": "2020-04-05T09:15:34+00:00",
        "closed_at": "2020-04-05T09:15:34+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 35,
        "title": "About ACL2019 ARNOR",
        "body": "你好，关于ACL2019收录论文，ARNOR，请问github中给出的的data version2的F1评测结果是macro的计算方式还是micro的计算方式，评测指标是否会去除None的标注。",
        "state": "open",
        "user": "fanxiangshangfen",
        "closed_by": null,
        "created_at": "2020-04-12T03:23:29+00:00",
        "updated_at": "2020-04-12T03:23:29+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 7,
        "title": "add webvision2018",
        "body": "see title, add webvision2018 code",
        "state": "closed",
        "user": "yuanpengcheng",
        "closed_by": "yuanpengcheng",
        "created_at": "2020-02-17T02:05:41+00:00",
        "updated_at": "2020-02-17T02:59:54+00:00",
        "closed_at": "2020-02-17T02:59:54+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 38,
        "title": "errors running DuReader-Robust-BASELINE",
        "body": "W0414 16:45:31.025034 10900 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.0, Runtime API Version: 9.0\r\nW0414 16:45:31.028314 10900 device_context.cc:245] device: 0, cuDNN Version: 7.6.\r\n\r\n\r\n\r\nI0414 16:45:33.431712 10900 parallel_executor.cc:440] The Program will be executed on CUDA using ParallelExecutor, 2 cards are used, so 2 programs are executed in parallel.\r\nW0414 16:45:36.668439 10900 init.cc:209] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0414 16:45:36.668462 10900 init.cc:211] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0414 16:45:36.668467 10900 init.cc:214] The detail failure signal is:\r\n\r\nW0414 16:45:36.668470 10900 init.cc:217] *** Aborted at 1586853936 (unix time) try \"date -d @1586853936\" if you are using GNU date ***\r\nW0414 16:45:36.670137 10900 init.cc:217] PC: @                0x0 (unknown)\r\nW0414 16:45:36.670218 10900 init.cc:217] *** SIGSEGV (@0x0) received by PID 10900 (TID 0x7f7fa99b1700) from PID 0; stack trace: ***\r\nW0414 16:45:36.671615 10900 init.cc:217]     @     0x7f7fa959d390 (unknown)\r\nW0414 16:45:36.673030 10900 init.cc:217]     @                0x0 (unknown)",
        "state": "closed",
        "user": "wuhenbai",
        "closed_by": "HongyuLi2018",
        "created_at": "2020-04-14T08:53:13+00:00",
        "updated_at": "2020-06-02T03:05:13+00:00",
        "closed_at": "2020-06-02T03:05:13+00:00",
        "comments_count": [
            "HongyuLi2018"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 37,
        "title": "Will release Pre-Trained Chinese PLATO models?",
        "body": "",
        "state": "open",
        "user": "bojone",
        "closed_by": null,
        "created_at": "2020-04-14T06:18:50+00:00",
        "updated_at": "2020-07-01T02:18:33+00:00",
        "closed_at": null,
        "comments_count": [
            "portia1026",
            "bojone",
            "portia1026",
            "bojone"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 41,
        "title": "关于PLATO模型：为什么需要隐变量？",
        "body": "按照文章的介绍，是为了更好地进行一对多生成，但事实上seq2seq模型本身就可以通过采样生成（而不是beam search确定性生成），所以原则上seq2seq模型本身就包含了一对多生成能力，文章所说的常规seq2seq不能很好地做一对多生成的断言似乎不能成立。\r\n\r\n那么，隐变量的意义何在呢？此外，我没看到关于隐变量的正则项，那么如何保证隐变量的分布不会退化为一个one hot分布呢（即变成只有一个类，等价于没有隐变量）？",
        "state": "open",
        "user": "bojone",
        "closed_by": null,
        "created_at": "2020-04-20T06:40:11+00:00",
        "updated_at": "2020-07-07T02:55:28+00:00",
        "closed_at": null,
        "comments_count": [
            "WorldEditors",
            "WorldEditors",
            "songyouwei",
            "WorldEditors",
            "eyuansu62",
            "WorldEditors",
            "eyuansu62"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 40,
        "title": "在AI Studio上新建项目运行报错",
        "body": "你好，\r\n  我在AI Studio上新建项目后，运行时出现错误：\r\n![image](https://user-images.githubusercontent.com/38073482/79349113-771df600-7f68-11ea-8384-07d0add5550d.png)\r\npython=3.7\r\nPaddlePaddle=1.6.0\r\n请问如何解决，谢谢！",
        "state": "closed",
        "user": "JBoRu",
        "closed_by": "sserdoubleh",
        "created_at": "2020-04-15T14:29:12+00:00",
        "updated_at": "2020-04-21T09:27:57+00:00",
        "closed_at": "2020-04-21T09:27:57+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 39,
        "title": "多卡运行NLP/DuReader-Robust-BASELINE报错：Tensor holds no memory. Call Tensor::mutable_data first.",
        "body": "NLP/DuReader-Robust-BASELINE的训练程序，单卡时正常运行，多卡时则会报错，具体信息如下：\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::framework::Tensor::check_memory_size() const\r\n3   long const* paddle::framework::Tensor::data<long>() const\r\n4   paddle::operators::LookupTableV2CUDAKernel<float>::Compute(paddle::framework::ExecutionContext const&) const\r\n5   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LookupTableV2CUDAKernel<float>, paddle::operators::LookupTableV2CUDAKernel<double>, paddle::operators::LookupTableV2CUDAKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const\r\n8   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&)\r\n9   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n10  paddle::framework::details::ThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n11  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::_Result_base::_Deleter>, void> >::_M_invoke(std::_Any_data const&)\r\n12  std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\r\n13  ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2459, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/input.py\", line 268, in embedding\r\n    'padding_idx': padding_idx\r\n  File \"/home/zhan/Research-master/NLP/DuReader-Robust-BASELINE/src/model/ernie.py\", line 97, in _build_model\r\n    name=self._pos_emb_name, initializer=self._param_initializer))\r\n  File \"/home/zhan/Research-master/NLP/DuReader-Robust-BASELINE/src/model/ernie.py\", line 81, in __init__\r\n    self._build_model(src_ids, position_ids, sentence_ids, input_mask)\r\n  File \"<ipython-input-13-e3525fc15485>\", line 39, in create_model\r\n    use_fp16=args.use_fp16)\r\n  File \"<ipython-input-14-d2515acdb659>\", line 6, in <module>\r\n    is_training=True)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\r\n    return runner(coro)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\r\n    user_expressions, allow_stdin,\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\r\n    yield gen.maybe_future(handler(stream, idents, msg))\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\r\n    yield gen.maybe_future(dispatch(*args))\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/gen.py\", line 714, in __init__\r\n    self.run()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\r\n    runner = Runner(result, future, yielded)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\r\n    yield self.process_one()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\r\n    self.run()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\r\n    ret = callback()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\r\n    lambda f: self._run_callback(functools.partial(callback, future))\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/asyncio/events.py\", line 88, in _run\r\n    self._context.run(self._callback, *self._args)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\r\n    handle._run()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\r\n    self._run_once()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 583, in start\r\n    self.io_loop.start()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\r\n    app.start()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/zhan/anaconda3/envs/paddle/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nPaddleCheckError: holder_ should not be null\r\nTensor holds no memory. Call Tensor::mutable_data first. at [/paddle/paddle/fluid/framework/tensor.cc:23]\r\n  [operator < lookup_table_v2 > error]\r\n\r\n运行环境为：\r\npaddlepaddle-gpu 1.6.1.post107\r\ncuda 10.0\r\ncudnn 7.6.4\r\nnccl 2.6.4",
        "state": "closed",
        "user": "QgZhan",
        "closed_by": "HongyuLi2018",
        "created_at": "2020-04-14T11:20:19+00:00",
        "updated_at": "2020-06-02T03:04:42+00:00",
        "closed_at": "2020-06-02T03:04:42+00:00",
        "comments_count": [
            "HongyuLi2018"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 43,
        "title": "官网给的test1文件怎么处理",
        "body": "",
        "state": "open",
        "user": "zhangzhiyi0108",
        "closed_by": null,
        "created_at": "2020-04-23T14:45:46+00:00",
        "updated_at": "2020-04-23T14:45:46+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 57,
        "title": "2_prepare_syn_trainlist",
        "body": "Traceback (most recent call last):\r\n  File \"2_prepare_syn_trainlist.py\", line 29, in <module>\r\n    color = s.attributes['colorID'].value\r\n  File \"/home/eini/anaconda3/lib/python3.7/xml/dom/minidom.py\", line 552, in __getitem__\r\n    return self._attrs[attname_or_tuple]\r\nKeyError: 'colorID'\r\n",
        "state": "open",
        "user": "wangzhiyuanking",
        "closed_by": null,
        "created_at": "2020-05-28T02:16:01+00:00",
        "updated_at": "2020-05-28T02:16:01+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 55,
        "title": "DuEL_Baseline 在运行predict.sh的时候，报 var read_file_0.tmp_3 not in this block 错误",
        "body": "详情log如下：\r\n请问是哪里出错了吗，训练是没有问题的\r\n\r\n环境：Cuda10+cudnn 7.4 + paddle1.7.1\r\n\r\n> Traceback (most recent call last):\r\n  File \"./ernie/infer_type_ranker.py\", line 358, in <module>\r\n    main(args)\r\n  File \"./ernie/infer_type_ranker.py\", line 163, in main\r\n    main_program=predict_prog,\r\n  File \"/home/hadoop-aipnlp/cephfs/data/gaojianwei/research/ccks2020/DuEL_Baseline/env2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 1221, in save_inference_model\r\n    prepend_feed_ops(main_program, feeded_var_names)\r\n  File \"/home/hadoop-aipnlp/cephfs/data/gaojianwei/research/ccks2020/DuEL_Baseline/env2/lib/python2.7/site-packages/paddle/fluid/io.py\", line 1031, in prepend_feed_ops\r\n    out = global_block.var(name)\r\n  File \"/home/hadoop-aipnlp/cephfs/data/gaojianwei/research/ccks2020/DuEL_Baseline/env2/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2280, in var\r\n    raise ValueError(\"var %s not in this block\" % name)\r\nValueError: var read_file_0.tmp_3 not in this block",
        "state": "closed",
        "user": "gjwei",
        "closed_by": "gjwei",
        "created_at": "2020-05-25T07:22:48+00:00",
        "updated_at": "2020-05-25T08:40:28+00:00",
        "closed_at": "2020-05-25T08:40:28+00:00",
        "comments_count": [
            "gjwei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 54,
        "title": "Research/CV/PaddleReid/process_aicity_data/",
        "body": "2_prepare_real_trainlist.py\r\n37行 all_ids.append(vid) 应该有错误，set不支持append方法，应该是add方法\r\n\r\n2_prepare_syn_trainlist.py\r\n29，30 行\r\ncolor = s.attributes['colorID'].value\r\ncartype = s.attributes['typeID'].value\r\n但是不是所有的车辆都有colorID这个属性，会造成程序崩溃",
        "state": "open",
        "user": "rrjia",
        "closed_by": null,
        "created_at": "2020-05-20T00:54:56+00:00",
        "updated_at": "2022-05-11T02:47:32+00:00",
        "closed_at": null,
        "comments_count": [
            "daiguangzhao",
            "wangzhiyuanking",
            "daiguangzhao",
            "lhbsww"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 56,
        "title": "运行PLATO模型，训练时进程被Killed",
        "body": "您好，\r\n我在PaddlePaddle 1.6.0，8核8G内存的Linux机器上运行PLATO模型时，报如下错误，请帮忙看看，谢谢！\r\n\r\n$ bash scripts/DailyDialog/train.sh \r\n+ SAVE_DIR=outputs/DailyDialog\r\n+ VOCAB_PATH=model/Bert/vocab.txt\r\n+ DATA_DIR=data/DailyDialog\r\n+ INIT_CHECKPOINT=model/PLATO\r\n+ DATA_TYPE=multi\r\n+ USE_VISUALDL=false\r\n+ export CUDA_VISIBLE_DEVICES=\r\n+ CUDA_VISIBLE_DEVICES=\r\n+ export FLAGS_fraction_of_gpu_memory_to_use=0.1\r\n+ FLAGS_fraction_of_gpu_memory_to_use=0.1\r\n+ export FLAGS_eager_delete_scope=True\r\n+ FLAGS_eager_delete_scope=True\r\n+ export FLAGS_eager_delete_tensor_gb=0.0\r\n+ FLAGS_eager_delete_tensor_gb=0.0\r\n+ python -u ./preprocess.py --vocab_path model/Bert/vocab.txt --data_dir data/DailyDialog --data_type multi\r\n+ [[ false = true ]]\r\n+ python -u ./run.py --do_train true --vocab_path model/Bert/vocab.txt --data_dir data/DailyDialog --data_type multi --batch_size 6 --valid_steps 2000 --num_type_embeddings 2 --use_discriminator true --num_epoch 20 --lr 1e-5 --save_checkpoint false --save_summary false --init_checkpoint model/PLATO --save_dir outputs/DailyDialog\r\n{\r\n  \"do_train\": true,\r\n  \"do_test\": false,\r\n  \"do_infer\": false,\r\n  \"num_infer_batches\": null,\r\n  \"hparams_file\": null,\r\n  \"BPETextField\": {\r\n    \"vocab_path\": \"model/Bert/vocab.txt\",\r\n    \"filtered\": false,\r\n    \"max_len\": 256,\r\n    \"min_utt_len\": 1,\r\n    \"max_utt_len\": 50,\r\n    \"min_ctx_turn\": 1,\r\n    \"max_ctx_turn\": 16,\r\n    \"max_knowledge_num\": 16,\r\n    \"max_knowledge_len\": 16,\r\n    \"tokenizer_type\": \"Bert\"\r\n  },\r\n  \"Dataset\": {\r\n    \"data_dir\": \"data/DailyDialog\",\r\n    \"data_type\": \"multi\"\r\n  },\r\n  \"Trainer\": {\r\n    \"use_data_distributed\": false,\r\n    \"valid_metric_name\": \"-loss\",\r\n    \"num_epochs\": 20,\r\n    \"save_dir\": \"outputs/DailyDialog\",\r\n    \"batch_size\": 6,\r\n    \"log_steps\": 100,\r\n    \"valid_steps\": 2000,\r\n    \"save_checkpoint\": false,\r\n    \"save_summary\": false,\r\n    \"shuffle\": true,\r\n    \"sort_pool_size\": 0\r\n  },\r\n  \"Model\": {\r\n    \"init_checkpoint\": \"model/PLATO\",\r\n    \"model\": \"UnifiedTransformer\",\r\n    \"num_token_embeddings\": -1,\r\n    \"num_pos_embeddings\": 512,\r\n    \"num_type_embeddings\": 2,\r\n    \"num_turn_embeddings\": 16,\r\n    \"num_latent\": 20,\r\n    \"tau\": 0.67,\r\n    \"with_bow\": true,\r\n    \"hidden_dim\": 768,\r\n    \"num_heads\": 12,\r\n    \"num_layers\": 12,\r\n    \"padding_idx\": 0,\r\n    \"dropout\": 0.1,\r\n    \"embed_dropout\": 0.0,\r\n    \"attn_dropout\": 0.1,\r\n    \"ff_dropout\": 0.1,\r\n    \"use_discriminator\": true,\r\n    \"dis_ratio\": 1.0,\r\n    \"weight_sharing\": true,\r\n    \"pos_trainable\": true,\r\n    \"two_layer_predictor\": false,\r\n    \"bidirectional_context\": true,\r\n    \"label_smooth\": 0.0,\r\n    \"initializer_range\": 0.02,\r\n    \"lr\": 1e-05,\r\n    \"weight_decay\": 0.0,\r\n    \"max_grad_norm\": null\r\n  },\r\n  \"Generator\": {\r\n    \"generator\": \"BeamSearch\",\r\n    \"min_gen_len\": 1,\r\n    \"max_gen_len\": 30,\r\n    \"beam_size\": 5,\r\n    \"length_average\": false,\r\n    \"length_penalty\": -1.0,\r\n    \"ignore_unk\": true\r\n  }\r\n}\r\nLoading parameters from model/PLATO\r\nLoaded parameters from model/PLATO\r\nscripts/DailyDialog/train.sh: line 45:  2041 Killed                  python -u ./run.py --do_train true --vocab_path $VOCAB_PATH --data_dir $DATA_DIR --data_type $DATA_TYPE --batch_size 6 --valid_steps 2000 --num_type_embeddings 2 --use_discriminator true --num_epoch 20 --lr 1e-5 --save_checkpoint false --save_summary $USE_VISUALDL --init_checkpoint $INIT_CHECKPOINT --save_dir $SAVE_DIR\r\n+ [[ false = true ]]\r\n\r\n",
        "state": "open",
        "user": "MartinKUNGGitHub",
        "closed_by": null,
        "created_at": "2020-05-27T00:49:12+00:00",
        "updated_at": "2020-06-05T06:25:33+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 59,
        "title": "About ACL2020-GraphSum",
        "body": "Hi, thx for your nice work accepted by acl2020. I check out the link attached on paper `leveraging graph to improve abstractive multi-document summarization`. But I did not find code and result in this repo and any other branch. How could I access codes and results. ",
        "state": "open",
        "user": "joelxiangnanchen",
        "closed_by": null,
        "created_at": "2020-05-29T08:07:30+00:00",
        "updated_at": "2020-06-16T03:24:36+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP",
            "Weili-NLP",
            "joelxiangnanchen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 58,
        "title": "ACL2019_DuConv generative_paddle loss error",
        "body": "Hi,\r\nI want to run the model in generative_paddle, but there is an error when I run run_train.sh:\r\n`AssertionError: The loss.shape should be (1L,), but the current loss.shape is (-1L,). Maybe that you should call fluid.layers.mean to process the current loss.\r\n`\r\nHow can I solve it? THANKS!",
        "state": "closed",
        "user": "julielin123",
        "closed_by": "julielin123",
        "created_at": "2020-05-29T07:25:36+00:00",
        "updated_at": "2020-11-08T12:00:16+00:00",
        "closed_at": "2020-06-22T07:03:25+00:00",
        "comments_count": [
            "yaolinli"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 61,
        "title": "Where is ACL20-DuRecDial?",
        "body": "",
        "state": "open",
        "user": "iriscxy",
        "closed_by": null,
        "created_at": "2020-06-07T01:45:57+00:00",
        "updated_at": "2021-02-26T09:55:46+00:00",
        "closed_at": null,
        "comments_count": [
            "zhubeniii",
            "Hu-chi",
            "liuzeming01",
            "DukeKevin"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 60,
        "title": "dusql-baseline",
        "body": "运行baseline时， 运行至2020-06-01 15:04:33,010-INFO: value feature is being used这个日志时，再无日志输入，gpu利用率为11m，运行的时lstm编码",
        "state": "open",
        "user": "hyybuaa",
        "closed_by": null,
        "created_at": "2020-06-01T07:07:11+00:00",
        "updated_at": "2020-07-01T07:50:14+00:00",
        "closed_at": null,
        "comments_count": [
            "stephenLee"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 67,
        "title": "How to parse sql_query to sql (NLP DuSQL-Baseline task)",
        "body": "Hi, @AoZhang , I download the original data from this link: https://dataset-bj.cdn.bcebos.com/dusql/DuSQL.tar. But I can't find any code about how to parse sql_query to sql in the train/dev/test data.   ",
        "state": "open",
        "user": "stephenLee",
        "closed_by": null,
        "created_at": "2020-06-29T06:11:45+00:00",
        "updated_at": "2020-06-29T06:17:07+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 71,
        "title": "How to train the mode with 2 GPUs",
        "body": "I have only two GPUs. How do I modify the code?",
        "state": "open",
        "user": "leopardv10",
        "closed_by": null,
        "created_at": "2020-07-12T20:50:52+00:00",
        "updated_at": "2020-07-12T20:50:52+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 73,
        "title": "Stuck with this errorr, please help (server not ready, wait 3 sec to retry)",
        "body": "Hello,\r\nWhen I run the training of ACL2020-GraphSum I got the following, would you please let me know how to solve this?\r\n<img width=\"1550\" alt=\"Screen Shot 2020-07-15 at 2 09 29 PM\" src=\"https://user-images.githubusercontent.com/60219670/87538709-5b300a80-c6a5-11ea-94dc-c5bbe70dd27c.png\">\r\n\r\n\r\nI am using Ubuntu\r\n\r\nMany thanks,",
        "state": "open",
        "user": "HindAlamro",
        "closed_by": null,
        "created_at": "2020-07-15T08:18:39+00:00",
        "updated_at": "2020-07-15T11:14:10+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 75,
        "title": "Duplicates in the ACL2020_SignOrSymptom_Relationship",
        "body": "Thanks for publishing the KG! \r\n\r\nIt seems that there are duplicates in the disease-finding relations. For example,\r\n\r\n```支气管哮喘\t气喘\tSymptom```\r\n\r\nappeared at least twice in the ```relations_respiration_all.txt```. Would this matter to the results?\r\n\r\nBest wishes,\r\nA",
        "state": "open",
        "user": "acadTags",
        "closed_by": null,
        "created_at": "2020-07-17T09:01:31+00:00",
        "updated_at": "2020-07-17T09:01:31+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 76,
        "title": "TypeError: _set_attr(): incompatible function arguments. The following argument types are supported",
        "body": "Any solution for this please.\r\n\r\n<img width=\"1494\" alt=\"Screen Shot 2020-07-19 at 12 46 36 AM\" src=\"https://user-images.githubusercontent.com/60219670/87862549-0e288e80-c95a-11ea-836e-bbd7a6aa0edf.png\">\r\n",
        "state": "open",
        "user": "HindAlamro",
        "closed_by": null,
        "created_at": "2020-07-18T21:53:13+00:00",
        "updated_at": "2020-07-18T21:53:13+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 72,
        "title": "How to provide custom input to ACL2020-GraphSum model",
        "body": "Your work is amazing. Can you please direct me to a method which tells how can we give our own paragraphs as input to GraphSum Model?",
        "state": "open",
        "user": "RishabhNewzera",
        "closed_by": null,
        "created_at": "2020-07-15T07:36:56+00:00",
        "updated_at": "2020-08-04T06:47:01+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP",
            "RishabhNewzera",
            "Wang-Yufei",
            "RishabhNewzera",
            "Weili-NLP"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 80,
        "title": "DatasetA label for fine-tuning",
        "body": "Can you provide label for dataset A on another hosting? I can't download from baidu. Thanks so much.",
        "state": "open",
        "user": "PhanVinhLong",
        "closed_by": null,
        "created_at": "2020-07-28T09:13:20+00:00",
        "updated_at": "2020-07-28T09:13:20+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 74,
        "title": "将DuIE_Baseline基线系统做了一个服务部署，可以在线查看抽取结果",
        "body": "http://www.junphy.com/wordpress/index.php/2020/07/17/duie-baseline/",
        "state": "open",
        "user": "Junphy-Jan",
        "closed_by": null,
        "created_at": "2020-07-17T05:53:08+00:00",
        "updated_at": "2020-08-17T05:35:35+00:00",
        "closed_at": null,
        "comments_count": [
            "iceriver97"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 78,
        "title": "'Parameter' object has no attribute '_grad_ivar'",
        "body": "I encountered this error when I run `sh scripts/DailyDialog/multi_gpu_train.sh`\r\n\r\nmy environment:\r\npaddlepaddle==1.6.0  via `pip install paddlepaddle-gpu==1.6.0`\r\ncuda 10\r\ncudnn 7.6\r\n\r\nthanks!",
        "state": "open",
        "user": "libing125",
        "closed_by": null,
        "created_at": "2020-07-20T14:29:49+00:00",
        "updated_at": "2020-09-01T07:27:54+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 86,
        "title": "NLP/ACL2018_DuReader ModuleNotFoundError: No module named 'bidaf_model'",
        "body": "![image](https://user-images.githubusercontent.com/8966194/89513855-b3bb7900-d807-11ea-8bc0-a34825b4e39a.png)\r\n尝试运行PaddlePaddle/Research/NLP/ACL2018_DuReader, 执行到'评估'阶段时，run.py中导包失败\r\n```\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 41, in <module>\r\n    import bidaf_model as rc_model\r\nModuleNotFoundError: No module named 'bidaf_model'\r\n```\r\n检查后，没有在项目中找到bidaf_model相关代码。\r\n希望可以帮忙解决一下，谢谢。\r\n",
        "state": "open",
        "user": "littlerookie",
        "closed_by": null,
        "created_at": "2020-08-06T09:16:41+00:00",
        "updated_at": "2020-08-06T09:16:41+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 81,
        "title": "About ACL2020-GraphSum",
        "body": "您好！我想用自己的数据测试模型，请问像WIKI.test.0.json这样的数据是怎么生成的呢？有相应程序吗？\r\n\r\n",
        "state": "open",
        "user": "Wang-Yufei",
        "closed_by": null,
        "created_at": "2020-07-28T13:08:41+00:00",
        "updated_at": "2020-08-04T07:20:12+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP",
            "Wang-Yufei"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 88,
        "title": "A question about ACL2020 GraphSum paper ",
        "body": "Hi, \r\n\r\nThanks for releasing the code. I read the paper of GraphSum and here is my question.\r\nIn section 3.3 You said, \"However, thanks to the graph modeling, our model can process much longer inputs.\" So, how do you process longer inputs? I am very interested in it.\r\n\r\nthank you!\r\n",
        "state": "closed",
        "user": "TysonYu",
        "closed_by": "TysonYu",
        "created_at": "2020-08-24T13:10:59+00:00",
        "updated_at": "2021-01-04T11:11:53+00:00",
        "closed_at": "2021-01-04T11:11:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 87,
        "title": "DuConv 数据集开放问题",
        "body": "这个数据集怎么只能在英文网站找到",
        "state": "closed",
        "user": "Li-rr",
        "closed_by": "Li-rr",
        "created_at": "2020-08-11T05:49:57+00:00",
        "updated_at": "2020-09-04T10:57:43+00:00",
        "closed_at": "2020-09-04T10:57:43+00:00",
        "comments_count": [
            "wwqydy",
            "Li-rr"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 89,
        "title": "Might be a bug",
        "body": "https://github.com/PaddlePaddle/Research/blob/b466c223b5b718588384460c470ffcf086559cfe/NLP/Dialogue-PLATO/plato/metrics/metrics.py#L32\r\n\r\nIs\r\n```\r\nzip(seq, seq[1:])\r\n```\r\nsuppose to be\r\n```\r\nzip(seq[:-1], seq[1:])\r\n```\r\n",
        "state": "closed",
        "user": "freesunshine0316",
        "closed_by": "freesunshine0316",
        "created_at": "2020-08-25T18:10:10+00:00",
        "updated_at": "2020-09-01T05:29:25+00:00",
        "closed_at": "2020-09-01T05:29:25+00:00",
        "comments_count": [
            "sserdoubleh"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 94,
        "title": "How to download dataset",
        "body": "Can you upload dataset on google driver. i can't download this link on baidu sever.",
        "state": "open",
        "user": "ThorPham",
        "closed_by": null,
        "created_at": "2020-09-03T05:07:23+00:00",
        "updated_at": "2020-09-03T05:07:23+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 90,
        "title": "关于EMNLP2019-AKGCM中，Minerva应用在对话中的query",
        "body": "您好，\r\n\r\n在Minerva文章中解决的是三元组的QA问题，所以他们的query也来自于relation。\r\n那对于对话中的query，是第一个人说的话吗？\r\n那训练的数据集是将triple中的relation全部换成sentence吗？\r\n\r\n谢谢！",
        "state": "closed",
        "user": "victorup",
        "closed_by": "victorup",
        "created_at": "2020-08-26T04:04:34+00:00",
        "updated_at": "2020-10-14T02:50:40+00:00",
        "closed_at": "2020-10-14T02:50:40+00:00",
        "comments_count": [
            "victorup"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 91,
        "title": "PLATO fine-tuning raises error.. Please help!",
        "body": "Hello,\r\nI installed all requirements by using pip install -r requirement.txt\r\nmy cuda version, cudnn version are fit for paddlepaddle-gpu == 1.6.1.post107 (which is on your requirements.txt)\r\nHowever, I met this error when I try to fine-tune the pre-trained model.\r\n\r\nTraceback (most recent call last):\r\n  File \"./run.py\", line 23, in <module>\r\n    import paddle.fluid as fluid\r\n  File \"/home/joy/Research/NLP/Dialogue-PLATO/vplato/lib/python3.6/site-packages/paddle/fluid/__init__.py\", line 35, in <module>\r\n    from . import framework\r\n  File \"/home/joy/Research/NLP/Dialogue-PLATO/vplato/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 35, in <module>\r\n    from . import core\r\n  File \"/home/joy/Research/NLP/Dialogue-PLATO/vplato/lib/python3.6/site-packages/paddle/fluid/core.py\", line 187, in <module>\r\n    raise e\r\n  File \"/home/joy/Research/NLP/Dialogue-PLATO/vplato/lib/python3.6/site-packages/paddle/fluid/core.py\", line 167, in <module>\r\n    from .core_avx import *\r\nImportError: /home/joy/Research/NLP/Dialogue-PLATO/vplato/lib/python3.6/site-packages/paddle/fluid/../libs/libmklml_intel.so: symbol __kmpc_omp_task_with_deps, version VERSION not defined in file libiomp5.so with link time reference\r\n+ [[ false = true ]]\r\n\r\nI tried my best to fix it, but it didn't work. What is the solution for this problem?",
        "state": "closed",
        "user": "rokslej",
        "closed_by": "rokslej",
        "created_at": "2020-08-27T04:26:20+00:00",
        "updated_at": "2020-08-31T06:32:02+00:00",
        "closed_at": "2020-08-31T06:27:23+00:00",
        "comments_count": [
            "rokslej"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 92,
        "title": "I think parallel.py in PLATO implementation raises attribute error",
        "body": "Hello, \r\nIt might be a silly question because it's my first time using paddle based codes... I hope your understanding!\r\n\r\nI'm trying to run PLATO fine-tuning code, and I met 'Parameter' object has no attribute '_grad_ivar' error' at apply_collectice_grads function in parallel.py in plato implementation.\r\n\r\nI also noticed that this function is also implemented in paddle/fluid/dygraph/parallel.py, and it was slightly different from the implementation in plato.\r\n\r\n\r\nTherefore, I changed the function in plato just like the function in paddle implementaion.\r\nAs a result, I can run this code, but I still don't know if this method will make sense... I need your help!!\r\n\r\nThank you.\r\n\r\n<pre>\r\n<code>\r\n        for param in self._layers.parameters():\r\n            # NOTE(zcd): The grad_ivar maybe no generated.\r\n            #if param.trainable and param._grad_ivar():\r\n            if param.trainable and param._ivar._grad_ivar():\r\n                g_var = param._grad_ivar()\r\n                grad_vars.append(g_var)\r\n                assert g_var not in grad_var_set\r\n                grad_var_set.add(g_var)\r\n</code>\r\n</pre>\r\nat apply_collectice_grads function in Research/NLP/Dialogue-PLATO/plato/modules/parallel.py\r\n<pre>\r\n<code>\r\n        for param in self._layers.parameters():\r\n            # NOTE(zcd): The grad_ivar maybe no generated.\r\n            if param.trainable and param._ivar._grad_ivar():\r\n                g_var = framework.Variable(\r\n                    block=self._helper.main_program.current_block(),\r\n                    name=param._ivar._grad_name(),\r\n                    stop_gradient=True,\r\n                    ivar=param._ivar._grad_ivar())\r\n                grad_vars.append(g_var)\r\n                assert g_var not in grad_var_set\r\n                grad_var_set.add(g_var)\r\n</code>\r\n</pre>\r\nat apply_collectice_grads function in paddle/fluid/dygraph/parallel.py\r\n",
        "state": "closed",
        "user": "rokslej",
        "closed_by": "rokslej",
        "created_at": "2020-09-01T02:56:09+00:00",
        "updated_at": "2020-09-01T08:44:12+00:00",
        "closed_at": "2020-09-01T08:44:12+00:00",
        "comments_count": [
            "sserdoubleh",
            "sserdoubleh",
            "rokslej"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 95,
        "title": "DuIE_Baseline编译报错",
        "body": "执行的时候报错，麻烦看下是啥问题？\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/home/yong-group/.local/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/home/yong-group/.local/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/home/yong-group/.local/lib/python3.7/site-packages/paddle/fluid/layers/sequence_lod.py\", line 1057, in sequence_unpad\r\n    outputs={'Out': out})\r\n  File \"/home/yong-group/XYN/PAP挑战赛/DuIE_Baseline/ernie/finetune/relation_extraction_multi_cls.py\", line 84, in create_model\r\n    lod_labels = fluid.layers.sequence_unpad(labels, seq_lens)\r\n  File \"/home/yong-group/XYN/PAP挑战赛/DuIE_Baseline/ernie/run_duie.py\", line 161, in main\r\n    ernie_config=ernie_config)\r\n  File \"/home/yong-group/XYN/PAP挑战赛/DuIE_Baseline/ernie/run_duie.py\", line 411, in <module>\r\n    main(args)\r\nInvalidArgumentError: The shape of Input(Length) should be [batch_size]. But received (2)\r\n  [Hint: Expected len_dims.size() == 1, but received len_dims.size():2 != 1:1.] at (/paddle/paddle/fluid/operators/sequence_ops/sequence_unpad_op.cc:52)\r\n  [operator < sequence_unpad > error]",
        "state": "open",
        "user": "xihuangshangrenlqm",
        "closed_by": null,
        "created_at": "2020-09-08T08:38:56+00:00",
        "updated_at": "2020-09-08T08:38:56+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 97,
        "title": "ACL2019-ARNOR dataset clarification",
        "body": "I have the following questions on data version 2.0.0.\r\n\r\n1) Is the dev.json file used for validation? or this is just another test set? did you use a part of train.json for validation ?\r\n2) did you include the instances in dev.json and test.json which is marked as is_noise=true in the F1 score calculation ? \r\n3) How many relations are used for the experiments ? Can you please provide a list of them ?\r\n\r\nThanks !!!!",
        "state": "open",
        "user": "nayakt",
        "closed_by": null,
        "created_at": "2020-10-01T13:29:46+00:00",
        "updated_at": "2020-10-02T09:08:54+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 98,
        "title": "Can dataset processed in MMPMS be Shared?",
        "body": "MMPMS(\"Generating Multiple Diverse Responses with Multi-Mapping and Posterior Mapping Selection\") evaluate the proposed model on two public conversation dataset: Weibo [Shang et al., 2015] and Reddit [Zhou et al., 2018] that maintain a large repository of post-response pairs from popular social websites.\r\nThe paper mentioned that \"After basic data cleaning, we have above 2 million pairs in both datasets.\" \r\nI would like to train the MMPMS from scratch. Could you please share the cleaned data?\r\n",
        "state": "open",
        "user": "ZihaoW123",
        "closed_by": null,
        "created_at": "2020-10-12T09:33:08+00:00",
        "updated_at": "2020-10-12T09:33:08+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 96,
        "title": "Plato能否在中文语料上从头训练？",
        "body": "您好，我发现Plato还没有chinese版本。我想要在自己的中文数据集上使用plato模型，请问能否从头开始训练？能的话应该如何训练？直接使用英文预训练的checkpoint肯定不行吧。\r\n\r\n谢谢",
        "state": "open",
        "user": "zhengyima",
        "closed_by": null,
        "created_at": "2020-09-28T14:44:14+00:00",
        "updated_at": "2021-07-22T10:05:24+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "Aman-4-Real"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 103,
        "title": "Why the \"Generated Summaries\" of testset on Multi-News only have 5590 lines?",
        "body": "Hi,\r\n\r\nThanks for releasing the result of test set. \r\nI'm doubting why the test result only has 5590 lines? The original Multi-News dataset contains 5622 document-pairs for testing. Did you exclude the outliers? Did you do the same during training? \r\n\r\nHope get your reply soon.\r\n\r\nJoyce",
        "state": "closed",
        "user": "MiaoYYu",
        "closed_by": "MiaoYYu",
        "created_at": "2020-11-10T09:18:40+00:00",
        "updated_at": "2020-11-10T10:47:56+00:00",
        "closed_at": "2020-11-10T10:47:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 104,
        "title": "Why the test result of Multi-News only has 5590 lines?",
        "body": "Hi,\r\n\r\nThanks for releasing the result of test set. \r\nI'm doubting why the test result only has 5590 lines? The original Multi-News dataset contains 5622 document-pairs for testing. Did you exclude the outliers? Did you do the same during training? \r\nHope get your reply soon.\r\n\r\nJoyce",
        "state": "open",
        "user": "MiaoYYu",
        "closed_by": null,
        "created_at": "2020-11-10T09:19:35+00:00",
        "updated_at": "2020-11-10T09:53:58+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 107,
        "title": " No such file or directory: 'log/graphsum.log'",
        "body": "When I run file 'predict_graphsum_local_multinews.sh' on google colab. I have this problem the following:\r\nTraceback (most recent call last):\r\n  File \"/content/drive/MyDrive/DATN/GraphSum/src/run.py\", line 31, in <module>\r\n    init_logger(args.log_file)\r\n  File \"/content/drive/MyDrive/DATN/GraphSum/src/utils/logging.py\", line 33, in init_logger\r\n    file_handler = logging.FileHandler(log_file)\r\n  File \"/usr/lib/python3.6/logging/__init__.py\", line 1032, in __init__\r\n    StreamHandler.__init__(self, self._open())\r\n  File \"/usr/lib/python3.6/logging/__init__.py\", line 1061, in _open\r\n    return open(self.baseFilename, self.mode, encoding=self.encoding)\r\nFileNotFoundError: [Errno 2] No such file or directory: '/content/log/graphsum.log'",
        "state": "closed",
        "user": "thainq0797",
        "closed_by": "thainq0797",
        "created_at": "2020-11-18T07:54:29+00:00",
        "updated_at": "2020-11-18T15:52:43+00:00",
        "closed_at": "2020-11-18T15:52:43+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 105,
        "title": "InvalidArgumentError",
        "body": "在aistudio上运行，报错误InvalidArgumentError: Python object is not type of St10shared_ptrIN6paddle10imperative7VarBaseEE (at /paddle/paddle/fluid/pybind/imperative.cc:216)，该如何解决",
        "state": "open",
        "user": "Sarraup",
        "closed_by": null,
        "created_at": "2020-11-11T08:55:15+00:00",
        "updated_at": "2020-11-11T08:55:15+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 99,
        "title": "RuntimeError: parallel_for failed: no kernel image is available for execution on the device",
        "body": "GrahpSum is very intriguing, but I'm unable to test with `./scripts/predict_graphsum_local_multinews.sh`.\r\n\r\nThe `log/lanch.log` file shows this error: `RuntimeError: parallel_for failed: no kernel image is available for execution on the device`\r\n\r\n```(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ ./scripts/predict_graphsum_local_multinews.sh\r\n+ source ./env_local/env_local.sh\r\n++ set -xe\r\n+++ hostname -i\r\n++ export iplist=127.0.1.1\r\n++ iplist=127.0.1.1\r\n++ unset http_proxy\r\n++ unset https_proxy\r\n+ source ./env_local/utils.sh\r\n++ set -u\r\n+ source ./model_config/graphsum_model_conf_local_multinews\r\n++ task=GraphSum_MDS\r\n++ VOCAB_PATH=./vocab/spm9998_3.model\r\n++ CONFIG_PATH=./model_config/graphsum_config.json\r\n++ TASK_DATA_PATH=/home/matt/mr/algos/GraphSum/data/MultiNews_data_tfidf_30_paddle\r\n++ lr_scheduler=noam_decay\r\n++ use_fp16=False\r\n++ use_fuse=True\r\n++ use_hierarchical_allreduce=True\r\n++ nccl_comm_num=3\r\n++ loss_scaling=12800\r\n++ WARMUP_PROP=0.01\r\n++ WARMUP_STEPS=8000\r\n++ beta1=0.9\r\n++ beta2=0.998\r\n++ eps=1e-9\r\n++ LR_RATE=2.0\r\n++ WEIGHT_DECAY=0.01\r\n+ export FLAGS_eager_delete_tensor_gb=1.0\r\n+ FLAGS_eager_delete_tensor_gb=1.0\r\n+ export FLAGS_sync_nccl_allreduce=1\r\n+ FLAGS_sync_nccl_allreduce=1\r\n+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\r\n+ FLAGS_fraction_of_gpu_memory_to_use=0.98\r\n+ export CUDA_VISIBLE_DEVICES=0\r\n+ CUDA_VISIBLE_DEVICES=0\r\n+ python -u ./src/run.py --model_name graphsum --use_cuda true --is_distributed false --use_multi_gpu_test False --use_fast_executor true --use_fp16 False --use_dynamic_loss_scaling False --init_loss_scaling 12800 --weight_sharing true --do_train false --do_val false --do_test true --do_dec true --verbose true --batch_size 30000 --in_tokens true --stream_job '' --init_pretraining_params '' --train_set /home/matt/mr/algos/GraphSum/data/MultiNews_data_tfidf_30_paddle/train --dev_set /home/matt/mr/algos/GraphSum/data/MultiNews_data_tfidf_30_paddle/valid --test_set /home/matt/mr/algos/GraphSum/data/MultiNews_data_tfidf_30_paddle/test --vocab_path ./vocab/spm9998_3.model --config_path model_config/graphsum_config.json --checkpoints ./models/graphsum_multinews --init_checkpoint ./models/graphsum_multinews/step_42976 --decode_path ./results/graphsum_multinews --lr_scheduler noam_decay --save_steps 10000 --weight_decay 0.01 --warmup_steps 8000 --validation_steps 20000 --epoch 100 --max_para_num 30 --max_para_len 60 --max_tgt_len 300 --max_out_len 300 --min_out_len 200 --beam_size 5 --graph_type similarity --len_penalty 0.6 --block_trigram True --report_rouge True --learning_rate 2.0 --skip_steps 100 --grad_norm 2.0 --pos_win 2.0 --label_smooth_eps 0.1 --num_iteration_per_drop_scope 10 --log_file log/graphsum_multinews_test.log --random_seed 1\r\n\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ cat log/lanch.log\r\n-----------  Configuration Arguments -----------\r\nbatch_size: 30000\r\nbeam_size: 5\r\nbeta1: 0.9\r\nbeta2: 0.998\r\nblock_trigram: True\r\ncheckpoints: ./models/graphsum_multinews\r\nconfig_path: model_config/graphsum_config.json\r\ndecode_path: ./results/graphsum_multinews\r\ndecr_every_n_nan_or_inf: 2\r\ndecr_ratio: 0.8\r\ndev_set: /home/matt/mr/algos/GraphSum/data/MultiNews_data_tfidf_30_paddle/valid\r\ndo_dec: True\r\ndo_lower_case: True\r\ndo_test: True\r\ndo_train: False\r\ndo_val: False\r\nencoder_json_file: roberta_config/encoder.json\r\nepoch: 100\r\neps: 1e-09\r\nernie_config_path: ernie_config/ernie_config.json\r\nernie_vocab_file: ernie_config/vocab.txt\r\nevaluate_blue: False\r\ngrad_norm: 2.0\r\ngraph_type: similarity\r\nin_tokens: True\r\nincr_every_n_steps: 100\r\nincr_ratio: 2.0\r\ninit_checkpoint: ./models/graphsum_multinews/step_42976\r\ninit_loss_scaling: 12800.0\r\ninit_pretraining_params:\r\nis_distributed: False\r\nlabel_smooth_eps: 0.1\r\nlearning_rate: 2.0\r\nlen_penalty: 0.6\r\nlog_file: log/graphsum_multinews_test.log\r\nlr_scheduler: noam_decay\r\nmax_out_len: 300\r\nmax_para_len: 60\r\nmax_para_num: 30\r\nmax_seq_len: 512\r\nmax_tgt_len: 300\r\nmetrics: True\r\nmin_out_len: 200\r\nmodel_name: graphsum\r\nnum_iteration_per_drop_scope: 10\r\npos_win: 2.0\r\nrandom_seed: 1\r\nreport_rouge: True\r\nroberta_config_path: roberta_config/roberta_config.json\r\nroberta_vocab_file: roberta_config/vocab.txt\r\nsave_steps: 10000\r\nskip_steps: 100\r\nstream_job:\r\ntest_set: /home/matt/mr/algos/GraphSum/data/MultiNews_data_tfidf_30_paddle/test\r\ntrain_set: /home/matt/mr/algos/GraphSum/data/MultiNews_data_tfidf_30_paddle/train\r\nuse_cuda: True\r\nuse_dynamic_loss_scaling: False\r\nuse_fast_executor: True\r\nuse_fp16: False\r\nuse_interval: False\r\nuse_multi_gpu_test: False\r\nvalidation_steps: 20000\r\nverbose: True\r\nvocab_bpe_file: roberta_config/vocab.bpe\r\nvocab_path: ./vocab/spm9998_3.model\r\nwarmup_proportion: 0.1\r\nwarmup_steps: 8000\r\nweight_decay: 0.01\r\nweight_sharing: True\r\n------------------------------------------------\r\nattention_probs_dropout_prob: 0.1\r\ndec_graph_layers: 8\r\ndec_word_pos_embedding_name: dec_word_pos_embedding\r\nenc_graph_layers: 2\r\nenc_sen_pos_embedding_name: enc_sen_pos_embedding\r\nenc_word_layers: 6\r\nenc_word_pos_embedding_name: enc_word_pos_embedding\r\nhidden_act: relu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 256\r\ninitializer_range: 0.02\r\nmax_position_embeddings: 512\r\nnum_attention_heads: 8\r\npostprocess_command: da\r\npreprocess_command: n\r\nword_embedding_name: word_embedding\r\n------------------------------------------------\r\n[2020-10-23 10:20:10,392 INFO] {'BOS': 4, 'EOS': 5, 'PAD': 6, 'EOT': 3, 'EOP': 7, 'EOQ': 8, 'UNK': 0}\r\n[2020-10-23 10:20:10,393 WARNING] paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n[2020-10-23 10:20:11,079 INFO] args.is_distributed: False\r\nW1023 10:20:11.511365 3292334 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 86, Driver API Version: 11.1, Runtime API Version: 10.0\r\nW1023 10:20:11.512548 3292334 device_context.cc:244] device: 0, cuDNN Version: 8.0.\r\nW1023 10:20:11.862699 3292334 operator.cc:179] truncated_gaussian_random raises an exception thrust::system::system_error, parallel_for failed: no kernel image is available for execution on the device\r\n/home/matt/anaconda3/envs/graphsum/lib/python3.6/site-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"./src/run.py\", line 35, in <module>\r\n    run_graphsum(args)\r\n  File \"/home/matt/mr/algos/Research/NLP/ACL2020-GraphSum/src/networks/graphsum/run_graphsum.py\", line 219, in main\r\n    exe.run(startup_prog)\r\n  File \"/home/matt/anaconda3/envs/graphsum/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/home/matt/anaconda3/envs/graphsum/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/matt/anaconda3/envs/graphsum/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/matt/anaconda3/envs/graphsum/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 822, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/home/matt/anaconda3/envs/graphsum/lib/python3.6/site-packages/paddle/fluid/executor.py\", line 899, in _run_program\r\n    fetch_var_name)\r\nRuntimeError: parallel_for failed: no kernel image is available for execution on the device\r\n\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ nvidia-smi\r\nFri Oct 23 10:21:38 2020\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 3090    Off  | 00000000:21:00.0 Off |                  N/A |\r\n| 30%   32C    P0    62W / 350W |      0MiB / 24265MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ python -V\r\nPython 3.6.9 :: Anaconda, Inc.\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ pip list | grep nltk\r\nnltk             3.4.5\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ pip list | grep numpy\r\nnumpy            1.18.1\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ pip list | grep paddlepaddle\r\npaddlepaddle-gpu 1.6.3.post107\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ pip list | grep pyrouge\r\npyrouge          0.1.3\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ pip list | grep regex\r\nregex            2020.2.20\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ pip list | grep requests\r\nrequests         2.22.0\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum $ pip list | grep sentencepiece\r\nsentencepiece    0.1.85\r\n\r\n(graphsum) matt@DeepWhite:~/mr/algos/GraphSum/log $ cat graphsum_multinews_test.log\r\n[2020-10-23 10:16:45,647 INFO] {'BOS': 4, 'EOS': 5, 'PAD': 6, 'EOT': 3, 'EOP': 7, 'EOQ': 8, 'UNK': 0}\r\n[2020-10-23 10:16:45,647 WARNING] paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n[2020-10-23 10:16:46,320 INFO] args.is_distributed: False\r\n[2020-10-23 10:19:38,037 INFO] {'BOS': 4, 'EOS': 5, 'PAD': 6, 'EOT': 3, 'EOP': 7, 'EOQ': 8, 'UNK': 0}\r\n[2020-10-23 10:19:38,037 WARNING] paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n[2020-10-23 10:19:38,740 INFO] args.is_distributed: False\r\n[2020-10-23 10:20:10,392 INFO] {'BOS': 4, 'EOS': 5, 'PAD': 6, 'EOT': 3, 'EOP': 7, 'EOQ': 8, 'UNK': 0}\r\n[2020-10-23 10:20:10,393 WARNING] paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n[2020-10-23 10:20:11,079 INFO] args.is_distributed: False\r\n[2020-10-23 10:43:43,574 INFO] {'BOS': 4, 'EOS': 5, 'PAD': 6, 'EOT': 3, 'EOP': 7, 'EOQ': 8, 'UNK': 0}\r\n[2020-10-23 10:43:43,574 WARNING] paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n[2020-10-23 10:43:44,258 INFO] args.is_distributed: False\r\n```\r\n",
        "state": "closed",
        "user": "mhillebrand",
        "closed_by": "mhillebrand",
        "created_at": "2020-10-23T18:12:59+00:00",
        "updated_at": "2020-10-24T04:47:19+00:00",
        "closed_at": "2020-10-24T04:47:19+00:00",
        "comments_count": [
            "mhillebrand"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 101,
        "title": "InvalidArgumentError: The shape of input[0] and input[1] is expected to be equal.But received input[0]'s shape = [-1, 0, 1], input[1]'s shape = [-1, 1, 1, 1].",
        "body": "I'm trying to test the [GraphSum](https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2020-GraphSum) model with the command `./scripts/predict_graphsum_local_multinews.sh` found in the documentation, but I get this error:\r\n\r\n```----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The shape of input[0] and input[1] is expected to be equal.But received input[0]'s shape = [-1, 0, 1], input[1]'s shape = [-1, 1, 1, 1].\r\n  [Hint: Expected inputs_dims[i].size() == out_dims.size(), but received inputs_dims[i].size():4 != out_dims.size():3.] at (/paddle/paddle/fluid/operators/concat_op.h:40)\r\n  [operator < concat > error]\r\n```\r\nI can't really debug this issue in PyCharm because of all the shell scripts involved. Any advice would be greatly appreciated. Thanks.",
        "state": "open",
        "user": "mhillebrand",
        "closed_by": null,
        "created_at": "2020-10-26T18:02:30+00:00",
        "updated_at": "2021-03-01T02:44:37+00:00",
        "closed_at": null,
        "comments_count": [
            "mhillebrand"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 100,
        "title": "AttributeError: 'Set'  Object has no attribute 'append' ",
        "body": "I am preparing AICity 2020 data and I have followed the instruction provided on process_aicity_data script. However, I am facing this issue and I've tried to solve it but I couldn't figure it out. Please help me to solve this issue.\r\nPS I am a very new to this. I would really appreciate it.\r\n\r\nTraceback (most recent call last):\r\n  File \"2_prepare_real_trainlist.py\", line 37, in <module>\r\n    all_ids.append(vid)\r\nAttributeError: 'set' object has no attribute 'append'\r\n\r\n![image](https://user-images.githubusercontent.com/36837450/97082965-d52a4500-163f-11eb-85ea-4ef3a99e4f16.png)\r\n\r\n",
        "state": "open",
        "user": "MAdil45",
        "closed_by": null,
        "created_at": "2020-10-24T13:25:12+00:00",
        "updated_at": "2021-05-12T11:44:25+00:00",
        "closed_at": null,
        "comments_count": [
            "gigibang",
            "wanglaotou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 108,
        "title": "关于GraphSum数据迁移的问题",
        "body": " @ZeyuChen @kahitomi \r\n你好，很感谢你们如此优秀的开源。\r\n我想问个问题，这份代码迁移到中文数据集的话，sentencepiece vocab file：spm9998_3.model 需要我们自己重新训练吗？直接用你们开源出来的可以吗？",
        "state": "closed",
        "user": "bultiful",
        "closed_by": "bultiful",
        "created_at": "2020-11-19T06:34:03+00:00",
        "updated_at": "2020-12-01T03:59:28+00:00",
        "closed_at": "2020-12-01T03:59:28+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 109,
        "title": "请问有预训练用的数据吗？",
        "body": "就是原文中提到的  Large-scale conversation datasets – Twitter (Cho et al., 2014) and Reddit (Zhou et al., 2018; Galley et al., 2019) are employed for pretraining, which results in 8.3 million training samples in total.\r\n",
        "state": "open",
        "user": "lemuria-wchen",
        "closed_by": null,
        "created_at": "2020-11-22T18:44:07+00:00",
        "updated_at": "2020-11-26T14:26:37+00:00",
        "closed_at": null,
        "comments_count": [
            "sserdoubleh",
            "lemuria-wchen",
            "lemuria-wchen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 110,
        "title": "aistudio上 使用predict.sh 预测，报错 ValueError: var read_file_0.tmp_3 not in this block",
        "body": "环境：aistudio Cuda9.2+cudnn 7.6 + paddle1.8.4\r\n使用paddle1.5就没事，但是这个就不行，请问怎么解决\r\n\r\n报错log如下\r\n\r\n```\r\n2020-11-23 14:35:49,888-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n[WARNING] 2020-11-23 14:35:49,888 [       io.py:  712]:\tpaddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n----------place-----------\r\nCUDAPlace(0)\r\nW1123 14:35:50.949314   187 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\r\nW1123 14:35:51.145216   187 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\n2020-11-23 14:35:57,108-INFO: Load pretraining parameters from ./checkpoints/step_20000.\r\n[INFO] 2020-11-23 14:35:57,108 [     init.py:  101]:\tLoad pretraining parameters from ./checkpoints/step_20000.\r\n2020-11-23 14:35:57,108-INFO: save inference model to ./checkpoints/inference_model/step_20000_inference_model\r\n[INFO] 2020-11-23 14:35:57,108 [infer_type_ranker.py:  158]:\tsave inference model to ./checkpoints/inference_model/step_20000_inference_model\r\nTraceback (most recent call last):\r\n  File \"./ernie/infer_type_ranker.py\", line 358, in <module>\r\n    main(args)\r\n  File \"./ernie/infer_type_ranker.py\", line 163, in main\r\n    main_program=predict_prog\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/io.py\", line 1247, in save_inference_model\r\n    prepend_feed_ops(main_program, feeded_var_names)\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/io.py\", line 1043, in prepend_feed_ops\r\n    out = global_block.var(name)\r\n  File \"/opt/conda/envs/python27-paddle120-env/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2377, in var\r\n    raise ValueError(\"var %s not in this block\" % name)\r\nValueError: var read_file_0.tmp_3 not in this block\r\n```",
        "state": "open",
        "user": "Attackzzw",
        "closed_by": null,
        "created_at": "2020-11-23T07:07:00+00:00",
        "updated_at": "2020-11-23T07:07:31+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 112,
        "title": "Knowledge Graph ",
        "body": "To whom may concern,\r\n\r\nI did not find any source codes and datasets about knowledge graph related articles.",
        "state": "open",
        "user": "foreverqing",
        "closed_by": null,
        "created_at": "2020-12-07T08:43:41+00:00",
        "updated_at": "2020-12-07T08:43:41+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 113,
        "title": "Relation Extraction",
        "body": "问下仓库中实现的关系抽取有参考的论文吗？",
        "state": "open",
        "user": "dickobe",
        "closed_by": null,
        "created_at": "2020-12-13T13:59:24+00:00",
        "updated_at": "2020-12-13T13:59:24+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 114,
        "title": "landmark求更新",
        "body": "可以更新一下吗？现在只有python2.7和cuda9的版本，谢谢",
        "state": "open",
        "user": "yunchangxiaoguan",
        "closed_by": null,
        "created_at": "2020-12-22T08:53:08+00:00",
        "updated_at": "2020-12-22T08:53:08+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 118,
        "title": "百度事件抽取baseline环境问题",
        "body": "你好，这个baseline上注明了是python2.7,但是我按照这个要求好多包会出现问题，而且环境并不能work,而且LIC2020-事件抽取任务基线系统上也没法使用，没有相应的环境，我已经在评论区评论提到这个问题了，还是没结果，可以把这块的依赖这块详细点吗",
        "state": "open",
        "user": "ddgetget",
        "closed_by": null,
        "created_at": "2021-01-05T09:04:47+00:00",
        "updated_at": "2021-01-05T09:04:47+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 120,
        "title": "事件抽取baseline运行问题",
        "body": "事件抽取baseline，按照操作运行到步骤4: 训练触发词抽取模型，执行代码sh script/train_event_trigger.sh ${GPUID} ${DATA_DIR} ${TRIGGER_SAVE_MODEL} ${PRETRAIN_MODEL} ${DICT}，一直报错，\r\n\r\nTraceback (most recent call last):\r\n  File \"run_event_trigger.py\", line 453, in <module>\r\n    main(args)\r\n  File \"run_event_trigger.py\", line 128, in main\r\n    ernie_config=ernie_config)\r\n  File \"/data/gaolu/DuEE_baseline/bin/finetune/sequence_label.py\", line 54, in create_model\r\n    use_double_buffer=True)\r\n  File \"/home/gaolu/miniconda3/envs/paddle_env/lib/python2.7/site-packages/paddle/fluid/layers/io.py\", line 724, in py_reader\r\n    use_double_buffer=use_double_buffer)\r\n  File \"/home/gaolu/miniconda3/envs/paddle_env/lib/python2.7/site-packages/paddle/fluid/layers/io.py\", line 452, in _py_reader\r\n    'ranks': ranks\r\n  File \"/home/gaolu/miniconda3/envs/paddle_env/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2837, in append_op\r\n    kwargs.get(\"stop_gradient\", False))\r\n  File \"/home/gaolu/miniconda3/envs/paddle_env/lib/python2.7/site-packages/paddle/fluid/dygraph/tracer.py\", line 45, in trace_op\r\n    not stop_gradient)\r\nValueError: (InvalidArgument) Python object is not type of St10shared_ptrIN6paddle10imperative7VarBaseEE (at /paddle/paddle/fluid/pybind/imperative.cc:220)\r\n  [Hint: If you need C++ stacktraces for debugging, please set `FLAGS_call_stack_level=2`.]\r\n\r\n请问一下怎么解决？跪求解决方案",
        "state": "closed",
        "user": "rela0426",
        "closed_by": "rela0426",
        "created_at": "2021-01-18T12:56:20+00:00",
        "updated_at": "2021-10-21T09:51:48+00:00",
        "closed_at": "2021-10-21T09:51:48+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 115,
        "title": "About Discourse Graph in ACL2020 GraphSum",
        "body": "Thanks for your work, I read your paper and code of GraphSum. But I have a question. How to implement discourse graph? I don't find it in your code.",
        "state": "open",
        "user": "biaofuxmu",
        "closed_by": null,
        "created_at": "2020-12-29T09:50:35+00:00",
        "updated_at": "2022-06-05T10:12:19+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP",
            "isaacisaactang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 119,
        "title": "图像检索GNN-Re-Ranking 运行make.sh 报错",
        "body": "(py36) (yw96)[root@aboluo02 /ywcx/guanxiao/new/Research/CV/GNN-Re-Ranking/lib]# sh make.sh \r\n/home/guanxiao/anaconda3/envs/py36/lib/python3.6/site-packages/paddle/include\r\n/home/guanxiao/anaconda3/envs/py36/lib/python3.6/site-packages/paddle/libs\r\nnvcc fatal   : Path to libdevice library not specified\r\nnvcc fatal   : Path to libdevice library not specified\r\ng++: error: vmat.cu.o: No such file or directory\r\ng++: error: qe.cu.o: No such file or directory\r\n\r\n请问大佬这个怎么解决",
        "state": "open",
        "user": "yunchangxiaoguan",
        "closed_by": null,
        "created_at": "2021-01-09T09:17:13+00:00",
        "updated_at": "2022-10-02T08:30:43+00:00",
        "closed_at": null,
        "comments_count": [
            "Xuanmeng-Zhang",
            "yunchangxiaoguan",
            "yunchangxiaoguan",
            "olochi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 121,
        "title": "训练数据集问题",
        "body": "尊敬的作者您好，感谢您的做出贡献，同时您方便提供下训练数据集？我想深度学习下您的模型。https://ai.baidu.com/broad/download?dataset=duee的DuEE上显示：数据集不可用，个人邮箱:zchuanuir@163.com",
        "state": "open",
        "user": "Harry12-svg",
        "closed_by": null,
        "created_at": "2021-01-25T06:52:35+00:00",
        "updated_at": "2021-01-25T06:52:35+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 137,
        "title": "where is ARNOR code?",
        "body": "Dear all, \r\n\r\ncould you please share ARNOR core?",
        "state": "open",
        "user": "tutubalinaev",
        "closed_by": null,
        "created_at": "2021-02-26T11:00:14+00:00",
        "updated_at": "2021-02-26T11:00:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 145,
        "title": "thank you for your contribution, could you share the vocab.txt in proactive conversation? ",
        "body": "",
        "state": "open",
        "user": "yhjiujiu",
        "closed_by": null,
        "created_at": "2021-03-30T03:31:14+00:00",
        "updated_at": "2021-03-30T03:31:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 146,
        "title": "GPU转CPU",
        "body": "代码移植到CPU版本的话需要进行什么改变",
        "state": "open",
        "user": "strawberrybbq",
        "closed_by": null,
        "created_at": "2021-04-01T04:06:05+00:00",
        "updated_at": "2021-04-01T04:06:05+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 128,
        "title": "convert_binary_model.py  Model conversion error",
        "body": "### After downloading the model, run the model transformation and report an error：\r\n`python convert_binary_model.py --model='ResNet152_vd' --pretrained_model=pretrained_models/res152_softmax_v2/ --binary_model=./binary_models/res152_softmax_v2 --image_shape=3,224,224 --task_mode='classification'`\r\n\r\n`RuntimeError: Variable's shape does not match, the Program requires a parameter with the shape of ((2048, 1000)), while the loaded parameter (namely [ fc_0.w_0 ]) has a shape of  ((2048, 203094))`\r\n\r\n\r\nHow to solve this problem? Thank you very much\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "1138886114",
        "closed_by": null,
        "created_at": "2021-02-20T01:14:10+00:00",
        "updated_at": "2022-05-23T06:30:20+00:00",
        "closed_at": null,
        "comments_count": [
            "aiot-tech"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 141,
        "title": "ACL2019-ARNOR dataset",
        "body": "Hi, the dataset for Baidu's paper: \"ARNOR: Attention Regularization based Noise Reduction for Distant Supervision Relation Classification\" was originally stored at: https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2019-ARNOR. But it has gone for some reason. Could you please point to the correct link for this dataset? Many thanks.\r\n",
        "state": "open",
        "user": "nilobud",
        "closed_by": null,
        "created_at": "2021-03-18T22:15:23+00:00",
        "updated_at": "2021-03-19T15:07:57+00:00",
        "closed_at": null,
        "comments_count": [
            "zhengya01",
            "ZeyuChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 144,
        "title": "ValueError: (InvalidArgument) Python object is not type of St10shared_ptrIN6paddle10imperative7VarBaseEE (at /paddle/paddle/fluid/pybind/imperative.cc:221)",
        "body": "I recently upgraded to `paddlepaddle-gpu 2.0.1.post110`, and this is the error I receive when running `./scripts/predict_graphsum_local_multinews.sh`:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"./src/run.py\", line 35, in <module>\r\n    run_graphsum(args)\r\n  File \"/home/matt/mr/algos/Research/NLP/ACL2020-GraphSum/src/networks/graphsum/run_graphsum.py\", line 180, in main\r\n    test_pyreader, test_graph_vars = graphsum.create_model(\r\n  File \"/home/matt/mr/algos/Research/NLP/ACL2020-GraphSum/src/networks/graphsum/graphsum_model.py\", line 414, in create_model\r\n    return self.fast_decode(pyreader_name)\r\n  File \"/home/matt/mr/algos/Research/NLP/ACL2020-GraphSum/src/networks/graphsum/graphsum_model.py\", line 486, in fast_decode\r\n    pyreader = fluid.layers.py_reader(\r\n  File \"/home/matt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/layers/io.py\", line 723, in py_reader\r\n    return _py_reader(\r\n  File \"/home/matt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/layers/io.py\", line 444, in _py_reader\r\n    startup_blk.append_op(\r\n  File \"/home/matt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/framework.py\", line 3010, in append_op\r\n    _dygraph_tracer().trace_op(type,\r\n  File \"/home/matt/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/tracer.py\", line 43, in trace_op\r\n    self.trace(type, inputs, outputs, attrs,\r\nValueError: (InvalidArgument) Python object is not type of St10shared_ptrIN6paddle10imperative7VarBaseEE (at /paddle/paddle/fluid/pybind/imperative.cc:221)\r\n```\r\n\r\nPython 3.8.8\r\n\r\n```\r\nPackage          Version\r\n---------------- -------------------\r\nastor            0.8.1\r\ncertifi          2020.12.5\r\nchardet          4.0.0\r\ndecorator        4.4.2\r\ngast             0.4.0\r\nidna             2.10\r\nnumpy            1.20.1\r\npaddlepaddle-gpu 2.0.1.post110\r\nPillow           8.1.2\r\npip              21.0.1\r\nprotobuf         3.15.6\r\npyrouge          0.1.3\r\nrequests         2.25.1\r\nsentencepiece    0.1.95\r\nsetuptools       52.0.0.post20210125\r\nsix              1.15.0\r\nurllib3          1.26.4\r\nwheel            0.36.2\r\n```",
        "state": "closed",
        "user": "mhillebrand",
        "closed_by": "mhillebrand",
        "created_at": "2021-03-26T19:09:21+00:00",
        "updated_at": "2023-09-05T03:30:08+00:00",
        "closed_at": "2023-09-05T03:30:08+00:00",
        "comments_count": [
            "otakusbear",
            "mhillebrand"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 147,
        "title": "Research/NLP/DuReader-Checklist-BASELINE/src/run.py",
        "body": "作者您好！在准备数据集的过程中，有一定概率出现答案的span跨越文本的两个分段的情况，在run.py中，该情况下的答案起始和终止被直接设置为了CLS所在的位置，同时answerable_label被设置为了0，即不可解。这种情况是否会影响部分实例的运算呢？",
        "state": "closed",
        "user": "W2Q3Q1",
        "closed_by": "W2Q3Q1",
        "created_at": "2021-04-26T11:38:56+00:00",
        "updated_at": "2021-06-30T08:11:05+00:00",
        "closed_at": "2021-06-30T08:11:05+00:00",
        "comments_count": [
            "libertatis",
            "W2Q3Q1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 148,
        "title": "CoKE on WN18RR",
        "body": "Hi Team, \r\n\r\nI am learning CoKE released from your team recently. I followed the steps and run the model on WN18RR with specified hyper-parameteres for multiple times, but the model trained locally cannot reproduce the performance denoted in the [paper](https://arxiv.org/abs/1911.02168). Here are the hyper-parameters for training (actually they are default settings specified in \"wn18rr_job_config.sh\"):\r\n\r\ndo_train: True\r\nema_decay: 0.9999\r\nepoch: 1000\r\nhidden_act: gelu\r\nhidden_dropout_prob: 0.1\r\nhidden_size: 256\r\nin_tokens: False\r\ninit_checkpoint: None\r\ninit_pretraining_params: None\r\ninitializer_range: 0.02\r\nintermediate_size: 512\r\nlearning_rate: 0.0005\r\nloss_scaling: 1.0\r\nlr_scheduler: linear_warmup_decay\r\nmax_position_embeddings: 40\r\nmax_seq_len: 3\r\nnum_attention_heads: 4\r\nnum_hidden_layers: 12\r\nnum_iteration_per_drop_scope: 1\r\nnum_relations: 11\r\npredict_file: None\r\nsen_candli_file: None\r\nsen_trivial_file: None\r\nskip_steps: 1000\r\nsoft_label: 0.15\r\ntrain_file: ./data/wn18rr/train.coke.txt\r\ntrue_triple_path: ./data/wn18rr/all.txt\r\nuse_cuda: True\r\nuse_ema: False\r\nuse_fast_executor: False\r\nuse_fp16: False\r\nverbose: False\r\nvocab_path: ./data/wn18rr/vocab.txt\r\nvocab_size: 41054\r\nwarmup_proportion: 0.1\r\nweight_decay: 0.01\r\nweight_sharing: True\r\n\r\nThe performance are: \r\nTASK    MRR Hits@1  Hits@3  Hits@10\r\nwn18rr  0.462   0.427   0.475   0.533 (local)\r\ninstead of \r\nwn18rr 0.484   0.450   0.496  0.553 (paper)\r\n\r\nI wonder whether this repository is the up-to-date version, or the best performance use another set of hyper-parameters? Could you please provide some hints for this issue.  Thank you.\r\n\r\nAdditionally, there is a pretrained model which can be downloaded using \"wget_kbc_models.sh\" (step 4), but it seems the link is unavailable now. Hopefully this can be fixed.\r\n\r\nBest regards",
        "state": "closed",
        "user": "ccchobits",
        "closed_by": "ccchobits",
        "created_at": "2021-04-26T20:12:23+00:00",
        "updated_at": "2021-05-06T02:58:06+00:00",
        "closed_at": "2021-04-29T07:38:41+00:00",
        "comments_count": [
            "jpilaul",
            "jpilaul",
            "ccchobits"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 161,
        "title": "怎么简单使用呢？",
        "body": "",
        "state": "open",
        "user": "lonngxiang",
        "closed_by": null,
        "created_at": "2021-05-27T03:28:28+00:00",
        "updated_at": "2021-05-27T03:28:28+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 155,
        "title": "CV/AICity2020-Anomaly-Detection/mask_code/mask_track.py tries to open a non-existent path",
        "body": "Hey @liyingying0113, this is trying to open a non-existent path. I haven't seen any code to make that path within the [CV/AICity2020-Anomaly-Detection](../tree/master/CV/AICity2020-Anomaly-Detection)\r\n\r\nhttps://github.com/PaddlePaddle/Research/blob/224ba67267b2875c46e94a76a162352d30457f72/CV/AICity2020-Anomaly-Detection/mask_code/mask_track.py#L18\r\n\r\n@AoZhang does this have a code to generate those files before this module?",
        "state": "open",
        "user": "Mandroide",
        "closed_by": null,
        "created_at": "2021-05-21T18:27:14+00:00",
        "updated_at": "2021-06-15T20:54:28+00:00",
        "closed_at": null,
        "comments_count": [
            "Mandroide",
            "Zef2316",
            "Mandroide"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 160,
        "title": "UNIMO 是准备开源英文模型，对中文模型闭源或者收费是吗？",
        "body": "",
        "state": "open",
        "user": "ThetaRgo",
        "closed_by": null,
        "created_at": "2021-05-26T14:49:35+00:00",
        "updated_at": "2022-02-14T07:56:58+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP",
            "lonngxiang",
            "dongmingli-Ben"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 165,
        "title": "filelock.py:318 * Lock 140479245190480 released on /root/.paddle-ernie-cache/466eabcffd6d6a83ae9cb97dd1a167bd.lock",
        "body": "怎么解决",
        "state": "open",
        "user": "hyttyfj211",
        "closed_by": null,
        "created_at": "2021-06-03T07:15:36+00:00",
        "updated_at": "2021-06-03T07:15:36+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 166,
        "title": "where is the model weights",
        "body": "It notes no Pretrained model path, can you tell me where is it?",
        "state": "open",
        "user": "dxs66",
        "closed_by": null,
        "created_at": "2021-06-04T16:33:03+00:00",
        "updated_at": "2021-06-05T02:54:40+00:00",
        "closed_at": null,
        "comments_count": [
            "dxs66"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 162,
        "title": "【UNIMO】Will you release the trainning code of UNIMO?",
        "body": "Q: Will you release the trainning code of UNIMO? Thanks for your reply.",
        "state": "open",
        "user": "imyzx2017",
        "closed_by": null,
        "created_at": "2021-05-31T01:53:17+00:00",
        "updated_at": "2021-05-31T08:12:49+00:00",
        "closed_at": null,
        "comments_count": [
            "TangMinLeo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 170,
        "title": "where is EMNLP2019-GELE",
        "body": "article: EMNLP2019 Enhancing Local Feature Extraction with Global Representation for Neural Text Classification\r\n",
        "state": "open",
        "user": "deweyamer",
        "closed_by": null,
        "created_at": "2021-06-10T05:56:57+00:00",
        "updated_at": "2021-06-10T05:56:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 167,
        "title": "没有pytorch版本的代码鸭，哭了。paddle这个框架不熟悉哇",
        "body": "",
        "state": "open",
        "user": "NostalgiaOfTime",
        "closed_by": null,
        "created_at": "2021-06-08T02:45:35+00:00",
        "updated_at": "2021-12-17T18:39:13+00:00",
        "closed_at": null,
        "comments_count": [
            "menghuanlater",
            "chandeler"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 172,
        "title": "Text2SQL-BASELINE训练过程出现Nan",
        "body": "为什么总是训练到第6个epoch的时候，损失函数就会变成nan",
        "state": "open",
        "user": "hyttyfj211",
        "closed_by": null,
        "created_at": "2021-06-15T02:07:31+00:00",
        "updated_at": "2021-10-18T08:40:49+00:00",
        "closed_at": null,
        "comments_count": [
            "wanglijiehit",
            "hyttyfj211",
            "Xuanfang1121"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 173,
        "title": "first pull request for CIKM2021-GenRegion",
        "body": "",
        "state": "open",
        "user": "liyanyanliyanyan",
        "closed_by": null,
        "created_at": "2021-06-16T03:10:54+00:00",
        "updated_at": "2021-06-16T03:10:54+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 175,
        "title": "commit for gen-region",
        "body": "",
        "state": "open",
        "user": "liyanyanliyanyan",
        "closed_by": null,
        "created_at": "2021-06-16T08:25:58+00:00",
        "updated_at": "2021-06-16T08:25:58+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 180,
        "title": "Train Model GraphSum",
        "body": "According to the paper, model train with 8 GPU.\r\nSo, I have a question: Can I train model GraphSum on a GPU (P100) with small dataset?",
        "state": "open",
        "user": "thainq0797",
        "closed_by": null,
        "created_at": "2021-06-20T09:10:12+00:00",
        "updated_at": "2022-05-16T00:37:15+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP",
            "77-qiqi-wang",
            "hammad26"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 184,
        "title": "Can you provide the article titles for data instances?",
        "body": "Hello,\r\n\r\nThanks for releasing this filtered version of WikiSum dataset.\r\nI wonder if you can also provide Titles data? the current version has inputs documents and target sequence but does not include the wikipedia article title. Is there any way to get titles for data points? Thanks",
        "state": "closed",
        "user": "fabrahman",
        "closed_by": "fabrahman",
        "created_at": "2021-07-01T21:26:54+00:00",
        "updated_at": "2021-07-02T02:26:46+00:00",
        "closed_at": "2021-07-02T02:26:46+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 182,
        "title": "vqa tasks",
        "body": "The work on the VQA dataset is amazing. I would like to know when it will be released if you don't mind. I can't wait to give it a try.",
        "state": "open",
        "user": "yixuan-qiao",
        "closed_by": null,
        "created_at": "2021-06-21T13:17:32+00:00",
        "updated_at": "2021-07-16T12:12:33+00:00",
        "closed_at": null,
        "comments_count": [
            "CCYChongyanChen"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 185,
        "title": "About ACL2020-GraphSum",
        "body": "Hey, \r\n\r\nThanks for providing the code. I was trying to fine-tune the model on my own dataset. This led me to look at your pre-processing code to make sure I am doing things correctly on my own dataset. \r\n\r\nI compared the [processed multi-news data](https://graphsum.bj.bcebos.com/data/MultiNews_data_tfidf_30_paddle.tar.gz) that you provided with the one that I generated. But I think the results are not matching. \r\n\r\nTo generate the processed dataset -\r\n1. I first download the multi-news data from [this drive link](https://drive.google.com/drive/folders/1qZ3zJBv0zrUy4HVWxnx33IsrHGimXLPy). \r\n_(I assume you used this particular version since you have simply referred to their repo in your readme but sadly, their repo has multiple versions of the dataset)_\r\n2. Next, I ran your scripts with `max_nsents=30` and other parameters being default. \r\n\r\nI understand that the ordering can be different because of the unordered map but I even looked at them individually and they are not the same. Is it possible that the authors of multi-news dataset have updated their files and that's why I am observing this discrepancy?\r\n\r\nThanks,\r\nNaman\r\n",
        "state": "open",
        "user": "bnaman50",
        "closed_by": null,
        "created_at": "2021-07-06T21:49:06+00:00",
        "updated_at": "2021-08-02T05:10:11+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP",
            "bnaman50",
            "Weili-NLP"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 187,
        "title": "Text2SQL-Baseline  compute_schema_linking",
        "body": "在linking-units中的compute_schema_linking函数，当它给question和table部分匹配打标签时，打了TEM标签，但是其实应该是TPM吧。\r\n`            # exact match case\r\n            for col_id, col in col_id2list.items():\r\n                # 如果n-gram-list拼起来之后和col名字相同, 则加入dict{i,col_id:CEM}，。。。{i+n，col_id：CEM}\r\n                if exact_match(n_gram_list, col):\r\n                    set_q_relation(q_col_match, i, n, col_id, \"CEM\")\r\n            for tab_id, tab in tab_id2list.items():\r\n                if exact_match(n_gram_list, tab):\r\n                    set_q_relation(q_tab_match, i, n, tab_id, \"TEM\")\r\n\r\n            # partial match case\r\n            for col_id, col in col_id2list.items():\r\n                if partial_match(n_gram_list, col):\r\n                    set_q_relation(q_col_match, i, n, col_id, \"CPM\", force=False)\r\n            for tab_id, tab in tab_id2list.items():\r\n                if partial_match(n_gram_list, tab):\r\n                    # 这里应该错了，原本是TEM，但其实应该是TPM\r\n                    # set_q_relation(q_tab_match, i, n, tab_id, \"TEM\", force=False)\r\n                    set_q_relation(q_tab_match, i, n, tab_id, \"TPM\", force=False)`\r\n\r\n还有一个问题是，在exact_match和partial_match中，会把n-gram list拼接起来，但是这样子不会导致大量的重复吗？比如原本是abc。2-gram的拼接变成abbc。还是我理解有问题。。。望大佬解惑\r\n\r\n\r\n\r\n还有另一个问题，在linking_unit中class Relations(object)的倒数，merge为ture的时候是不是写的有问题。\r\n`             \r\n         for i in range(-qq_max_dist, qq_max_dist + 1):\r\n                self.relation_ids['cc_dist', i] = self.relation_ids['qq_dist', i]\r\n                self.relation_ids['tt_dist', i] = self.relation_ids['tt_dist', i]`\r\n感觉这个for循环最后一句完全没有意义",
        "state": "open",
        "user": "zjzzzz",
        "closed_by": null,
        "created_at": "2021-07-16T08:02:05+00:00",
        "updated_at": "2021-09-06T08:52:04+00:00",
        "closed_at": null,
        "comments_count": [
            "ThisIsSoMe"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 186,
        "title": "Text2SQL-BASELINE",
        "body": "想知道value_indexes的值是不是不能大于510？如果我修改了就预测不了了，所以这个510是和什么有关，能修改么?如果修改了还需要修改哪里才能让它继续预测？\r\n\r\n![Uploading 微信图片_20210709173718.png…]()\r\n\r\n",
        "state": "open",
        "user": "hyttyfj211",
        "closed_by": null,
        "created_at": "2021-07-09T09:40:06+00:00",
        "updated_at": "2021-07-15T12:01:45+00:00",
        "closed_at": null,
        "comments_count": [
            "hyttyfj211",
            "ThisIsSoMe"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 189,
        "title": "P3AC的term_dict能否开放一下",
        "body": "",
        "state": "closed",
        "user": "xiabofei",
        "closed_by": "xiabofei",
        "created_at": "2021-07-26T15:14:04+00:00",
        "updated_at": "2021-07-26T15:15:52+00:00",
        "closed_at": "2021-07-26T15:15:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 190,
        "title": "Can author release the test dataset of Dureader_robust?",
        "body": "Can author release the more than 3 thousand test set of Dureader_robust mentioned in the paper [?](https://arxiv.org/abs/2004.11142)",
        "state": "open",
        "user": "flyinging",
        "closed_by": null,
        "created_at": "2021-07-28T02:34:03+00:00",
        "updated_at": "2021-07-28T02:34:03+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 188,
        "title": "关于UNIMO预训练样本格式的问题",
        "body": "您好，想请教2个问题：\r\n1）同一个具体的text-image pair样本，在预训练的时候，是否同时会用该样本来计算CMCL损失和MRM/MLM损失？\r\n2）如果第一个问题的结果为是的话，那对于这个具体的text-image pair样本，在做CMCL任务时是不是也含有mask字符或者mask roI？这样的话，整个模型在联合预训练的时候不会出现标签泄露的问题吗？\r\n非常感谢~",
        "state": "closed",
        "user": "JianWenJun",
        "closed_by": "JianWenJun",
        "created_at": "2021-07-20T13:33:59+00:00",
        "updated_at": "2021-08-04T09:26:10+00:00",
        "closed_at": "2021-07-22T13:43:40+00:00",
        "comments_count": [
            "TriLoo"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 195,
        "title": "Unimo use CMCL cannot converge",
        "body": "I implemented my own unimo network and use triplet as CMCL loss. The text cls outputs in same batch were set as negative samples corresponding to positive image-text pair, but the model cannot converge. Looks like the model have collapsed, i.e. the output similarity matrix were same (1 in the diagonal, other elements are 0)  regardless what any inputs are. I wonder if anyone else have met this problem ?\r\n\r\nI have tried different lr, triplet margin, online in-batch hard negative mining, negative sample queue (moco) to enlarge negative sample nums, but all failed.\r\n\r\nI saw the unimo paper mention that text-rewrited text as negative samples,  could you give some more details about how these negative samples are used in the unimo, which is a single-stream network and the CMCL loss is used? thanks\r\n\r\n",
        "state": "open",
        "user": "TriLoo",
        "closed_by": null,
        "created_at": "2021-08-05T06:37:55+00:00",
        "updated_at": "2021-08-05T06:38:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 197,
        "title": "面向推荐的对话的数据集获取",
        "body": "请问面向推荐的对话这个任务的数据集如何获取,竞赛官网的数据集下载好像已经关闭了.",
        "state": "open",
        "user": "27182812",
        "closed_by": null,
        "created_at": "2021-08-16T13:57:53+00:00",
        "updated_at": "2021-08-16T13:57:53+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 196,
        "title": "SSAN predict",
        "body": "hey @BenfengXu i am using ssan(https://github.com/PaddlePaddle/Research/tree/master/KG/AAAI2021_SSAN).\r\nI have followed the steps as per readme but still not getting any result.json file.\r\nFollowing are logs of my trial.\r\n```\r\n2021-08-09 07:10:49,604-INFO: -----------  Configuration Arguments -----------\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   68]:\t-----------  Configuration Arguments -----------\r\n2021-08-09 07:10:49,604-INFO: batch_size: 4\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   70]:\tbatch_size: 4\r\n2021-08-09 07:10:49,604-INFO: data_path: ./data/\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   70]:\tdata_path: ./data/\r\n2021-08-09 07:10:49,604-INFO: decr_every_n_nan_or_inf: 2\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   70]:\tdecr_every_n_nan_or_inf: 2\r\n2021-08-09 07:10:49,604-INFO: decr_ratio: 0.8\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   70]:\tdecr_ratio: 0.8\r\n2021-08-09 07:10:49,604-INFO: do_lower_case: True\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   70]:\tdo_lower_case: True\r\n2021-08-09 07:10:49,604-INFO: do_test: True\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   70]:\tdo_test: True\r\n2021-08-09 07:10:49,604-INFO: do_train: False\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   70]:\tdo_train: False\r\n2021-08-09 07:10:49,604-INFO: do_val: False\r\n[INFO] 2021-08-09 07:10:49,604 [     args.py:   70]:\tdo_val: False\r\n2021-08-09 07:10:49,605-INFO: epoch: 3\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tepoch: 3\r\n2021-08-09 07:10:49,605-INFO: in_tokens: False\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tin_tokens: False\r\n2021-08-09 07:10:49,605-INFO: incr_every_n_steps: 100\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tincr_every_n_steps: 100\r\n2021-08-09 07:10:49,605-INFO: incr_ratio: 2.0\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tincr_ratio: 2.0\r\n2021-08-09 07:10:49,605-INFO: init_checkpoint: ./pretrained_lm/ernie2_base_en/params\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tinit_checkpoint: ./pretrained_lm/ernie2_base_en/params\r\n2021-08-09 07:10:49,605-INFO: init_loss_scaling: 102400\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tinit_loss_scaling: 102400\r\n2021-08-09 07:10:49,605-INFO: is_distributed: False\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tis_distributed: False\r\n2021-08-09 07:10:49,605-INFO: label_map_config: None\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tlabel_map_config: None\r\n2021-08-09 07:10:49,605-INFO: learning_rate: 5e-05\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tlearning_rate: 5e-05\r\n2021-08-09 07:10:49,605-INFO: lr_scheduler: linear_warmup_decay\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tlr_scheduler: linear_warmup_decay\r\n2021-08-09 07:10:49,605-INFO: max_ent_cnt: 42\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tmax_ent_cnt: 42\r\n2021-08-09 07:10:49,605-INFO: max_seq_len: 512\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tmax_seq_len: 512\r\n2021-08-09 07:10:49,605-INFO: metric: simple_accuracy\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tmetric: simple_accuracy\r\n2021-08-09 07:10:49,605-INFO: model_path: ./pretrained_lm/ernie2_base_en\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tmodel_path: ./pretrained_lm/ernie2_base_en\r\n2021-08-09 07:10:49,605-INFO: num_iteration_per_drop_scope: 10\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tnum_iteration_per_drop_scope: 10\r\n2021-08-09 07:10:49,605-INFO: num_labels: 97\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tnum_labels: 97\r\n2021-08-09 07:10:49,605-INFO: predict_thresh: 0.1\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\tpredict_thresh: 0.1\r\n2021-08-09 07:10:49,605-INFO: random_seed: None\r\n[INFO] 2021-08-09 07:10:49,605 [     args.py:   70]:\trandom_seed: None\r\n2021-08-09 07:10:49,606-INFO: save_checkpoints: checkpoints\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\tsave_checkpoints: checkpoints\r\n2021-08-09 07:10:49,606-INFO: skip_steps: 10\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\tskip_steps: 10\r\n2021-08-09 07:10:49,606-INFO: tokenizer: FullTokenizer\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\ttokenizer: FullTokenizer\r\n2021-08-09 07:10:49,606-INFO: use_cuda: True\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\tuse_cuda: True\r\n2021-08-09 07:10:49,606-INFO: use_dynamic_loss_scaling: True\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\tuse_dynamic_loss_scaling: True\r\n2021-08-09 07:10:49,606-INFO: use_fast_executor: True\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\tuse_fast_executor: True\r\n2021-08-09 07:10:49,606-INFO: use_fp16: False\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\tuse_fp16: False\r\n2021-08-09 07:10:49,606-INFO: verbose: False\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\tverbose: False\r\n2021-08-09 07:10:49,606-INFO: warmup_proportion: 0.1\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\twarmup_proportion: 0.1\r\n2021-08-09 07:10:49,606-INFO: weight_decay: 0.0\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\tweight_decay: 0.0\r\n2021-08-09 07:10:49,606-INFO: with_ent_structure: False\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   70]:\twith_ent_structure: False\r\n2021-08-09 07:10:49,606-INFO: ------------------------------------------------\r\n[INFO] 2021-08-09 07:10:49,606 [     args.py:   71]:\t------------------------------------------------\r\n2021-08-09 07:10:49,606-INFO: attention_probs_dropout_prob: 0.1\r\n[INFO] 2021-08-09 07:10:49,606 [     SSAN.py:   52]:\tattention_probs_dropout_prob: 0.1\r\n2021-08-09 07:10:49,606-INFO: hidden_act: gelu\r\n[INFO] 2021-08-09 07:10:49,606 [     SSAN.py:   52]:\thidden_act: gelu\r\n2021-08-09 07:10:49,606-INFO: hidden_dropout_prob: 0.1\r\n[INFO] 2021-08-09 07:10:49,606 [     SSAN.py:   52]:\thidden_dropout_prob: 0.1\r\n2021-08-09 07:10:49,607-INFO: hidden_size: 768\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   52]:\thidden_size: 768\r\n2021-08-09 07:10:49,607-INFO: initializer_range: 0.02\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   52]:\tinitializer_range: 0.02\r\n2021-08-09 07:10:49,607-INFO: max_position_embeddings: 512\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   52]:\tmax_position_embeddings: 512\r\n2021-08-09 07:10:49,607-INFO: num_attention_heads: 12\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   52]:\tnum_attention_heads: 12\r\n2021-08-09 07:10:49,607-INFO: num_hidden_layers: 12\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   52]:\tnum_hidden_layers: 12\r\n2021-08-09 07:10:49,607-INFO: sent_type_vocab_size: 4\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   52]:\tsent_type_vocab_size: 4\r\n2021-08-09 07:10:49,607-INFO: task_type_vocab_size: 16\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   52]:\ttask_type_vocab_size: 16\r\n2021-08-09 07:10:49,607-INFO: vocab_size: 30522\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   52]:\tvocab_size: 30522\r\n2021-08-09 07:10:49,607-INFO: ------------------------------------------------\r\n[INFO] 2021-08-09 07:10:49,607 [     SSAN.py:   53]:\t------------------------------------------------\r\nW0809 07:10:50.520205   270 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.2, Runtime API Version: 10.0\r\nW0809 07:10:50.523030   270 device_context.cc:244] device: 0, cuDNN Version: 7.6.\r\n2021-08-09 07:10:52,073-INFO: Load model from ./pretrained_lm/ernie2_base_en/params\r\n[INFO] 2021-08-09 07:10:52,073 [     init.py:   64]:\tLoad model from ./pretrained_lm/ernie2_base_en/params\r\n2021-08-09 07:10:52,334-INFO: ***** prediction start *****\r\n[INFO] 2021-08-09 07:10:52,334 [ run_ssan.py:  313]:\t***** prediction start *****\r\nKilled\r\n```",
        "state": "open",
        "user": "kbrajwani",
        "closed_by": null,
        "created_at": "2021-08-09T07:20:25+00:00",
        "updated_at": "2023-02-23T06:23:22+00:00",
        "closed_at": null,
        "comments_count": [
            "BenfengXu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 198,
        "title": "Duconv数据无法读取",
        "body": "retriveal方法中Duconv数据无法正确读取，显示IndexError: list index out of range",
        "state": "open",
        "user": "SunyanGu",
        "closed_by": null,
        "created_at": "2021-08-30T04:59:24+00:00",
        "updated_at": "2021-08-30T04:59:24+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 199,
        "title": "MRQA-2019-DNET中的三个预训练模型可否提供计算图代码？",
        "body": "D-Net中使用的三个预训练模型是使用fluid.io.load_inference_model方法将__model__文件直接加载成program，但是我想参考一下这三个模型原计算图的代码，请问这部分可以如何得到？",
        "state": "open",
        "user": "ma-biao",
        "closed_by": null,
        "created_at": "2021-08-31T06:37:54+00:00",
        "updated_at": "2021-08-31T06:37:54+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 200,
        "title": "ablation study中的模型开源问题",
        "body": "您好，请问可以提供下训练好的UNIMO-base w/o texts 以及 w/o pairs&images的模型吗？谢谢！",
        "state": "open",
        "user": "VickiCui",
        "closed_by": null,
        "created_at": "2021-09-01T01:26:46+00:00",
        "updated_at": "2021-09-01T01:27:06+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 203,
        "title": "可以公布txt2img的代码和预训练模型吗？",
        "body": "看ACL2021视频中，UNIMO+vqvae的txt2img的效果很惊艳",
        "state": "open",
        "user": "XuanxuanGao",
        "closed_by": null,
        "created_at": "2021-09-09T03:48:11+00:00",
        "updated_at": "2021-09-09T03:48:11+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 201,
        "title": "How can I train NER and RELATION EXTRACTION using Paddle ?",
        "body": "Hello,\r\nI am working on a project where I need to find Named Entity with its relations. Any guide to train and prepare the dataset for this task would be helpful.\r\n\r\nThanks",
        "state": "open",
        "user": "karndeepsingh",
        "closed_by": null,
        "created_at": "2021-09-06T11:24:24+00:00",
        "updated_at": "2021-10-22T17:11:50+00:00",
        "closed_at": null,
        "comments_count": [
            "iamqiz"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 206,
        "title": "那里可以找到 kpi.py，我算法里缺失这个文件，也没有找到ceroot 文件夹，可以提供一个下载地址吗？",
        "body": "那里可以找到 kpi.py，我算法里缺失这个文件，也没有找到ceroot 文件夹，可以提供一个下载地址吗\r\n\r\nsys.path.append(os.environ['ceroot'])\r\n\r\nfrom kpi import CostKpi, DurationKpi, AccKpi\r\n\r\n#### NOTE kpi.py should shared in models in some way!!!!\r\n",
        "state": "open",
        "user": "lguowang",
        "closed_by": null,
        "created_at": "2021-10-11T01:33:26+00:00",
        "updated_at": "2021-10-11T01:34:26+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 204,
        "title": "关于ACL2020GraphSum的一些细节问题",
        "body": "您好，阅读了GraphSum的论文和代码后，有一处细节不太能理解，看论文里对gaussian weights是使用这个公式\r\n![屏幕快照 2021-09-16 下午4 32 37](https://user-images.githubusercontent.com/33123730/133710251-0b6d2f70-4264-4e2a-b932-056bd4035089.png)\r\n\r\n\r\n但在代码里使用的却是这个公式，\r\n![屏幕快照 2021-09-16 下午4 34 57](https://user-images.githubusercontent.com/33123730/133579923-eece4e11-0e07-4077-bd7b-3b97e403a76e.png)\r\n\r\n而且不太能理解计算graph_attn_bias * graph_attn_bias的作用，graph_attn_bias我理解应该是每个document之间的相关性得分\r\n这块有些疑惑，不知道作者是否能简单答疑下",
        "state": "open",
        "user": "lhbrichard",
        "closed_by": null,
        "created_at": "2021-09-17T01:42:40+00:00",
        "updated_at": "2021-09-22T04:08:07+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 208,
        "title": "Should this line be changed as \"'where': self.parse_cond(sql['conds'], [sql['cond_conn_op']]),\"",
        "body": "https://github.com/PaddlePaddle/Research/blob/f745a7a5668d68ef7fe5183b67cb1fb3c8eff25c/NLP/Text2SQL-BASELINE/text2sql/grammars/nl2sql.py#L155",
        "state": "closed",
        "user": "TianHongTao",
        "closed_by": "TianHongTao",
        "created_at": "2021-10-12T10:30:39+00:00",
        "updated_at": "2021-10-12T10:32:19+00:00",
        "closed_at": "2021-10-12T10:32:19+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 207,
        "title": "UNIMO tensorflow",
        "body": "您好，请问一下，UNIMO有tensorflow版本吗？",
        "state": "open",
        "user": "SkipAngel",
        "closed_by": null,
        "created_at": "2021-10-11T08:23:23+00:00",
        "updated_at": "2021-12-16T08:36:12+00:00",
        "closed_at": null,
        "comments_count": [
            "xealml"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 217,
        "title": "eHealth文档中CBLUE链接错误",
        "body": "https://github.com/PaddlePaddle/Research/tree/master/KG/eHealth\r\n\r\nWe provide eHealth's performance on CBLUE (Chinese Biomedical Language Understanding Evaluation) benchmark, which is composed of 8 diversified biomedical NLP tasks, ranging from medical text classification and matching to medical information extraction and medical term normalization.\r\n\r\nCBLUE正确地址：https://github.com/CBLUEbenchmark/CBLUE",
        "state": "closed",
        "user": "chenmosha",
        "closed_by": "kgresearch",
        "created_at": "2021-10-26T04:02:30+00:00",
        "updated_at": "2021-11-26T09:58:53+00:00",
        "closed_at": "2021-11-26T09:58:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 216,
        "title": "Text2SQL-BASELINE验证集上的acc超过1",
        "body": "在paddle 2.1.3上运行text2sql-baseline代码，数据集为dusql，验证集上的结果超过1，这个是怎么回事？在paddle 2.0上运行代码会报错\r\n下面是验证集上结果：\r\n[eval] dev loss 0.000000, acc 6.0000. got best and saved. cost [4.41s]\r\n[eval] dev loss 0.000000, acc 7.0000. got best and saved. cost [4.21s]\r\n[eval] dev loss 0.000000, acc 8.0000. got best and saved. cost [1321.91s]\r\n",
        "state": "closed",
        "user": "Xuanfang1121",
        "closed_by": "Xuanfang1121",
        "created_at": "2021-10-20T01:59:24+00:00",
        "updated_at": "2022-05-02T08:02:48+00:00",
        "closed_at": "2022-05-02T08:02:48+00:00",
        "comments_count": [
            "ThisIsSoMe",
            "Xuanfang1121"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 222,
        "title": "GRAN训练报错",
        "body": "您好，我运行代码产生这个错误，是环境的问题么\r\nRTX3070，win11，CUDA9.2，paddlepaddle-gpu==1.5.0.post97，cudnn7.6.5\r\nhttps://github.com/PaddlePaddle/Research/tree/master/KG/ACL2021_GRAN\r\n![image](https://user-images.githubusercontent.com/49112179/143396275-f9511444-3841-4166-88f4-7e7d33ca0c32.png)\r\n我该怎么做\r\n",
        "state": "closed",
        "user": "DabeyHolmes",
        "closed_by": "DabeyHolmes",
        "created_at": "2021-11-25T07:14:51+00:00",
        "updated_at": "2021-12-07T16:20:47+00:00",
        "closed_at": "2021-12-07T16:20:47+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 220,
        "title": "Text2SQL-BASELINE 多卡训练报错",
        "body": "最近text2sql-baseline 代码采用多卡进行训练，数据集为nl2sql，在conf/text2sql_nl2sql.jsonnet中的use_data_parallel 设置为true。代码报错如下：\r\n![4088288C-85B9-41b6-92B6-52AA37476B5A](https://user-images.githubusercontent.com/33194029/141733942-d4765e5b-70b8-4941-a3f7-7ba9170c2c00.png)\r\n环境配置如下：\r\npaddle-ernie==0.2.0.dev1，\r\npaddlenlp==2.1.0，\r\npaddlepaddle-gpu==2.1.3.post112， \r\nCUDA的版本为11.2，显卡为2080Ti 和3080Ti\r\npython的版本为3.7.9\r\n这个报错如何处理？",
        "state": "closed",
        "user": "Xuanfang1121",
        "closed_by": "Xuanfang1121",
        "created_at": "2021-11-15T06:40:35+00:00",
        "updated_at": "2022-05-02T08:02:27+00:00",
        "closed_at": "2022-05-02T08:02:27+00:00",
        "comments_count": [
            "ThisIsSoMe",
            "Xuanfang1121"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 221,
        "title": "Data augmentation",
        "body": "作者你好，我看论文中有提到数据增强框架，但是链接已经失效，可以给个新的链接么。",
        "state": "open",
        "user": "yaozhuojiang",
        "closed_by": null,
        "created_at": "2021-11-17T01:25:30+00:00",
        "updated_at": "2022-04-29T03:38:48+00:00",
        "closed_at": null,
        "comments_count": [
            "Xuanfang1121",
            "ThisIsSoMe"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 224,
        "title": "每个审稿人都让我比较GRAN，但是Paddle运行老出错 GRAN模型运行Python object is not type of class std::shared_ptr<class paddle::imperative::VarBase>",
        "body": "Python object is not type of class std::shared_ptr<class paddle::imperative::VarBase> (at ..\\paddle\\fluid\\pybind\\imperative.cc:79)\r\n每个审稿人都让我比较这一篇SOTA的GRAN，我想在上面跑一下一个另外的数据集，但是这个paddle的环境真的阻碍了我很久了。这个问题该怎么解决啊，",
        "state": "open",
        "user": "chandeler",
        "closed_by": null,
        "created_at": "2021-12-17T18:43:55+00:00",
        "updated_at": "2021-12-17T18:43:55+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 223,
        "title": "请问可以提供UNIMO的预训练代码吗？",
        "body": "如题，对预训练过程中单模态数据的使用细节很感兴趣，谢谢",
        "state": "open",
        "user": "yellow-binary-tree",
        "closed_by": null,
        "created_at": "2021-12-17T09:13:09+00:00",
        "updated_at": "2022-02-18T12:00:57+00:00",
        "closed_at": null,
        "comments_count": [
            "longkukuhi"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 225,
        "title": "关于ACL2020-GraphSum的一些疑问",
        "body": "您好～看见论文中提到可以用预训练的模型去代替transformer encoder部分对输入的长文本进行字符级别的encoding，通过分别对每个段落进行编码而使得模型可以处理超过512长度的文本输入，实验部分的结果也验证了预训练roberta模型的有效性。\r\n但是按照下图文中所提的格式化输入文档的方式，这个输入还是需要截断到512个字符，不知道是不是自己的理解有偏差，但没有找到相关的代码，或者这块处理的时候是有一些具体细节，作者可以解答一下吗？\r\n<img width=\"450\" alt=\"KIM20211218-230983\" src=\"https://user-images.githubusercontent.com/48503458/146633187-f09caca9-3e92-4c31-80cf-154d3293d644.png\">\r\n\r\n感谢！",
        "state": "open",
        "user": "Orange1999",
        "closed_by": null,
        "created_at": "2021-12-18T07:25:15+00:00",
        "updated_at": "2021-12-23T11:17:00+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 231,
        "title": "百度事件抽取baseline推理报错！",
        "body": "推理脚本：predict_event_role.sh\r\npython run_event_role.py --use_cuda true\\\r\n                   --do_train false \\\r\n                   --do_val true \\\r\n                   --do_test true \\\r\n                   --batch_size 16 \\\r\n                   --init_pretraining_params ${MODEL_PATH}/params \\\r\n                   --trigger_pred_save_path ${CKPT_PATH}/../pred_role.json \\\r\n                   --chunk_scheme \"IOB\" \\\r\n                   --label_map_config ${DICT}/vocab_roles_label_map.txt \\\r\n                   --train_set ${DATA_DIR}/train.json \\\r\n                   --dev_set ${DATA_DIR}/dev.json \\\r\n                   --test_set ${DATA_DIR}/test.json \\\r\n                   --vocab_path ${MODEL_PATH}/vocab.txt \\\r\n                   --ernie_config_path ${MODEL_PATH}/ernie_config.json \\\r\n                   --save_steps 500 \\\r\n                   --weight_decay  0.0 \\\r\n                   --warmup_proportion 0.1 \\\r\n                   --validation_steps 100 \\\r\n                   --use_fp16 false \\\r\n                   --epoch 6 \\\r\n                   --max_seq_len 300 \\\r\n                   --learning_rate 5e-5 \\\r\n                   --skip_steps 20 \\\r\n                   --num_iteration_per_drop_scope 1 \\\r\n                   --init_checkpoint ${CKPT_PATH} \\\r\n                   --random_seed 1\r\n报错信息：\r\n=========MODEL CONFIG============\r\n2022-01-14 07:03:46,591-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\n[WARNING] 2022-01-14 07:03:46,591 [       io.py:  690]:\tpaddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\r\nW0114 07:03:47.201992  3003 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 11.2, Runtime API Version: 9.0\r\nW0114 07:03:47.203670  3003 device_context.cc:244] device: 0, cuDNN Version: 7.6.\r\n/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/executor.py:795: UserWarning: The current program is empty.\r\n  warnings.warn(error_info)\r\n2022-01-14 07:03:47,798-INFO: Load model from /home/Research-master/KG/DuEE_baseline/save_model/trigger\r\n[INFO] 2022-01-14 07:03:47,798 [     init.py:   69]:\tLoad model from /home/Research-master/KG/DuEE_baseline/save_model/trigger\r\n/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/executor.py:779: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"run_event_trigger.py\", line 466, in <module>\r\n    main(args)\r\n  File \"run_event_trigger.py\", line 317, in main\r\n    graph_vars, 1, 'final')\r\n  File \"run_event_trigger.py\", line 427, in predict_wrapper\r\n    res = predict(exe, test_prog, test_pyreader, graph_vars, dev_count=1)\r\n  File \"/home/Research-master/KG/DuEE_baseline/bin/finetune/sequence_label.py\", line 231, in predict\r\n    fetch_list=fetch_list)\r\n  File \"/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 780, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 775, in run\r\n    use_program_cache=use_program_cache)\r\n  File \"/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 822, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/executor.py\", line 899, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   void paddle::operators::math::Blas<paddle::platform::CUDADeviceContext>::MatMul<float>(paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, float, paddle::framework::Tensor*, float) const\r\n3   paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n9   paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/framework.py\", line 2488, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/python2.7/lib/python2.7/site-packages/paddle/fluid/layers/nn.py\", line 7072, in matmul\r\n    'alpha': float(alpha),\r\n  File \"/home/Research-master/KG/DuEE_baseline/bin/model/ernie.py\", line 157, in _build_model\r\n    x=input_mask, y=input_mask, transpose_y=True)\r\n  File \"/home/Research-master/KG/DuEE_baseline/bin/model/ernie.py\", line 108, in __init__\r\n    input_mask)\r\n  File \"/home/Research-master/KG/DuEE_baseline/bin/finetune/sequence_label.py\", line 66, in create_model\r\n    use_fp16=args.use_fp16)\r\n  File \"run_event_trigger.py\", line 168, in main\r\n    ernie_config=ernie_config)\r\n  File \"run_event_trigger.py\", line 466, in <module>\r\n    main(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nError: Paddle internal Check failed. (Please help us create a new issue, here we need to find the developer to add a user friendly error message)\r\n  [CUBLAS: execution failed.] at (/paddle/paddle/fluid/operators/math/blas_impl.cu.h:51)\r\n  [operator < matmul > error]\r\n",
        "state": "open",
        "user": "lanmao9000",
        "closed_by": null,
        "created_at": "2022-01-14T07:33:14+00:00",
        "updated_at": "2022-01-14T07:33:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 226,
        "title": "EMNLP2021-SgSum Inference on Custom Data",
        "body": "Hi, \r\n\r\nThanks for your amazing effort, i just want to ask How to make inference without the need of the target summary ?\r\nI checked the code inside data_preprocess directory, but it was need to provide the src and tgt files for the data preprocessing phase. and also the model itself need the sent_labels in the ext_predict method.\r\nSo, if there any way to do inference on the unseen data, just with src summary ?\r\n\r\nThanks in advance!",
        "state": "open",
        "user": "muhammedjax",
        "closed_by": null,
        "created_at": "2021-12-20T15:57:36+00:00",
        "updated_at": "2021-12-24T02:47:42+00:00",
        "closed_at": null,
        "comments_count": [
            "endlesstalking"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 228,
        "title": "Training the GraphSum & SgSum issue",
        "body": "Hi, GraphSum and SgSum are outstanding works. \r\n\r\nBut by repeating the training process, we faced the issue,\r\n\r\n_RuntimeError: parallel_for failed: no kernel image is available for execution on the device_\r\n\r\nFor the line,\r\n\r\n_exe.run(startup_prog)_\r\n\r\nCould you please give me some idea for resolving this problem? Is the issue occur because of the non-distribute training?\r\n\r\nMany thanks.",
        "state": "open",
        "user": "77-qiqi-wang",
        "closed_by": null,
        "created_at": "2021-12-27T15:28:30+00:00",
        "updated_at": "2022-03-09T06:51:56+00:00",
        "closed_at": null,
        "comments_count": [
            "Weili-NLP"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 232,
        "title": "Add the link of paper \"CIKM2022-DuMapper\"?",
        "body": null,
        "state": "closed",
        "user": "943fansi",
        "closed_by": "943fansi",
        "created_at": "2022-01-18T03:26:23+00:00",
        "updated_at": "2022-12-08T08:12:52+00:00",
        "closed_at": "2022-12-08T08:12:52+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 236,
        "title": "能共享生成的非地标数据文件吗？",
        "body": "看您的介绍，使用检测模型筛选出了一批非地标的图片，然后通过检索扩充更多的非地标图，生成的非地标文件列表能共享一下吗？谢谢",
        "state": "open",
        "user": "widgetxp",
        "closed_by": null,
        "created_at": "2022-02-13T00:20:33+00:00",
        "updated_at": "2022-02-13T00:20:33+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 243,
        "title": "执行exe.run报错",
        "body": "版本：python3.7，paddlepaddle-gpu1.8.3post107，cuda10.1，cudnn7.6（python3.6，paddle1.5.1.post97，cuda9.0会出现一样的错误）\r\npaddlepaddle-gpu版本为1.5.0,也会有错误\r\n复现：https://github.com/PaddlePaddle/Research/tree/master/KG/ACL2021_GRAN\r\n问题：执行到exe.run时会出现如下错误：\r\n------------------------------------------\r\npaddlepaddle-gpu版本为1.5.0：\r\n------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"./src/run.py\", line 472, in <module>\r\n    main(args)\r\n  File \"./src/run.py\", line 365, in main\r\n    outputs = train_exe.run(fetch_list=fetch_list)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/parallel_executor.py\", line 280, in run\r\n    return_numpy=return_numpy)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 665, in run\r\n    return_numpy=return_numpy)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 527, in _run_parallel\r\n    exe.run(fetch_var_names, fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: Invoke operator matmul error.\r\nPython Callstacks: \r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 1748, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 5218, in matmul\r\n    'alpha': float(alpha),\r\n  File \"/data/GRAN/src/model/gran_model.py\", line 127, in _build_model\r\n    x=input_mask, y=input_mask, transpose_y=True)\r\n  File \"/data/GRAN/src/model/gran_model.py\", line 72, in __init__\r\n    self._build_model(input_ids, input_mask, edge_labels)\r\n  File \"./src/run.py\", line 137, in create_model\r\n    use_fp16=args.use_fp16)\r\n  File \"./src/run.py\", line 266, in main\r\n    pyreader_name='train_reader', config=config)\r\n  File \"./src/run.py\", line 472, in <module>\r\n    main(args)\r\nC++ Callstacks: \r\nCUBLAS: execution failed,  at [/paddle/paddle/fluid/operators/math/blas_impl.cu.h:50]\r\nPaddlePaddle Call Stacks: \r\n0       0x7f947a5e8500p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352\r\n1       0x7f947a5e8879p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137\r\n2       0x7f947a9d75aap void paddle::operators::math::Blas<paddle::platform::CUDADeviceContext>::MatMul<float>(paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, float, paddle::framework::Tensor*, float) const + 3370\r\n3       0x7f947a9d7ae9p paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 761\r\n4       0x7f947a9d7bf3p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35\r\n5       0x7f947c66b797p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375\r\n6       0x7f947c66bb71p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529\r\n7       0x7f947c66916cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332\r\n8       0x7f947c4658bap paddle::framework::details::ComputationOpHandle::RunImpl() + 250\r\n9       0x7f947c458260p paddle::framework::details::OpHandleBase::Run(bool) + 160\r\n10      0x7f947c3b32ccp paddle::framework::details::ThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*) + 316\r\n11      0x7f947c3ae1d7p paddle::framework::details::ThreadedSSAGraphExecutor::RunTracedOps(std::vector<paddle::framework::details::OpHandleBase*, std::allocator<paddle::framework::details::OpHandleBase*> > const&) + 71\r\n12      0x7f947c3b64ebp paddle::framework::details::ThreadedSSAGraphExecutor::RunImpl(std::vector<std::string, std::allocator<std::string> > const&) + 3547\r\n13      0x7f947c3b2cf2p paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 482\r\n14      0x7f947c39f10cp paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&) + 124\r\n15      0x7f947a7be761p paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, std::string const&) + 305\r\n16      0x7f947a5d984ep\r\n17      0x7f947a61aee6p\r\n18      0x55ebdc6d9ac4p _PyMethodDef_RawFastCallKeywords + 596\r\n19      0x55ebdc70f861p _PyObject_FastCallKeywords + 305\r\n20      0x55ebdc7102d1p\r\n21      0x55ebdc757602p _PyEval_EvalFrameDefault + 18594\r\n22      0x55ebdc6a959cp _PyEval_EvalCodeWithName + 3164\r\n23      0x55ebdc6c9223p _PyFunction_FastCallKeywords + 1683\r\n24      0x55ebdc7100c5p\r\n25      0x55ebdc7541bcp _PyEval_EvalFrameDefault + 5212\r\n26      0x55ebdc6a8bb3p _PyEval_EvalCodeWithName + 627\r\n27      0x55ebdc6c9223p _PyFunction_FastCallKeywords + 1683\r\n28      0x55ebdc7100c5p\r\n29      0x55ebdc7541bcp _PyEval_EvalFrameDefault + 5212\r\n30      0x55ebdc6a8bb3p _PyEval_EvalCodeWithName + 627\r\n31      0x55ebdc6c9223p _PyFunction_FastCallKeywords + 1683\r\n32      0x55ebdc7100c5p\r\n33      0x55ebdc7541bcp _PyEval_EvalFrameDefault + 5212\r\n34      0x55ebdc6c8d17p _PyFunction_FastCallKeywords + 391\r\n35      0x55ebdc753155p _PyEval_EvalFrameDefault + 1013\r\n36      0x55ebdc6a8bb3p _PyEval_EvalCodeWithName + 627\r\n37      0x55ebdc6a9ee3p PyEval_EvalCode + 35\r\n38      0x55ebdc7b7802p\r\n39      0x55ebdc7c194ep PyRun_FileExFlags + 158\r\n40      0x55ebdc7c1b3bp PyRun_SimpleFileExFlags + 443\r\n41      0x55ebdc7c2c3ap\r\n42      0x55ebdc7c2cccp _Py_UnixMain + 60\r\n43      0x7f95e06da840p __libc_start_main + 240\r\n44      0x55ebdc767555p\r\n\r\n------------------------------------------\r\n如将paddle版本升至1.8.3后仍会报错，错误如下：\r\n------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"./src/run.py\", line 472, in <module>\r\n    main(args)\r\n  File \"./src/run.py\", line 365, in main\r\n    outputs = train_exe.run(fetch_list=fetch_list)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/parallel_executor.py\", line 303, in run\r\n    return_numpy=return_numpy)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1167, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 879, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\r\n2   void paddle::operators::math::Blas<paddle::platform::CUDADeviceContext>::MatMul<float>(paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, paddle::framework::Tensor const&, paddle::operators::math::MatDescriptor const&, float, paddle::framework::Tensor*, float) const\r\n3   paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\r\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, float>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, double>, paddle::operators::MatMulKernel<paddle::platform::CUDADeviceContext, paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\r\n5   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n7   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n8   paddle::framework::details::ComputationOpHandle::RunImpl()\r\n9   paddle::framework::details::ThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*)\r\n10  paddle::framework::details::ThreadedSSAGraphExecutor::RunTracedOps(std::vector<paddle::framework::details::OpHandleBase*, std::allocator<paddle::framework::details::OpHandleBase*> > const&)\r\n11  paddle::framework::details::ThreadedSSAGraphExecutor::RunImpl(std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n12  paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n13  paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n14  paddle::framework::ParallelExecutor::Run(std::vector<std::string, std::allocator<std::string> > const&, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\", line 43, in append_op\r\n    return self.main_program.current_block().append_op(*args, **kwargs)\r\n  File \"/data/anaconda3/envs/py37/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 6416, in matmul\r\n    attrs=attrs)\r\n  File \"/data/GRAN/src/model/gran_model.py\", line 127, in _build_model\r\n    x=input_mask, y=input_mask, transpose_y=True)\r\n  File \"/data/GRAN/src/model/gran_model.py\", line 72, in __init__\r\n    self._build_model(input_ids, input_mask, edge_labels)\r\n  File \"./src/run.py\", line 137, in create_model\r\n    use_fp16=args.use_fp16)\r\n  File \"./src/run.py\", line 266, in main\r\n    pyreader_name='train_reader', config=config)\r\n  File \"./src/run.py\", line 472, in <module>\r\n    main(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nExternalError:  Cublas error, CUBLAS_STATUS_EXECUTION_FAILED  at (/paddle/paddle/fluid/operators/math/blas_impl.cu.h:61)\r\n  [operator < matmul > error]\r\nterminate called without an active exception\r\nW0304 21:29:48.526862 209578 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\r\nW0304 21:29:48.526906 209578 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\r\nW0304 21:29:48.526917 209578 init.cc:221] The detail failure signal is:\r\n\r\nW0304 21:29:48.526929 209578 init.cc:224] *** Aborted at 1646400588 (unix time) try \"date -d @1646400588\" if you are using GNU date ***\r\nW0304 21:29:48.531188 209578 init.cc:224] PC: @                0x0 (unknown)\r\nW0304 21:29:48.531322 209578 init.cc:224] *** SIGABRT (@0x3fb000331ca) received by PID 209354 (TID 0x7f0bcb241700) from PID 209354; stack trace: ***\r\nW0304 21:29:48.534565 209578 init.cc:224]     @     0x7f0bf1f44390 (unknown)\r\nW0304 21:29:48.535984 209578 init.cc:224]     @     0x7f0bf1b9e438 gsignal\r\nW0304 21:29:48.537391 209578 init.cc:224]     @     0x7f0bf1ba003a abort\r\nW0304 21:29:48.538328 209578 init.cc:224]     @     0x7f0b27f1c872 __gnu_cxx::__verbose_terminate_handler()\r\nW0304 21:29:48.539134 209578 init.cc:224]     @     0x7f0b27f1af6f __cxxabiv1::__terminate()\r\nW0304 21:29:48.540019 209578 init.cc:224]     @     0x7f0b27f1afb1 std::terminate()\r\nW0304 21:29:48.540805 209578 init.cc:224]     @     0x7f0b27f1ac82 __gxx_personality_v0\r\nW0304 21:29:48.541549 209578 init.cc:224]     @     0x7f0b4ba8cbc6 _Unwind_ForcedUnwind_Phase2\r\nW0304 21:29:48.542297 209578 init.cc:224]     @     0x7f0b4ba8ceac _Unwind_ForcedUnwind\r\nW0304 21:29:48.543699 209578 init.cc:224]     @     0x7f0bf1f43070 __GI___pthread_unwind\r\nW0304 21:29:48.545024 209578 init.cc:224]     @     0x7f0bf1f3b845 __pthread_exit\r\nW0304 21:29:48.545274 209578 init.cc:224]     @     0x561a3f47db09 PyThread_exit_thread\r\nW0304 21:29:48.545343 209578 init.cc:224]     @     0x561a3f303e3e PyEval_RestoreThread.cold.742\r\nW0304 21:29:48.546340 209578 init.cc:224]     @     0x7f0a724d1b19 pybind11::gil_scoped_release::~gil_scoped_release()\r\nW0304 21:29:48.546478 209578 init.cc:224]     @     0x7f0a725b9eb6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\r\nW0304 21:29:48.547439 209578 init.cc:224]     @     0x7f0a724ef329 pybind11::cpp_function::dispatcher()\r\nW0304 21:29:48.547737 209578 init.cc:224]     @     0x561a3f3e7ac4 _PyMethodDef_RawFastCallKeywords\r\nW0304 21:29:48.547976 209578 init.cc:224]     @     0x561a3f41d861 _PyObject_FastCallKeywords\r\nW0304 21:29:48.548120 209578 init.cc:224]     @     0x561a3f41e2d1 call_function\r\nW0304 21:29:48.548375 209578 init.cc:224]     @     0x561a3f465602 _PyEval_EvalFrameDefault\r\nW0304 21:29:48.548611 209578 init.cc:224]     @     0x561a3f3b759c _PyEval_EvalCodeWithName\r\nW0304 21:29:48.548846 209578 init.cc:224]     @     0x561a3f3d6206 _PyFunction_FastCallDict\r\nW0304 21:29:48.549104 209578 init.cc:224]     @     0x561a3f462a6d _PyEval_EvalFrameDefault\r\nW0304 21:29:48.549325 209578 init.cc:224]     @     0x561a3f3d6d17 _PyFunction_FastCallKeywords\r\nW0304 21:29:48.549470 209578 init.cc:224]     @     0x561a3f41e0c5 call_function\r\nW0304 21:29:48.549722 209578 init.cc:224]     @     0x561a3f461381 _PyEval_EvalFrameDefault\r\nW0304 21:29:48.549947 209578 init.cc:224]     @     0x561a3f3d6d17 _PyFunction_FastCallKeywords\r\nW0304 21:29:48.550091 209578 init.cc:224]     @     0x561a3f41e0c5 call_function\r\nW0304 21:29:48.550343 209578 init.cc:224]     @     0x561a3f461381 _PyEval_EvalFrameDefault\r\nW0304 21:29:48.550572 209578 init.cc:224]     @     0x561a3f3b80a6 _PyObject_FastCallDict\r\nW0304 21:29:48.550659 209578 init.cc:224]     @     0x561a3f3cd041 method_call\r\nW0304 21:29:48.550915 209578 init.cc:224]     @     0x561a3f3b87b6 PyObject_Call\r\n",
        "state": "closed",
        "user": "QWERZPY",
        "closed_by": "QWERZPY",
        "created_at": "2022-03-07T07:38:16+00:00",
        "updated_at": "2022-03-09T02:25:11+00:00",
        "closed_at": "2022-03-09T02:25:11+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 239,
        "title": "关于eHealth-base模型的问题",
        "body": "请问eHealth-base模型文件里面是否少了saved_weights.pdparams？\r\n还是说这个文件是跟Ernie-base一致的？",
        "state": "open",
        "user": "LeoWood",
        "closed_by": null,
        "created_at": "2022-02-26T13:56:38+00:00",
        "updated_at": "2022-03-22T08:02:11+00:00",
        "closed_at": null,
        "comments_count": [
            "s65b40",
            "LeoWood",
            "wenyu332",
            "LeoWood"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 240,
        "title": "关于代码参数的问题",
        "body": "请问代码中参数设置需要调整吗，如果调用gpu的话会报错，调用cpu的话可以运行但没有输出epoch步骤也就是训练的步骤，直接进入了test",
        "state": "closed",
        "user": "QWERZPY",
        "closed_by": "QWERZPY",
        "created_at": "2022-03-01T14:47:51+00:00",
        "updated_at": "2022-03-10T02:45:37+00:00",
        "closed_at": "2022-03-10T02:45:37+00:00",
        "comments_count": [
            "QWERZPY"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 249,
        "title": "How to use trained models in PyTorch, TensorFlow?",
        "body": "Hi, just like in the case of RocketQA models, I was wondering whether there is any way that you can make the trained PAIR models available for use in other widely used computational frameworks, such as PyTorch.\r\nWhile I believe that the research community would benefit from using and integrating PAIR and PaddlePaddle has very interesting capabilities, the vast majority of researchers and practitioners use other computational frameworks, and making trained models available for these frameworks would be highly appreciated.",
        "state": "open",
        "user": "gzerveas",
        "closed_by": null,
        "created_at": "2022-03-16T04:57:57+00:00",
        "updated_at": "2022-03-16T04:57:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 244,
        "title": "复现参数设置问题",
        "body": "在复现论文结果时，按照如下参数设置\r\n![149bb12d44d1783fe4c603cc88e3242](https://user-images.githubusercontent.com/39788820/157578339-fb2231e8-dd93-4080-b810-246e57121db5.png)\r\n![73d97dbee7b3744f94174bb25e40638](https://user-images.githubusercontent.com/39788820/157578367-38334d13-66ef-4cf8-a8c1-83aec8708173.png)\r\n对JF17K进行复现，结果要比论文中的均少0.03,请问是参数哪里还需要调整吗\r\n复现结果如下：\r\n![26453ff763ce01d0c624dc273da530b](https://user-images.githubusercontent.com/39788820/157578532-ff099f75-08c6-4eb7-b950-fae8af11ef33.png)",
        "state": "open",
        "user": "QWERZPY",
        "closed_by": null,
        "created_at": "2022-03-10T02:46:39+00:00",
        "updated_at": "2022-03-10T02:48:27+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 253,
        "title": "Has the code of 2019-AKGCM been released?",
        "body": "I only found the README.md file with datasets for this work, so where's the code?",
        "state": "open",
        "user": "SeaEagleI",
        "closed_by": null,
        "created_at": "2022-04-12T07:04:14+00:00",
        "updated_at": "2022-04-12T07:04:14+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 254,
        "title": "CoKE trained models",
        "body": "您好，我想下载coke训练好的模型，wget_kbc_models.sh里的模型地址是失效了吗\r\n",
        "state": "open",
        "user": "pooruss",
        "closed_by": null,
        "created_at": "2022-04-13T04:55:38+00:00",
        "updated_at": "2022-04-13T04:55:38+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 250,
        "title": "When will the data and code for ACL2022-DuLeMon be open source",
        "body": "The paper ACL2022-DuLeMon is very impressing, waiting for open-source data and code.",
        "state": "open",
        "user": "linjianz",
        "closed_by": null,
        "created_at": "2022-03-22T03:54:36+00:00",
        "updated_at": "2022-03-31T02:25:48+00:00",
        "closed_at": null,
        "comments_count": [
            "ZubinGou",
            "sony-au",
            "ZubinGou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 255,
        "title": "why are some tokens missed in the decoded output of Graphsum?",
        "body": "Hi, I trained graphsum on new mult-document summarization for comparision. But when I do  testing ,I find some tokens are missing in the output, like this \"\" n \" exical \" unctional \" rammars\". \r\nIt seems that the first token is not decoded. So I guess it may be cause by sentencepiece tokenizer. So I wonder what's the special format of the raw input?\r\n\r\nThanks. @Weili-NLP ",
        "state": "closed",
        "user": "muguruzawang",
        "closed_by": "muguruzawang",
        "created_at": "2022-04-25T08:20:11+00:00",
        "updated_at": "2022-05-24T04:21:09+00:00",
        "closed_at": "2022-04-26T02:09:44+00:00",
        "comments_count": [
            "muguruzawang",
            "isaacisaactang"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 256,
        "title": "help",
        "body": null,
        "state": "closed",
        "user": "hellffen",
        "closed_by": "hellffen",
        "created_at": "2022-04-28T10:01:28+00:00",
        "updated_at": "2022-04-28T10:02:31+00:00",
        "closed_at": "2022-04-28T10:02:31+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 263,
        "title": "English version of ACL-2020 DuRecDial",
        "body": "Hello,\r\nDo you plan to release an English version of the DuRecDial dataset from ACL 2020?",
        "state": "closed",
        "user": "almightyGOSU",
        "closed_by": "almightyGOSU",
        "created_at": "2022-05-19T10:43:09+00:00",
        "updated_at": "2022-05-21T06:30:14+00:00",
        "closed_at": "2022-05-21T06:30:14+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 257,
        "title": " how can I run your elvaluation code on our own dataset",
        "body": " how can I run your elvaluation code on our own dataset",
        "state": "open",
        "user": "Gary-code",
        "closed_by": null,
        "created_at": "2022-05-13T13:59:47+00:00",
        "updated_at": "2022-05-13T14:00:54+00:00",
        "closed_at": null,
        "comments_count": [
            "Gary-code"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 269,
        "title": "CHAML 除 0 问题",
        "body": "[CHAML](https://github.com/PaddlePaddle/Research/tree/master/ST_DM/KDD2021-CHAML) 严格按照 readme 操作后，在最后一步执行 run.sh 命令后报错“除 0”。\r\n\r\n详细错误代码是：\r\n```\r\n(CHAML) dch@gpuadmin-SYS-7048GR-TR:~/source/CHAML$ sh run.sh\r\n06/10 11:21:02 - INFO -   method is meta. HARD_TASK: True, HARD_USER: True, CURRICULUM: True, PACING_FUNCTION: ssp, PER_TEST_LOG: 2500, PATIENCE: 2\r\n06/10 11:21:02 - INFO -   curriculum is: [0, 1, 2, 3, 4, 5, 6, 7]\r\n06/10 11:21:02 - INFO -   Got config from config/config-chaml.json\r\n{'update_lr': 0.001, 'meta_lr': 0.001, 'update_step': 1, 'update_step_test': 1, 'task_batch_size': 4, 'train_qry_batch_size': 512, 'max_train_steps': 100000, 'few_num': 512, 'num_poi_types': 230, 'num_time': 25, 'embed_dim': 50, 'poiid_dim': 50, 'mlp_hidden': 300, 'local_fix_var': 1, 'global_fix_var': 1, 'sample_batch_size': 1024, 'test_task_batch_size': 1, 'num_epoch': 10, 'with_cont_feat': True}\r\n<model.meta.Meta object at 0x7fbc1dded7d8>\r\n06/10 11:21:02 - INFO -   Total trainable tensors: 225653\r\n06/10 11:21:06 - INFO -   Loaded all the data pickles!\r\n/home/dch/source/CHAML/utils/metadataset.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n  final_pos_samples.append(np.array([user_id, hist, pos_candi, label]))\r\n/home/dch/source/CHAML/utils/metadataset.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n  final_neg_samples.append(np.array([user_id, hist, neg_candi, 0]))\r\n/home/common/anaconda3/envs/dch-CHAML/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py:165: RuntimeWarning: divide by zero encountered in double_scalars\r\n  return _scalar_elementwise_op_(var, 1.0 / value, 0.0)\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 374, in <module>\r\n    main_meta(meta_path, root_path, id_emb_path)\r\n  File \"main.py\", line 283, in main_meta\r\n    'stage1', CURRICULUM, HARD_TASK, batch_id=batch_id)\r\n  File \"main.py\", line 222, in one_meta_training_step\r\n    poiid_embs=poiid_embs, cont_feat_scalers=cont_feat_scalers)\r\n  File \"/home/common/anaconda3/envs/dch-CHAML/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 891, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/dch/source/CHAML/model/meta.py\", line 76, in forward\r\n    vars=None, scaler=scaler)\r\n  File \"/home/common/anaconda3/envs/dch-CHAML/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 891, in __call__\r\n    outputs = self.forward(*inputs, **kwargs)\r\n  File \"/home/dch/source/CHAML/model/learner.py\", line 133, in forward\r\n    hist_embed, mask)\r\n  File \"/home/dch/source/CHAML/model/learner.py\", line 73, in attention\r\n    score = paddle.where(mask==1, wall, score)\r\n  File \"/home/common/anaconda3/envs/dch-CHAML/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py\", line 238, in __impl__\r\n    return math_op(self, other_var, 'axis', axis)\r\nRuntimeError: (NotFound) Operator equal does not have kernel for data_type[bool]:data_layout[ANY_LAYOUT]:place[CPUPlace]:library_type[PLAIN].\r\n  [Hint: Expected kernel_iter != kernels.end(), but received kernel_iter == kernels.end().] (at /paddle/paddle/fluid/imperative/prepared_operator.cc:127)\r\n  [operator < equal > error]\r\n```",
        "state": "open",
        "user": "Wonderdch",
        "closed_by": null,
        "created_at": "2022-06-19T08:10:07+00:00",
        "updated_at": "2022-06-19T08:10:07+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 270,
        "title": "issue in KG/CoKE",
        "body": "Hi, developer, thanks for the great work.\r\nI realize the code having a new 'layer_norm' structure replacing the built-in paddle 'layer_norm'.\r\nIs there anything new in this layer_norm that is very different? Can the pytorch 'layer_norm' achieve the similar results?\r\nThanks.",
        "state": "open",
        "user": "Kunlun-Zhu",
        "closed_by": null,
        "created_at": "2022-06-20T01:43:03+00:00",
        "updated_at": "2022-06-20T01:43:03+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 280,
        "title": "About ACL2020-GraphSum",
        "body": "你好，就是在复现的时候出现了下面这种情况，请问这是什么原因造成的？\r\n\r\n-----------  Configuration Arguments -----------\r\ncurrent_node_ip: 127.0.1.1\r\nlog_prefix: \r\nnode_id: 0\r\nnode_ips: 127.0.1.1\r\nnproc_per_node: 8\r\nprint_config: True\r\nselected_gpus: 0,1,2,3,4,5,6,7\r\nsplit_log_path: log\r\ntraining_script: ./src/run.py\r\ntraining_script_args: ['--model_name', 'graphsum', '--use_cuda', 'true', '--is_distributed', 'true', '--use_multi_gpu_test', 'false', '--use_fast_executor', 'true', '--use_fp16', 'False', '--use_dynamic_loss_scaling', 'False', '--init_loss_scaling', '12800', '--weight_sharing', 'true', '--do_train', 'true', '--do_val', 'false', '--do_test', 'true', '--do_dec', 'true', '--verbose', 'true', '--batch_size', '10', '--in_tokens', 'false', '--stream_job', '', '--init_pretraining_params', '', '--train_set', '../WikiSum_data_tfidf_paddle/train', '--dev_set', '../WikiSum_data_tfidf_paddle/valid', '--test_set', '../WikiSum_data_tfidf_paddle/test', '--vocab_path', './vocab/spm9998_3.model', '--config_path', 'model_config/graphsum_config.json', '--checkpoints', './models/graphsum_wikisum', '--decode_path', './results/graphsum_wikisum', '--lr_scheduler', 'noam_decay', '--save_steps', '100000', '--weight_decay', '0.01', '--warmup_steps', '8000', '--validation_steps', '200000', '--epoch', '100', '--max_para_num', '30', '--max_para_len', '150', '--max_tgt_len', '400', '--max_out_len', '400', '--min_out_len', '20', '--graph_type', 'similarity', '--len_penalty', '0.4', '--block_trigram', 'True', '--report_rouge', 'True', '--learning_rate', '2.0', '--skip_steps', '100', '--grad_norm', '2.0', '--pos_win', '2.0', '--label_smooth_eps', '0.1', '--num_iteration_per_drop_scope', '10', '--log_file', 'log/graphsum_wikisum.log', '--random_seed', '1']\r\n------------------------------------------------\r\n127.0.1.1\r\nall_trainer_endpoints:  127.0.1.1:6170,127.0.1.1:6171,127.0.1.1:6172,127.0.1.1:6173,127.0.1.1:6174,127.0.1.1:6175,127.0.1.1:6176,127.0.1.1:6177 , node_id:  0 , current_ip:  127.0.1.1 , num_nodes:  1 , node_ips:  ['127.0.1.1'] , gpus_per_proc:  1 , selected_gpus_per_proc:  [['0'], ['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7']] , nranks:  8\r\nTraceback (most recent call last):\r\n  File \"./src/launch.py\", line 133, in <module>\r\n    main(lanch_args)\r\n  File \"./src/launch.py\", line 128, in main\r\n    start_procs(args)\r\n  File \"./src/launch.py\", line 117, in start_procs\r\n    cmd=cmds[i])\r\nsubprocess.CalledProcessError: Command '['/home/anaconda3/envs/bin/python', '-u', './src/run.py', '--model_name', 'graphsum', '--use_cuda', 'true', '--is_distributed', 'true', '--use_multi_gpu_test', 'false', '--use_fast_executor', 'true', '--use_fp16', 'False', '--use_dynamic_loss_scaling', 'False', '--init_loss_scaling', '12800', '--weight_sharing', 'true', '--do_train', 'true', '--do_val', 'false', '--do_test', 'true', '--do_dec', 'true', '--verbose', 'true', '--batch_size', '10', '--in_tokens', 'false', '--stream_job', '', '--init_pretraining_params', '', '--train_set', '../WikiSum_data_tfidf_paddle/train', '--dev_set', '../WikiSum_data_tfidf_paddle/valid', '--test_set', '../WikiSum_data_tfidf_paddle/test', '--vocab_path', './vocab/spm9998_3.model', '--config_path', 'model_config/graphsum_config.json', '--checkpoints', './models/graphsum_wikisum', '--decode_path', './results/graphsum_wikisum', '--lr_scheduler', 'noam_decay', '--save_steps', '100000', '--weight_decay', '0.01', '--warmup_steps', '8000', '--validation_steps', '200000', '--epoch', '100', '--max_para_num', '30', '--max_para_len', '150', '--max_tgt_len', '400', '--max_out_len', '400', '--min_out_len', '20', '--graph_type', 'similarity', '--len_penalty', '0.4', '--block_trigram', 'True', '--report_rouge', 'True', '--learning_rate', '2.0', '--skip_steps', '100', '--grad_norm', '2.0', '--pos_win', '2.0', '--label_smooth_eps', '0.1', '--num_iteration_per_drop_scope', '10', '--log_file', 'log/graphsum_wikisum.log', '--random_seed', '1']' returned non-zero exit status 1.\r\n",
        "state": "closed",
        "user": "Hao-Ni",
        "closed_by": "Hao-Ni",
        "created_at": "2022-07-15T12:18:14+00:00",
        "updated_at": "2022-07-20T03:10:53+00:00",
        "closed_at": "2022-07-20T03:10:53+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 264,
        "title": "PLATO-LTM中的Persona Extractor一些疑惑",
        "body": "非常感谢Baidu的开源~\r\n\r\n有两个问题希望可以解答一下：\r\n1): 关于在PLATO-LTM中的Persona Extractor，在我看来应该有四个作用：PE用来判断一句话是否需要用到角色信息和一句话是否可以作为角色信息，所以**PE是否应该是一个四分类的分类器？**，即：0-不能作为角色信息、1-可以作为机器人的角色信息、2-可以作为用户的角色信息、3-需要用到Memory中的角色信息**，其中1和2作为Positive sample.\r\n\r\n2):关于开源数据集如何训练PE\r\n开源的数据集似乎不是训练PE的数据集，请问**是否有开源计划？**\r\n\r\n非常希望得到解答~\r\n祝520快乐~",
        "state": "closed",
        "user": "cingtiye",
        "closed_by": "cingtiye",
        "created_at": "2022-05-19T13:08:13+00:00",
        "updated_at": "2022-07-12T01:58:07+00:00",
        "closed_at": "2022-06-21T07:54:12+00:00",
        "comments_count": [
            "hrwise-nlp",
            "cingtiye",
            "fengmingfeng",
            "cingtiye",
            "ZubinGou",
            "cingtiye",
            "ZubinGou",
            "cingtiye",
            "ZubinGou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 281,
        "title": "ACL2019-ARNOR, the link of Data version 2.0.0 is gone",
        "body": "Hi, in the page of paper ACL2019-ARNOR, the download link of Data version 2.0.0 cannot be used for some reason. Could you please fix it?\r\n\r\nThe page link for paper ACL2019-ARNOR is https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2019-ARNOR\r\n\r\nMany Thanks!",
        "state": "open",
        "user": "Emma1066",
        "closed_by": null,
        "created_at": "2022-07-20T01:03:57+00:00",
        "updated_at": "2022-07-20T01:03:57+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 279,
        "title": "ACL2022-DuLeMon中首次对话的原始数据能否公开",
        "body": "PersonaExtractor从首次对话中提取相关的个性化信息，但是我发现你们公开的数据中，没有一次对话的原文，取之而代的是已经提取好的个性化信息",
        "state": "open",
        "user": "aa452948257",
        "closed_by": null,
        "created_at": "2022-06-27T08:33:53+00:00",
        "updated_at": "2022-07-07T14:56:17+00:00",
        "closed_at": null,
        "comments_count": [
            "hrwise-nlp",
            "cingtiye",
            "ZubinGou"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 282,
        "title": "AttributeError: module 'easymia.transforms.functional' has no attribute 'load_dcm'",
        "body": "in running file rsna_lhd_preprocess.py of Effective Transformer-based Solution for RSNA Intracranial Hemorrhage Detection, in line of  # Image Dicom -> .npy\r\n    _ = Parallel(n_jobs=24, verbose=0)(\r\n        (delayed(dataset.preprocess)(series_id, rows.slice_id.tolist(), train_dicom_dir, savepath=image_savepath) \r\n        for series_id, rows in train_meta_info.groupby(\"series_id\")))\r\nraise AttributeError: module 'easymia.transforms.functional' has no attribute 'load_dcm'\r\ntrace back to easymia.transforms.functional,'load_dcm' function is not exist!",
        "state": "open",
        "user": "vincentxu199112",
        "closed_by": null,
        "created_at": "2022-07-27T07:10:18+00:00",
        "updated_at": "2022-07-27T07:10:18+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 288,
        "title": "请问会开源SynCLM的预训练模型吗",
        "body": null,
        "state": "open",
        "user": "JUJUEZAIWAN",
        "closed_by": null,
        "created_at": "2022-10-07T05:54:44+00:00",
        "updated_at": "2022-10-07T05:54:44+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 283,
        "title": "提供的DuReader-Checklist-BASELINE代码特征处理部分有问题？",
        "body": "图中tokenized_examples返回的是一个四个键的字典，这里遍历后下面划线的代码会出错，请问这里问题主要出现在哪里？\r\n![image](https://user-images.githubusercontent.com/73978694/183022623-7d201570-9645-4004-ac2b-3dcbf3579e59.png)\r\n",
        "state": "open",
        "user": "Chucy2020",
        "closed_by": null,
        "created_at": "2022-08-05T07:18:03+00:00",
        "updated_at": "2023-03-20T13:15:45+00:00",
        "closed_at": null,
        "comments_count": [
            "zhangsone"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 289,
        "title": "找不到DuConv的初始embedding文件sgns.weibo.300d.txt",
        "body": "在network.py中，单词embedding的初始文件是sgns.weibo.300d.txt，导致最后复现结果比paper少了5个点左右，但是在公开的数据集好像没有找到这个文件，请问可以给一下这个txt的链接么，谢谢。",
        "state": "open",
        "user": "Becky0909",
        "closed_by": null,
        "created_at": "2022-10-09T07:43:33+00:00",
        "updated_at": "2022-10-09T07:43:33+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 297,
        "title": "AICITY2020-track1链结失效",
        "body": "请问可以再提供一次AICITY2020-track1 Vehicle Counting的docker image链结还有label好的DatasetA链结吗？谢谢！",
        "state": "open",
        "user": "JoyChen-0108",
        "closed_by": null,
        "created_at": "2023-01-17T01:01:34+00:00",
        "updated_at": "2023-01-17T01:01:34+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 284,
        "title": "请问ACL2022-DuLeMon预计什么时候开源demo?",
        "body": "您好，最近在做对话任务方面的研究，通过读到\"Long Time No See! Open-Domain Conversation with Long-Term Persona Memory\"这篇paper链接到这个repo，请问预计什么时候开源demo提供学习？",
        "state": "open",
        "user": "jiangliqin",
        "closed_by": null,
        "created_at": "2022-08-22T01:17:44+00:00",
        "updated_at": "2023-09-25T07:33:42+00:00",
        "closed_at": null,
        "comments_count": [
            "JackieJqZHANG",
            "zlh1992"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 301,
        "title": "How to install unimo package",
        "body": "How can I install the unimo package. I need to use UnimoCRFModel. Can you mention the exact steps to install it. I could install it using pip install unimo.",
        "state": "open",
        "user": "mayanku",
        "closed_by": null,
        "created_at": "2023-02-20T09:39:13+00:00",
        "updated_at": "2023-02-20T09:39:13+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 302,
        "title": "想问问这个训练集和测试集",
        "body": "想问问经过训练后，可以直接做多轮对话的测试吗。即我在这边输入，模型输出，然后我再输入，他根据上下文再输出",
        "state": "open",
        "user": "sanwei111",
        "closed_by": null,
        "created_at": "2023-02-20T10:53:36+00:00",
        "updated_at": "2023-02-20T10:53:36+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 299,
        "title": "Graphsum environment",
        "body": "Hello,\r\nThank you for sharing code and data.\r\nCould you please specify for the Graphsum work what version of cuda, paddlepaddle, nccl and nvcc to use?\r\nI tried multiple versions and I keep running into errors like:\r\n\"The third-party dynamic library (libnccl.so) that Paddle depends on is not configured correctly. (error code is libnccl.so: cannot open shared object file: No such file or directory)\"\r\nand \r\n\"parallel_for failed: no kernel image is available for execution on the device\"\r\nThank you",
        "state": "open",
        "user": "InesArous",
        "closed_by": null,
        "created_at": "2023-01-23T18:45:15+00:00",
        "updated_at": "2024-12-05T15:48:18+00:00",
        "closed_at": null,
        "comments_count": [
            "cywuuuu"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 304,
        "title": "SSAN result.json is empty",
        "body": null,
        "state": "closed",
        "user": "XingYu131",
        "closed_by": "XingYu131",
        "created_at": "2023-02-23T06:26:35+00:00",
        "updated_at": "2023-02-25T01:56:01+00:00",
        "closed_at": "2023-02-25T01:56:01+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 306,
        "title": "text2sql baseline 训练好的模型在CSpider数据集上推理报错",
        "body": "在尝试复现text2sql的效果，Dusql和nl2sql都成功复现，在Cspider的模型上报错\r\n这是我启动脚本的命令 bash ./run.sh ./script/text2sql_main.py --mode infer          --config conf/text2sql_cspider.jsonnet          --data-root data/CSpider/preproc          --test-set data/CSpider/preproc/dev.pkl          --init-model-param output/trained_model/cspider.pdparams          --output eval/cspider_dev_infer_result.sql\r\n报错如下\r\n![$%HPNMR9ML8( IG2L1(M%%V](https://user-images.githubusercontent.com/27061950/225854025-d67ee3ab-8d3c-488a-9ede-57c8a17505ed.png)\r\n",
        "state": "closed",
        "user": "longborn",
        "closed_by": "longborn",
        "created_at": "2023-03-17T08:36:31+00:00",
        "updated_at": "2023-04-23T10:45:38+00:00",
        "closed_at": "2023-04-23T10:45:38+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 307,
        "title": "When will release PLATO-LTM code ?",
        "body": "We would like to use your work as a comparison in our research. When is the code expected to be made available? Also, would it be possible to have access to the framework used when using the English version of Persona-Chat?",
        "state": "open",
        "user": "Exe-dev",
        "closed_by": null,
        "created_at": "2023-03-30T05:36:54+00:00",
        "updated_at": "2023-03-30T05:36:54+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 309,
        "title": "Text2SQL-BASELINE安装ernie时出错",
        "body": "按照文档安装ernie：\r\n```\r\nmkdir third\r\ncd third\r\ngit clone https://github.com/PaddlePaddle/ERNIE.git\r\ncd ERNIE && git checkout develop\r\n```\r\n然后执行下面的脚本出错：\r\n```\r\nbash data/download_ernie1.0.sh\r\n```\r\n我看来一下，没有这个脚本，是不是最新的develop分支的代码结构改了？",
        "state": "closed",
        "user": "fancyerii",
        "closed_by": "fancyerii",
        "created_at": "2023-04-25T04:06:27+00:00",
        "updated_at": "2023-04-26T12:28:18+00:00",
        "closed_at": "2023-04-26T12:28:18+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 305,
        "title": "SSAN出现loss为nan",
        "body": "您好，我将SSAN训练中文数据时，刚开始训练就出现loss为nan，请问有什么解决办法吗，数据是没有问题的",
        "state": "open",
        "user": "XingYu131",
        "closed_by": null,
        "created_at": "2023-03-06T13:20:43+00:00",
        "updated_at": "2024-08-23T08:33:22+00:00",
        "closed_at": null,
        "comments_count": [
            "XingYu131",
            "catbbblack",
            "yangguoer"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 310,
        "title": "text2sql推理问题",
        "body": "在使用text2sql-baseline推理的时候出现\r\nTraceback (most recent call last):\r\n  File \"./script/text2sql_main.py\", line 277, in <module>\r\n    inference(config)\r\n  File \"./script/text2sql_main.py\", line 156, in inference\r\n    test_reader = DataLoaderClass(config, test_set, batch_size=1, shuffle=False)\r\n  File \"Research/NLP/Text2SQL-BASELINE/text2sql/dataproc/dataloader.py\", line 144, in __init__\r\n    self.dataloader = paddle.io.DataLoader.from_generator(\r\nAttributeError: type object 'DataLoader' has no attribute 'from_generator'",
        "state": "open",
        "user": "shuoshuo0",
        "closed_by": null,
        "created_at": "2023-07-25T03:17:06+00:00",
        "updated_at": "2023-07-25T03:17:06+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 308,
        "title": "Text2SQL-BASELINE 训练速度慢",
        "body": "paddlepaddle-gpu 2.3.2 ， GPU A6000,  数据集合3400左右\r\n\r\n参数使用默认（batch_size = 16）单轮次训练在2400S，跑完30个轮次需要一天左右的时间，尝试调整batch_size，32/64/128等，实际只有内存占用升高，GPU使用率并无明显提升，训练用时相差不大，该如何调整参数来提高GPU的使用率以提升训练效率？\r\n\r\n另外，数据集加载预处理也比较耗时，在资源充足的情况下无法跑满，效率较低，近3w条数据的情况下，光数据集预加载就需要耗时在15min左右！\r\n\r\n\r\n",
        "state": "open",
        "user": "funs690",
        "closed_by": null,
        "created_at": "2023-04-19T08:35:09+00:00",
        "updated_at": "2023-06-02T06:01:55+00:00",
        "closed_at": null,
        "comments_count": [
            "fancyerii",
            "funs690",
            "fancyerii",
            "yohohohoho"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 312,
        "title": "EMNLP2021-SgSum code problem",
        "body": "The paper is very enlightening, but the code runs with the following problems:\r\n\r\n[2023-08-26 18:13:33,076 INFO] Loading dataset from ../data/examples_dataset/train/train.0.json, number of examples: 98\r\n/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception.\r\n  \"The following exception is not an EOF exception.\")\r\nTraceback (most recent call last):\r\n  File \"/root/autodl-tmp/SgSum/src/networks/roberta_multigraphextsum/run_graphsum.py\", line 319, in main\r\n    eval_phase=\"train\", vocab_size=vocab_size)\r\n  File \"/root/autodl-tmp/SgSum/src/networks/roberta_multigraphextsum/run_graphsum.py\", line 499, in evaluate_train\r\n    outputs = exe.run(fetch_list=fetch_list)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/parallel_executor.py\", line 303, in run\r\n    return_numpy=return_numpy)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1167, in _run_impl\r\n    return_merged=return_merged)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 879, in _run_parallel\r\n    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()\r\npaddle.fluid.core_avx.EOFException: There is no next data. at [/paddle/paddle/fluid/operators/reader/read_op.cc:111]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/autodl-tmp/SgSum/src/run_roberta.py\", line 37, in <module>\r\n    run_multigraphsum(args)\r\n  File \"/root/autodl-tmp/SgSum/src/networks/roberta_multigraphextsum/run_graphsum.py\", line 385, in main\r\n    fluid.io.save_persistables(exe, save_path, train_program)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/io.py\", line 648, in save_persistables\r\n    filename=filename)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/io.py\", line 302, in save_vars\r\n    filename=filename)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/io.py\", line 357, in save_vars\r\n    executor.run(save_program)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1071, in run\r\n    six.reraise(*sys.exc_info())\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/six.py\", line 719, in reraise\r\n    raise value\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1066, in run\r\n    return_merged=return_merged)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1154, in _run_impl\r\n    use_program_cache=use_program_cache)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/executor.py\", line 1229, in _run_program\r\n    fetch_var_name)\r\npaddle.fluid.core_avx.EnforceNotMet: \r\n\r\n--------------------------------------------\r\nC++ Call Stacks (More useful to developers):\r\n--------------------------------------------\r\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\r\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\r\n2   paddle::framework::OperatorWithKernel::ParseInputDataType(paddle::framework::ExecutionContext const&, std::string const&, paddle::framework::proto::VarType_Type*) const\r\n3   paddle::framework::OperatorWithKernel::IndicateVarDataType(paddle::framework::ExecutionContext const&, std::string const&) const\r\n4   paddle::operators::SaveOp::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const\r\n5   paddle::framework::OperatorWithKernel::ChooseKernel(paddle::framework::RuntimeContext const&, paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n6   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&, paddle::framework::RuntimeContext*) const\r\n7   paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, paddle::platform::Place const&) const\r\n8   paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, paddle::platform::Place const&)\r\n9   paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool)\r\n10  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\r\n11  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool, bool)\r\n\r\n------------------------------------------\r\nPython Call Stacks (More useful to users):\r\n------------------------------------------\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 2610, in append_op\r\n    attrs=kwargs.get(\"attrs\", None))\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/io.py\", line 328, in save_vars\r\n    attrs={'file_path': os.path.normpath(save_file_path)})\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/io.py\", line 302, in save_vars\r\n    filename=filename)\r\n  File \"/root/miniconda3/envs/sgsum/lib/python3.7/site-packages/paddle/fluid/io.py\", line 648, in save_persistables\r\n    filename=filename)\r\n  File \"/root/autodl-tmp/SgSum/src/networks/roberta_multigraphextsum/run_graphsum.py\", line 385, in main\r\n    fluid.io.save_persistables(exe, save_path, train_program)\r\n  File \"/root/autodl-tmp/SgSum/src/run_roberta.py\", line 37, in <module>\r\n    run_multigraphsum(args)\r\n\r\n----------------------\r\nError Message Summary:\r\n----------------------\r\nInvalidArgumentError: The Tensor in the save Op's Input Variable X(reduce_sum_6.tmp_0) is not initialized.\r\n  [Hint: Expected t->IsInitialized() == true, but received t->IsInitialized():0 != true:1.] at (/paddle/paddle/fluid/framework/operator.cc:1289)\r\n  [operator < save > error]",
        "state": "open",
        "user": "Jack11486",
        "closed_by": null,
        "created_at": "2023-08-26T10:25:10+00:00",
        "updated_at": "2023-08-26T10:25:10+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 311,
        "title": "您好，请问research的lanmark模型能补个链接吗，谢谢！",
        "body": "链接：https://github.com/PaddlePaddle/Research/tree/master/CV/landmark\r\n\r\n[res152_arcmargin](https://landmark.gz.bcebos.com/res152_arcmargin.tar)\r\n[res152_arcmargin_index](https://landmark.gz.bcebos.com/res152_arcmargin_index.tar)\r\n\r\n这几个模型的链接都无法访问了。\r\n\r\n\r\n\r\n\r\n\r\n",
        "state": "open",
        "user": "yang1112git",
        "closed_by": null,
        "created_at": "2023-07-30T14:47:24+00:00",
        "updated_at": "2023-07-30T14:47:24+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 313,
        "title": "Text2SQL-BASELINE 继续训练问题",
        "body": "Text2SQL-BASELINE 已训练了30 epoches， loss 都达到了 0.1（[train] epoch 30/30 loss is 0.104724, cost 5030.63s.），后面在text2sql_dusql.jsonnet  修改 init_model_params 和 init_model_optim 为30轮次的参数再重新训练，也就相当于第31次训练，但 loss 反而变的很大（[train] epoch 1, batch 100. loss is 1035.5252058463. cost 426.66s），不连续的训练会使结果变差吗？这是为什么？",
        "state": "closed",
        "user": "mrzjl",
        "closed_by": "mrzjl",
        "created_at": "2024-04-24T08:13:29+00:00",
        "updated_at": "2024-05-17T03:11:57+00:00",
        "closed_at": "2024-05-17T03:11:57+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 314,
        "title": "ACL2022-SynCLM这个文件夹里没有代码提供吗？",
        "body": null,
        "state": "closed",
        "user": "gan0422",
        "closed_by": "gan0422",
        "created_at": "2024-04-27T03:18:21+00:00",
        "updated_at": "2024-05-10T07:43:08+00:00",
        "closed_at": "2024-05-10T07:43:07+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/Research",
        "number": 315,
        "title": "用自己的数据集训练，f1值很低",
        "body": "用自己的数据集训练了60个epoch，loss一直是nan，F1值只有0.01，请问是什么原因呢\r\n![Uploading image.png…]()\r\n\r\n",
        "state": "open",
        "user": "yangguoer",
        "closed_by": null,
        "created_at": "2024-08-23T04:19:11+00:00",
        "updated_at": "2024-08-23T08:42:27+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    }
]