[
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9b4a0a550b5422cf1d6bb46d7fde010ae738d964",
        "created_at": "2024-09-23 09:25:10 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "opt-bwk-skip-load-53",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 32,
                "deletions": 10,
                "changes": 42
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6f8ae73cd96415c50ccc301de2696aaf5481c639",
        "created_at": "2024-12-04 21:16:06 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "add-flag-to-skip-compile-59",
        "files": [
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "modified",
                "additions": 165,
                "deletions": 155,
                "changes": 320
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d8915628a941d946c0f962e628e28de5469ae690",
        "created_at": "2024-10-14 21:02:20 +0800",
        "author": "umiswing",
        "committer": "web-flow",
        "message": "Support-densemask-with-causal.-57",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/generate_kernels.py",
                "status": "modified",
                "additions": 0,
                "deletions": 2,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b459f7deb627a8e3a61649907d66da9ed87233a2",
        "created_at": "2025-03-17 20:41:11 +0800",
        "author": "jeng1220",
        "committer": "web-flow",
        "message": "bugfix-add-missing-header-cstdio-56",
        "files": [
            {
                "filename": "csrc/flash_attn/src/cuda_utils.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "749aca380794b472096d4e7ea01dd252ab0887c9",
        "created_at": "2025-06-04 11:25:23 +0800",
        "author": "hxzd5568",
        "committer": "web-flow",
        "message": "Support-hdimQK-hdimV-backward-64",
        "files": [
            {
                "filename": "csrc/flash_attn_v3/epilogue_bwd.hpp",
                "status": "modified",
                "additions": 27,
                "deletions": 17,
                "changes": 44
            },
            {
                "filename": "csrc/flash_attn_v3/flash_api.cu",
                "status": "modified",
                "additions": 10,
                "deletions": 10,
                "changes": 20
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 14,
                "deletions": 5,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn_v3/mainloop_bwd_sm80.hpp",
                "status": "modified",
                "additions": 19,
                "deletions": 9,
                "changes": 28
            },
            {
                "filename": "csrc/flash_attn_v3/mainloop_bwd_sm90_tma_gmma_ws.hpp",
                "status": "modified",
                "additions": 9,
                "deletions": 4,
                "changes": 13
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 6,
                "deletions": 6,
                "changes": 12
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6c165641f3150420b7351735ba82455ffe27d79c",
        "created_at": "2024-12-06 17:02:41 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "fix-bug-of-FA2-densemask-when-casual-True-60",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 6,
                "deletions": 4,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "21f25e86ba0765d574959b39cb370e3a43798972",
        "created_at": "2024-08-29 19:20:24 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "Revert-Flashmask-support-upend-46-50",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 5,
                "deletions": 22,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 31,
                "deletions": 88,
                "changes": 119
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 0,
                "deletions": 40,
                "changes": 40
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9741fce0ee752a6fa65acd98f3adec23e636e0c7",
        "created_at": "2024-09-23 15:36:24 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "remove-enable_mask_bypass-limit-54",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6f6cc4401ad1da519478ce4da563c732fa6fa6c7",
        "created_at": "2024-09-11 15:05:31 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "Supports-FlashMask-bidirectional-attention-has-start-row-51",
        "files": [
            {
                "filename": ".gitignore",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "modified",
                "additions": 41,
                "deletions": 53,
                "changes": 94
            },
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 17,
                "deletions": 19,
                "changes": 36
            },
            {
                "filename": "csrc/flash_attn/flash_api.cpp",
                "status": "modified",
                "additions": 4,
                "deletions": 18,
                "changes": 22
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 20,
                "changes": 20
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 26,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim224_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim224_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 16,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 16,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 16,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 35,
                "changes": 35
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 20,
                "changes": 20
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 22,
                "changes": 22
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 1636,
                "deletions": 134,
                "changes": 1770
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 69,
                "deletions": 80,
                "changes": 149
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 19,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 32,
                "changes": 32
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 27,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 16,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 27,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim224_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim224_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 23,
                "changes": 23
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 19,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 26,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 23,
                "changes": 23
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 1067,
                "deletions": 78,
                "changes": 1145
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 131,
                "deletions": 145,
                "changes": 276
            },
            {
                "filename": "csrc/flash_attn/src/generate_kernels.py",
                "status": "added",
                "additions": 121,
                "deletions": 0,
                "changes": 121
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 24,
                "deletions": 14,
                "changes": 38
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f2962ac64c743f6c604eef44425e805dd28aa3e6",
        "created_at": "2024-09-13 19:17:03 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "optimize-skip-calculation-logic-to-improve-performance-52",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 63,
                "deletions": 100,
                "changes": 163
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 159,
                "deletions": 154,
                "changes": 313
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6ea759b3ea9563b49d92f1ae0c4cb0fb26a7b365",
        "created_at": "2024-10-26 09:30:07 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "add-fa3-58",
        "files": [
            {
                "filename": ".gitignore",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": ".gitmodules",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "modified",
                "additions": 68,
                "deletions": 14,
                "changes": 82
            },
            {
                "filename": "csrc/flash_attn_v3/combine.h",
                "status": "added",
                "additions": 248,
                "deletions": 0,
                "changes": 248
            },
            {
                "filename": "csrc/flash_attn_v3/cuda_utils.cu",
                "status": "added",
                "additions": 51,
                "deletions": 0,
                "changes": 51
            },
            {
                "filename": "csrc/flash_attn_v3/cuda_utils.h",
                "status": "added",
                "additions": 35,
                "deletions": 0,
                "changes": 35
            },
            {
                "filename": "csrc/flash_attn_v3/cutlass",
                "status": "added",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn_v3/epilogue_bwd_sm90_tma.hpp",
                "status": "added",
                "additions": 275,
                "deletions": 0,
                "changes": 275
            },
            {
                "filename": "csrc/flash_attn_v3/epilogue_fwd_sm90_tma.hpp",
                "status": "added",
                "additions": 418,
                "deletions": 0,
                "changes": 418
            },
            {
                "filename": "csrc/flash_attn_v3/flash.h",
                "status": "added",
                "additions": 245,
                "deletions": 0,
                "changes": 245
            },
            {
                "filename": "csrc/flash_attn_v3/flash_api.cu",
                "status": "added",
                "additions": 773,
                "deletions": 0,
                "changes": 773
            },
            {
                "filename": "csrc/flash_attn_v3/flash_api.h",
                "status": "added",
                "additions": 135,
                "deletions": 0,
                "changes": 135
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_kernel.h",
                "status": "added",
                "additions": 310,
                "deletions": 0,
                "changes": 310
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_launch_template.h",
                "status": "added",
                "additions": 212,
                "deletions": 0,
                "changes": 212
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_postprocess_kernel.h",
                "status": "added",
                "additions": 255,
                "deletions": 0,
                "changes": 255
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_preprocess_kernel.h",
                "status": "added",
                "additions": 255,
                "deletions": 0,
                "changes": 255
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_kernel.h",
                "status": "added",
                "additions": 420,
                "deletions": 0,
                "changes": 420
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_launch_template.h",
                "status": "added",
                "additions": 543,
                "deletions": 0,
                "changes": 543
            },
            {
                "filename": "csrc/flash_attn_v3/generate_kernels.py",
                "status": "added",
                "additions": 134,
                "deletions": 0,
                "changes": 134
            },
            {
                "filename": "csrc/flash_attn_v3/kernel_traits.h",
                "status": "added",
                "additions": 1086,
                "deletions": 0,
                "changes": 1086
            },
            {
                "filename": "csrc/flash_attn_v3/mainloop_bwd_sm90_tma_gmma_ws.hpp",
                "status": "added",
                "additions": 895,
                "deletions": 0,
                "changes": 895
            },
            {
                "filename": "csrc/flash_attn_v3/mainloop_fwd_sm90_tma_gmma_ws.hpp",
                "status": "added",
                "additions": 1125,
                "deletions": 0,
                "changes": 1125
            },
            {
                "filename": "csrc/flash_attn_v3/named_barrier.hpp",
                "status": "added",
                "additions": 42,
                "deletions": 0,
                "changes": 42
            },
            {
                "filename": "csrc/flash_attn_v3/random_utils.h",
                "status": "added",
                "additions": 79,
                "deletions": 0,
                "changes": 79
            },
            {
                "filename": "csrc/flash_attn_v3/seq_len.h",
                "status": "added",
                "additions": 372,
                "deletions": 0,
                "changes": 372
            },
            {
                "filename": "csrc/flash_attn_v3/softmax.h",
                "status": "added",
                "additions": 236,
                "deletions": 0,
                "changes": 236
            },
            {
                "filename": "csrc/flash_attn_v3/static_switch.h",
                "status": "added",
                "additions": 159,
                "deletions": 0,
                "changes": 159
            },
            {
                "filename": "csrc/flash_attn_v3/tile_scheduler.hpp",
                "status": "added",
                "additions": 302,
                "deletions": 0,
                "changes": 302
            },
            {
                "filename": "csrc/flash_attn_v3/tile_scheduler_bwd.hpp",
                "status": "added",
                "additions": 93,
                "deletions": 0,
                "changes": 93
            },
            {
                "filename": "csrc/flash_attn_v3/utils.h",
                "status": "added",
                "additions": 449,
                "deletions": 0,
                "changes": 449
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "7c0f9623bc710bf1fd1a8bd17bdccc68cf2237d5",
        "created_at": "2025-03-31 14:07:51 +0800",
        "author": "umiswing",
        "committer": "web-flow",
        "message": "Update-flash-attention-3-62",
        "files": [
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "modified",
                "additions": 219,
                "deletions": 19,
                "changes": 238
            },
            {
                "filename": "csrc/flash_attn_v3/block.h",
                "status": "added",
                "additions": 94,
                "deletions": 0,
                "changes": 94
            },
            {
                "filename": "csrc/flash_attn_v3/combine.h",
                "status": "removed",
                "additions": 0,
                "deletions": 248,
                "changes": 248
            },
            {
                "filename": "csrc/flash_attn_v3/copy_sm90_bulk_reduce.hpp",
                "status": "added",
                "additions": 49,
                "deletions": 0,
                "changes": 49
            },
            {
                "filename": "csrc/flash_attn_v3/cuda_check.h",
                "status": "added",
                "additions": 19,
                "deletions": 0,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn_v3/cuda_utils.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 51,
                "changes": 51
            },
            {
                "filename": "csrc/flash_attn_v3/cuda_utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 35,
                "changes": 35
            },
            {
                "filename": "csrc/flash_attn_v3/cutlass",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn_v3/epilogue_bwd.hpp",
                "status": "added",
                "additions": 523,
                "deletions": 0,
                "changes": 523
            },
            {
                "filename": "csrc/flash_attn_v3/epilogue_bwd_sm90_tma.hpp",
                "status": "removed",
                "additions": 0,
                "deletions": 275,
                "changes": 275
            },
            {
                "filename": "csrc/flash_attn_v3/epilogue_fwd.hpp",
                "status": "added",
                "additions": 484,
                "deletions": 0,
                "changes": 484
            },
            {
                "filename": "csrc/flash_attn_v3/epilogue_fwd_sm90_tma.hpp",
                "status": "removed",
                "additions": 0,
                "deletions": 418,
                "changes": 418
            },
            {
                "filename": "csrc/flash_attn_v3/flash.h",
                "status": "modified",
                "additions": 74,
                "deletions": 103,
                "changes": 177
            },
            {
                "filename": "csrc/flash_attn_v3/flash_api.cu",
                "status": "modified",
                "additions": 502,
                "deletions": 722,
                "changes": 1224
            },
            {
                "filename": "csrc/flash_attn_v3/flash_api.h",
                "status": "modified",
                "additions": 223,
                "deletions": 121,
                "changes": 344
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_kernel_sm80.h",
                "status": "added",
                "additions": 173,
                "deletions": 0,
                "changes": 173
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_kernel_sm90.h",
                "status": "modified",
                "additions": 60,
                "deletions": 88,
                "changes": 148
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 275,
                "deletions": 110,
                "changes": 385
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_postprocess_kernel.h",
                "status": "modified",
                "additions": 85,
                "deletions": 84,
                "changes": 169
            },
            {
                "filename": "csrc/flash_attn_v3/flash_bwd_preprocess_kernel.h",
                "status": "modified",
                "additions": 36,
                "deletions": 39,
                "changes": 75
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_combine.cu",
                "status": "added",
                "additions": 13,
                "deletions": 0,
                "changes": 13
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_combine_kernel.h",
                "status": "added",
                "additions": 482,
                "deletions": 0,
                "changes": 482
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_combine_launch_template.h",
                "status": "added",
                "additions": 80,
                "deletions": 0,
                "changes": 80
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_kernel.h",
                "status": "removed",
                "additions": 0,
                "deletions": 420,
                "changes": 420
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_kernel_sm80.h",
                "status": "added",
                "additions": 214,
                "deletions": 0,
                "changes": 214
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_kernel_sm90.h",
                "status": "added",
                "additions": 456,
                "deletions": 0,
                "changes": 456
            },
            {
                "filename": "csrc/flash_attn_v3/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 192,
                "deletions": 512,
                "changes": 704
            },
            {
                "filename": "csrc/flash_attn_v3/flash_prepare_scheduler.cu",
                "status": "added",
                "additions": 124,
                "deletions": 0,
                "changes": 124
            },
            {
                "filename": "csrc/flash_attn_v3/generate_kernels.py",
                "status": "modified",
                "additions": 147,
                "deletions": 60,
                "changes": 207
            },
            {
                "filename": "csrc/flash_attn_v3/heuristics.h",
                "status": "added",
                "additions": 59,
                "deletions": 0,
                "changes": 59
            },
            {
                "filename": "csrc/flash_attn_v3/kernel_traits.h",
                "status": "removed",
                "additions": 0,
                "deletions": 1086,
                "changes": 1086
            },
            {
                "filename": "csrc/flash_attn_v3/mainloop_bwd_sm80.hpp",
                "status": "added",
                "additions": 901,
                "deletions": 0,
                "changes": 901
            },
            {
                "filename": "csrc/flash_attn_v3/mainloop_bwd_sm90_tma_gmma_ws.hpp",
                "status": "modified",
                "additions": 634,
                "deletions": 500,
                "changes": 1134
            },
            {
                "filename": "csrc/flash_attn_v3/mainloop_fwd_sm80.hpp",
                "status": "added",
                "additions": 849,
                "deletions": 0,
                "changes": 849
            },
            {
                "filename": "csrc/flash_attn_v3/mainloop_fwd_sm90_tma_gmma_ws.hpp",
                "status": "modified",
                "additions": 1500,
                "deletions": 918,
                "changes": 2418
            },
            {
                "filename": "csrc/flash_attn_v3/mask.h",
                "status": "added",
                "additions": 157,
                "deletions": 0,
                "changes": 157
            },
            {
                "filename": "csrc/flash_attn_v3/named_barrier.hpp",
                "status": "modified",
                "additions": 48,
                "deletions": 12,
                "changes": 60
            },
            {
                "filename": "csrc/flash_attn_v3/pack_gqa.h",
                "status": "added",
                "additions": 255,
                "deletions": 0,
                "changes": 255
            },
            {
                "filename": "csrc/flash_attn_v3/paged_kv.h",
                "status": "added",
                "additions": 354,
                "deletions": 0,
                "changes": 354
            },
            {
                "filename": "csrc/flash_attn_v3/random_utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 79,
                "changes": 79
            },
            {
                "filename": "csrc/flash_attn_v3/rotary.h",
                "status": "added",
                "additions": 489,
                "deletions": 0,
                "changes": 489
            },
            {
                "filename": "csrc/flash_attn_v3/seq_len.h",
                "status": "removed",
                "additions": 0,
                "deletions": 372,
                "changes": 372
            },
            {
                "filename": "csrc/flash_attn_v3/seqlen.h",
                "status": "added",
                "additions": 93,
                "deletions": 0,
                "changes": 93
            },
            {
                "filename": "csrc/flash_attn_v3/sm90_pipeline_no_cluster.hpp",
                "status": "added",
                "additions": 99,
                "deletions": 0,
                "changes": 99
            },
            {
                "filename": "csrc/flash_attn_v3/softmax.h",
                "status": "modified",
                "additions": 34,
                "deletions": 100,
                "changes": 134
            },
            {
                "filename": "csrc/flash_attn_v3/static_switch.h",
                "status": "modified",
                "additions": 145,
                "deletions": 123,
                "changes": 268
            },
            {
                "filename": "csrc/flash_attn_v3/tile_scheduler.hpp",
                "status": "modified",
                "additions": 406,
                "deletions": 109,
                "changes": 515
            },
            {
                "filename": "csrc/flash_attn_v3/tile_scheduler_bwd.hpp",
                "status": "removed",
                "additions": 0,
                "deletions": 93,
                "changes": 93
            },
            {
                "filename": "csrc/flash_attn_v3/tile_size.h",
                "status": "added",
                "additions": 73,
                "deletions": 0,
                "changes": 73
            },
            {
                "filename": "csrc/flash_attn_v3/utils.h",
                "status": "modified",
                "additions": 488,
                "deletions": 274,
                "changes": 762
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "666d5c56bba917f9f5197cb4a2fdee123f0f6c38",
        "created_at": "2024-08-09 10:28:25 +0800",
        "author": "kircle888",
        "committer": "web-flow",
        "message": "Flashmask-support-upend-46",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 22,
                "deletions": 5,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 88,
                "deletions": 31,
                "changes": 119
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 40,
                "deletions": 0,
                "changes": 40
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5fd7b3e097d9078716c63955b5481f9b0fec8200",
        "created_at": "2024-07-05 16:05:08 +0800",
        "author": "umiswing",
        "committer": "web-flow",
        "message": "Support-reduce-attention-scores.-43",
        "files": [
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "modified",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 127,
                "deletions": 0,
                "changes": 127
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 26,
                "deletions": 0,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim128_bf16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim128_fp16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim160_bf16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim160_fp16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim192_bf16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim192_fp16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim224_bf16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim224_fp16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim256_bf16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim256_fp16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim32_bf16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim32_fp16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim64_bf16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim64_fp16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim96_bf16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/hdim96_fp16_sm80.cu",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_dispatch/launch_template.h",
                "status": "added",
                "additions": 158,
                "deletions": 0,
                "changes": 158
            },
            {
                "filename": "csrc/flash_attn/src/calc_reduced_attn_scores_kernel.h",
                "status": "added",
                "additions": 324,
                "deletions": 0,
                "changes": 324
            },
            {
                "filename": "csrc/flash_attn/src/kernel_traits.h",
                "status": "modified",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ce8a8feca7f84eeec198a26d1dfa41b895bcf3da",
        "created_at": "2024-04-19 20:18:13 +0800",
        "author": "kircle888",
        "committer": "web-flow",
        "message": "Revert-build-flash-attn-whl-33-39",
        "files": [
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "modified",
                "additions": 7,
                "deletions": 47,
                "changes": 54
            },
            {
                "filename": "csrc/env_dict.py.in",
                "status": "removed",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 0,
                "deletions": 19,
                "changes": 19
            },
            {
                "filename": "csrc/setup.py",
                "status": "removed",
                "additions": 0,
                "deletions": 143,
                "changes": 143
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c9515ed29f88b08cce9a1fb972b16b119622a4b7",
        "created_at": "2024-08-28 22:44:46 +0800",
        "author": "umiswing",
        "committer": "web-flow",
        "message": "fix-bug-in-apply_sparse_mask-at-diagonal-48",
        "files": [
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4b554d00b5386b6f4f959302635cee17fb9bfa18",
        "created_at": "2024-02-26 22:46:18 +0800",
        "author": "zhangting2020",
        "committer": "web-flow",
        "message": "build-flash-attn-whl-33",
        "files": [
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "modified",
                "additions": 47,
                "deletions": 7,
                "changes": 54
            },
            {
                "filename": "csrc/env_dict.py.in",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 19,
                "deletions": 0,
                "changes": 19
            },
            {
                "filename": "csrc/setup.py",
                "status": "added",
                "additions": 143,
                "deletions": 0,
                "changes": 143
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "22b604199d911d4e155fe9e54124148c7a290263",
        "created_at": "2024-04-23 17:30:52 +0800",
        "author": "kircle888",
        "committer": "web-flow",
        "message": "Revert-Cherry-pick-Support-flash-attention-2-with-causal-masking-when-KV-s-40",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 3,
                "deletions": 5,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 5,
                "deletions": 6,
                "changes": 11
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "806cdc487fa079dc70ed48082a2efcf06b5f73d8",
        "created_at": "2024-07-23 20:01:35 +0800",
        "author": "kircle888",
        "committer": "web-flow",
        "message": "Flashmask-45",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 61,
                "deletions": 33,
                "changes": 94
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 12,
                "deletions": 6,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 16,
                "deletions": 2,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 125,
                "deletions": 17,
                "changes": 142
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 6,
                "deletions": 3,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 204,
                "deletions": 38,
                "changes": 242
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 5,
                "deletions": 4,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/mask.h",
                "status": "added",
                "additions": 127,
                "deletions": 0,
                "changes": 127
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 76,
                "deletions": 2,
                "changes": 78
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5fc132ac11e78d26471ca09e5ba0cd817c3424d8",
        "created_at": "2024-01-11 20:48:03 +0800",
        "author": "sneaxiy",
        "committer": "web-flow",
        "message": "fix-Is_equal_qk-error-34",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5341f980d349a1a566360b5c80d494d5a7b0ce9e",
        "created_at": "2024-04-10 15:05:09 +0800",
        "author": "kircle888",
        "committer": "web-flow",
        "message": "flashattn-support-stride-and-padded-varlen-37",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 394,
                "deletions": 10,
                "changes": 404
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 78,
                "deletions": 4,
                "changes": 82
            },
            {
                "filename": "csrc/flash_attn/src/block_info.h",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "86e9188702504340680d9e7bd46aebeb974b8c24",
        "created_at": "2024-04-08 11:14:51 +0800",
        "author": "Wanglongzhi2001",
        "committer": "web-flow",
        "message": "Cherry-pick-Support-flash-attention-2-with-causal-masking-when-KV-s-seq-length-is-longer-than-Q-s-seq-length.-36",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 5,
                "deletions": 3,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 6,
                "deletions": 5,
                "changes": 11
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "fd6890c7ef6e53380b9eddc0a12b5acc641eb57d",
        "created_at": "2024-01-04 00:18:42 +0800",
        "author": "sneaxiy",
        "committer": "web-flow",
        "message": "support-gqa-and-mqa-32",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 7,
                "deletions": 7,
                "changes": 14
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d98d8a36cc9b884a1f405d187a0c41caeb5144c6",
        "created_at": "2024-02-21 12:10:51 +0800",
        "author": "GuoxiaWang",
        "committer": "web-flow",
        "message": "Support-FlashAttentionWithSparseMask-35",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 28,
                "deletions": 4,
                "changes": 32
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 8,
                "deletions": 2,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 23,
                "deletions": 2,
                "changes": 25
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 45,
                "deletions": 7,
                "changes": 52
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/src/kernel_traits.h",
                "status": "modified",
                "additions": 5,
                "deletions": 3,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 36,
                "deletions": 0,
                "changes": 36
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a96f8024714455fb86a326e20c3b7f700ec50772",
        "created_at": "2023-12-08 10:07:17 +0800",
        "author": "sneaxiy",
        "committer": "web-flow",
        "message": "add-FA-deterministic-mode-30",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 10,
                "deletions": 10,
                "changes": 20
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 13,
                "deletions": 10,
                "changes": 23
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2197ddb04c1adb8aa40fa173814fa89a30ba5005",
        "created_at": "2023-12-08 09:38:12 +0800",
        "author": "sneaxiy",
        "committer": "web-flow",
        "message": "fix-SM90-compilation-error-28",
        "files": [
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "modified",
                "additions": 19,
                "deletions": 2,
                "changes": 21
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0598fa245bbfb8c4462002600864518c0e37e714",
        "created_at": "2023-11-01 18:57:08 +0800",
        "author": "AnnaTrainingG",
        "committer": "web-flow",
        "message": "Add-template-when-seqlen_q-equal-to-seqlen_k-with-casual-mask-23",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 8,
                "deletions": 5,
                "changes": 13
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 18,
                "deletions": 15,
                "changes": 33
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1f8dbad952af5d19b122fcd7ea6f04f446b5e3a3",
        "created_at": "2023-09-21 02:32:21 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Remove-unused-modification",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 8,
                "deletions": 4,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 9,
                "deletions": 9,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/kernel_traits.h",
                "status": "modified",
                "additions": 0,
                "deletions": 18,
                "changes": 18
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9ebf2af4ad53533a48da58f9ded1627cfa39ccc6",
        "created_at": "2023-09-21 05:06:54 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Remove-TODO.-Modify-comment",
        "files": [
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 2,
                "deletions": 5,
                "changes": 7
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0fa5933537dc2f1cf002d970488bfc3b46c3d58b",
        "created_at": "2023-10-27 22:53:21 +0800",
        "author": "AnnaTrainingG",
        "committer": "web-flow",
        "message": "Revert-num_splits-in-flash_bwd_kernel.h-for-large-model-21",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 9,
                "deletions": 9,
                "changes": 18
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "28676577ac99068eb49cd50759278dc3b11606ce",
        "created_at": "2023-09-20 13:03:16 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Add-a-check-macro",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 28,
                "deletions": 66,
                "changes": 94
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f939e9c301976d788173c50786120505f1ce66fe",
        "created_at": "2023-09-19 04:30:14 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Add-template-param-Is_attn_mask",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 6,
                "deletions": 5,
                "changes": 11
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 13,
                "deletions": 10,
                "changes": 23
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 8,
                "deletions": 29,
                "changes": 37
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 18,
                "deletions": 15,
                "changes": 33
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 3,
                "deletions": 9,
                "changes": 12
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8454bbbd447f82df89d2e9b821fbd2c94ee89b53",
        "created_at": "2023-09-20 13:12:44 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Untab",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 38,
                "deletions": 38,
                "changes": 76
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ec8bf4fcd00960d4718c21f75bc0a930c898e75f",
        "created_at": "2023-09-18 02:40:47 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "add-residue-to-avoid-oob-mem-access",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 9,
                "deletions": 2,
                "changes": 11
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 14,
                "deletions": 69,
                "changes": 83
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "957a73c2afc166d78dcc58c6d7eab1f5f7330869",
        "created_at": "2023-09-21 03:21:35 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Rename-mask_seq_mod_size-mask_seq_q_mod_size",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 12,
                "deletions": 12,
                "changes": 24
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b74460b385b691d881ff2d3a1adbcefdcac574a3",
        "created_at": "2023-09-22 18:44:43 +0800",
        "author": "Xreki",
        "committer": "web-flow",
        "message": "Merge-pull-request-19-from-umiswing-fa2_mask",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a3a1c27bdd2a1528a0a28e580e2cc768781e135f",
        "created_at": "2023-09-15 08:38:26 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Fix-bug-when-tiles-do-not-fit-evenly-into-seqlen",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 7,
                "deletions": 4,
                "changes": 11
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 51,
                "deletions": 9,
                "changes": 60
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 42,
                "deletions": 3,
                "changes": 45
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2e133ca051c4782b5d80d69d39cc620e6b762ad6",
        "created_at": "2023-09-13 16:53:00 +0800",
        "author": "Xreki",
        "committer": "web-flow",
        "message": "Merge-pull-request-18-from-Xreki-update_to_v2.0.8",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d85752b7c7ca30033ef9e0cab00a2518920d0bb9",
        "created_at": "2023-09-13 08:58:44 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Merge-branch-main-of-https-github.com-PaddlePaddle-flash-attention-into-fa2_mask",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "854c4df972375b32bbad636108600a533d7ef2f3",
        "created_at": "2023-09-14 11:48:21 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Add-api-for-varlen-kernel",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 20,
                "deletions": 13,
                "changes": 33
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "447c093c41cbee0b72425105f4f62477dc9d3100",
        "created_at": "2023-09-13 08:08:13 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Merge-tag-v2.0.8-into-fa2_mask",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "49d2a232e9acf730d26fb4760817f666968d32c6",
        "created_at": "2023-09-14 03:28:32 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Add-softmax_unscale-on-kernel-and-padded-api",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "67032ff8eed442eee525f2c8529cb20d165ca05b",
        "created_at": "2023-09-13 15:57:55 +0800",
        "author": "Xreki",
        "committer": "Xreki",
        "message": "Merge-branch-origin-into-update_to_v2.0.8",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c718d53b65beb026738bdc8a3a579c1a062979ee",
        "created_at": "2023-09-13 08:36:18 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Comment-out-log-to-avoid-compile-error",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d7ad81973b1673ec411bca0faeb16723ac346aff",
        "created_at": "2023-09-12 07:55:28 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Just-remove-some-log",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 0,
                "deletions": 14,
                "changes": 14
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e1564d5dabc09c047d0966efffe5d977a5607ce3",
        "created_at": "2023-09-12 12:15:14 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Merge-branch-main-of-https-github.com-PaddlePaddle-flash-attention-into-fa2_mask",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "29f691d8bcc9e3a02b68eb72587e36de5ffec000",
        "created_at": "2023-09-10 17:01:43 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Fix-buggy-tile-rule-in-fwd-and-bwd",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 14,
                "deletions": 2,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "csrc/flash_attn/src/kernel_traits.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "479ce211faab640de81ee16ef991422020287f48",
        "created_at": "2023-09-10 08:55:30 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Remove-unused-code",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 0,
                "deletions": 45,
                "changes": 45
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 0,
                "deletions": 18,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 3,
                "deletions": 7,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4c162e894841dc1d7d585a5755d1d1d9142a52a8",
        "created_at": "2023-09-05 02:35:36 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Bug-fix-fix-scale-setting-typo-for-attn-mask",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c2383fd094988d920e9e0eb71c1e485343337bcd",
        "created_at": "2023-09-09 03:29:48 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Add-gMask-tile-rule-for-bwd",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 26,
                "deletions": 5,
                "changes": 31
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 61,
                "deletions": 2,
                "changes": 63
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 30,
                "deletions": 29,
                "changes": 59
            },
            {
                "filename": "csrc/flash_attn/src/kernel_traits.h",
                "status": "modified",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 26,
                "deletions": 0,
                "changes": 26
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2286d7cea7ca8264165c16b2442b6436c43140de",
        "created_at": "2023-08-16 15:13:12 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v2.0.8",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e6b9d0d48c29f8205b440dede6a48ceb8394383f",
        "created_at": "2023-08-30 14:19:21 +0800",
        "author": "AnnaTrainingG",
        "committer": "web-flow",
        "message": "Add-num_splits-in-flash_attn-backward-api-to-support-determistic-result-17",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 21,
                "deletions": 11,
                "changes": 32
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 10,
                "deletions": 2,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c65b5106ac8098c05351d6852561b5c1eb3bc875",
        "created_at": "2023-08-16 15:11:49 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-Bwd-NaN-for-varlen-when-seqlen_q-seqlen_k-and-causal",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 4,
                "deletions": 1,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6
            },
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 33,
                "deletions": 0,
                "changes": 33
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c60851a8253257eb970e06a022c82517a8033e8c",
        "created_at": "2023-08-14 14:55:35 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v2.0.7",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "aab603af4f65cd392fc2841067c27dcc78529844",
        "created_at": "2023-08-14 14:54:26 -0700",
        "author": "tmm1",
        "committer": "web-flow",
        "message": "fix-binary-wheel-installation-when-nvcc-is-not-available-448",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 0,
                "deletions": 2,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0f7853c6a166d137b2a88ff39d868e5470a27216",
        "created_at": "2023-08-15 08:33:15 -0700",
        "author": "lxuechen",
        "committer": "web-flow",
        "message": "enable-loading-hf-llama-checkpoints-for-training-446",
        "files": [
            {
                "filename": ".gitignore",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "flash_attn/models/llama.py",
                "status": "modified",
                "additions": 100,
                "deletions": 6,
                "changes": 106
            },
            {
                "filename": "flash_attn/utils/pretrained.py",
                "status": "modified",
                "additions": 36,
                "deletions": 11,
                "changes": 47
            },
            {
                "filename": "tests/models/test_llama.py",
                "status": "modified",
                "additions": 43,
                "deletions": 25,
                "changes": 68
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "471f95f767c0f121c5faccd0b763f593cb4dde9c",
        "created_at": "2023-09-01 09:27:22 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Add-addiction-mask-support.-Tested-on-flash_attn_fwd",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 43,
                "deletions": 6,
                "changes": 49
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 85,
                "deletions": 3,
                "changes": 88
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f8dccfc90a115ce797fed7d5eaf8b066f2753d34",
        "created_at": "2023-08-14 10:27:26 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "CI-Fix-MATRIX_CUDA_VERSION-check",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "67ae6fd74b4bc99c36b2ce524cf139c35663793c",
        "created_at": "2023-08-13 16:52:48 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v2.0.6",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9c531bdc0a3404369ead182af6f8558b3e860162",
        "created_at": "2023-08-14 10:03:31 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Use-single-thread-compilation-for-cuda12.1-torch2.1-to-avoid-OOM-CI",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2ddeaa406c9b1408dcbc0051d4d02a9dc1689ebc",
        "created_at": "2023-08-13 16:48:47 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-wheel-building",
        "files": [
            {
                "filename": ".github/workflows/cuda/cu102-Linux-env.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu102-Linux.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": ".github/workflows/cuda/cu113-Linux-env.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu113-Linux.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 21,
                "changes": 21
            },
            {
                "filename": ".github/workflows/cuda/cu116-Linux-env.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu116-Linux.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 18,
                "changes": 18
            },
            {
                "filename": ".github/workflows/cuda/cu117-Linux-env.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu117-Linux.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 18,
                "changes": 18
            },
            {
                "filename": ".github/workflows/cuda/cu120-Linux-env.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 9,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu120-Linux.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 18,
                "changes": 18
            },
            {
                "filename": ".github/workflows/env.sh",
                "status": "removed",
                "additions": 0,
                "deletions": 53,
                "changes": 53
            },
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 143,
                "deletions": 147,
                "changes": 290
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 37,
                "deletions": 26,
                "changes": 63
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "3c458cff771c2c22ee5b3296f557194b62ccff53",
        "created_at": "2023-08-13 16:03:51 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Merge-branch-feature-demo-wheels-of-https-github.com-piercefreeman-flash-attention-into-piercefreeman-feature-demo-wheels",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d8ec6a2f1352c3fdccf8e993c52d75c7da39a4ce",
        "created_at": "2023-08-13 16:09:38 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Merge-branch-piercefreeman-feature-demo-wheels",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6ef3bd800e8b8104537ffa0ba4ea10306da40f42",
        "created_at": "2023-08-10 20:12:20 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Install-standard-non-wheel-package",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 12,
                "deletions": 1,
                "changes": 13
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c5e87b11e95fbebd6d79bb3f05b1f8dce4fe5f7f",
        "created_at": "2023-08-13 13:55:04 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v2.0.5",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dbd79237822c851de3594db08bfb40a3ff992954",
        "created_at": "2023-08-13 15:24:32 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Prepare-for-Cutlass-3.2",
        "files": [
            {
                "filename": "csrc/flash_attn/src/kernel_traits.h",
                "status": "modified",
                "additions": 29,
                "deletions": 17,
                "changes": 46
            },
            {
                "filename": "csrc/flash_attn/src/utils.h",
                "status": "modified",
                "additions": 11,
                "deletions": 4,
                "changes": 15
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ecc6535443c73efca91007b1a300c4b049c6c0ff",
        "created_at": "2023-08-10 19:56:24 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Remove-release-creation",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 18,
                "deletions": 18,
                "changes": 36
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "3524e13c11c7866511973a39ebfd60ff6d74f8ce",
        "created_at": "2023-08-13 13:53:17 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-to-Cutlass-3.1",
        "files": [
            {
                "filename": "csrc/cutlass",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 164,
                "deletions": 118,
                "changes": 282
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 39,
                "deletions": 30,
                "changes": 69
            },
            {
                "filename": "csrc/flash_attn/src/utils.h",
                "status": "modified",
                "additions": 19,
                "deletions": 16,
                "changes": 35
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 6,
                "deletions": 6,
                "changes": 12
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "bc6d4992f2de570969bfbc956799c67fd81c31d0",
        "created_at": "2023-08-10 19:55:52 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Build-wheel-on-each-push",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 46,
                "deletions": 44,
                "changes": 90
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "364a5b4a71203b9977def9829a5c1a6af45468c8",
        "created_at": "2023-08-10 00:04:38 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "MLP-Change-the-check-for-out_features-being-None",
        "files": [
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 10,
                "deletions": 8,
                "changes": 18
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "565615c603bc83ff0215cf62bc4d907b27041215",
        "created_at": "2023-08-10 19:54:29 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Isolate-2.0.0-cuda12",
        "files": [
            {
                "filename": ".github/workflows/cuda/cu120-Linux-env.sh",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu120-Linux.sh",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 15,
                "deletions": 3,
                "changes": 18
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b5bdb79d5e1f2f88b1ef62e86899a14f82fa079a",
        "created_at": "2023-08-06 17:31:27 +0800",
        "author": "umiswing",
        "committer": "web-flow",
        "message": "Pass-RNG-state-to-kernel-launch-params-16",
        "files": [
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "modified",
                "additions": 19,
                "deletions": 3,
                "changes": 22
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "modified",
                "additions": 7,
                "deletions": 3,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "cba96bd67fec9e7805e2681204162a0c2a4ddc4c",
        "created_at": "2023-08-04 20:49:34 +0800",
        "author": "Xreki",
        "committer": "Xreki",
        "message": "Merge-branch-main-of-https-github.com-Dao-AILab-flash-attention-into-update_repo",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4d949462efdfa062336b26abf9d026e74ee3aaf6",
        "created_at": "2023-08-04 21:23:29 +0800",
        "author": "Xreki",
        "committer": "web-flow",
        "message": "Merge-pull-request-15-from-Xreki-update_repo",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ee74a8f0f7f0ba9a97539946875405264dd9a910",
        "created_at": "2023-08-04 20:18:27 +0800",
        "author": "umiswing",
        "committer": "web-flow",
        "message": "FA2-CAPI-for-paddle-14",
        "files": [
            {
                "filename": "csrc/CMakeLists.txt",
                "status": "added",
                "additions": 120,
                "deletions": 0,
                "changes": 120
            },
            {
                "filename": "csrc/capi/flash_attn.cu",
                "status": "added",
                "additions": 710,
                "deletions": 0,
                "changes": 710
            },
            {
                "filename": "csrc/capi/flash_attn.h",
                "status": "added",
                "additions": 189,
                "deletions": 0,
                "changes": 189
            },
            {
                "filename": "csrc/flash_attn/src/cuda_utils.cu",
                "status": "added",
                "additions": 51,
                "deletions": 0,
                "changes": 51
            },
            {
                "filename": "csrc/flash_attn/src/cuda_utils.h",
                "status": "added",
                "additions": 35,
                "deletions": 0,
                "changes": 35
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/philox.cuh",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            },
            {
                "filename": "csrc/flash_attn/src/random_utils.h",
                "status": "added",
                "additions": 79,
                "deletions": 0,
                "changes": 79
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/CMakeLists.txt",
                "status": "removed",
                "additions": 0,
                "deletions": 69,
                "changes": 69
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/flash_attn_with_bias_mask.cu",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/flash_attn_with_bias_mask.h",
                "status": "modified",
                "additions": 2,
                "deletions": 64,
                "changes": 66
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/cuda_utils.cu",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e63698ce2c0e0be02f162efd1926cac57e071149",
        "created_at": "2023-07-28 08:58:49 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Add-flash-attn-1-again-to-temporarily-support",
        "files": [
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/CMakeLists.txt",
                "status": "added",
                "additions": 69,
                "deletions": 0,
                "changes": 69
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/flash_attn.cpp",
                "status": "added",
                "additions": 503,
                "deletions": 0,
                "changes": 503
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/flash_attn.h",
                "status": "added",
                "additions": 147,
                "deletions": 0,
                "changes": 147
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/flash_attn_with_bias_mask.cpp",
                "status": "added",
                "additions": 543,
                "deletions": 0,
                "changes": 543
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/fmha_api.cpp",
                "status": "added",
                "additions": 779,
                "deletions": 0,
                "changes": 779
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/cuda_utils.cpp",
                "status": "added",
                "additions": 46,
                "deletions": 0,
                "changes": 46
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/cuda_utils.h",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha.h",
                "status": "added",
                "additions": 219,
                "deletions": 0,
                "changes": 219
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha/gemm.h",
                "status": "added",
                "additions": 466,
                "deletions": 0,
                "changes": 466
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha/gmem_tile.h",
                "status": "added",
                "additions": 1139,
                "deletions": 0,
                "changes": 1139
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha/kernel_traits.h",
                "status": "added",
                "additions": 125,
                "deletions": 0,
                "changes": 125
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha/mask.h",
                "status": "added",
                "additions": 90,
                "deletions": 0,
                "changes": 90
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha/smem_tile.h",
                "status": "added",
                "additions": 1703,
                "deletions": 0,
                "changes": 1703
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha/softmax.h",
                "status": "added",
                "additions": 647,
                "deletions": 0,
                "changes": 647
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha/utils.h",
                "status": "added",
                "additions": 1249,
                "deletions": 0,
                "changes": 1249
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "added",
                "additions": 63,
                "deletions": 0,
                "changes": 63
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "added",
                "additions": 772,
                "deletions": 0,
                "changes": 772
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_block_fprop_fp16_kernel.sm80.cu",
                "status": "added",
                "additions": 90,
                "deletions": 0,
                "changes": 90
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_block_fprop_kernel_1xN.h",
                "status": "added",
                "additions": 533,
                "deletions": 0,
                "changes": 533
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_blockmask.h",
                "status": "added",
                "additions": 57,
                "deletions": 0,
                "changes": 57
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_bwd_hdim128.cu",
                "status": "added",
                "additions": 12,
                "deletions": 0,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_bwd_hdim32.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_bwd_hdim64.cu",
                "status": "added",
                "additions": 31,
                "deletions": 0,
                "changes": 31
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_bwd_launch_template.h",
                "status": "added",
                "additions": 115,
                "deletions": 0,
                "changes": 115
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_bwd_with_mask_bias_hdim128.cu",
                "status": "added",
                "additions": 12,
                "deletions": 0,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_bwd_with_mask_bias_hdim32.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_bwd_with_mask_bias_hdim64.cu",
                "status": "added",
                "additions": 30,
                "deletions": 0,
                "changes": 30
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_bwd_with_mask_bias_launch_template.h",
                "status": "added",
                "additions": 61,
                "deletions": 0,
                "changes": 61
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "added",
                "additions": 1567,
                "deletions": 0,
                "changes": 1567
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fprop_kernel_1xN.h",
                "status": "added",
                "additions": 1185,
                "deletions": 0,
                "changes": 1185
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fwd_hdim128.cu",
                "status": "added",
                "additions": 12,
                "deletions": 0,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fwd_hdim32.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fwd_hdim64.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fwd_launch_template.h",
                "status": "added",
                "additions": 92,
                "deletions": 0,
                "changes": 92
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fwd_with_mask_bias_hdim128.cu",
                "status": "added",
                "additions": 26,
                "deletions": 0,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fwd_with_mask_bias_hdim32.cu",
                "status": "added",
                "additions": 21,
                "deletions": 0,
                "changes": 21
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fwd_with_mask_bias_hdim64.cu",
                "status": "added",
                "additions": 29,
                "deletions": 0,
                "changes": 29
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_fwd_with_mask_bias_launch_template.h",
                "status": "added",
                "additions": 68,
                "deletions": 0,
                "changes": 68
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_kernel.h",
                "status": "added",
                "additions": 78,
                "deletions": 0,
                "changes": 78
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/fmha_utils.h",
                "status": "added",
                "additions": 100,
                "deletions": 0,
                "changes": 100
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/philox.cuh",
                "status": "added",
                "additions": 157,
                "deletions": 0,
                "changes": 157
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/random_utils.h",
                "status": "added",
                "additions": 70,
                "deletions": 0,
                "changes": 70
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/static_switch.h",
                "status": "added",
                "additions": 62,
                "deletions": 0,
                "changes": 62
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/utils.cu",
                "status": "added",
                "additions": 51,
                "deletions": 0,
                "changes": 51
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/src/utils.h",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5d7dbbae3646a4829027dd7f3c957fe59714218c",
        "created_at": "2023-07-28 10:48:09 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Add-cutlass2-for-flash_attn_with_bias_mask",
        "files": [
            {
                "filename": ".gitmodules",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn_with_bias_and_mask/cutlass",
                "status": "added",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c585eb3a22b6686f305f28579cce781da66f78ea",
        "created_at": "2023-08-02 20:25:31 +0800",
        "author": "Xreki",
        "committer": "web-flow",
        "message": "Merge-pull-request-12-from-umiswing-bump_to_fa2",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d30f2e1cd50185c98ed88c0684b4a603f15bee37",
        "created_at": "2023-08-01 09:01:07 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v2.0.4",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e700b350dbf886d3354da1c5c16c8f61cc68f49f",
        "created_at": "2023-07-28 08:45:14 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Remove-flash_attn-to-avoid-conflict",
        "files": [
            {
                "filename": ".gitmodules",
                "status": "modified",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/CMakeLists.txt",
                "status": "removed",
                "additions": 0,
                "deletions": 69,
                "changes": 69
            },
            {
                "filename": "csrc/flash_attn/cutlass",
                "status": "removed",
                "additions": 0,
                "deletions": 1,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/flash_attn.cpp",
                "status": "removed",
                "additions": 0,
                "deletions": 503,
                "changes": 503
            },
            {
                "filename": "csrc/flash_attn/flash_attn.h",
                "status": "removed",
                "additions": 0,
                "deletions": 147,
                "changes": 147
            },
            {
                "filename": "csrc/flash_attn/flash_attn_with_bias_mask.cpp",
                "status": "removed",
                "additions": 0,
                "deletions": 543,
                "changes": 543
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "removed",
                "additions": 0,
                "deletions": 779,
                "changes": 779
            },
            {
                "filename": "csrc/flash_attn/src/cuda_utils.cpp",
                "status": "removed",
                "additions": 0,
                "deletions": 46,
                "changes": 46
            },
            {
                "filename": "csrc/flash_attn/src/cuda_utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 11,
                "changes": 11
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "removed",
                "additions": 0,
                "deletions": 219,
                "changes": 219
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gemm.h",
                "status": "removed",
                "additions": 0,
                "deletions": 466,
                "changes": 466
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "removed",
                "additions": 0,
                "deletions": 1139,
                "changes": 1139
            },
            {
                "filename": "csrc/flash_attn/src/fmha/kernel_traits.h",
                "status": "removed",
                "additions": 0,
                "deletions": 125,
                "changes": 125
            },
            {
                "filename": "csrc/flash_attn/src/fmha/mask.h",
                "status": "removed",
                "additions": 0,
                "deletions": 90,
                "changes": 90
            },
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "removed",
                "additions": 0,
                "deletions": 1703,
                "changes": 1703
            },
            {
                "filename": "csrc/flash_attn/src/fmha/softmax.h",
                "status": "removed",
                "additions": 0,
                "deletions": 647,
                "changes": 647
            },
            {
                "filename": "csrc/flash_attn/src/fmha/utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 1249,
                "changes": 1249
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 63,
                "changes": 63
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "removed",
                "additions": 0,
                "deletions": 772,
                "changes": 772
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 90,
                "changes": 90
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "removed",
                "additions": 0,
                "deletions": 533,
                "changes": 533
            },
            {
                "filename": "csrc/flash_attn/src/fmha_blockmask.h",
                "status": "removed",
                "additions": 0,
                "deletions": 57,
                "changes": 57
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim128.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 12,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim32.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim64.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 31,
                "changes": 31
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_launch_template.h",
                "status": "removed",
                "additions": 0,
                "deletions": 115,
                "changes": 115
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim128.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 12,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim32.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim64.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 30,
                "changes": 30
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_launch_template.h",
                "status": "removed",
                "additions": 0,
                "deletions": 61,
                "changes": 61
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "removed",
                "additions": 0,
                "deletions": 1567,
                "changes": 1567
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "removed",
                "additions": 0,
                "deletions": 1185,
                "changes": 1185
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim128.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 12,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim32.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim64.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_launch_template.h",
                "status": "removed",
                "additions": 0,
                "deletions": 92,
                "changes": 92
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim128.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 26,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim32.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 21,
                "changes": 21
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim64.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 29,
                "changes": 29
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_launch_template.h",
                "status": "removed",
                "additions": 0,
                "deletions": 68,
                "changes": 68
            },
            {
                "filename": "csrc/flash_attn/src/fmha_kernel.h",
                "status": "removed",
                "additions": 0,
                "deletions": 78,
                "changes": 78
            },
            {
                "filename": "csrc/flash_attn/src/fmha_utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 100,
                "changes": 100
            },
            {
                "filename": "csrc/flash_attn/src/philox.cuh",
                "status": "removed",
                "additions": 0,
                "deletions": 157,
                "changes": 157
            },
            {
                "filename": "csrc/flash_attn/src/random_utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 70,
                "changes": 70
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "removed",
                "additions": 0,
                "deletions": 62,
                "changes": 62
            },
            {
                "filename": "csrc/flash_attn/src/utils.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 51,
                "changes": 51
            },
            {
                "filename": "csrc/flash_attn/src/utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 15,
                "changes": 15
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1c41d2b0e5021907374e9509250ad7a22e5693bd",
        "created_at": "2023-08-01 09:00:10 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-race-condition-in-bwd-overwriting-sK",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 5,
                "deletions": 3,
                "changes": 8
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 20,
                "deletions": 15,
                "changes": 35
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a4e5d1edddd67f9299fba510732b3c67dcab7219",
        "created_at": "2023-07-31 17:49:23 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v2.0.3",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b6b03f793bc10c2ac861f6cfaf62c6ed6c6aefb5",
        "created_at": "2023-08-02 06:48:15 +0000",
        "author": "umiswing",
        "committer": "umiswing",
        "message": "Merge-commit-b252072409e69c25f2b9d473cc534e49b24decd2-into-bump_to_fa2",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8f4cd4c16bc3143b6a2aa3cecbcc8dc8d89dff9e",
        "created_at": "2023-07-31 17:47:03 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Fix-docstring-about-Q-nheads-being-divisible-by-KV-nheads",
        "files": [
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a4f148b6abe077cd387e69e5caae45d63a76bb24",
        "created_at": "2023-07-31 17:46:34 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-masking-of-bwd-when-seqlen-is-not-divisible-by-128",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 37,
                "deletions": 26,
                "changes": 63
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "modified",
                "additions": 9,
                "deletions": 9,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "modified",
                "additions": 5,
                "deletions": 2,
                "changes": 7
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 94,
                "deletions": 0,
                "changes": 94
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "184b992dcb2a0890adaa19eb9b541c3e4f9d2a08",
        "created_at": "2023-07-28 15:52:48 -1000",
        "author": "tridao",
        "committer": "tridao",
        "message": "GPT-Implement-parallel-LLaMa",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 15,
                "deletions": 2,
                "changes": 17
            },
            {
                "filename": "tests/models/test_falcon.py",
                "status": "modified",
                "additions": 0,
                "deletions": 2,
                "changes": 2
            },
            {
                "filename": "tests/models/test_llama.py",
                "status": "modified",
                "additions": 161,
                "deletions": 39,
                "changes": 200
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "60499abcfda1fabd48e1b97341f4f888c66991a3",
        "created_at": "2023-07-28 00:26:52 -1000",
        "author": "tridao",
        "committer": "tridao",
        "message": "Benchmark-Add-script-to-benchmark-FlashAttention",
        "files": [
            {
                "filename": "benchmarks/benchmark_flash_attention.py",
                "status": "modified",
                "additions": 142,
                "deletions": 44,
                "changes": 186
            },
            {
                "filename": "flash_attn/utils/benchmark.py",
                "status": "modified",
                "additions": 45,
                "deletions": 27,
                "changes": 72
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "840f7925a0a82aff7e981ee1a28f660623e94a93",
        "created_at": "2023-07-28 12:26:29 -1000",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Fix-mention-of-MQA-GQA-in-qkvpacked-functions",
        "files": [
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 4,
                "deletions": 6,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4c98d0b41f38ee638a979064856ae06fc1aec8b6",
        "created_at": "2023-07-26 09:39:37 -1000",
        "author": "tridao",
        "committer": "tridao",
        "message": "MLP-Edit-ParallelGatedMlp",
        "files": [
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 18,
                "deletions": 13,
                "changes": 31
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "32a953f4860511bd1dbf6ef3b92939869c8c7b3f",
        "created_at": "2023-07-28 02:46:03 -0700",
        "author": "ksivaman",
        "committer": "web-flow",
        "message": "Request-for-v2.0.2-388",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a03f6f8e9ea6692568d98411b464034c22304afd",
        "created_at": "2023-07-27 16:11:34 -0700",
        "author": "ksivaman",
        "committer": "web-flow",
        "message": "Enable-CUDA-graphs-386",
        "files": [
            {
                "filename": "csrc/flash_attn/flash_api.cpp",
                "status": "modified",
                "additions": 36,
                "deletions": 14,
                "changes": 50
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 4,
                "deletions": 6,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "modified",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 24,
                "deletions": 62,
                "changes": 86
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8ee62efca3809894df380aa302516de483a14335",
        "created_at": "2023-07-27 03:14:15 +0800",
        "author": "eggiter",
        "committer": "web-flow",
        "message": "Implement-ParallelGatedMlp-251",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 11,
                "deletions": 3,
                "changes": 14
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 27,
                "deletions": 2,
                "changes": 29
            },
            {
                "filename": "tests/modules/test_mlp_parallel.py",
                "status": "added",
                "additions": 114,
                "deletions": 0,
                "changes": 114
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8e9820a55bc7d610d942cf5453838197869393e2",
        "created_at": "2023-07-26 07:16:10 -1000",
        "author": "tridao",
        "committer": "tridao",
        "message": "Rotary-Fix-tests-when-loading-state-dict-with-rotary-inv_freqs",
        "files": [
            {
                "filename": "tests/models/test_gptj.py",
                "status": "modified",
                "additions": 2,
                "deletions": 4,
                "changes": 6
            },
            {
                "filename": "tests/models/test_llama.py",
                "status": "modified",
                "additions": 3,
                "deletions": 5,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "56ccaff12678868c773cb9d4af7b309763173a7b",
        "created_at": "2023-07-26 07:22:22 -1000",
        "author": "tridao",
        "committer": "tridao",
        "message": "GPT-Add-LLaMa-13B-to-test",
        "files": [
            {
                "filename": "tests/models/test_llama.py",
                "status": "modified",
                "additions": 4,
                "deletions": 3,
                "changes": 7
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2a2a3c4bfdaa9d078c8421b516ae7536e6275312",
        "created_at": "2023-07-23 12:31:55 -1000",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Add-test-for-randomness",
        "files": [
            {
                "filename": "tests/ops/test_dropout_layer_norm.py",
                "status": "modified",
                "additions": 26,
                "deletions": 0,
                "changes": 26
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b252072409e69c25f2b9d473cc534e49b24decd2",
        "created_at": "2023-07-23 12:33:42 -1000",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v2.0.1",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "767b71ccf0664ea382135f039212f087afc4c682",
        "created_at": "2023-07-23 18:05:13 -0400",
        "author": "jlamypoirier",
        "committer": "web-flow",
        "message": "Fix-random-state-for-dropout_layer_norm-315",
        "files": [
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 10,
                "deletions": 10,
                "changes": 20
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "684196b8c55d0cf04d1f657dc3d96e8982f7747b",
        "created_at": "2023-07-23 08:21:45 +0100",
        "author": "jamaliki",
        "committer": "web-flow",
        "message": "Allow-rotary-embeddings-for-Bert-363",
        "files": [
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 7,
                "deletions": 2,
                "changes": 9
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d38357dd2fb4ed92bd8e4156f6c0cff8ddc487e4",
        "created_at": "2023-07-23 10:29:23 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "GPT-Implement-Falcon",
        "files": [
            {
                "filename": "flash_attn/models/falcon.py",
                "status": "added",
                "additions": 122,
                "deletions": 0,
                "changes": 122
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "tests/models/test_falcon.py",
                "status": "added",
                "additions": 370,
                "deletions": 0,
                "changes": 370
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "425dbcb6c6f570346a927ed49fb260bb155adcef",
        "created_at": "2023-07-23 00:06:58 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "MHA-Implement-MQA-GQA",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 80,
                "deletions": 13,
                "changes": 93
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 47,
                "deletions": 14,
                "changes": 61
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 209,
                "deletions": 121,
                "changes": 330
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "tests/models/test_gptj.py",
                "status": "modified",
                "additions": 0,
                "deletions": 1,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ec9f74ab9ac9f2110d747f0e7c5e01e257c41d78",
        "created_at": "2023-07-22 23:52:42 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Rotary-Don-t-store-inv_freq-in-state_dict",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 0,
                "deletions": 1,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "cbf982afa5e3ac03d49e6738e356cbac1c9edf41",
        "created_at": "2023-07-23 03:21:30 -0400",
        "author": "iantimmis",
        "committer": "web-flow",
        "message": "README-syntax-highlighting-365",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 10,
                "deletions": 8,
                "changes": 18
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a157cc8c9bf4460da70243bc100a363b5daad9ba",
        "created_at": "2023-07-22 23:47:01 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "FT-Implement-MQA-GQA",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention.h",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_template.hpp",
                "status": "modified",
                "additions": 27,
                "deletions": 19,
                "changes": 46
            },
            {
                "filename": "csrc/ft_attention/ft_attention.cpp",
                "status": "modified",
                "additions": 18,
                "deletions": 10,
                "changes": 28
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b3177dfaf696ee522a495bcb48b88d32167aa17f",
        "created_at": "2023-07-21 17:29:10 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "GPT-Enable-FlashAttention-for-GPT-J",
        "files": [
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "tests/models/test_gptj.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "75e334d407029be25a4665a49c64d59acd45448f",
        "created_at": "2023-07-22 23:45:51 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "MLP-Add-ParallelMLP",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 9,
                "deletions": 6,
                "changes": 15
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 30,
                "deletions": 0,
                "changes": 30
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6fc1e07da22a344b6f0927b9e21e0eafb31fda99",
        "created_at": "2023-07-21 16:34:19 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Block-Re-enable-DropPath",
        "files": [
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 17,
                "deletions": 19,
                "changes": 36
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9ee0ff1d9b6a99630e2a6868b9291dfa32d35abd",
        "created_at": "2023-07-20 17:39:00 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-using-dO-stride-for-O-which-can-cause-memory-error-in-bwd",
        "files": [
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2dd87d060958a9de8d86f4437254cb22b073aff1",
        "created_at": "2023-07-20 19:41:24 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-360-from-chuanli11-fix-dockerfile",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "31ae2488e62bbe7b2470c3899c06841da75c63fc",
        "created_at": "2023-07-19 04:27:07 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-343-from-danthe3rd-if_constexpr",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "30fd8c17d8253310ff3a69636e5c9ce8982e3cf5",
        "created_at": "2023-07-20 16:40:15 +0000",
        "author": "chuanli11",
        "committer": "chuanli11",
        "message": "remove-checkout-v2.0.0.post1-from-dockerfile",
        "files": [
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b8020d73c9e068665586989883083a4a5429a443",
        "created_at": "2023-07-19 17:25:37 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-348-from-eltociear-patch-2",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dfc60f6b7d9a2bd94ffa95ae3f0f7d3c4fb4efcb",
        "created_at": "2023-07-20 01:16:16 +0900",
        "author": "eltociear",
        "committer": "web-flow",
        "message": "LayerNorm-Fix-typo-in-ln_api.cpp",
        "files": [
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "538d570c96cc88030cfc68d538f0fc57be8c72a7",
        "created_at": "2023-07-19 08:04:55 +0000",
        "author": null,
        "committer": null,
        "message": "Fix-compile-error-on-MSVC",
        "files": [
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 50,
                "deletions": 49,
                "changes": 99
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d1a3b52f17b914c93bf740654387b566a7330687",
        "created_at": "2023-07-17 23:17:47 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-instruction-about-limiting-number-of-ninja-jobs",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4f285b354796fb17df8636485b9a04df3ebbb7dc",
        "created_at": "2023-07-17 05:26:11 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "FlashAttention-2-release",
        "files": [
            {
                "filename": ".gitmodules",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "AUTHORS",
                "status": "modified",
                "additions": 1,
                "deletions": 2,
                "changes": 3
            },
            {
                "filename": "MANIFEST.in",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 119,
                "deletions": 151,
                "changes": 270
            },
            {
                "filename": "assets/flash2_a100_fwd_bwd_benchmark.png",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/flash2_h100_fwd_bwd_benchmark.png",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/flashattention_logo.png",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "benchmarks/benchmark_causal.py",
                "status": "modified",
                "additions": 145,
                "deletions": 21,
                "changes": 166
            },
            {
                "filename": "benchmarks/benchmark_flash_attention.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/cutlass",
                "status": "added",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/cutlass",
                "status": "removed",
                "additions": 0,
                "deletions": 1,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/flash_api.cpp",
                "status": "added",
                "additions": 912,
                "deletions": 0,
                "changes": 912
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "removed",
                "additions": 0,
                "deletions": 796,
                "changes": 796
            },
            {
                "filename": "csrc/flash_attn/src/block_info.h",
                "status": "added",
                "additions": 41,
                "deletions": 0,
                "changes": 41
            },
            {
                "filename": "csrc/flash_attn/src/flash.h",
                "status": "added",
                "additions": 141,
                "deletions": 0,
                "changes": 141
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu",
                "status": "added",
                "additions": 20,
                "deletions": 0,
                "changes": 20
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu",
                "status": "added",
                "additions": 26,
                "deletions": 0,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim160_bf16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim160_fp16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim192_bf16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim192_fp16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim224_bf16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim224_fp16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim256_bf16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim256_fp16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu",
                "status": "added",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu",
                "status": "added",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu",
                "status": "added",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu",
                "status": "added",
                "additions": 35,
                "deletions": 0,
                "changes": 35
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu",
                "status": "added",
                "additions": 20,
                "deletions": 0,
                "changes": 20
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu",
                "status": "added",
                "additions": 22,
                "deletions": 0,
                "changes": 22
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_kernel.h",
                "status": "added",
                "additions": 1519,
                "deletions": 0,
                "changes": 1519
            },
            {
                "filename": "csrc/flash_attn/src/flash_bwd_launch_template.h",
                "status": "added",
                "additions": 355,
                "deletions": 0,
                "changes": 355
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu",
                "status": "added",
                "additions": 19,
                "deletions": 0,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu",
                "status": "added",
                "additions": 32,
                "deletions": 0,
                "changes": 32
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu",
                "status": "added",
                "additions": 27,
                "deletions": 0,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu",
                "status": "added",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu",
                "status": "added",
                "additions": 27,
                "deletions": 0,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim224_bf16_sm80.cu",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim224_fp16_sm80.cu",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim256_bf16_sm80.cu",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim256_fp16_sm80.cu",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu",
                "status": "added",
                "additions": 23,
                "deletions": 0,
                "changes": 23
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu",
                "status": "added",
                "additions": 19,
                "deletions": 0,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu",
                "status": "added",
                "additions": 26,
                "deletions": 0,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu",
                "status": "added",
                "additions": 23,
                "deletions": 0,
                "changes": 23
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_kernel.h",
                "status": "added",
                "additions": 576,
                "deletions": 0,
                "changes": 576
            },
            {
                "filename": "csrc/flash_attn/src/flash_fwd_launch_template.h",
                "status": "added",
                "additions": 251,
                "deletions": 0,
                "changes": 251
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "removed",
                "additions": 0,
                "deletions": 211,
                "changes": 211
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gemm.h",
                "status": "removed",
                "additions": 0,
                "deletions": 451,
                "changes": 451
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "removed",
                "additions": 0,
                "deletions": 555,
                "changes": 555
            },
            {
                "filename": "csrc/flash_attn/src/fmha/kernel_traits.h",
                "status": "removed",
                "additions": 0,
                "deletions": 116,
                "changes": 116
            },
            {
                "filename": "csrc/flash_attn/src/fmha/mask.h",
                "status": "removed",
                "additions": 0,
                "deletions": 90,
                "changes": 90
            },
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "removed",
                "additions": 0,
                "deletions": 1703,
                "changes": 1703
            },
            {
                "filename": "csrc/flash_attn/src/fmha/softmax.h",
                "status": "removed",
                "additions": 0,
                "deletions": 607,
                "changes": 607
            },
            {
                "filename": "csrc/flash_attn/src/fmha/utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 1215,
                "changes": 1215
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 64,
                "changes": 64
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "removed",
                "additions": 0,
                "deletions": 772,
                "changes": 772
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 90,
                "changes": 90
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "removed",
                "additions": 0,
                "deletions": 533,
                "changes": 533
            },
            {
                "filename": "csrc/flash_attn/src/fmha_blockmask.h",
                "status": "removed",
                "additions": 0,
                "deletions": 57,
                "changes": 57
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim128.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 12,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim32.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim64.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 30,
                "changes": 30
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_launch_template.h",
                "status": "removed",
                "additions": 0,
                "deletions": 114,
                "changes": 114
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "removed",
                "additions": 0,
                "deletions": 841,
                "changes": 841
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "removed",
                "additions": 0,
                "deletions": 707,
                "changes": 707
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim128.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 12,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim32.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim64.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 17,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_launch_template.h",
                "status": "removed",
                "additions": 0,
                "deletions": 91,
                "changes": 91
            },
            {
                "filename": "csrc/flash_attn/src/fmha_kernel.h",
                "status": "removed",
                "additions": 0,
                "deletions": 78,
                "changes": 78
            },
            {
                "filename": "csrc/flash_attn/src/fmha_utils.h",
                "status": "removed",
                "additions": 0,
                "deletions": 100,
                "changes": 100
            },
            {
                "filename": "csrc/flash_attn/src/kernel_traits.h",
                "status": "added",
                "additions": 366,
                "deletions": 0,
                "changes": 366
            },
            {
                "filename": "csrc/flash_attn/src/kernel_traits_sm90.h",
                "status": "added",
                "additions": 159,
                "deletions": 0,
                "changes": 159
            },
            {
                "filename": "csrc/flash_attn/src/philox.cuh",
                "status": "modified",
                "additions": 104,
                "deletions": 96,
                "changes": 200
            },
            {
                "filename": "csrc/flash_attn/src/softmax.h",
                "status": "added",
                "additions": 272,
                "deletions": 0,
                "changes": 272
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 51,
                "deletions": 26,
                "changes": 77
            },
            {
                "filename": "csrc/flash_attn/src/utils.h",
                "status": "added",
                "additions": 388,
                "deletions": 0,
                "changes": 388
            },
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 8,
                "deletions": 1,
                "changes": 9
            },
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "removed",
                "additions": 0,
                "deletions": 101,
                "changes": 101
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 367,
                "deletions": 208,
                "changes": 575
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 19,
                "deletions": 17,
                "changes": 36
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 17,
                "deletions": 56,
                "changes": 73
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 42,
                "deletions": 18,
                "changes": 60
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 462,
                "deletions": 641,
                "changes": 1103
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b4cc152e97cec3fb608288abdc5fe48daaed32e2",
        "created_at": "2023-07-17 21:54:44 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Make-sure-dout-is-contiguous",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 10,
                "deletions": 12,
                "changes": 22
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6d48e14a6c2f551db96f0badc658a6279a929df3",
        "created_at": "2023-07-17 03:16:40 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v1.0.9",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "01c40dacc45c91f80b74d4a29f91a44eddd64011",
        "created_at": "2023-07-15 20:36:48 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-313-from-philipturner-patch-1",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4dbcaa144378c1461f0e64420c59fcdd1cd43409",
        "created_at": "2023-07-15 08:40:46 -0400",
        "author": "philipturner",
        "committer": "web-flow",
        "message": "Update-usage.md",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "905c13a2d9a845e9ac8bd597e30a19270b058382",
        "created_at": "2023-07-15 01:55:43 -0400",
        "author": "philipturner",
        "committer": "web-flow",
        "message": "Update-usage.md",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "70ab266a5659b3024d88bc1ea58386bc2448779b",
        "created_at": "2023-07-08 12:01:07 +0200",
        "author": "proger",
        "committer": "proger",
        "message": "rotary-update-cos-sin-cache-when-switching-from-inference-mode",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "72ad03eaa661f6bf3a14c855316c27fbab4f8f4c",
        "created_at": "2023-07-08 12:16:51 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-299-from-proger-rotary-inference-mode",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6ababeb7dba9277ce6a4819e97da28715daee274",
        "created_at": "2023-07-15 01:34:24 -0400",
        "author": "philipturner",
        "committer": "web-flow",
        "message": "Update-usage.md",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2800efc71fbd56436829eafad90c795a4fe6a73f",
        "created_at": "2023-07-06 15:33:33 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "FT-rotary_cos-sin-should-have-batch_size-dimension",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_template.hpp",
                "status": "modified",
                "additions": 12,
                "deletions": 4,
                "changes": 16
            },
            {
                "filename": "csrc/ft_attention/ft_attention.cpp",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d2f4324f4c56e017fbf22dc421943793a8ca6c3b",
        "created_at": "2023-07-04 14:52:42 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Make-sure-memory-addresses-are-aligned-to-16-bytes",
        "files": [
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 39,
                "deletions": 31,
                "changes": 70
            },
            {
                "filename": "tests/ops/test_dropout_layer_norm.py",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e8a0b4acddeff1a85d7d0ad7273ea0f2aeab6143",
        "created_at": "2023-07-02 17:23:52 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Doc-Change-total-total_q",
        "files": [
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "3a9bfd076f98746c73362328958dbc68d145fbec",
        "created_at": "2023-07-03 09:41:04 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "FT-rotary_cos-sin-should-have-shape-dim-instead-of-seqlen-dim",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_utils.h",
                "status": "modified",
                "additions": 34,
                "deletions": 34,
                "changes": 68
            },
            {
                "filename": "csrc/ft_attention/ft_attention.cpp",
                "status": "modified",
                "additions": 3,
                "deletions": 4,
                "changes": 7
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9610114ce8fc16923b09515d2c2f8c1ac7459f0a",
        "created_at": "2023-07-02 17:04:54 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v1.0.8",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a5d8714c2699c5755b201f717577c7fb31389e06",
        "created_at": "2023-07-02 16:41:47 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Build-Remove-pyproject.toml",
        "files": [
            {
                "filename": "pyproject.toml",
                "status": "removed",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "62e981446609156b0c5d2c2a54eb628cce83e66d",
        "created_at": "2023-07-02 16:39:39 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Rotary-Make-sure-frequency-calculation-is-in-fp32",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention.h",
                "status": "modified",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_template.hpp",
                "status": "modified",
                "additions": 26,
                "deletions": 7,
                "changes": 33
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_utils.h",
                "status": "modified",
                "additions": 236,
                "deletions": 5,
                "changes": 241
            },
            {
                "filename": "csrc/ft_attention/ft_attention.cpp",
                "status": "modified",
                "additions": 59,
                "deletions": 4,
                "changes": 63
            },
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 48,
                "deletions": 19,
                "changes": 67
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 14,
                "deletions": 4,
                "changes": 18
            },
            {
                "filename": "tests/models/test_llama.py",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9af165c38920bd18fc066e193383903e6ecff451",
        "created_at": "2023-06-07 17:26:13 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Clean-setup.py-imports",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 3,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "eb812c205b4a4327230f5e75407d06e75917417b",
        "created_at": "2023-06-07 17:20:13 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Remove-builder-project",
        "files": [
            {
                "filename": "flash_attn_builder/README.md",
                "status": "removed",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            },
            {
                "filename": "flash_attn_builder/flash_attn_builder/__init__.py",
                "status": "removed",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn_builder/flash_attn_builder/main.py",
                "status": "removed",
                "additions": 0,
                "deletions": 54,
                "changes": 54
            },
            {
                "filename": "flash_attn_builder/pyproject.toml",
                "status": "removed",
                "additions": 0,
                "deletions": 15,
                "changes": 15
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6c730dc8c669ffd140ed90366cd96aa031a08594",
        "created_at": "2023-06-07 17:07:14 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Bump-version",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "494b2aa48657edb55eb9f5907d5e980014d9dbdc",
        "created_at": "2023-06-04 06:14:05 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Add-notes-to-github-action-workflow",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 6,
                "deletions": 3,
                "changes": 9
            },
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn_builder/README.md",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "flash_attn_builder/flash_attn_builder/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn_builder/flash_attn_builder/main.py",
                "status": "added",
                "additions": 54,
                "deletions": 0,
                "changes": 54
            },
            {
                "filename": "flash_attn_builder/pyproject.toml",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "pyproject.toml",
                "status": "removed",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 31,
                "deletions": 15,
                "changes": 46
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8d60c373e4ed0075baa4c597891ffd9fb576752c",
        "created_at": "2023-06-03 20:26:45 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Add-torch-dependency-to-final-build",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1848d0004f4bf698b908db871db0a22666d2e311",
        "created_at": "2023-06-03 19:10:47 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Exclude-cuda-erroring-builds",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 27,
                "deletions": 23,
                "changes": 50
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ac543b0e8d0d5f30e6ce02411f860995127ca013",
        "created_at": "2023-06-02 22:47:29 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Full-version-matrix",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 8,
                "deletions": 6,
                "changes": 14
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "84009fcc66fe7a9d777f3b3ec49277ae704656b8",
        "created_at": "2023-06-03 09:51:13 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Exclude-additional-disallowed-matrix-params",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a372e2be1bd970956bd9b2b8e84f23b7e86e2a4a",
        "created_at": "2023-06-02 19:19:49 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Add-CUDA-11.7",
        "files": [
            {
                "filename": ".github/workflows/cuda/cu116-Linux.sh",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": ".github/workflows/cuda/cu117-Linux-env.sh",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu117-Linux.sh",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 7,
                "deletions": 4,
                "changes": 11
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "18e100d312b9fe04079d993aebb2b68dd145daa3",
        "created_at": "2023-06-02 19:01:44 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Release-is-actually-unsupported",
        "files": [
            {
                "filename": ".github/workflows/cuda/cu102-Linux.sh",
                "status": "modified",
                "additions": 1,
                "deletions": 3,
                "changes": 4
            },
            {
                "filename": ".github/workflows/cuda/cu113-Linux.sh",
                "status": "modified",
                "additions": 1,
                "deletions": 3,
                "changes": 4
            },
            {
                "filename": ".github/workflows/cuda/cu116-Linux.sh",
                "status": "modified",
                "additions": 1,
                "deletions": 3,
                "changes": 4
            },
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 0,
                "deletions": 2,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "061470ae58220a189272e72995a4a206f7447d39",
        "created_at": "2023-06-02 18:59:09 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "echo-OS-version",
        "files": [
            {
                "filename": ".github/workflows/cuda/cu102-Linux.sh",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": ".github/workflows/cuda/cu113-Linux.sh",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": ".github/workflows/cuda/cu116-Linux.sh",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2dadfdbbcab2edc6a56b068a8cedc73c8324aacc",
        "created_at": "2023-06-02 18:48:02 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Temp-disable-deploy",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 29,
                "deletions": 29,
                "changes": 58
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a682252be78e09f55925e36775ff5818a26b5172",
        "created_at": "2023-06-02 18:47:25 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "OS-version-build-numbers",
        "files": [
            {
                "filename": ".github/workflows/cuda/cu102-Linux.sh",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4
            },
            {
                "filename": ".github/workflows/cuda/cu113-Linux.sh",
                "status": "modified",
                "additions": 7,
                "deletions": 1,
                "changes": 8
            },
            {
                "filename": ".github/workflows/cuda/cu116-Linux.sh",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4
            },
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 11,
                "deletions": 6,
                "changes": 17
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "cd0c169eeef47eba8d67c0717bec19f6484739b0",
        "created_at": "2023-06-02 18:28:00 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Restore-full-build-matrix",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 7,
                "deletions": 13,
                "changes": 20
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ea2ed8862341767d1bb7d82bff3cbd27c9740784",
        "created_at": "2023-06-02 18:22:44 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Refactor-and-clean-of-setup.py",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 131,
                "deletions": 115,
                "changes": 246
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9fc9820a5bf0eb851b79388908f43a70affbe296",
        "created_at": "2023-06-02 18:02:24 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Strip-cuda-name-from-torch-version",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5e4699782a8734f871bee1f628b55d25c05a46a5",
        "created_at": "2023-06-02 15:58:36 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Allow-fallback-install",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 4,
                "deletions": 1,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dab99053e46c32f394fee40c6d8627f302566b9f",
        "created_at": "2023-06-02 14:52:31 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Bump-build-to-use-116-for-testing",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 2,
                "deletions": 6,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0e7769c813fcd2b04882a9cd7e13945002a903d3",
        "created_at": "2023-06-02 14:41:07 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Guessing-wheel-URL",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 6,
                "deletions": 4,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e1faefce9de958fa64747edef823a0779392b027",
        "created_at": "2023-06-02 13:20:39 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Raise-cuda-error-on-build",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 9,
                "deletions": 3,
                "changes": 12
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "add4f0bc42e7d85c23ed20a64453f918f232039d",
        "created_at": "2023-05-30 15:53:18 -0700",
        "author": "piercefreeman",
        "committer": "piercefreeman",
        "message": "Scaffolding-for-wheel-prototype",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 54,
                "deletions": 17,
                "changes": 71
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 51,
                "deletions": 1,
                "changes": 52
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9818f85fee29ac6b60c9214bce841f8109a18b1b",
        "created_at": "2023-06-02 02:23:25 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-255-from-beginlner-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8e44c0eefbaf526874406488fcbac3ca70bdefa2",
        "created_at": "2023-06-02 13:46:19 +0800",
        "author": "beginlner",
        "committer": "web-flow",
        "message": "Fix-a-bug",
        "files": [
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "85b51d61eea5ed85c93168262048005c1a9131c0",
        "created_at": "2023-05-30 14:18:44 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-version-to-1.0.7",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "27f8f890dff58986391b606bc7c181c3b9f5148a",
        "created_at": "2023-05-30 14:17:26 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "FusedDense-Allocate-lt_workspace-on-input-device",
        "files": [
            {
                "filename": "csrc/fused_dense_lib/fused_dense.cpp",
                "status": "modified",
                "additions": 28,
                "deletions": 6,
                "changes": 34
            },
            {
                "filename": "csrc/fused_dense_lib/fused_dense_cuda.cu",
                "status": "modified",
                "additions": 48,
                "deletions": 46,
                "changes": 94
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "48bc6eacd61b4b57bbd250057655d52f7068ba2f",
        "created_at": "2023-05-30 13:38:34 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Add-rotary-base-as-an-argument-to-FT-attention-kernel",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_template.hpp",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_utils.h",
                "status": "modified",
                "additions": 54,
                "deletions": 54,
                "changes": 108
            },
            {
                "filename": "csrc/ft_attention/ft_attention.cpp",
                "status": "modified",
                "additions": 5,
                "deletions": 2,
                "changes": 7
            },
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 13,
                "deletions": 9,
                "changes": 22
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "7c766b1bbc65d341f5f7fcead82946319c9657d0",
        "created_at": "2023-05-26 22:48:08 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-243-from-ksivaman-bump_version_to_v1_0_6",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dd9c3a1fc25d415688da65729ecdf7b46341fae1",
        "created_at": "2023-05-26 17:44:10 -0700",
        "author": "ksivaman",
        "committer": "ksivaman",
        "message": "bump-to-v1.0.6",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ce68305c8475b6265ac3493109f3a2189e233bbb",
        "created_at": "2023-05-25 16:52:52 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-installation-instruction",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "cf4f0a39f3ce94a6c19c7a465efad02205bf892d",
        "created_at": "2023-05-25 18:34:41 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-241-from-ksivaman-fix_compilation_time",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "852bc40b8c9a5ea0dbe203a3b1bb5b9b1ed07d6b",
        "created_at": "2023-05-25 19:12:22 +0000",
        "author": "ksivaman",
        "committer": "ksivaman",
        "message": "Remove-torch-from-pyproject.toml",
        "files": [
            {
                "filename": "pyproject.toml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6d45d0bd6c9f833204d8a6438c4b2d5438729026",
        "created_at": "2023-05-25 21:22:50 +0000",
        "author": "ksivaman",
        "committer": "ksivaman",
        "message": "Re-add-ninja",
        "files": [
            {
                "filename": "pyproject.toml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c1d117c2d070bbdd0c94be67213bd16ed9717618",
        "created_at": "2023-05-25 19:12:00 +0000",
        "author": "ksivaman",
        "committer": "ksivaman",
        "message": "Remove-ninja-from-pyproject.toml",
        "files": [
            {
                "filename": "pyproject.toml",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f0c40b7ddb188bccee800628af45214cdced0ad5",
        "created_at": "2023-05-19 09:40:21 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Recommend-Nvidia-s-Pytorch-container",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "3cad2ab35d516b014d95d41f6b986f94e3703555",
        "created_at": "2023-05-19 11:43:24 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-229-from-maxhgerlach-local-version",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "31f78a9814951374af5238af969338bce45394e4",
        "created_at": "2023-05-19 16:30:25 +0200",
        "author": "maxhgerlach",
        "committer": "maxhgerlach",
        "message": "Allow-adding-an-optional-local-version-to-the-package-version",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 13,
                "deletions": 1,
                "changes": 14
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "40a25c8ee7465cf547b929cfa2937034e37bfce9",
        "created_at": "2023-05-17 08:32:26 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-roadmap",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "18106c1ba0ccee81b97ca947397c08a141815a47",
        "created_at": "2023-05-18 17:41:01 +0800",
        "author": "Xreki",
        "committer": "web-flow",
        "message": "Try-to-crop-the-library-s-size.-6",
        "files": [
            {
                "filename": "csrc/flash_attn/CMakeLists.txt",
                "status": "modified",
                "additions": 17,
                "deletions": 2,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn/flash_attn.h",
                "status": "modified",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/flash_attn_with_bias_mask.cpp",
                "status": "modified",
                "additions": 183,
                "deletions": 179,
                "changes": 362
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 12,
                "deletions": 14,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha/softmax.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_launch_template.h",
                "status": "modified",
                "additions": 0,
                "deletions": 126,
                "changes": 126
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim128.cu",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim16.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 22,
                "changes": 22
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim32.cu",
                "status": "modified",
                "additions": 6,
                "deletions": 6,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim64.cu",
                "status": "modified",
                "additions": 8,
                "deletions": 8,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_launch_template.h",
                "status": "added",
                "additions": 61,
                "deletions": 0,
                "changes": 61
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 25,
                "deletions": 17,
                "changes": 42
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 29,
                "deletions": 69,
                "changes": 98
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_launch_template.h",
                "status": "modified",
                "additions": 0,
                "deletions": 133,
                "changes": 133
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim128.cu",
                "status": "modified",
                "additions": 8,
                "deletions": 8,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim16.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 23,
                "changes": 23
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim32.cu",
                "status": "modified",
                "additions": 9,
                "deletions": 9,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim64.cu",
                "status": "modified",
                "additions": 10,
                "deletions": 10,
                "changes": 20
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_launch_template.h",
                "status": "added",
                "additions": 68,
                "deletions": 0,
                "changes": 68
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "eff9fe6b8076df59d64d7a3f464696738a3c7c24",
        "created_at": "2023-05-12 14:16:53 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-ninja-to-pyproject.toml-build-system-bump-to-v1.0.5",
        "files": [
            {
                "filename": "pyproject.toml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "36d0a19f1eb5dc5922bbcad6b04749c6d49b6a66",
        "created_at": "2023-05-11 21:26:28 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-193-from-anthonyhu-pyproject-build",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "69f5f7d0a23db4debd6888d2b21c5a6a898f8432",
        "created_at": "2023-05-07 03:07:44 +0900",
        "author": "fedebotu",
        "committer": "fedebotu",
        "message": "BugFix-cannot-unpack-non-iterable-NoneType-object",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "209f02b3852f1f6672b01e00729f20f0e52633a9",
        "created_at": "2023-05-08 11:20:17 +0800",
        "author": "JamesLim-sy",
        "committer": "web-flow",
        "message": "Opitmization-for-AlphaFold2-model-4",
        "files": [
            {
                "filename": "csrc/flash_attn/CMakeLists.txt",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/flash_attn.cpp",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/flash_attn.h",
                "status": "modified",
                "additions": 73,
                "deletions": 0,
                "changes": 73
            },
            {
                "filename": "csrc/flash_attn/flash_attn_with_bias_mask.cpp",
                "status": "added",
                "additions": 539,
                "deletions": 0,
                "changes": 539
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 6,
                "deletions": 7,
                "changes": 13
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 21,
                "deletions": 0,
                "changes": 21
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gemm.h",
                "status": "modified",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 585,
                "deletions": 1,
                "changes": 586
            },
            {
                "filename": "csrc/flash_attn/src/fmha/kernel_traits.h",
                "status": "modified",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "csrc/flash_attn/src/fmha/softmax.h",
                "status": "modified",
                "additions": 40,
                "deletions": 0,
                "changes": 40
            },
            {
                "filename": "csrc/flash_attn/src/fmha/utils.h",
                "status": "modified",
                "additions": 34,
                "deletions": 0,
                "changes": 34
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 2,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim32.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_launch_template.h",
                "status": "modified",
                "additions": 126,
                "deletions": 0,
                "changes": 126
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim128.cu",
                "status": "added",
                "additions": 12,
                "deletions": 0,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim16.cu",
                "status": "added",
                "additions": 22,
                "deletions": 0,
                "changes": 22
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim32.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_with_mask_bias_hdim64.cu",
                "status": "added",
                "additions": 30,
                "deletions": 0,
                "changes": 30
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 720,
                "deletions": 0,
                "changes": 720
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 524,
                "deletions": 0,
                "changes": 524
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim32.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_launch_template.h",
                "status": "modified",
                "additions": 133,
                "deletions": 0,
                "changes": 133
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim128.cu",
                "status": "added",
                "additions": 26,
                "deletions": 0,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim16.cu",
                "status": "added",
                "additions": 23,
                "deletions": 0,
                "changes": 23
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim32.cu",
                "status": "added",
                "additions": 21,
                "deletions": 0,
                "changes": 21
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_with_mask_bias_hdim64.cu",
                "status": "added",
                "additions": 29,
                "deletions": 0,
                "changes": 29
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 22,
                "deletions": 0,
                "changes": 22
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "3889ba168b2fc0149fb77de1ffdadb478da15e1a",
        "created_at": "2023-05-07 03:07:30 +0900",
        "author": "fedebotu",
        "committer": "fedebotu",
        "message": "BugFix-cannot-unpack-non-iterable-NoneType-object",
        "files": [
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5bf7f57d477ff318bb4b650c198fe8b4bc9c8360",
        "created_at": "2023-05-06 14:15:02 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-202-from-fedebotu-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a9a4b4e4f260ae4d96386ae38a38a3c7638fefc9",
        "created_at": "2023-05-04 23:39:43 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "LLaMa-Fix-last-norm-layer-to-use-RMSNorm-instead-of-LayerNorm",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 7,
                "deletions": 2,
                "changes": 9
            },
            {
                "filename": "tests/models/test_llama.py",
                "status": "modified",
                "additions": 6,
                "deletions": 7,
                "changes": 13
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d63cfc35518a84ed038426d10ac882029d482091",
        "created_at": "2023-04-27 11:51:52 +0100",
        "author": "anthonyhu",
        "committer": "anthonyhu",
        "message": "Use-pyproject.toml-to-specify-build-dependencies",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "pyproject.toml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ad113948a6c3864fbe48156a9857e97a38ce758c",
        "created_at": "2023-04-26 09:19:48 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Clearer-error-message-for-bwd-d-64-bump-to-v1.0.4",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "67ef5d28df71d395bc16787b31e08ea1afbe4178",
        "created_at": "2023-04-21 12:04:53 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-version-to-1.0.3",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "fcab93b43add5324d97147cd56b245a99424b4c7",
        "created_at": "2023-04-21 11:56:47 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Minor-tweak-to-allocate_inference_cache",
        "files": [
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 5,
                "deletions": 2,
                "changes": 7
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "fbbb10784881c5b8b2183cb9e4727c397a131aa7",
        "created_at": "2023-04-21 13:37:23 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-version-to-v1.0.3.post0",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "311d6606bf82cece56b600f7f500b4c41d88e27d",
        "created_at": "2023-04-20 16:26:12 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Fix-FT-kernel-smem-size-CG-when-batch-size-changed",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention.cu",
                "status": "modified",
                "additions": 7,
                "deletions": 8,
                "changes": 15
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 15,
                "deletions": 5,
                "changes": 20
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 4,
                "deletions": 3,
                "changes": 7
            },
            {
                "filename": "tests/models/test_gpt_generation_cg.py",
                "status": "added",
                "additions": 80,
                "deletions": 0,
                "changes": 80
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "96d10f654527cc82c81022e16f77a8d9564f7eba",
        "created_at": "2023-04-18 21:43:37 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-LLaMa",
        "files": [
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 2,
                "deletions": 6,
                "changes": 8
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 40,
                "deletions": 13,
                "changes": 53
            },
            {
                "filename": "flash_attn/models/gptj.py",
                "status": "modified",
                "additions": 1,
                "deletions": 3,
                "changes": 4
            },
            {
                "filename": "flash_attn/models/llama.py",
                "status": "added",
                "additions": 124,
                "deletions": 0,
                "changes": 124
            },
            {
                "filename": "flash_attn/models/opt.py",
                "status": "modified",
                "additions": 2,
                "deletions": 6,
                "changes": 8
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 26,
                "deletions": 7,
                "changes": 33
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 7,
                "deletions": 6,
                "changes": 13
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/ops/rms_norm.py",
                "status": "modified",
                "additions": 18,
                "deletions": 2,
                "changes": 20
            },
            {
                "filename": "flash_attn/ops/triton/mlp.py",
                "status": "modified",
                "additions": 6,
                "deletions": 5,
                "changes": 11
            },
            {
                "filename": "tests/models/test_gpt_neox.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "tests/models/test_gptj.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "tests/models/test_llama.py",
                "status": "added",
                "additions": 277,
                "deletions": 0,
                "changes": 277
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ba2fe7f378c938263e8b5eeeac0fb2766c754551",
        "created_at": "2023-04-20 18:15:12 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Move-allocate_inference_cache-to-within-the-model",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 10,
                "deletions": 7,
                "changes": 17
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b630aef53fb263520a10f86fe08cd5cfb0360702",
        "created_at": "2023-04-18 03:37:14 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-GatedMlp",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 24,
                "deletions": 17,
                "changes": 41
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 25,
                "deletions": 0,
                "changes": 25
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 8,
                "deletions": 8,
                "changes": 16
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "3da42d24b1678b3ed930ab86e801b4ee851af1d2",
        "created_at": "2023-04-20 17:21:08 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "GPT-Add-option-to-only-return-the-logit-for-the-last-token",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 6,
                "deletions": 6,
                "changes": 12
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ac3b684cdb2d3262a0dff2b7952ee1519ffcdc9c",
        "created_at": "2023-04-17 22:34:05 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Have-a-separate-nn.Dropout-module-in-SelfAttention-module",
        "files": [
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 12,
                "deletions": 12,
                "changes": 24
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "635f159ee32c78319d7ab41b160be998bc4b91b0",
        "created_at": "2023-04-16 00:27:33 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-166-from-ksivaman-enable_cuda_graph_capture",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "df1344f8668829d6e46b32d79d9089d19888da9f",
        "created_at": "2023-04-15 22:19:31 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v1.0.2",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a0997bc77c89710878ea6ee9d100bb0f808e0b21",
        "created_at": "2023-04-14 21:45:37 -0700",
        "author": "ksivaman",
        "committer": "web-flow",
        "message": "Merge-branch-HazyResearch-main-into-enable_cuda_graph_capture",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "45567a25a2f74cabe17f9d59f88169ad06d4c874",
        "created_at": "2023-04-15 06:09:41 +0000",
        "author": "ksivaman",
        "committer": "ksivaman",
        "message": "only-1-thread-writes-to-global-mem-in-fprop",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "221a39fd3a6aa12809d05c1cb4fffcac73f6b9ed",
        "created_at": "2023-04-14 21:20:38 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Link-to-Forbes-article",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "605655bc66bc0fb11ac10dad2e656a97f3729b5b",
        "created_at": "2023-04-14 16:50:01 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Fix-FT-kernel-when-using-CG",
        "files": [
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 12,
                "deletions": 9,
                "changes": 21
            },
            {
                "filename": "tests/models/test_gptj.py",
                "status": "modified",
                "additions": 91,
                "deletions": 1,
                "changes": 92
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dceb2687c5b0aa40ee0bbb9f0068acc0143499fc",
        "created_at": "2023-04-14 15:41:46 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-170-from-CrustaceanJ-dependencies",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "72629ac9ba3cedb2ae5333cac3be64b66bc71811",
        "created_at": "2023-04-14 20:08:24 +0300",
        "author": "CrustaceanJ",
        "committer": "CrustaceanJ",
        "message": "add-missed-module",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1c9ef9b39967f0eab77e3a4ea17690833ec931d6",
        "created_at": "2023-04-13 15:39:56 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Measure-prompt-processing-decoding-time-not-just-decoding",
        "files": [
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "081c2b012a08ef90346d6adf7e54f55a58b58e9f",
        "created_at": "2023-04-13 19:36:45 -0700",
        "author": "ksivaman",
        "committer": "web-flow",
        "message": "Merge-branch-HazyResearch-main-into-enable_cuda_graph_capture",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6f6e9a9aaf42b2894055495dc3ae4b11be054f3f",
        "created_at": "2023-04-13 15:28:44 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "FusedDense-Enable-sqrelu-activation-in-FusedMLP",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/ops/activations.py",
                "status": "modified",
                "additions": 18,
                "deletions": 1,
                "changes": 19
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 19,
                "deletions": 18,
                "changes": 37
            },
            {
                "filename": "flash_attn/ops/triton/mlp.py",
                "status": "modified",
                "additions": 1,
                "deletions": 11,
                "changes": 12
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "7d25a4ec4f4ecef5df1a208ec74ca34455dcb439",
        "created_at": "2023-04-13 06:25:52 +0000",
        "author": "ksivaman",
        "committer": "ksivaman",
        "message": "Handle-FlashAttnQKVPackedSplitFunc-by-making-rng_state-optional-in-backward",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 11,
                "deletions": 2,
                "changes": 13
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "315fd31f0c317b1d0127af71da922fd2a846eef3",
        "created_at": "2023-04-12 22:42:24 -0700",
        "author": "ksivaman",
        "committer": "web-flow",
        "message": "Merge-branch-HazyResearch-main-into-enable_cuda_graph_capture",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5cee071431b94ec84c2354861da019231e7a16b4",
        "created_at": "2023-04-12 23:21:12 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-164-from-ZhiyuanChen-patch-1",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "31018c5fa0349384d3b90ad66f12d560182020e7",
        "created_at": "2023-04-12 16:53:22 -0700",
        "author": "ksivaman",
        "committer": "ksivaman",
        "message": "Support-CUDA-graph-capture",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 8,
                "deletions": 7,
                "changes": 15
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 6,
                "deletions": 4,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 12,
                "deletions": 32,
                "changes": 44
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8c424156641ceadc9cd1f5de71c8ae144b4db113",
        "created_at": "2023-04-13 11:08:21 +0800",
        "author": "ZhiyuanChen",
        "committer": "web-flow",
        "message": "make-mlp-hidden_features-defaults-to-4-in_features",
        "files": [
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "853ff72963e73456c2a318bde1ebfa292ce935e9",
        "created_at": "2023-04-12 10:05:01 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-version-to-v1.0.1-fix-Cutlass-version",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5ff4bbf56ad066750407c4aef16ac740ebda0717",
        "created_at": "2023-04-12 15:33:07 +0800",
        "author": "kuizhiqing",
        "committer": "web-flow",
        "message": "fix-loop-cond-for-num_split-1-5",
        "files": [
            {
                "filename": "csrc/flash_attn/flash_attn.cpp",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "74af0233166583e58b38c50241831c6114dfea0b",
        "created_at": "2023-04-11 23:32:35 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-version-to-1.0.0",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d478eeec8f16c7939c54e4617dbd36f59b8eeed7",
        "created_at": "2023-04-04 02:54:37 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-154-from-kuizhiqing-usage",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dec4f2e9101f88f8beffabc9d0f0379323748973",
        "created_at": "2023-04-06 23:40:15 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "FusedDense-Set-workspace-size-to-32M-for-Hopper-and-4M-for-others",
        "files": [
            {
                "filename": "csrc/fused_dense_lib/fused_dense_cuda.cu",
                "status": "modified",
                "additions": 7,
                "deletions": 3,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c5be8d3aabef5d282dc095268185c6688ee81dcd",
        "created_at": "2023-04-04 14:15:51 +0800",
        "author": "kuizhiqing",
        "committer": "kuizhiqing",
        "message": "add-paddlepaddle-in-usage",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "393882bc089aff64863c260a8633b8390c90aa78",
        "created_at": "2023-03-29 15:59:36 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Implement-LN-with-parallel-residual-support-dim-8k",
        "files": [
            {
                "filename": "csrc/layer_norm/README.md",
                "status": "modified",
                "additions": 7,
                "deletions": 4,
                "changes": 11
            },
            {
                "filename": "csrc/layer_norm/ln.h",
                "status": "modified",
                "additions": 43,
                "deletions": 3,
                "changes": 46
            },
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 408,
                "deletions": 32,
                "changes": 440
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_7168.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_8192.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_7168.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_8192.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_1024.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_1280.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_1536.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_2048.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_256.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_2560.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_3072.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_4096.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_512.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_5120.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_6144.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_7168.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_768.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_bwd_8192.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_1024.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_1280.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_1536.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_2048.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_256.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_2560.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_3072.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_4096.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_512.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_5120.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_6144.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_7168.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_768.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_fwd_8192.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh",
                "status": "added",
                "additions": 540,
                "deletions": 0,
                "changes": 540
            },
            {
                "filename": "csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh",
                "status": "added",
                "additions": 281,
                "deletions": 0,
                "changes": 281
            },
            {
                "filename": "csrc/layer_norm/ln_utils.cuh",
                "status": "modified",
                "additions": 33,
                "deletions": 0,
                "changes": 33
            },
            {
                "filename": "csrc/layer_norm/setup.py",
                "status": "modified",
                "additions": 32,
                "deletions": 0,
                "changes": 32
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 21,
                "deletions": 8,
                "changes": 29
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 30,
                "deletions": 15,
                "changes": 45
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 109,
                "deletions": 2,
                "changes": 111
            },
            {
                "filename": "flash_attn/ops/rms_norm.py",
                "status": "modified",
                "additions": 14,
                "deletions": 0,
                "changes": 14
            },
            {
                "filename": "tests/models/test_gpt_neox.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "tests/models/test_gptj.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "tests/ops/test_dropout_layer_norm.py",
                "status": "modified",
                "additions": 344,
                "deletions": 48,
                "changes": 392
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d6fc86057305cc15d91f21221acc78a6bc1d672d",
        "created_at": "2023-03-31 17:32:50 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-147-from-ksivaman-add_deterministic_execution_option",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b6aa059bbfee365db7f991db88af99d3d0bf82da",
        "created_at": "2023-03-30 18:23:35 -0700",
        "author": "ksivaman",
        "committer": "ksivaman",
        "message": "Add-option-for-deterministic-execution",
        "files": [
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 36,
                "deletions": 21,
                "changes": 57
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "009a3e71ece11b2ec20629883f7d66212db52c7d",
        "created_at": "2023-03-29 01:43:39 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Training-Fix-lightning-_PATH-import",
        "files": [
            {
                "filename": "training/src/utils/ddp_zero1.py",
                "status": "modified",
                "additions": 7,
                "deletions": 2,
                "changes": 9
            },
            {
                "filename": "training/src/utils/ddp_zero2.py",
                "status": "modified",
                "additions": 7,
                "deletions": 2,
                "changes": 9
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "993d12448e2af5fe73bad1c8f93a3cb524aade33",
        "created_at": "2023-03-29 01:21:25 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-GPT-NeoX",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 6,
                "deletions": 3,
                "changes": 9
            },
            {
                "filename": "flash_attn/models/gpt_neox.py",
                "status": "added",
                "additions": 107,
                "deletions": 0,
                "changes": 107
            },
            {
                "filename": "flash_attn/models/gptj.py",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5
            },
            {
                "filename": "tests/models/test_gpt_neox.py",
                "status": "added",
                "additions": 84,
                "deletions": 0,
                "changes": 84
            },
            {
                "filename": "tests/models/test_gptj.py",
                "status": "modified",
                "additions": 7,
                "deletions": 6,
                "changes": 13
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4360cfc6a850ee2431cc7b21fdba4fdc6bec4d0f",
        "created_at": "2023-03-22 01:34:38 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Triton-Fix-benchmark_causal.py",
        "files": [
            {
                "filename": "benchmarks/benchmark_causal.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f5d0fbd46805155a4406d36e8fb9f9d0324030c4",
        "created_at": "2023-03-28 21:27:00 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "FT-Fix-FT-s-single-query-attention-for-bf16-hdim128-rotary",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_utils.h",
                "status": "modified",
                "additions": 14,
                "deletions": 16,
                "changes": 30
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 1,
                "deletions": 2,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dc08ea1c33afca500a3d4ada907608f7815a11d9",
        "created_at": "2023-03-15 16:59:27 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-H100-for-other-CUDA-extensions",
        "files": [
            {
                "filename": "csrc/ft_attention/setup.py",
                "status": "modified",
                "additions": 31,
                "deletions": 22,
                "changes": 53
            },
            {
                "filename": "csrc/fused_dense_lib/setup.py",
                "status": "modified",
                "additions": 5,
                "deletions": 6,
                "changes": 11
            },
            {
                "filename": "csrc/layer_norm/setup.py",
                "status": "modified",
                "additions": 26,
                "deletions": 19,
                "changes": 45
            },
            {
                "filename": "csrc/rotary/setup.py",
                "status": "modified",
                "additions": 26,
                "deletions": 19,
                "changes": 45
            },
            {
                "filename": "csrc/xentropy/setup.py",
                "status": "modified",
                "additions": 26,
                "deletions": 19,
                "changes": 45
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 7,
                "deletions": 2,
                "changes": 9
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4d87e4d875077ad9efd25030efa4ab0ba92c19e1",
        "created_at": "2023-03-22 16:16:58 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-GPT-J",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 213,
                "deletions": 56,
                "changes": 269
            },
            {
                "filename": "flash_attn/models/gptj.py",
                "status": "added",
                "additions": 95,
                "deletions": 0,
                "changes": 95
            },
            {
                "filename": "flash_attn/models/opt.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 90,
                "deletions": 0,
                "changes": 90
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 25,
                "deletions": 19,
                "changes": 44
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 11,
                "deletions": 4,
                "changes": 15
            },
            {
                "filename": "tests/models/test_gpt.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "tests/models/test_gpt_generation_parallel.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "tests/models/test_gptj.py",
                "status": "added",
                "additions": 80,
                "deletions": 0,
                "changes": 80
            },
            {
                "filename": "tests/models/test_opt.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5d079fdd7a20bbd354080a80b20b5c36c93898d4",
        "created_at": "2023-03-22 00:51:16 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Triton-Fix-benchmark_causal-mention-Triton-version",
        "files": [
            {
                "filename": "benchmarks/benchmark_causal.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 7,
                "deletions": 1,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1b18f1b7a133c20904c096b8b222a0916e1b3d37",
        "created_at": "2023-03-15 14:55:22 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-H100",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 9,
                "deletions": 7,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 14,
                "deletions": 8,
                "changes": 22
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim64.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 25,
                "deletions": 21,
                "changes": 46
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "318e2f1b9b2cdbfae36e3a6b2d5c51d4f096d012",
        "created_at": "2023-03-15 17:16:00 -0400",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-140-from-VikParuchuri-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "31653980749654c80c561bff5bb697c176da3b46",
        "created_at": "2023-03-15 10:36:19 -0700",
        "author": "VikParuchuri",
        "committer": "VikParuchuri",
        "message": "Remove-unused-kwargs-in-flashattention",
        "files": [
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e45a46a5b767d76e14c76e4bfac408b7cf94d896",
        "created_at": "2023-03-14 14:28:28 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Rotary-Implement-GPT-J-style-interleaved-rotary",
        "files": [
            {
                "filename": "csrc/rotary/rotary.cpp",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            },
            {
                "filename": "csrc/rotary/rotary_cuda.cu",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            },
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 61,
                "deletions": 26,
                "changes": 87
            },
            {
                "filename": "tests/layers/test_rotary.py",
                "status": "added",
                "additions": 114,
                "deletions": 0,
                "changes": 114
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f28d61cb2a3969d7ad1c77c5995f613d67ab3d63",
        "created_at": "2023-03-13 12:48:07 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-README-on-requirements-nvcc-and-Pytorch",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "57ee618170e1adecbf787365cdf330c63768abd2",
        "created_at": "2023-02-14 19:03:08 -0800",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-94-from-calebthomas259-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2dc2a195890d323f6f9e1b74e4667099e6144f79",
        "created_at": "2023-02-09 12:21:16 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-roadmap",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 9,
                "deletions": 8,
                "changes": 17
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5994ce06e9f90b9fac810a7a36a72ddb896cdf06",
        "created_at": "2023-02-06 13:13:26 +0800",
        "author": "kuizhiqing",
        "committer": "web-flow",
        "message": "CAPI-for-paddle-1",
        "files": [
            {
                "filename": "csrc/flash_attn/CMakeLists.txt",
                "status": "added",
                "additions": 53,
                "deletions": 0,
                "changes": 53
            },
            {
                "filename": "csrc/flash_attn/flash_attn.cpp",
                "status": "added",
                "additions": 499,
                "deletions": 0,
                "changes": 499
            },
            {
                "filename": "csrc/flash_attn/flash_attn.h",
                "status": "added",
                "additions": 77,
                "deletions": 0,
                "changes": 77
            },
            {
                "filename": "csrc/flash_attn/src/cuda_utils.cpp",
                "status": "added",
                "additions": 46,
                "deletions": 0,
                "changes": 46
            },
            {
                "filename": "csrc/flash_attn/src/cuda_utils.h",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 2,
                "deletions": 11,
                "changes": 13
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim64.cu",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_launch_template.h",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_launch_template.h",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/random_utils.h",
                "status": "added",
                "additions": 70,
                "deletions": 0,
                "changes": 70
            },
            {
                "filename": "csrc/flash_attn/src/utils.cu",
                "status": "added",
                "additions": 51,
                "deletions": 0,
                "changes": 51
            },
            {
                "filename": "csrc/flash_attn/src/utils.h",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "06da275bcba0f4554f205f52fa20f74309f2d973",
        "created_at": "2023-01-27 12:18:16 -0800",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-110-from-eltociear-patch-1",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6b4a48218edb55fb67e087f4df8d7ba4711e75bb",
        "created_at": "2023-01-25 15:32:40 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "FA-Remove-unused-variable-rng_engine_inputs",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 0,
                "deletions": 2,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f0edf243a813a65d05c75fcb331b2a95faf96bbc",
        "created_at": "2023-02-13 10:23:47 +0800",
        "author": "kuizhiqing",
        "committer": "web-flow",
        "message": "fix-zero-bug-fix-num_splits-2",
        "files": [
            {
                "filename": "csrc/flash_attn/flash_attn.cpp",
                "status": "modified",
                "additions": 9,
                "deletions": 6,
                "changes": 15
            },
            {
                "filename": "csrc/flash_attn/src/utils.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "78b7a1dc1869e03a39cf3d2e2d9e5dbb1f669810",
        "created_at": "2023-01-22 17:01:32 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "OPT-Load-fp16-weights-on-CPU-before-moving-to-GPU",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "flash_attn/models/opt.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 11,
                "deletions": 4,
                "changes": 15
            },
            {
                "filename": "flash_attn/utils/pretrained.py",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "tests/models/test_gpt_generation_parallel.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "419ea45b64fc5e34c61b48387a3e6af6ee1ff4e5",
        "created_at": "2023-01-21 00:47:12 +0900",
        "author": "eltociear",
        "committer": "web-flow",
        "message": "fix-typo-in-default.yaml",
        "files": [
            {
                "filename": "training/configs/callbacks/default.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "33e0860c9c5667fded5af674882e731909096a7f",
        "created_at": "2023-01-19 13:17:19 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v0.2.8",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "eb33e587e95ec29a13c58f76dadca04b64122784",
        "created_at": "2023-01-19 13:07:27 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Rename-x1-residual",
        "files": [
            {
                "filename": "csrc/layer_norm/ln.h",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 15,
                "deletions": 15,
                "changes": 30
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_kernels.cuh",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_kernels.cuh",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 48,
                "deletions": 48,
                "changes": 96
            },
            {
                "filename": "flash_attn/ops/rms_norm.py",
                "status": "modified",
                "additions": 12,
                "deletions": 11,
                "changes": 23
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f68d41ec7768db6c5578ca8718d081de36fa1246",
        "created_at": "2023-01-17 19:59:06 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Add-OPT-to-generation-test",
        "files": [
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 8,
                "deletions": 4,
                "changes": 12
            },
            {
                "filename": "flash_attn/utils/pretrained.py",
                "status": "modified",
                "additions": 25,
                "deletions": 3,
                "changes": 28
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 130,
                "deletions": 4,
                "changes": 134
            },
            {
                "filename": "tests/models/test_opt.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "88173a1aafe8e2796fcfc9433160838138f0dfc1",
        "created_at": "2023-01-17 18:12:27 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "FusedDense-Support-relu-rename-FusedDenseGeluDense-FusedMLP",
        "files": [
            {
                "filename": "csrc/fused_dense_lib/fused_dense.cpp",
                "status": "modified",
                "additions": 41,
                "deletions": 45,
                "changes": 86
            },
            {
                "filename": "csrc/fused_dense_lib/fused_dense_cuda.cu",
                "status": "modified",
                "additions": 266,
                "deletions": 478,
                "changes": 744
            },
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 7,
                "deletions": 7,
                "changes": 14
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 18,
                "deletions": 14,
                "changes": 32
            },
            {
                "filename": "flash_attn/models/vit.py",
                "status": "modified",
                "additions": 8,
                "deletions": 8,
                "changes": 16
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 111,
                "deletions": 64,
                "changes": 175
            },
            {
                "filename": "tests/models/test_bert.py",
                "status": "modified",
                "additions": 6,
                "deletions": 6,
                "changes": 12
            },
            {
                "filename": "tests/models/test_gpt.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 5,
                "deletions": 118,
                "changes": 123
            },
            {
                "filename": "tests/models/test_gpt_generation_parallel.py",
                "status": "added",
                "additions": 131,
                "deletions": 0,
                "changes": 131
            },
            {
                "filename": "tests/models/test_gpt_parallel.py",
                "status": "modified",
                "additions": 7,
                "deletions": 3,
                "changes": 10
            },
            {
                "filename": "tests/models/test_vit.py",
                "status": "modified",
                "additions": 6,
                "deletions": 5,
                "changes": 11
            },
            {
                "filename": "tests/modules/test_block_parallel.py",
                "status": "modified",
                "additions": 5,
                "deletions": 6,
                "changes": 11
            },
            {
                "filename": "tests/ops/test_fused_dense.py",
                "status": "modified",
                "additions": 25,
                "deletions": 9,
                "changes": 34
            },
            {
                "filename": "tests/ops/test_fused_dense_parallel.py",
                "status": "modified",
                "additions": 8,
                "deletions": 9,
                "changes": 17
            },
            {
                "filename": "training/README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/owt/gpt2s-flash.yaml",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "training/configs/experiment/pile/gpt3s-flash.yaml",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2ec7d3f72ceace2116311084ab406703ac686042",
        "created_at": "2023-01-15 23:01:20 -0800",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-105-from-jamaliki-patch-1",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "780e8eeabb84fe3f41e8244f04521743b032ba35",
        "created_at": "2023-01-16 01:20:04 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "ViT-Support-timm-checkpoint-add-tests",
        "files": [
            {
                "filename": "flash_attn/models/vit.py",
                "status": "modified",
                "additions": 29,
                "deletions": 4,
                "changes": 33
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 10,
                "deletions": 3,
                "changes": 13
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 7,
                "deletions": 3,
                "changes": 10
            },
            {
                "filename": "tests/models/test_opt.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "tests/models/test_vit.py",
                "status": "added",
                "additions": 49,
                "deletions": 0,
                "changes": 49
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ef085cfcdac0efd7eed8e27a31ae6fbd27126ad4",
        "created_at": "2023-01-15 22:58:56 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "ViT-Fix-extra-norm_0-use-new-LN-order-in-Block",
        "files": [
            {
                "filename": "flash_attn/models/vit.py",
                "status": "modified",
                "additions": 45,
                "deletions": 33,
                "changes": 78
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ff34123bd426bcc3ca0d1a11b6173652fb84d033",
        "created_at": "2023-01-15 22:14:31 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Reorder-LN-in-Block-support-OPT",
        "files": [
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 106,
                "deletions": 56,
                "changes": 162
            },
            {
                "filename": "flash_attn/models/opt.py",
                "status": "added",
                "additions": 104,
                "deletions": 0,
                "changes": 104
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 41,
                "deletions": 19,
                "changes": 60
            },
            {
                "filename": "flash_attn/modules/embedding.py",
                "status": "modified",
                "additions": 14,
                "deletions": 3,
                "changes": 17
            },
            {
                "filename": "tests/models/test_gpt.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "tests/models/test_opt.py",
                "status": "added",
                "additions": 77,
                "deletions": 0,
                "changes": 77
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f1e01c27ba92f62339338113fef0b0cee9e81443",
        "created_at": "2023-01-15 12:02:30 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Pass-qkv_stride-to-ft_attention-kernel-for-batched-generation",
        "files": [
            {
                "filename": "csrc/ft_attention/ft_attention.cpp",
                "status": "modified",
                "additions": 14,
                "deletions": 20,
                "changes": 34
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "7c2191542afe110c87f61f227f8df4e95d0ea0af",
        "created_at": "2023-01-15 11:34:27 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Make-generation-work-with-Tensor-Parallel",
        "files": [
            {
                "filename": "csrc/ft_attention/ft_attention.cpp",
                "status": "modified",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 33,
                "deletions": 20,
                "changes": 53
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 87,
                "deletions": 54,
                "changes": 141
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 118,
                "deletions": 64,
                "changes": 182
            },
            {
                "filename": "flash_attn/utils/pretrained.py",
                "status": "modified",
                "additions": 5,
                "deletions": 2,
                "changes": 7
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 125,
                "deletions": 6,
                "changes": 131
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "41cb9097414d853dd9c248a39f949b21fcca4094",
        "created_at": "2023-01-13 10:50:07 +0000",
        "author": "jamaliki",
        "committer": "web-flow",
        "message": "Change-default-dropout-value-in-documentation",
        "files": [
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d509832426ddaaa6263640b5040962e334fdbbe3",
        "created_at": "2023-01-12 22:15:41 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Compilation-Add-_NO_HALF2-flags-to-be-consistent-with-Pytorch",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f95c2fc108a1a63e2fdd9aed87190ac3fd492af2",
        "created_at": "2023-01-07 19:06:39 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Remove-commented-code",
        "files": [
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b48599002a5e62b16927711ed04378ae7c9833b1",
        "created_at": "2023-01-07 19:05:09 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Add-timing-option",
        "files": [
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 103,
                "deletions": 4,
                "changes": 107
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 9,
                "deletions": 3,
                "changes": 12
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0938298e4cf3492c59367471e4d185e2b83f1013",
        "created_at": "2023-01-07 17:27:54 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Adjust-shape-of-kv_cache-when-using-FT",
        "files": [
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 34,
                "deletions": 15,
                "changes": 49
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "11be742aa33f4ce016addb6d0dfb6672f74fdd1e",
        "created_at": "2023-01-07 14:33:54 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Test-generation-with-rotary-embedding",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 5,
                "deletions": 3,
                "changes": 8
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 2,
                "deletions": 3,
                "changes": 5
            },
            {
                "filename": "flash_attn/utils/pretrained.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 33,
                "deletions": 21,
                "changes": 54
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e02fd588aaaf24cb9af11df0ea7533f2a017c719",
        "created_at": "2023-01-07 17:00:02 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Implement-top-k-and-top-p-sampling",
        "files": [
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 57,
                "deletions": 10,
                "changes": 67
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 0,
                "deletions": 2,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8d9674ed087e8215c5a7c72a9e04d26ab57de0b7",
        "created_at": "2023-01-07 13:56:20 -0800",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-102-from-Lamikins-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "93383bd55bfffb0fa2c4584c4849971152397035",
        "created_at": "2023-01-07 13:45:22 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "TP-Implement-TensorParallel-without-sequence-parallel",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 27,
                "deletions": 13,
                "changes": 40
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 15,
                "deletions": 1,
                "changes": 16
            },
            {
                "filename": "flash_attn/modules/embedding.py",
                "status": "modified",
                "additions": 5,
                "deletions": 3,
                "changes": 8
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 57,
                "deletions": 40,
                "changes": 97
            },
            {
                "filename": "flash_attn/utils/distributed.py",
                "status": "modified",
                "additions": 38,
                "deletions": 12,
                "changes": 50
            },
            {
                "filename": "tests/models/test_gpt_parallel.py",
                "status": "modified",
                "additions": 14,
                "deletions": 10,
                "changes": 24
            },
            {
                "filename": "tests/modules/test_block_parallel.py",
                "status": "modified",
                "additions": 30,
                "deletions": 15,
                "changes": 45
            },
            {
                "filename": "tests/modules/test_embedding_parallel.py",
                "status": "modified",
                "additions": 9,
                "deletions": 4,
                "changes": 13
            },
            {
                "filename": "tests/modules/test_mha_parallel.py",
                "status": "modified",
                "additions": 18,
                "deletions": 8,
                "changes": 26
            },
            {
                "filename": "tests/ops/test_fused_dense_parallel.py",
                "status": "modified",
                "additions": 39,
                "deletions": 22,
                "changes": 61
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "aec35fd67c0dd691b9357f8e7235aa6e994ec4ce",
        "created_at": "2023-01-07 12:58:41 -0800",
        "author": "darius-lam",
        "committer": "darius-lam",
        "message": "fixed-cross-attention-typeerror",
        "files": [
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ce26d3d73d07e9779c5ba6fb2ca3bc187a34c6cc",
        "created_at": "2023-01-06 17:37:30 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v0.2.7",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6738d9477dc906ec6089b44db2c4de8cb2923ee9",
        "created_at": "2023-01-06 17:33:11 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Implement-RMS-Norm",
        "files": [
            {
                "filename": "csrc/layer_norm/README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/layer_norm/ln.h",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 26,
                "deletions": 10,
                "changes": 36
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_kernels.cuh",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_kernels.cuh",
                "status": "modified",
                "additions": 7,
                "deletions": 3,
                "changes": 10
            },
            {
                "filename": "csrc/layer_norm/ln_utils.cuh",
                "status": "modified",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 30,
                "deletions": 22,
                "changes": 52
            },
            {
                "filename": "flash_attn/ops/rms_norm.py",
                "status": "added",
                "additions": 58,
                "deletions": 0,
                "changes": 58
            },
            {
                "filename": "tests/ops/test_dropout_layer_norm.py",
                "status": "modified",
                "additions": 71,
                "deletions": 43,
                "changes": 114
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a1f49a2b92b6fa022379bbebafed9d7f5e96a675",
        "created_at": "2023-01-06 14:40:58 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Compilation-Change-BOOL_SWITCH-to-fix-Windows-compilation",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim128.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim32.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim64.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim128.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim32.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim64.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_launch_template.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 21,
                "deletions": 16,
                "changes": 37
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a668890fcd12f5ba04e9374c6846d04e3a557e65",
        "created_at": "2023-01-03 22:10:31 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Add-option-to-run-generation-with-FT-attention-kernel",
        "files": [
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 39,
                "deletions": 15,
                "changes": 54
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 11,
                "deletions": 4,
                "changes": 15
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "be1afaa2765d3fc57fbf7a6810cd3b146cfdd0ee",
        "created_at": "2023-01-03 22:09:22 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-FT-Use-fp32-accum-for-FMA",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_template.hpp",
                "status": "modified",
                "additions": 1,
                "deletions": 22,
                "changes": 23
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4cab4de5eabb5e630b75c668f1e3915814d349a0",
        "created_at": "2023-01-02 08:47:48 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "TP-Put-parallel-embeddings-in-separate-modules",
        "files": [
            {
                "filename": "flash_attn/modules/embedding.py",
                "status": "modified",
                "additions": 63,
                "deletions": 37,
                "changes": 100
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f266fc7262b6dbc7ef262195b38ab216a5fdb720",
        "created_at": "2023-01-03 17:46:55 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-FT-Use-tlength-instead-of-params.timestep-for-rotary",
        "files": [
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_template.hpp",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1ec09ebd90c28b936538d193f275c99f06d5e8d1",
        "created_at": "2023-01-01 17:06:39 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "FusedDense-Limit-matrix-dims-to-2M-instead-of-64k",
        "files": [
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 9,
                "deletions": 9,
                "changes": 18
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a01d1213d7dd2224d91b54affaa9cacbcdd7e721",
        "created_at": "2023-01-03 17:37:43 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Gen-Add-kernel-from-FasterTransformer-for-benchmarking",
        "files": [
            {
                "filename": "csrc/ft_attention/README.md",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "csrc/ft_attention/cuda_bf16_fallbacks.cuh",
                "status": "added",
                "additions": 257,
                "deletions": 0,
                "changes": 257
            },
            {
                "filename": "csrc/ft_attention/cuda_bf16_wrapper.h",
                "status": "added",
                "additions": 23,
                "deletions": 0,
                "changes": 23
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention.cu",
                "status": "added",
                "additions": 152,
                "deletions": 0,
                "changes": 152
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention.h",
                "status": "added",
                "additions": 181,
                "deletions": 0,
                "changes": 181
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_template.hpp",
                "status": "added",
                "additions": 1605,
                "deletions": 0,
                "changes": 1605
            },
            {
                "filename": "csrc/ft_attention/decoder_masked_multihead_attention_utils.h",
                "status": "added",
                "additions": 1788,
                "deletions": 0,
                "changes": 1788
            },
            {
                "filename": "csrc/ft_attention/ft_attention.cpp",
                "status": "added",
                "additions": 167,
                "deletions": 0,
                "changes": 167
            },
            {
                "filename": "csrc/ft_attention/setup.py",
                "status": "added",
                "additions": 143,
                "deletions": 0,
                "changes": 143
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "714c1b4f0f0c6685d57bfe57da937dd3e4670b99",
        "created_at": "2023-01-01 10:37:00 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bert-Fix-embedding-layer-norm-before-embedding-dropout",
        "files": [
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 5,
                "deletions": 6,
                "changes": 11
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 5,
                "deletions": 2,
                "changes": 7
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ef1ba918c6d149dba5cb9352b740a41a6b734212",
        "created_at": "2023-01-01 00:09:33 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "GPT-Refactor-function-to-shard-state_dict-for-TensorParallel",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 50,
                "deletions": 0,
                "changes": 50
            },
            {
                "filename": "tests/models/test_gpt_parallel.py",
                "status": "modified",
                "additions": 37,
                "deletions": 63,
                "changes": 100
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "65b4064b2acf24436a1d057f81f88f62992b75db",
        "created_at": "2022-12-31 22:47:34 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "FusedDense-Kick-off-input-all_gather-before-weight-dtype-conversion",
        "files": [
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 35,
                "deletions": 23,
                "changes": 58
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "71befc19e130ff65e9ad0f3113635c7a7ea9db60",
        "created_at": "2022-12-31 22:43:28 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Loss-Use-flash_attn.losses.cross_entropy.CrossEntropyLoss",
        "files": [
            {
                "filename": "training/configs/experiment/owt/base.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/base.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/src/losses/cross_entropy.py",
                "status": "removed",
                "additions": 0,
                "deletions": 129,
                "changes": 129
            },
            {
                "filename": "training/src/metrics/perplexity.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "43798966cfa8bf587c1e81c73ed9b267b2942f10",
        "created_at": "2022-12-30 00:01:55 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Fix-formatting",
        "files": [
            {
                "filename": "training/README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "cadfa396b89397451ca629d0edc71486b1c39bdf",
        "created_at": "2022-12-30 02:42:28 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docker-Set-torchmetrics-0.10.3",
        "files": [
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "3c7cbfc1952337932455a5517a17eb77219f092a",
        "created_at": "2022-12-29 23:55:33 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Mention-that-dropout_layer_norm-supports-all-dims-up-to-6k",
        "files": [
            {
                "filename": "training/README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "984d5204e2502607fa20cd6b296068989b3ad299",
        "created_at": "2022-12-29 15:12:08 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-training-Dockerfile-to-use-flash-attn-0.2.6",
        "files": [
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 9,
                "deletions": 10,
                "changes": 19
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "85b8e3d334fb6e87a845b65f61f3b9d05440f891",
        "created_at": "2022-12-29 20:25:02 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Mention-that-XPos-s-scale_base-is-recommended-to-be-512",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "029617179f5e829f2692b9a07be930ee8f7dd0c2",
        "created_at": "2022-12-28 15:36:36 -0800",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-95-from-Quentin-Anthony-patch-1",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d2a69a55e26061c224857f9d91d86356e69f4dca",
        "created_at": "2022-12-28 18:33:58 -0500",
        "author": "Quentin-Anthony",
        "committer": "web-flow",
        "message": "Add-gpt-neox-adoption",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a6ec1782dc69b1d1a9ed94e2323c3ed5ba56cc13",
        "created_at": "2022-12-27 21:18:45 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v0.2.6",
        "files": [
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "63670fd84a03bb448eb681806122c68e91e1b83e",
        "created_at": "2022-12-27 20:58:50 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-generation-for-GPT",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 13,
                "deletions": 5,
                "changes": 18
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 82,
                "deletions": 24,
                "changes": 106
            },
            {
                "filename": "flash_attn/utils/generation.py",
                "status": "added",
                "additions": 64,
                "deletions": 0,
                "changes": 64
            },
            {
                "filename": "tests/models/test_gpt.py",
                "status": "modified",
                "additions": 0,
                "deletions": 10,
                "changes": 10
            },
            {
                "filename": "tests/models/test_gpt_generation.py",
                "status": "added",
                "additions": 83,
                "deletions": 0,
                "changes": 83
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b4018a502895b522018c190e22bed2110858162f",
        "created_at": "2022-12-25 20:12:28 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-Tensor-Parallel-for-GPT-model",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 83,
                "deletions": 28,
                "changes": 111
            },
            {
                "filename": "flash_attn/utils/distributed.py",
                "status": "modified",
                "additions": 23,
                "deletions": 0,
                "changes": 23
            },
            {
                "filename": "tests/losses/test_cross_entropy_parallel.py",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5
            },
            {
                "filename": "tests/models/test_gpt_parallel.py",
                "status": "added",
                "additions": 211,
                "deletions": 0,
                "changes": 211
            },
            {
                "filename": "tests/modules/test_block_parallel.py",
                "status": "modified",
                "additions": 2,
                "deletions": 7,
                "changes": 9
            },
            {
                "filename": "training/src/losses/cross_entropy.py",
                "status": "modified",
                "additions": 4,
                "deletions": 3,
                "changes": 7
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9d797d8848244dfe88149ff3b821124e2212137f",
        "created_at": "2022-12-27 11:22:48 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-loading-GPT2-weights-from-Huggingface",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 106,
                "deletions": 6,
                "changes": 112
            },
            {
                "filename": "tests/models/test_gpt.py",
                "status": "added",
                "additions": 133,
                "deletions": 0,
                "changes": 133
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c6ecd40a5965dcb7f0e723866e827744677b62f7",
        "created_at": "2022-12-27 09:49:59 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Tweak-CrossEntropyLoss-to-take-process_group-in-init",
        "files": [
            {
                "filename": "flash_attn/losses/cross_entropy.py",
                "status": "modified",
                "additions": 4,
                "deletions": 3,
                "changes": 7
            },
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 1,
                "deletions": 6,
                "changes": 7
            },
            {
                "filename": "flash_attn/utils/distributed.py",
                "status": "modified",
                "additions": 7,
                "deletions": 3,
                "changes": 10
            },
            {
                "filename": "flash_attn/utils/pretrained.py",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "tests/losses/test_cross_entropy_parallel.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "tests/models/test_bert.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c9a649805bccc4adb6df4f22f1c12562501070f0",
        "created_at": "2022-12-27 14:13:59 +0800",
        "author": "calebthomas259",
        "committer": "calebthomas259",
        "message": "Add-a-simple-tutorial-to-README.md",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 63,
                "deletions": 0,
                "changes": 63
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "78225c5366dd4c1c743d9e2ff9d9b6e1ffcb03e7",
        "created_at": "2022-12-25 14:29:53 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-Tensor-Parallel-for-GPT2Embeddings",
        "files": [
            {
                "filename": "flash_attn/modules/embedding.py",
                "status": "modified",
                "additions": 82,
                "deletions": 7,
                "changes": 89
            },
            {
                "filename": "tests/modules/test_embedding_parallel.py",
                "status": "added",
                "additions": 84,
                "deletions": 0,
                "changes": 84
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1e712ea8b07850b0875c12afcfa4ddb67ed08c43",
        "created_at": "2022-12-24 16:33:07 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-TensorParallel-for-MHA",
        "files": [
            {
                "filename": "csrc/rotary/rotary.cpp",
                "status": "modified",
                "additions": 8,
                "deletions": 5,
                "changes": 13
            },
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 7,
                "deletions": 5,
                "changes": 12
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 75,
                "deletions": 13,
                "changes": 88
            },
            {
                "filename": "tests/modules/test_mha_parallel.py",
                "status": "added",
                "additions": 109,
                "deletions": 0,
                "changes": 109
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a8cfe51551f507537126b966a7b35cb71710081a",
        "created_at": "2022-12-25 11:40:14 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-Tensor-Parallel-for-transformer-Block",
        "files": [
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 9,
                "deletions": 1,
                "changes": 10
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "tests/modules/test_block_parallel.py",
                "status": "added",
                "additions": 186,
                "deletions": 0,
                "changes": 186
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "226a1b721dba950e5798e4f96ca46a8a13ecb452",
        "created_at": "2022-12-23 17:53:16 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-TensorParallel-for-FusedDense-and-FusedDenseGeluDense",
        "files": [
            {
                "filename": "csrc/fused_dense_lib/fused_dense.cpp",
                "status": "modified",
                "additions": 13,
                "deletions": 0,
                "changes": 13
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 233,
                "deletions": 57,
                "changes": 290
            },
            {
                "filename": "flash_attn/utils/distributed.py",
                "status": "added",
                "additions": 74,
                "deletions": 0,
                "changes": 74
            },
            {
                "filename": "tests/ops/test_fused_dense_parallel.py",
                "status": "added",
                "additions": 180,
                "deletions": 0,
                "changes": 180
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dff68c2b228234e34714a6cb1b966cb3a09496b9",
        "created_at": "2022-12-23 14:51:08 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-smoothing-for-CrossEntropyParallel-rename-to-CrossEntropyLoss",
        "files": [
            {
                "filename": "csrc/xentropy/interface.cpp",
                "status": "modified",
                "additions": 19,
                "deletions": 11,
                "changes": 30
            },
            {
                "filename": "csrc/xentropy/xentropy_kernel.cu",
                "status": "modified",
                "additions": 28,
                "deletions": 22,
                "changes": 50
            },
            {
                "filename": "flash_attn/losses/cross_entropy.py",
                "status": "added",
                "additions": 128,
                "deletions": 0,
                "changes": 128
            },
            {
                "filename": "flash_attn/losses/cross_entropy_apex.py",
                "status": "removed",
                "additions": 0,
                "deletions": 51,
                "changes": 51
            },
            {
                "filename": "flash_attn/losses/cross_entropy_parallel.py",
                "status": "removed",
                "additions": 0,
                "deletions": 122,
                "changes": 122
            },
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "tests/losses/test_cross_entropy.py",
                "status": "modified",
                "additions": 5,
                "deletions": 4,
                "changes": 9
            },
            {
                "filename": "tests/losses/test_cross_entropy_parallel.py",
                "status": "modified",
                "additions": 9,
                "deletions": 6,
                "changes": 15
            },
            {
                "filename": "training/configs/experiment/owt/base.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/base.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/src/losses/cross_entropy.py",
                "status": "added",
                "additions": 128,
                "deletions": 0,
                "changes": 128
            },
            {
                "filename": "training/src/losses/cross_entropy_apex.py",
                "status": "removed",
                "additions": 0,
                "deletions": 51,
                "changes": 51
            },
            {
                "filename": "training/src/losses/cross_entropy_parallel.py",
                "status": "removed",
                "additions": 0,
                "deletions": 112,
                "changes": 112
            },
            {
                "filename": "training/src/metrics/perplexity.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1bc6e5b09c7d2c7f89866924cd3f1855e54d9a81",
        "created_at": "2022-12-21 14:33:18 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v0.2.5",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e68ebbe89a9005f3919e26eb9c3c4150c8829047",
        "created_at": "2022-12-22 19:21:12 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Simplify-FusedDense",
        "files": [
            {
                "filename": "csrc/fused_dense_lib/fused_dense.cpp",
                "status": "modified",
                "additions": 72,
                "deletions": 243,
                "changes": 315
            },
            {
                "filename": "csrc/fused_dense_lib/fused_dense_cuda.cu",
                "status": "modified",
                "additions": 18,
                "deletions": 431,
                "changes": 449
            },
            {
                "filename": "flash_attn/layers/patch_embed.py",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 10,
                "deletions": 8,
                "changes": 18
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 7,
                "deletions": 6,
                "changes": 13
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 2,
                "deletions": 44,
                "changes": 46
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 146,
                "deletions": 233,
                "changes": 379
            },
            {
                "filename": "tests/ops/test_fused_dense.py",
                "status": "modified",
                "additions": 57,
                "deletions": 94,
                "changes": 151
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "496e4f528c647aa29fb5fb8e8e989078ebe7ef6c",
        "created_at": "2022-12-21 14:17:58 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-XPos-Sun-et-al",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 43,
                "deletions": 14,
                "changes": 57
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "13cdceb3770537ac884e82e1f284daff69059c91",
        "created_at": "2022-12-19 22:18:46 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-last_layer_subset-optimization-for-BERT",
        "files": [
            {
                "filename": "flash_attn/models/bert.py",
                "status": "modified",
                "additions": 151,
                "deletions": 44,
                "changes": 195
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 70,
                "deletions": 34,
                "changes": 104
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 6,
                "deletions": 5,
                "changes": 11
            },
            {
                "filename": "tests/models/test_bert.py",
                "status": "modified",
                "additions": 35,
                "deletions": 19,
                "changes": 54
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c2407dec96630a7287a0d51cd4c22893c90d3e0a",
        "created_at": "2022-12-21 13:42:30 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-typo-in-config-train.gpu-train.gpu_mem",
        "files": [
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-hdim128-rotary-8k.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-hdim128-rotary.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-rotary-8k.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-rotary.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5fb6df0e04ea5f55bdb8d3440d883015c6807a8a",
        "created_at": "2022-12-18 21:47:27 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-BERT",
        "files": [
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn/models/bert.py",
                "status": "added",
                "additions": 426,
                "deletions": 0,
                "changes": 426
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "modified",
                "additions": 14,
                "deletions": 3,
                "changes": 17
            },
            {
                "filename": "flash_attn/modules/embedding.py",
                "status": "modified",
                "additions": 43,
                "deletions": 9,
                "changes": 52
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "modified",
                "additions": 76,
                "deletions": 23,
                "changes": 99
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            },
            {
                "filename": "tests/models/test_bert.py",
                "status": "added",
                "additions": 219,
                "deletions": 0,
                "changes": 219
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dc24c226037f696b7f18cf1c79460b014c2a1746",
        "created_at": "2022-12-17 11:22:06 -0800",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-92-from-ploshkin-rm-shape-asserts",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ee8984d2bed01f6dbf52db70d0f3cb815c20d505",
        "created_at": "2022-12-17 13:34:57 +0400",
        "author": "ploshkin",
        "committer": "ploshkin",
        "message": "add-asserts-for-sin-shape",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c7c66976cce3b1fa9281ddca02970bd383de9ebc",
        "created_at": "2022-12-16 15:39:06 +0400",
        "author": "ploshkin",
        "committer": "ploshkin",
        "message": "fix-slicing-dimensions",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 12,
                "deletions": 14,
                "changes": 26
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b78f5a392d3232cf7a220b8cb6e1a58b71d8f344",
        "created_at": "2022-12-15 19:49:04 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Mention-Megatron-LM",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "04c4c6106e2c055b4d13c0ebbd6f6a709fd0f5bc",
        "created_at": "2022-12-14 14:49:26 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v0.2.4",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ece8f05d09f539e1412dec17905e60f062126aef",
        "created_at": "2022-12-15 19:44:59 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Mention-PubMedGPT",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6b5f271c6d9f9a42a0f440c025b55f5a35119a13",
        "created_at": "2022-12-14 14:48:41 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Triton-Avoid-einops-repeat-by-using-Tensor.expand",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 2,
                "deletions": 12,
                "changes": 14
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "96656b93237423a86a7a95f6270d8b005d3dbbc5",
        "created_at": "2022-12-15 18:13:21 +0400",
        "author": "ploshkin",
        "committer": "ploshkin",
        "message": "Remove-redundant-shape-asserts-in-rotary-embeddings",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 0,
                "deletions": 2,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a1a5d2ee494bcd5482efe9dc80197d47d861d0e1",
        "created_at": "2022-12-13 01:37:02 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-to-v0.2.3",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5db330519a9fe8037ba5eb2b67b9dd1848189342",
        "created_at": "2022-12-12 22:16:14 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Support-taking-subset-of-input-or-subset-of-output",
        "files": [
            {
                "filename": "csrc/layer_norm/ln.h",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 71,
                "deletions": 15,
                "changes": 86
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_kernels.cuh",
                "status": "modified",
                "additions": 138,
                "deletions": 103,
                "changes": 241
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_kernels.cuh",
                "status": "modified",
                "additions": 49,
                "deletions": 33,
                "changes": 82
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 119,
                "deletions": 4,
                "changes": 123
            },
            {
                "filename": "tests/ops/test_dropout_layer_norm.py",
                "status": "modified",
                "additions": 267,
                "deletions": 17,
                "changes": 284
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "88c4e5dbf677dd184cf953599414e0be622835e1",
        "created_at": "2022-12-13 13:58:17 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-the-case-when-dout-is-not-contiguous",
        "files": [
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ae137ed17afd71db169fff816c6ca43096299756",
        "created_at": "2022-12-10 20:29:05 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Fuse-LayerScale",
        "files": [
            {
                "filename": "csrc/layer_norm/ln.h",
                "status": "modified",
                "additions": 8,
                "deletions": 1,
                "changes": 9
            },
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 58,
                "deletions": 133,
                "changes": 191
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_kernels.cuh",
                "status": "modified",
                "additions": 118,
                "deletions": 57,
                "changes": 175
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_kernels.cuh",
                "status": "modified",
                "additions": 45,
                "deletions": 44,
                "changes": 89
            },
            {
                "filename": "csrc/layer_norm/ln_kernel_traits.h",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4
            },
            {
                "filename": "csrc/layer_norm/ln_utils.cuh",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 47,
                "deletions": 80,
                "changes": 127
            },
            {
                "filename": "tests/ops/test_dropout_layer_norm.py",
                "status": "modified",
                "additions": 31,
                "deletions": 12,
                "changes": 43
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8c6609ae1a6841263d56bcbdef2d2949de1d46ad",
        "created_at": "2022-12-08 15:40:13 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Support-all-dimensions-up-to-6k-if-divisible-by-8",
        "files": [
            {
                "filename": "csrc/layer_norm/README.md",
                "status": "modified",
                "additions": 4,
                "deletions": 3,
                "changes": 7
            },
            {
                "filename": "csrc/layer_norm/ln.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "modified",
                "additions": 17,
                "deletions": 4,
                "changes": 21
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_1024.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_1280.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_1536.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_2048.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_256.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_2560.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_3072.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_4096.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_512.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_5120.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_6144.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_768.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_kernels.cuh",
                "status": "modified",
                "additions": 198,
                "deletions": 88,
                "changes": 286
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_semi_cuda_kernel.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 325,
                "changes": 325
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_1024.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_1280.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_1536.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_2048.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_256.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_2560.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_3072.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_4096.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_512.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_5120.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_6144.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_768.cu",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_cuda_kernel.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 302,
                "changes": 302
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_kernels.cuh",
                "status": "modified",
                "additions": 140,
                "deletions": 48,
                "changes": 188
            },
            {
                "filename": "csrc/layer_norm/ln_utils.cuh",
                "status": "modified",
                "additions": 27,
                "deletions": 18,
                "changes": 45
            },
            {
                "filename": "csrc/layer_norm/setup.py",
                "status": "modified",
                "additions": 24,
                "deletions": 2,
                "changes": 26
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "modified",
                "additions": 1,
                "deletions": 2,
                "changes": 3
            },
            {
                "filename": "tests/ops/test_dropout_layer_norm.py",
                "status": "modified",
                "additions": 8,
                "deletions": 3,
                "changes": 11
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8a2ece89f7bd5d3124a6cae5fd95db5e85f07ee6",
        "created_at": "2022-12-06 14:16:04 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Simplify-BOOL_SWITCH-macro-to-fix-compiling-error-on-gcc-7",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim128.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 3,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim32.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 3,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim64.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 3,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_launch_template.h",
                "status": "modified",
                "additions": 2,
                "deletions": 3,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim128.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim32.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim64.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_launch_template.h",
                "status": "modified",
                "additions": 2,
                "deletions": 3,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/fp16_switch.h",
                "status": "removed",
                "additions": 0,
                "deletions": 27,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 22,
                "deletions": 12,
                "changes": 34
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a84d07283c23d5afa10fece6927da088f7fff81e",
        "created_at": "2022-12-05 00:34:09 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Mention-FasterTransformer-integration",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4a6eaa9f27df6fff7ffb2c24e894938a687dd870",
        "created_at": "2022-11-29 04:13:51 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-configs-add-results",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 14,
                "deletions": 0,
                "changes": 14
            },
            {
                "filename": "assets/gpt2_training_curve.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/gpt2_training_efficiency.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/gpt3_training_curve.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/gpt3_training_efficiency.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "training/Dockerfile",
                "status": "modified",
                "additions": 0,
                "deletions": 8,
                "changes": 8
            },
            {
                "filename": "training/README.md",
                "status": "modified",
                "additions": 127,
                "deletions": 29,
                "changes": 156
            },
            {
                "filename": "training/configs/experiment/owt/gpt2l-flash.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/owt/gpt2m-flash.yaml",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/owt/gpt2xl-flash.yaml",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "training/configs/experiment/owt/gpt2xl-hf.yaml",
                "status": "added",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-8k.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-hdim128-rotary-8k.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-hdim128-rotary.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-hdim128.yaml",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-rotary-8k.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-rotary.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash.yaml",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-hf-hdim128.yaml",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-hf.yaml",
                "status": "added",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "training/configs/experiment/pile/gpt3l-hf.yaml",
                "status": "added",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "training/configs/experiment/pile/gpt3m-flash.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3m-hf.yaml",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "training/configs/experiment/pile/gpt3s-hf.yaml",
                "status": "added",
                "additions": 12,
                "deletions": 0,
                "changes": 12
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash-8k.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash-rotary-60B.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash-rotary-8k.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash-rotary.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash.yaml",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-hf.yaml",
                "status": "added",
                "additions": 35,
                "deletions": 0,
                "changes": 35
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9bc63d1e2dd3eee8cf0307036e077a752bd79fde",
        "created_at": "2022-11-25 16:35:08 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-typo-in-comments",
        "files": [
            {
                "filename": "csrc/flash_attn/src/.DS_Store",
                "status": "removed",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim128.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim32.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim64.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim128.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim32.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim64.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0bf5e50038ee341ece03bfd0c8ff45a6c57aed5a",
        "created_at": "2022-11-28 17:31:19 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Release-training-code",
        "files": [
            {
                "filename": "csrc/layer_norm/README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/Dockerfile",
                "status": "added",
                "additions": 107,
                "deletions": 0,
                "changes": 107
            },
            {
                "filename": "training/README.md",
                "status": "added",
                "additions": 133,
                "deletions": 0,
                "changes": 133
            },
            {
                "filename": "training/configs/callbacks/causality-monitor.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/callbacks/default.yaml",
                "status": "added",
                "additions": 45,
                "deletions": 0,
                "changes": 45
            },
            {
                "filename": "training/configs/callbacks/ema.yaml",
                "status": "added",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            },
            {
                "filename": "training/configs/callbacks/flop-count.yaml",
                "status": "added",
                "additions": 5,
                "deletions": 0,
                "changes": 5
            },
            {
                "filename": "training/configs/callbacks/gpu-monitor.yaml",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "training/configs/callbacks/model-summary.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/callbacks/none.yaml",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "training/configs/callbacks/norm-monitor.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/callbacks/params-log.yaml",
                "status": "added",
                "additions": 5,
                "deletions": 0,
                "changes": 5
            },
            {
                "filename": "training/configs/callbacks/wandb.yaml",
                "status": "added",
                "additions": 26,
                "deletions": 0,
                "changes": 26
            },
            {
                "filename": "training/configs/config.yaml",
                "status": "added",
                "additions": 50,
                "deletions": 0,
                "changes": 50
            },
            {
                "filename": "training/configs/datamodule/openwebtext.yaml",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "training/configs/datamodule/thepile.yaml",
                "status": "added",
                "additions": 14,
                "deletions": 0,
                "changes": 14
            },
            {
                "filename": "training/configs/experiment/owt/base.yaml",
                "status": "added",
                "additions": 82,
                "deletions": 0,
                "changes": 82
            },
            {
                "filename": "training/configs/experiment/owt/gpt2l-flash.yaml",
                "status": "added",
                "additions": 41,
                "deletions": 0,
                "changes": 41
            },
            {
                "filename": "training/configs/experiment/owt/gpt2l-hf.yaml",
                "status": "added",
                "additions": 14,
                "deletions": 0,
                "changes": 14
            },
            {
                "filename": "training/configs/experiment/owt/gpt2l.yaml",
                "status": "added",
                "additions": 14,
                "deletions": 0,
                "changes": 14
            },
            {
                "filename": "training/configs/experiment/owt/gpt2m-flash.yaml",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "training/configs/experiment/owt/gpt2m-hf.yaml",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "training/configs/experiment/owt/gpt2m.yaml",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "training/configs/experiment/owt/gpt2s-flash.yaml",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "training/configs/experiment/owt/gpt2s-hf.yaml",
                "status": "added",
                "additions": 23,
                "deletions": 0,
                "changes": 23
            },
            {
                "filename": "training/configs/experiment/owt/gpt2s.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/owt/gpt2xl-flash.yaml",
                "status": "added",
                "additions": 21,
                "deletions": 0,
                "changes": 21
            },
            {
                "filename": "training/configs/experiment/owt/gpt2xl.yaml",
                "status": "added",
                "additions": 14,
                "deletions": 0,
                "changes": 14
            },
            {
                "filename": "training/configs/experiment/pile/base.yaml",
                "status": "added",
                "additions": 83,
                "deletions": 0,
                "changes": 83
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-8k.yaml",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-hdim128-rotary-8k.yaml",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-hdim128-rotary.yaml",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-rotary-8k.yaml",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "training/configs/experiment/pile/gpt3-2.7B-flash-rotary.yaml",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "training/configs/experiment/pile/gpt3l-flash-8k.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/experiment/pile/gpt3l-flash-rotary-30B.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/experiment/pile/gpt3l-flash-rotary-8k.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/pile/gpt3l-flash-rotary.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/pile/gpt3l-flash.yaml",
                "status": "added",
                "additions": 24,
                "deletions": 0,
                "changes": 24
            },
            {
                "filename": "training/configs/experiment/pile/gpt3m-flash-8k.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/experiment/pile/gpt3m-flash-rotary-30B.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/experiment/pile/gpt3m-flash-rotary-8k.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/pile/gpt3m-flash-rotary.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/pile/gpt3m-flash.yaml",
                "status": "added",
                "additions": 16,
                "deletions": 0,
                "changes": 16
            },
            {
                "filename": "training/configs/experiment/pile/gpt3s-flash-8k.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/experiment/pile/gpt3s-flash-rotary-30B.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/experiment/pile/gpt3s-flash-rotary-8k.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/pile/gpt3s-flash-rotary.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/pile/gpt3s-flash.yaml",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash-8k.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash-rotary-60B.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash-rotary-8k.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash-rotary.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/experiment/pile/gpt3xl-flash.yaml",
                "status": "added",
                "additions": 35,
                "deletions": 0,
                "changes": 35
            },
            {
                "filename": "training/configs/logger/comet.yaml",
                "status": "added",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "training/configs/logger/csv.yaml",
                "status": "added",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "training/configs/logger/many_loggers.yaml",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "training/configs/logger/mlflow.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/logger/neptune.yaml",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "training/configs/logger/tensorboard.yaml",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "training/configs/logger/wandb.yaml",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": "training/configs/metrics/acc.yaml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "training/configs/metrics/acc_ignore_index.yaml",
                "status": "added",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            },
            {
                "filename": "training/configs/metrics/acctop5.yaml",
                "status": "added",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            },
            {
                "filename": "training/configs/metrics/mse.yaml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "training/configs/metrics/num-tokens.yaml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "training/configs/metrics/perplexity.yaml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "training/configs/mode/debug.yaml",
                "status": "added",
                "additions": 27,
                "deletions": 0,
                "changes": 27
            },
            {
                "filename": "training/configs/mode/default.yaml",
                "status": "added",
                "additions": 13,
                "deletions": 0,
                "changes": 13
            },
            {
                "filename": "training/configs/mode/exp.yaml",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "training/configs/mode/profile.yaml",
                "status": "added",
                "additions": 31,
                "deletions": 0,
                "changes": 31
            },
            {
                "filename": "training/configs/mode/smoke.yaml",
                "status": "added",
                "additions": 22,
                "deletions": 0,
                "changes": 22
            },
            {
                "filename": "training/configs/model/gpt2-hf.yaml",
                "status": "added",
                "additions": 13,
                "deletions": 0,
                "changes": 13
            },
            {
                "filename": "training/configs/model/gpt2.yaml",
                "status": "added",
                "additions": 13,
                "deletions": 0,
                "changes": 13
            },
            {
                "filename": "training/configs/model/gpt2model/gpt2-large.yaml",
                "status": "added",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "training/configs/model/gpt2model/gpt2-medium.yaml",
                "status": "added",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "training/configs/model/gpt2model/gpt2-small.yaml",
                "status": "added",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "training/configs/model/gpt2model/gpt2-xlarge.yaml",
                "status": "added",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "training/configs/optimizer/adam.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/optimizer/adamw-apex-distributed.yaml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "training/configs/optimizer/adamw-apex-zero.yaml",
                "status": "added",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "training/configs/optimizer/adamw-apex.yaml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "training/configs/optimizer/adamw-zero.yaml",
                "status": "added",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "training/configs/optimizer/adamw.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/optimizer/fusedlamb-ds.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/optimizer/fusedlamb.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/optimizer/sgd.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/scheduler/cosine-warmup-timm.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/scheduler/cosine-warmup.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/scheduler/invsqrt.yaml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "training/configs/scheduler/linear-warmup.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/scheduler/multi-step.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/scheduler/plateau.yaml",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "training/configs/scheduler/poly-warmup.yaml",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "training/configs/scheduler/step.yaml",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "training/configs/task/sequence-model.yaml",
                "status": "added",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "training/configs/trainer/all_params.yaml",
                "status": "added",
                "additions": 49,
                "deletions": 0,
                "changes": 49
            },
            {
                "filename": "training/configs/trainer/ddp.yaml",
                "status": "added",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "training/configs/trainer/debug.yaml",
                "status": "added",
                "additions": 21,
                "deletions": 0,
                "changes": 21
            },
            {
                "filename": "training/configs/trainer/default.yaml",
                "status": "added",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "training/run.py",
                "status": "added",
                "additions": 68,
                "deletions": 0,
                "changes": 68
            },
            {
                "filename": "training/src/callbacks/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "training/src/callbacks/causality_monitor.py",
                "status": "added",
                "additions": 61,
                "deletions": 0,
                "changes": 61
            },
            {
                "filename": "training/src/callbacks/ema.py",
                "status": "added",
                "additions": 82,
                "deletions": 0,
                "changes": 82
            },
            {
                "filename": "training/src/callbacks/flop_count.py",
                "status": "added",
                "additions": 43,
                "deletions": 0,
                "changes": 43
            },
            {
                "filename": "training/src/callbacks/gpu_affinity.py",
                "status": "added",
                "additions": 40,
                "deletions": 0,
                "changes": 40
            },
            {
                "filename": "training/src/callbacks/loss_scale_monitor.py",
                "status": "added",
                "additions": 32,
                "deletions": 0,
                "changes": 32
            },
            {
                "filename": "training/src/callbacks/model_checkpoint.py",
                "status": "added",
                "additions": 36,
                "deletions": 0,
                "changes": 36
            },
            {
                "filename": "training/src/callbacks/norm_monitor.py",
                "status": "added",
                "additions": 79,
                "deletions": 0,
                "changes": 79
            },
            {
                "filename": "training/src/callbacks/params_log.py",
                "status": "added",
                "additions": 34,
                "deletions": 0,
                "changes": 34
            },
            {
                "filename": "training/src/callbacks/speed_monitor.py",
                "status": "added",
                "additions": 95,
                "deletions": 0,
                "changes": 95
            },
            {
                "filename": "training/src/callbacks/wandb_callbacks.py",
                "status": "added",
                "additions": 289,
                "deletions": 0,
                "changes": 289
            },
            {
                "filename": "training/src/datamodules/datasets/detokenizer.py",
                "status": "added",
                "additions": 53,
                "deletions": 0,
                "changes": 53
            },
            {
                "filename": "training/src/datamodules/datasets/lm_dataset.py",
                "status": "added",
                "additions": 32,
                "deletions": 0,
                "changes": 32
            },
            {
                "filename": "training/src/datamodules/fault_tolerant_sampler.py",
                "status": "added",
                "additions": 123,
                "deletions": 0,
                "changes": 123
            },
            {
                "filename": "training/src/datamodules/imagenet.py",
                "status": "added",
                "additions": 283,
                "deletions": 0,
                "changes": 283
            },
            {
                "filename": "training/src/datamodules/language_modeling_hf.py",
                "status": "added",
                "additions": 299,
                "deletions": 0,
                "changes": 299
            },
            {
                "filename": "training/src/datamodules/timm_mixup.py",
                "status": "added",
                "additions": 20,
                "deletions": 0,
                "changes": 20
            },
            {
                "filename": "training/src/distributed/ddp_comm_hooks.py",
                "status": "added",
                "additions": 43,
                "deletions": 0,
                "changes": 43
            },
            {
                "filename": "training/src/eval.py",
                "status": "added",
                "additions": 129,
                "deletions": 0,
                "changes": 129
            },
            {
                "filename": "training/src/losses/cross_entropy_apex.py",
                "status": "added",
                "additions": 51,
                "deletions": 0,
                "changes": 51
            },
            {
                "filename": "training/src/losses/cross_entropy_parallel.py",
                "status": "added",
                "additions": 112,
                "deletions": 0,
                "changes": 112
            },
            {
                "filename": "training/src/metrics/accuracy.py",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "training/src/metrics/num_tokens.py",
                "status": "added",
                "additions": 45,
                "deletions": 0,
                "changes": 45
            },
            {
                "filename": "training/src/metrics/perplexity.py",
                "status": "added",
                "additions": 70,
                "deletions": 0,
                "changes": 70
            },
            {
                "filename": "training/src/models/modules/seq_common.py",
                "status": "added",
                "additions": 342,
                "deletions": 0,
                "changes": 342
            },
            {
                "filename": "training/src/optim/param_grouping.py",
                "status": "added",
                "additions": 114,
                "deletions": 0,
                "changes": 114
            },
            {
                "filename": "training/src/optim/timm_lr_scheduler.py",
                "status": "added",
                "additions": 30,
                "deletions": 0,
                "changes": 30
            },
            {
                "filename": "training/src/tasks/seq.py",
                "status": "added",
                "additions": 192,
                "deletions": 0,
                "changes": 192
            },
            {
                "filename": "training/src/train.py",
                "status": "added",
                "additions": 136,
                "deletions": 0,
                "changes": 136
            },
            {
                "filename": "training/src/utils/checkpoint.py",
                "status": "added",
                "additions": 76,
                "deletions": 0,
                "changes": 76
            },
            {
                "filename": "training/src/utils/ddp_zero1.py",
                "status": "added",
                "additions": 101,
                "deletions": 0,
                "changes": 101
            },
            {
                "filename": "training/src/utils/ddp_zero2.py",
                "status": "added",
                "additions": 141,
                "deletions": 0,
                "changes": 141
            },
            {
                "filename": "training/src/utils/distributed.py",
                "status": "added",
                "additions": 111,
                "deletions": 0,
                "changes": 111
            },
            {
                "filename": "training/src/utils/ema.py",
                "status": "added",
                "additions": 280,
                "deletions": 0,
                "changes": 280
            },
            {
                "filename": "training/src/utils/flops.py",
                "status": "added",
                "additions": 45,
                "deletions": 0,
                "changes": 45
            },
            {
                "filename": "training/src/utils/gpu_affinity.py",
                "status": "added",
                "additions": 142,
                "deletions": 0,
                "changes": 142
            },
            {
                "filename": "training/src/utils/utils.py",
                "status": "added",
                "additions": 146,
                "deletions": 0,
                "changes": 146
            },
            {
                "filename": "training/tests/datamodules/test_language_modeling_hf.py",
                "status": "added",
                "additions": 218,
                "deletions": 0,
                "changes": 218
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d95ee1a95da2b138073b5eef0f09ce4de615ba5e",
        "created_at": "2022-11-25 16:29:17 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Speed-up-compilation-by-splitting-into-separate-.cu-files",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 21,
                "deletions": 2,
                "changes": 23
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim128.cu",
                "status": "added",
                "additions": 13,
                "deletions": 0,
                "changes": 13
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim32.cu",
                "status": "added",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_hdim64.cu",
                "status": "added",
                "additions": 31,
                "deletions": 0,
                "changes": 31
            },
            {
                "filename": "csrc/flash_attn/src/fmha_bwd_launch_template.h",
                "status": "modified",
                "additions": 17,
                "deletions": 55,
                "changes": 72
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 153,
                "changes": 153
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim128.cu",
                "status": "added",
                "additions": 12,
                "deletions": 0,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim32.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_hdim64.cu",
                "status": "added",
                "additions": 17,
                "deletions": 0,
                "changes": 17
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fwd_launch_template.h",
                "status": "added",
                "additions": 92,
                "deletions": 0,
                "changes": 92
            },
            {
                "filename": "csrc/flash_attn/src/fmha_kernel.h",
                "status": "modified",
                "additions": 0,
                "deletions": 103,
                "changes": 103
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 7,
                "deletions": 3,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b784ed73cf89cc1c820d18a4bf6f232f91004b47",
        "created_at": "2022-11-25 10:49:17 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Clarify-OpenFold-speedup",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d9021ae4ec8bc850c86ac071e9b0732b9d0e2e51",
        "created_at": "2022-11-23 13:01:19 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Mention-OpenFold",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b8ccd20098934da5667ddf4a2675a502bf7330eb",
        "created_at": "2022-11-22 02:07:32 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Triton-Fix-variable-name-from-qkv-to-kv-h-t-FrankZijlstra",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "45bcf37b975006fe935e5ed888e70e26ac370c90",
        "created_at": "2022-11-22 02:12:22 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Docs-Capitalize-the-bibtex-citation",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1feb94265c276dac0ba8c6cd32c436afca93d948",
        "created_at": "2022-11-23 12:48:56 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "ViT-Use-dropout_add_ln-for-the-1st-layer-norm",
        "files": [
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "modified",
                "additions": 7,
                "deletions": 7,
                "changes": 14
            },
            {
                "filename": "flash_attn/models/vit.py",
                "status": "modified",
                "additions": 20,
                "deletions": 2,
                "changes": 22
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "modified",
                "additions": 0,
                "deletions": 1,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "054816177e5bfe8f1e9883d9e03fe9bb8473410c",
        "created_at": "2022-11-20 22:35:59 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bump-version-to-0.2.1",
        "files": [
            {
                "filename": "flash_attn/losses/cross_entropy_parallel.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "71f674ae23e69af55b09ea75d81ee1b5010f9244",
        "created_at": "2022-11-17 11:43:36 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Rotary-Customize-base-support-seqlen_offset",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 12,
                "deletions": 7,
                "changes": 19
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0fa5c0d7ef8cb3738711b2c23d424e272c11d7bb",
        "created_at": "2022-11-17 16:56:06 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-PatchEmbed",
        "files": [
            {
                "filename": "flash_attn/layers/patch_embed.py",
                "status": "added",
                "additions": 56,
                "deletions": 0,
                "changes": 56
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ece539abd6de8044d7f491654cc4d1a02edc071b",
        "created_at": "2022-11-17 16:55:44 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-__init__.py-files-to-subdirectories-for-installation",
        "files": [
            {
                "filename": "flash_attn/layers/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/losses/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/models/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/modules/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/ops/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/utils/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "39ed597b289db83db0130bf988bfd2e989afd5cf",
        "created_at": "2022-11-17 11:45:11 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Compile-for-both-sm70-and-sm80",
        "files": [
            {
                "filename": "csrc/layer_norm/setup.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d6ef701aa99bd1c5f7e0c277f4a8aed0462ce1f5",
        "created_at": "2022-11-15 14:15:05 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Set-version-to-0.2.0-instead-of-0.2",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "56aa49037d906ff35fdad28fedda94426c69f26a",
        "created_at": "2022-11-15 13:55:59 -0800",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-75-from-lucidrains-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4040256b5e4b2f8a3fd5f314d61c1d87171aff49",
        "created_at": "2022-11-15 14:10:36 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-pip-install-instructions-bump-to-0.2",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 8,
                "deletions": 3,
                "changes": 11
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dcf39865900c2d37e5f17745154f99709858701e",
        "created_at": "2022-11-15 13:38:13 -0800",
        "author": "lucidrains",
        "committer": "lucidrains",
        "message": "update-manifest",
        "files": [
            {
                "filename": "MANIFEST.in",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b0eac3297fecf4fe604f7b937a72d9f59c1b70c6",
        "created_at": "2022-11-15 13:26:55 -0800",
        "author": "lucidrains",
        "committer": "lucidrains",
        "message": "allow-for-uploading-to-pypi",
        "files": [
            {
                "filename": ".gitignore",
                "status": "added",
                "additions": 21,
                "deletions": 0,
                "changes": 21
            },
            {
                "filename": "MANIFEST.in",
                "status": "added",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "Makefile",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e4d3013e154e6f8f149f36f91366c315962e3a9a",
        "created_at": "2022-11-15 07:05:13 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "LayerNorm-Check-cuda-error-after-querying-ctas_per_sm",
        "files": [
            {
                "filename": "csrc/layer_norm/ln_bwd_semi_cuda_kernel.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_cuda_kernel.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "43ab0b5205decb1f8a8e499d03de529703700cb4",
        "created_at": "2022-11-15 07:10:25 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Mention-that-some-CUDA-extensions-have-only-been-tested-on-A100s",
        "files": [
            {
                "filename": "csrc/fused_dense_lib/README.md",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/layer_norm/README.md",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/xentropy/README.md",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b0ed0a73fdf1b905af84a5e4561201b773ee625c",
        "created_at": "2022-11-14 10:01:16 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Mention-DeepSpeed-inference-in-usage.md",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "25387b24c1495c61ccc96c89ff4fdd9cbcb7fa5f",
        "created_at": "2022-11-14 09:31:55 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Mention-AITemplate-Stable-Diffusion-in-usage.md",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 16,
                "deletions": 9,
                "changes": 25
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d4b320b31f35608ad9c652c888b639f6b1e792ea",
        "created_at": "2022-11-13 22:06:44 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-MLP-MHA-Block-Embedding-modules",
        "files": [
            {
                "filename": "flash_attn/layers/rotary.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/modules/block.py",
                "status": "added",
                "additions": 129,
                "deletions": 0,
                "changes": 129
            },
            {
                "filename": "flash_attn/modules/embedding.py",
                "status": "added",
                "additions": 35,
                "deletions": 0,
                "changes": 35
            },
            {
                "filename": "flash_attn/modules/mha.py",
                "status": "added",
                "additions": 319,
                "deletions": 0,
                "changes": 319
            },
            {
                "filename": "flash_attn/modules/mlp.py",
                "status": "added",
                "additions": 72,
                "deletions": 0,
                "changes": 72
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "modified",
                "additions": 0,
                "deletions": 2,
                "changes": 2
            },
            {
                "filename": "tests/test_rotary.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2e33fc8e36ee60ea60b5d91ab4a7bc3eb42e0662",
        "created_at": "2022-11-13 22:13:44 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-GPT-and-ViT-models",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "csrc/fused_dense_lib/README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/layer_norm/README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn/models/gpt.py",
                "status": "added",
                "additions": 174,
                "deletions": 0,
                "changes": 174
            },
            {
                "filename": "flash_attn/models/vit.py",
                "status": "added",
                "additions": 249,
                "deletions": 0,
                "changes": 249
            },
            {
                "filename": "flash_attn/ops/triton/k_activations.py",
                "status": "added",
                "additions": 162,
                "deletions": 0,
                "changes": 162
            },
            {
                "filename": "flash_attn/ops/triton/linear.py",
                "status": "added",
                "additions": 479,
                "deletions": 0,
                "changes": 479
            },
            {
                "filename": "flash_attn/ops/triton/mlp.py",
                "status": "added",
                "additions": 140,
                "deletions": 0,
                "changes": 140
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "fa6d1ce44fc2c8f9fe6330b5e98697fdc434e729",
        "created_at": "2022-11-13 21:52:00 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-fused_dense-and-dropout_add_layernorm-CUDA-extensions",
        "files": [
            {
                "filename": "csrc/fused_dense_lib/README.md",
                "status": "added",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            },
            {
                "filename": "csrc/fused_dense_lib/fused_dense.cpp",
                "status": "added",
                "additions": 356,
                "deletions": 0,
                "changes": 356
            },
            {
                "filename": "csrc/fused_dense_lib/fused_dense_cuda.cu",
                "status": "added",
                "additions": 1336,
                "deletions": 0,
                "changes": 1336
            },
            {
                "filename": "csrc/fused_dense_lib/setup.py",
                "status": "added",
                "additions": 42,
                "deletions": 0,
                "changes": 42
            },
            {
                "filename": "csrc/layer_norm/README.md",
                "status": "added",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "csrc/layer_norm/ln.h",
                "status": "added",
                "additions": 226,
                "deletions": 0,
                "changes": 226
            },
            {
                "filename": "csrc/layer_norm/ln_api.cpp",
                "status": "added",
                "additions": 455,
                "deletions": 0,
                "changes": 455
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_kernels.cuh",
                "status": "added",
                "additions": 328,
                "deletions": 0,
                "changes": 328
            },
            {
                "filename": "csrc/layer_norm/ln_bwd_semi_cuda_kernel.cu",
                "status": "added",
                "additions": 325,
                "deletions": 0,
                "changes": 325
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_cuda_kernel.cu",
                "status": "added",
                "additions": 302,
                "deletions": 0,
                "changes": 302
            },
            {
                "filename": "csrc/layer_norm/ln_fwd_kernels.cuh",
                "status": "added",
                "additions": 159,
                "deletions": 0,
                "changes": 159
            },
            {
                "filename": "csrc/layer_norm/ln_kernel_traits.h",
                "status": "added",
                "additions": 170,
                "deletions": 0,
                "changes": 170
            },
            {
                "filename": "csrc/layer_norm/ln_utils.cuh",
                "status": "added",
                "additions": 734,
                "deletions": 0,
                "changes": 734
            },
            {
                "filename": "csrc/layer_norm/setup.py",
                "status": "added",
                "additions": 143,
                "deletions": 0,
                "changes": 143
            },
            {
                "filename": "csrc/layer_norm/static_switch.h",
                "status": "added",
                "additions": 25,
                "deletions": 0,
                "changes": 25
            },
            {
                "filename": "csrc/xentropy/README.md",
                "status": "added",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "flash_attn/ops/fused_dense.py",
                "status": "added",
                "additions": 358,
                "deletions": 0,
                "changes": 358
            },
            {
                "filename": "flash_attn/ops/gelu_activation.py",
                "status": "added",
                "additions": 82,
                "deletions": 0,
                "changes": 82
            },
            {
                "filename": "flash_attn/ops/layer_norm.py",
                "status": "added",
                "additions": 167,
                "deletions": 0,
                "changes": 167
            },
            {
                "filename": "tests/ops/test_dropout_layer_norm.py",
                "status": "added",
                "additions": 267,
                "deletions": 0,
                "changes": 267
            },
            {
                "filename": "tests/ops/test_fused_dense.py",
                "status": "added",
                "additions": 154,
                "deletions": 0,
                "changes": 154
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "343492ec305d474bcf6e45bc05893bbc040fcc30",
        "created_at": "2022-11-13 17:27:26 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Make-nccl-operations-async-in-CrossEntropyLossParallel",
        "files": [
            {
                "filename": "flash_attn/losses/cross_entropy_parallel.py",
                "status": "modified",
                "additions": 34,
                "deletions": 24,
                "changes": 58
            },
            {
                "filename": "tests/losses/test_cross_entropy_apex.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "tests/losses/test_cross_entropy_parallel.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b92f2c3b67ab338c4feb7213c88530165e4fb976",
        "created_at": "2022-11-13 20:49:05 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Link-to-Colossal-AI-s-stable-diffusion-in-usage.md",
        "files": [
            {
                "filename": "usage.md",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "3dda4f76deeee9e17ad03e8608d33e7a5fa714bf",
        "created_at": "2022-11-13 16:49:11 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Update-README",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 7,
                "deletions": 1,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "79160a69a944c22dc170327e9d7c5f0264c4123e",
        "created_at": "2022-11-13 16:40:18 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-a-page-on-where-FlashAttention-is-being-used",
        "files": [
            {
                "filename": "usage.md",
                "status": "added",
                "additions": 86,
                "deletions": 0,
                "changes": 86
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9d3116addf00e585eaf3f249a6543f5970365288",
        "created_at": "2022-11-13 12:21:03 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Don-t-enforce-bitwise-consistency-for-dq-in-race-condition-test",
        "files": [
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 6,
                "deletions": 1,
                "changes": 7
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a8fec99a9ac2e971cc2b0b7e8ab41139d4c93ad5",
        "created_at": "2022-11-13 12:27:48 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Skip-flash_attn_split-test",
        "files": [
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "7c9953815aa04bb61e24237ffc29780708cc9c8e",
        "created_at": "2022-11-12 19:49:33 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-fused-cross-entropy-loss",
        "files": [
            {
                "filename": "csrc/xentropy/interface.cpp",
                "status": "added",
                "additions": 51,
                "deletions": 0,
                "changes": 51
            },
            {
                "filename": "csrc/xentropy/setup.py",
                "status": "added",
                "additions": 131,
                "deletions": 0,
                "changes": 131
            },
            {
                "filename": "csrc/xentropy/xentropy_kernel.cu",
                "status": "added",
                "additions": 754,
                "deletions": 0,
                "changes": 754
            },
            {
                "filename": "flash_attn/losses/cross_entropy_apex.py",
                "status": "added",
                "additions": 51,
                "deletions": 0,
                "changes": 51
            },
            {
                "filename": "flash_attn/losses/cross_entropy_parallel.py",
                "status": "added",
                "additions": 112,
                "deletions": 0,
                "changes": 112
            },
            {
                "filename": "tests/losses/test_cross_entropy_apex.py",
                "status": "added",
                "additions": 39,
                "deletions": 0,
                "changes": 39
            },
            {
                "filename": "tests/losses/test_cross_entropy_parallel.py",
                "status": "added",
                "additions": 56,
                "deletions": 0,
                "changes": 56
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "908a5b2244850fb299d22a23345723e61b0c4613",
        "created_at": "2022-11-07 08:58:16 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Set-num_warps-4-for-headdim-64-in-Triton-fw-h-t-Michael-Benesty",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 14,
                "deletions": 13,
                "changes": 27
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6998e0ecdba7aa06e1dc22357ef9729ac06af5f4",
        "created_at": "2022-11-09 08:17:37 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-out-of-bound-memory-read",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 18,
                "deletions": 0,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 7,
                "deletions": 2,
                "changes": 9
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "7479757191c04cc1d5a029b0b34c5064278c93ef",
        "created_at": "2022-11-06 11:46:55 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-pipelining-bug-in-Triton-bwd-with-bias_type-matrix",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 36,
                "deletions": 16,
                "changes": 52
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 10,
                "deletions": 10,
                "changes": 20
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "55797f32c949ce6c3a6539bc09b9b4ff646413b3",
        "created_at": "2022-11-10 11:54:36 -0800",
        "author": "tridao",
        "committer": "tridao",
        "message": "Remove-RotaryEmbedding-from-FlashAttention-module",
        "files": [
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 3,
                "deletions": 17,
                "changes": 20
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "557781933dbc13cc4e75626bb064b4784869426f",
        "created_at": "2022-11-05 16:26:17 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Parallelize-CUDA-bwd-along-seqlen_k-instead-of-seqlen_q",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 10,
                "deletions": 14,
                "changes": 24
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 21,
                "deletions": 51,
                "changes": 72
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 45,
                "deletions": 33,
                "changes": 78
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 150,
                "deletions": 68,
                "changes": 218
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 5,
                "deletions": 4,
                "changes": 9
            },
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 5,
                "deletions": 4,
                "changes": 9
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ca81f32e04b3dcab69ff919322abab578a26d12f",
        "created_at": "2022-11-04 22:42:01 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-rotary-embedding-in-CUDA",
        "files": [
            {
                "filename": "csrc/rotary/rotary.cpp",
                "status": "added",
                "additions": 34,
                "deletions": 0,
                "changes": 34
            },
            {
                "filename": "csrc/rotary/rotary_cuda.cu",
                "status": "added",
                "additions": 41,
                "deletions": 0,
                "changes": 41
            },
            {
                "filename": "csrc/rotary/setup.py",
                "status": "added",
                "additions": 118,
                "deletions": 0,
                "changes": 118
            },
            {
                "filename": "flash_attn/rotary.py",
                "status": "modified",
                "additions": 122,
                "deletions": 90,
                "changes": 212
            },
            {
                "filename": "tests/test_rotary.py",
                "status": "added",
                "additions": 44,
                "deletions": 0,
                "changes": 44
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "62025e1aff6df2ec2c349a0bfd3f57440b91e8e0",
        "created_at": "2022-11-04 12:38:18 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-more-race-condition-in-Triton-bwd-when-there-s-bias",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ff78ea4123a29e10dccade3d73b7c4869f383b6a",
        "created_at": "2022-11-04 11:20:27 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-race-condition-in-Triton-bwd-when-there-s-bias",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "470010f59b00a53f371e602cfcfd9bb2919f140d",
        "created_at": "2022-11-03 15:26:53 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-race-condition-for-Triton-bwd-for-headdim-48-and-96",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 19,
                "deletions": 22,
                "changes": 41
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "aacc10fbab8ce4d252524e9b18c6edcff02ffa88",
        "created_at": "2022-11-02 07:32:04 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-race-condition-in-Triton-bwd-for-non-po2-headdims",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 8,
                "deletions": 16,
                "changes": 24
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 15,
                "deletions": 11,
                "changes": 26
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "86862cfd7bab1fe0279d1cdcdf370268792339cb",
        "created_at": "2022-11-04 10:28:40 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-attention-bias-for-Triton-version",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 180,
                "deletions": 48,
                "changes": 228
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 45,
                "deletions": 16,
                "changes": 61
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1fb12afdfb65a0c89f6955a66f338b47c87d13ef",
        "created_at": "2022-11-01 15:06:45 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Avoid-memcpy-in-the-Triton-bwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 23,
                "deletions": 15,
                "changes": 38
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 14,
                "deletions": 8,
                "changes": 22
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "731f154de32834c474ae28f0173f2a36f79f4667",
        "created_at": "2022-11-01 14:09:22 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-race-conditions-in-the-Triton-bwd-for-headdim-64",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 20,
                "deletions": 12,
                "changes": 32
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "215930bce365dc31ed890edeee8517102ca2ee35",
        "created_at": "2022-10-31 01:41:49 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-EVEN_M-EVEN_HEADDIM-for-headdim-40-in-Triton-bwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 3,
                "deletions": 5,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4f81aff46e65277d6df30843e98327d4f2571b5f",
        "created_at": "2022-10-31 01:25:02 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-debug_barrier-for-all-headdims-in-Triton-bwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9b0bc978729d5470aaf5667b8f65df6fa2b3a007",
        "created_at": "2022-10-31 14:34:22 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-race-condition-in-Triton-fwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 15,
                "deletions": 5,
                "changes": 20
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 41,
                "deletions": 0,
                "changes": 41
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "bedcbd6a71cbf8470686a20934ac1ef2e70123cd",
        "created_at": "2022-10-31 01:05:31 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Disable-some-autotune-configs-that-give-wrong-results-in-Triton-bwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 6,
                "deletions": 5,
                "changes": 11
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e78d509c64bf6d203c7c0a26485f11b800ec5cbb",
        "created_at": "2022-10-31 00:46:22 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "WIP-Support-all-head-dimensions-up-to-128-in-the-Triton-bwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 122,
                "deletions": 60,
                "changes": 182
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 21,
                "deletions": 20,
                "changes": 41
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dc55469355d6715e4c9acbfd4c6d07c1ad6c7002",
        "created_at": "2022-10-30 21:26:26 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-arbitrary-seqlen_k-in-Triton-bwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 30,
                "deletions": 8,
                "changes": 38
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "008951f1d94a29eaeee48d25dbfa11df1ba12413",
        "created_at": "2022-10-30 22:10:48 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-all-head-dimensions-up-to-128-in-the-Triton-fwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 51,
                "deletions": 17,
                "changes": 68
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 17,
                "deletions": 14,
                "changes": 31
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b910bf14c1baa7e6a4886c1cd07d65e7a61390c0",
        "created_at": "2022-10-30 21:50:53 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-arbitrary-seqlens-both-q-k-in-Triton-bwd",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 27,
                "deletions": 14,
                "changes": 41
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 15,
                "deletions": 18,
                "changes": 33
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d11341fd1a6913272666123baecfc32b3804f928",
        "created_at": "2022-10-30 19:04:00 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-Triton-fwd-to-support-seqlen-not-multiples-of-128",
        "files": [
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "modified",
                "additions": 9,
                "deletions": 6,
                "changes": 15
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 22,
                "deletions": 17,
                "changes": 39
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b0c0db81f64cf8d2adc8d5fd962a49cd3e9396a4",
        "created_at": "2022-10-30 18:06:06 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-FlashAttention-in-Triton",
        "files": [
            {
                "filename": "benchmarks/benchmark_causal.py",
                "status": "modified",
                "additions": 13,
                "deletions": 16,
                "changes": 29
            },
            {
                "filename": "flash_attn/flash_attn_triton.py",
                "status": "added",
                "additions": 529,
                "deletions": 0,
                "changes": 529
            },
            {
                "filename": "flash_attn/flash_attn_triton_og.py",
                "status": "modified",
                "additions": 5,
                "deletions": 93,
                "changes": 98
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 55,
                "deletions": 0,
                "changes": 55
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "46fd2a20b20849598b1abb438ea09520449d7eb3",
        "created_at": "2022-10-24 16:02:03 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-all-head-dims-that-are-multiples-of-8-up-to-128",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 16,
                "deletions": 10,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 18,
                "deletions": 9,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 10,
                "deletions": 5,
                "changes": 15
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 7,
                "deletions": 20,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 18,
                "deletions": 9,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 7,
                "deletions": 20,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 10,
                "deletions": 5,
                "changes": 15
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 17,
                "deletions": 17,
                "changes": 34
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c422fee3776eb3ea24e011ef641fd5fbeb212623",
        "created_at": "2022-10-24 17:29:36 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Get-rid-of-o_rows_are_valid-since-we-don-t-have-headdim-16-anymore",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 4,
                "deletions": 13,
                "changes": 17
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "97e13de2b40a95ea8510766e8073a9ca6ba6d945",
        "created_at": "2022-10-24 15:59:49 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Cast-q.get_device-to-char-to-avoid-compiler-warning-narrowing",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ed553e92387a5f193f0a1f3792e1d4fd1eb5123e",
        "created_at": "2022-10-23 23:04:16 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-Megatron-attention-implementation-for-benchmarking",
        "files": [
            {
                "filename": "benchmarks/benchmark_causal.py",
                "status": "modified",
                "additions": 32,
                "deletions": 3,
                "changes": 35
            },
            {
                "filename": "csrc/fused_softmax/fused_softmax.cpp",
                "status": "added",
                "additions": 148,
                "deletions": 0,
                "changes": 148
            },
            {
                "filename": "csrc/fused_softmax/scaled_masked_softmax.h",
                "status": "added",
                "additions": 528,
                "deletions": 0,
                "changes": 528
            },
            {
                "filename": "csrc/fused_softmax/scaled_masked_softmax_cuda.cu",
                "status": "added",
                "additions": 121,
                "deletions": 0,
                "changes": 121
            },
            {
                "filename": "csrc/fused_softmax/scaled_upper_triang_masked_softmax.h",
                "status": "added",
                "additions": 529,
                "deletions": 0,
                "changes": 529
            },
            {
                "filename": "csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu",
                "status": "added",
                "additions": 98,
                "deletions": 0,
                "changes": 98
            },
            {
                "filename": "csrc/fused_softmax/setup.py",
                "status": "added",
                "additions": 49,
                "deletions": 0,
                "changes": 49
            },
            {
                "filename": "csrc/fused_softmax/type_shim.h",
                "status": "added",
                "additions": 20,
                "deletions": 0,
                "changes": 20
            },
            {
                "filename": "flash_attn/fused_softmax.py",
                "status": "added",
                "additions": 205,
                "deletions": 0,
                "changes": 205
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "50ca23488ddb460cb9bda5e38bff578391789d2d",
        "created_at": "2022-10-23 17:01:31 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-Triton-implementation-for-benchmarking",
        "files": [
            {
                "filename": "benchmarks/benchmark_causal.py",
                "status": "added",
                "additions": 79,
                "deletions": 0,
                "changes": 79
            },
            {
                "filename": "flash_attn/triton/fused_attention.py",
                "status": "added",
                "additions": 364,
                "deletions": 0,
                "changes": 364
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9e92a1f2d22622c3f9adbbcf8472c0a3e662e788",
        "created_at": "2022-10-23 16:22:43 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Attempt-to-use-atomicCAS-to-replace-atomicAdd-bfloat16",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 13,
                "deletions": 0,
                "changes": 13
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "fb88e5e4b332aa2682413f850084ea4040ba6747",
        "created_at": "2022-10-23 12:50:00 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Move-benchmark-utils-support-AMP",
        "files": [
            {
                "filename": "benchmarks/benchmark_flash_attention.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn/utils/benchmark.py",
                "status": "modified",
                "additions": 52,
                "deletions": 35,
                "changes": 87
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a5a8806d1a4405d4521380e9a8a56f0d02a5ece3",
        "created_at": "2022-10-23 11:35:15 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Split-bwd-on-the-seqlen_q-dimension",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 24,
                "deletions": 3,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 42,
                "deletions": 2,
                "changes": 44
            },
            {
                "filename": "csrc/flash_attn/src/fmha/kernel_traits.h",
                "status": "modified",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 62,
                "deletions": 40,
                "changes": 102
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 52,
                "deletions": 30,
                "changes": 82
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 0,
                "deletions": 35,
                "changes": 35
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 9,
                "deletions": 6,
                "changes": 15
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 5,
                "deletions": 3,
                "changes": 8
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6731855b1f8861188ddabcb8e388d425ab16f8a5",
        "created_at": "2022-10-23 12:52:51 -0700",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-61-from-robotcator-workflow",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "871db479416a58c584da5643955d80c1847c98d9",
        "created_at": "2022-10-21 18:22:27 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Don-t-need-to-run-configure-for-the-forward-pass",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 3,
                "deletions": 5,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 18,
                "deletions": 31,
                "changes": 49
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 8,
                "deletions": 5,
                "changes": 13
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1aa6d7d9b60bf8fbb5584f057934bdee15ed33fe",
        "created_at": "2022-10-18 23:04:01 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Rework-dropout-to-decouple-forward-and-backward",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha/mask.h",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "modified",
                "additions": 13,
                "deletions": 0,
                "changes": 13
            },
            {
                "filename": "csrc/flash_attn/src/fmha/softmax.h",
                "status": "modified",
                "additions": 24,
                "deletions": 56,
                "changes": 80
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 7,
                "deletions": 3,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 3,
                "deletions": 13,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 24,
                "deletions": 11,
                "changes": 35
            },
            {
                "filename": "csrc/flash_attn/src/philox.cuh",
                "status": "modified",
                "additions": 71,
                "deletions": 58,
                "changes": 129
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 2,
                "deletions": 4,
                "changes": 6
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "7fc39832e2f1bac23ece617fd51d9ffb5d020791",
        "created_at": "2022-10-21 13:19:54 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Use-block_size-128-for-headdim-128-on-SM80",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 11,
                "deletions": 14,
                "changes": 25
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a44f48df5ab9166089003d048a6e69f6c02aee0b",
        "created_at": "2022-10-21 11:58:14 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Split-fwd-on-the-seqlen_q-dimension",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 18,
                "deletions": 8,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 42,
                "deletions": 5,
                "changes": 47
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 41,
                "deletions": 30,
                "changes": 71
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 8,
                "deletions": 2,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1d0b41be3b0fa759502e274779db6758617fc7b9",
        "created_at": "2022-10-17 09:38:48 -0700",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-60-from-201419-patch-1",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "35d589fa81a68b7cb806982af4fafac0f19d644d",
        "created_at": "2022-10-17 17:41:37 +0800",
        "author": "robotcator",
        "committer": "robotcator",
        "message": "Merge-branch-main-of-github.com-robotcator-flash-attention-into-workflow",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "10d074596681d1bb00c2993baf30073b7c15c244",
        "created_at": "2022-10-17 17:39:08 +0800",
        "author": "robotcator",
        "committer": "robotcator",
        "message": "using-tag-trigger-rather-than-push-trigger",
        "files": [
            {
                "filename": ".github/workflows/publish.yml",
                "status": "modified",
                "additions": 3,
                "deletions": 6,
                "changes": 9
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ff07250e8fede23687c2cbc42a24e98d40b32683",
        "created_at": "2022-10-17 16:13:47 +0800",
        "author": "201419",
        "committer": "web-flow",
        "message": "fix-typo-in-function-mha_fwd",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1b9facacc3ed49c2fff797b0410215c31643adf4",
        "created_at": "2022-10-14 03:33:41 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-QKV-interface-to-allocate-output-in-Python",
        "files": [
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "52fb4b729be7fc35e49af12910e38d141c66834d",
        "created_at": "2022-10-16 12:51:26 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-54-set-device-for-multi-GPU-case",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 7,
                "deletions": 0,
                "changes": 7
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 75,
                "deletions": 0,
                "changes": 75
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5badfb78485adf1333f04c46510d99ac56a17622",
        "created_at": "2022-10-13 20:47:54 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-attention-kernel-that-splits-the-batch-into-two",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 20,
                "deletions": 18,
                "changes": 38
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 128,
                "deletions": 10,
                "changes": 138
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 108,
                "deletions": 3,
                "changes": 111
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f515c77f2528b5062ebcc6c905c8817ca0ac0ad1",
        "created_at": "2022-10-09 22:26:22 -0700",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-53-from-robotcator-workflow",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8dd52b078882bca47536951ac773434ccaf54dd8",
        "created_at": "2022-10-06 10:29:38 -0700",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-55-from-ajfadam-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "88dc2040a073b270773a4d2c71d91c78e9d837cb",
        "created_at": "2022-10-04 21:25:37 -0700",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-52-from-bob80333-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4e38df059e911ef3cec872adefbe32779d422e3a",
        "created_at": "2022-10-06 19:17:15 +0200",
        "author": "ajfadam",
        "committer": "web-flow",
        "message": "remove-numpy-dependency",
        "files": [
            {
                "filename": "flash_attn/bert_padding.py",
                "status": "modified",
                "additions": 2,
                "deletions": 4,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2211db5fabbd4e91dd1cb89605ba23762491b949",
        "created_at": "2022-10-04 21:25:46 -0400",
        "author": "bob80333",
        "committer": "bob80333",
        "message": "Fixed-switch-statement-thanks-yocabon",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fp16_switch.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9b1b011bf6fa369bebe9e8fbab4049451b75b931",
        "created_at": "2022-10-03 13:43:51 -0400",
        "author": "bob80333",
        "committer": "bob80333",
        "message": "Add-C-17-arg-to-compiler-since-C-17-features-are-used-fixes-windows-build",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9d7fd5b6e7e9e259514e174b3cc59123d6d748fa",
        "created_at": "2022-10-03 13:42:25 -0400",
        "author": "bob80333",
        "committer": "bob80333",
        "message": "Replace-BOOL_SWITCH-with-FP16_SWITCH-to-work-around-MSVC-bug-with-constexpr-variables-and-templates",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fp16_switch.h",
                "status": "added",
                "additions": 27,
                "deletions": 0,
                "changes": 27
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0c01568dafb316d3673e9dc0fef6dbbd7deabc2d",
        "created_at": "2022-10-04 18:06:08 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Only-run-backward-test-for-d-128-on-A100",
        "files": [
            {
                "filename": "tests/test_flash_attn.py",
                "status": "modified",
                "additions": 10,
                "deletions": 8,
                "changes": 18
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f7e7e912c1afd9569dee95d8e66168f0e186805e",
        "created_at": "2022-09-26 10:57:37 +0800",
        "author": "robotcator",
        "committer": "robotcator",
        "message": "add-publish",
        "files": [
            {
                "filename": ".github/workflows/env.sh",
                "status": "added",
                "additions": 53,
                "deletions": 0,
                "changes": 53
            },
            {
                "filename": ".github/workflows/publish.yml",
                "status": "added",
                "additions": 130,
                "deletions": 0,
                "changes": 130
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2c853fe821df677d35e7e38c0ca0631103568544",
        "created_at": "2022-09-26 10:59:48 +0800",
        "author": "robotcator",
        "committer": "robotcator",
        "message": "add-publish",
        "files": [
            {
                "filename": ".github/workflows/cuda/cu102-Linux-env.sh",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu102-Linux.sh",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": ".github/workflows/cuda/cu113-Linux-env.sh",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu113-Linux.sh",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            },
            {
                "filename": ".github/workflows/cuda/cu116-Linux-env.sh",
                "status": "added",
                "additions": 9,
                "deletions": 0,
                "changes": 9
            },
            {
                "filename": ".github/workflows/cuda/cu116-Linux.sh",
                "status": "added",
                "additions": 15,
                "deletions": 0,
                "changes": 15
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "8166063a556e17e03e4a0697ba604def1eeb6a99",
        "created_at": "2022-09-12 14:21:29 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Use-block_size-128-for-d-128-on-SM86-to-avoid-exceeding-smem-limit",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "64f42cd0576344ad21c178abe2cd58aac4c92e4e",
        "created_at": "2022-09-09 12:06:43 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Change-license-from-Apache-2.0-to-BSD",
        "files": [
            {
                "filename": "AUTHORS",
                "status": "added",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            },
            {
                "filename": "LICENSE",
                "status": "modified",
                "additions": 29,
                "deletions": 201,
                "changes": 230
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "13403e81157ba37ca525890f2f0f2137edf75311",
        "created_at": "2022-09-11 12:09:43 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Relax-assert-to-allow-both-bf16-and-fp16",
        "files": [
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b410d14f28c419fba626ada20781f3677931a63d",
        "created_at": "2022-09-06 17:29:49 -0400",
        "author": "eric-tc-wong",
        "committer": "web-flow",
        "message": "Update-flash_attention.py",
        "files": [
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "19d126102542086ba5dbaee07878220a24c58581",
        "created_at": "2022-08-09 10:14:10 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-back-need_weights-in-FlashMHA",
        "files": [
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "04fb198523a687f8f66e304e8555b3d62cb52a2a",
        "created_at": "2022-09-06 14:37:31 -0700",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-43-from-eric-tc-wong-patch-1",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6cc7342575393568f32c69aba6365e93d7701cbb",
        "created_at": "2022-08-05 09:47:56 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-index_first_axis-with-more-than-2-dimensions",
        "files": [
            {
                "filename": "flash_attn/bert_padding.py",
                "status": "modified",
                "additions": 53,
                "deletions": 14,
                "changes": 67
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4577151ff81fda86a8f7db612eaed0380a211eac",
        "created_at": "2022-07-11 15:57:45 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Link-to-Triton-implementation",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2ed471ecc450801cbe30be2169936a7fe69058c4",
        "created_at": "2022-07-22 17:54:09 -0400",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-tests-for-numerical-error",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "tests/test_flash_attn.py",
                "status": "added",
                "additions": 667,
                "deletions": 0,
                "changes": 667
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "42f54d884053fc0b01eaad9d649c2edb8a17bb75",
        "created_at": "2022-07-11 17:02:29 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Edit-mention-of-Triton-implementation",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "713ea302d7b3a191d200f9cb7fd174a3872a9b92",
        "created_at": "2022-08-05 09:46:08 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Allow-headdim-128-in-FlashMHA-interface",
        "files": [
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 8,
                "deletions": 11,
                "changes": 19
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "bc2c210254dbbe8814498449a562bc1996c5bf7d",
        "created_at": "2022-07-11 10:28:46 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Don-t-nest-BOOL_SWITCH-to-work-around-gcc-7-bug",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 20,
                "deletions": 18,
                "changes": 38
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 18,
                "deletions": 14,
                "changes": 32
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d1fc80a3bb9ba49daafe3ab99323a05c85dacd24",
        "created_at": "2022-07-10 12:10:45 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Link-to-IEEE-Spectrum-article-on-MLPerf",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1bbebccc0a99068a93820c17338ab408609ef6ac",
        "created_at": "2022-07-09 23:34:29 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Edit-README-to-mention-bf16-support",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6a77a6da109a19dc6e9a05b6e12c17f54b4b69b1",
        "created_at": "2022-07-08 15:37:52 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Refactor-gemm_cl-to-template-on-either-__half-or-__nv_bfloat16",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha/gemm.h",
                "status": "modified",
                "additions": 19,
                "deletions": 2,
                "changes": 21
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 12,
                "deletions": 12,
                "changes": 24
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 12,
                "deletions": 12,
                "changes": 24
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "de19de7ab13301e840a8bc483e77be6e424e7b32",
        "created_at": "2022-07-09 18:39:02 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-for-bf16",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 17,
                "deletions": 13,
                "changes": 30
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/src/fmha/kernel_traits.h",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 94,
                "deletions": 92,
                "changes": 186
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 29,
                "deletions": 21,
                "changes": 50
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 122,
                "deletions": 120,
                "changes": 242
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 25,
                "deletions": 12,
                "changes": 37
            },
            {
                "filename": "csrc/flash_attn/src/fmha_utils.h",
                "status": "modified",
                "additions": 9,
                "deletions": 1,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/static_switch.h",
                "status": "added",
                "additions": 25,
                "deletions": 0,
                "changes": 25
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e518a4b327feba519219e54245039e30e846005c",
        "created_at": "2022-07-08 15:18:58 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Refactor-to-template-on-__half-implement-bf16-util-functions",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha/gemm.h",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 5,
                "deletions": 32,
                "changes": 37
            },
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/fmha/softmax.h",
                "status": "modified",
                "additions": 5,
                "deletions": 23,
                "changes": 28
            },
            {
                "filename": "csrc/flash_attn/src/fmha/utils.h",
                "status": "modified",
                "additions": 84,
                "deletions": 25,
                "changes": 109
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 7,
                "deletions": 7,
                "changes": 14
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 3,
                "deletions": 4,
                "changes": 7
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 13,
                "deletions": 14,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 3,
                "deletions": 4,
                "changes": 7
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2dc1b205f609e83712438631c048988cf5ffce42",
        "created_at": "2022-07-09 23:17:14 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-Illegal-Memory-Access-bug-in-fwd-when-d-16",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 15,
                "deletions": 4,
                "changes": 19
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5b838a8bef78186196244a4156ec35bbb58c337d",
        "created_at": "2022-06-29 22:53:11 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Apply-dropout-scaling-to-dQ-and-dK-instead-of-to-V-in-bwd",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 17,
                "deletions": 15,
                "changes": 32
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "af4a9ce02425a2e9e99594d7b322bbf49a24bfbc",
        "created_at": "2022-07-03 02:04:55 -0400",
        "author": "gahdritz",
        "committer": "gahdritz",
        "message": "Add-missing-__init__.py",
        "files": [
            {
                "filename": "flash_attn/__init__.py",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a5559a0e752ec9f8ce7157e1d4db9f08593638c3",
        "created_at": "2022-07-03 17:52:05 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Do-P-dP-pointwise-in-the-bwd-in-fp32-instead-of-fp16",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 19,
                "deletions": 40,
                "changes": 59
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "01947bc93b12e071c0a7f86b4defa9eba49d5a8c",
        "created_at": "2022-07-02 23:33:14 -0700",
        "author": "tridao",
        "committer": "web-flow",
        "message": "Merge-pull-request-18-from-gahdritz-main",
        "files": []
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "6c3a8c65af8c2f2905b60014b4d9cb3d104b90b1",
        "created_at": "2022-06-30 20:26:04 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-cross-attention",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 5,
                "deletions": 4,
                "changes": 9
            },
            {
                "filename": "benchmarks/benchmark_flash_attention.py",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 424,
                "deletions": 273,
                "changes": 697
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 39,
                "deletions": 22,
                "changes": 61
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 13,
                "deletions": 13,
                "changes": 26
            },
            {
                "filename": "csrc/flash_attn/src/fmha/mask.h",
                "status": "modified",
                "additions": 7,
                "deletions": 8,
                "changes": 15
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 6,
                "deletions": 6,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 15,
                "deletions": 15,
                "changes": 30
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 6,
                "deletions": 6,
                "changes": 12
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 10,
                "deletions": 9,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn/src/fmha_blockmask.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 15,
                "deletions": 15,
                "changes": 30
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 15,
                "deletions": 16,
                "changes": 31
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 23,
                "deletions": 23,
                "changes": 46
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 10,
                "deletions": 9,
                "changes": 19
            },
            {
                "filename": "csrc/flash_attn/src/fmha_kernel.h",
                "status": "modified",
                "additions": 9,
                "deletions": 7,
                "changes": 16
            },
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 16,
                "deletions": 12,
                "changes": 28
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 197,
                "deletions": 45,
                "changes": 242
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "440e9c49f261a29ae616f4a1dcf5d46aab346430",
        "created_at": "2022-07-03 02:04:24 -0400",
        "author": "gahdritz",
        "committer": "gahdritz",
        "message": "Add-einops-installation-to-setup.py",
        "files": [
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f66603cb6fa8414705e55985d43672a4a4febbb7",
        "created_at": "2022-06-29 23:16:24 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-batch-size-64K-by-swapping-grid.x-and-grid.y",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 4,
                "deletions": 4,
                "changes": 8
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c0daa62eaafbc59a03ba470a2a05ba8d9d43b1ce",
        "created_at": "2022-06-26 11:41:30 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-type-check-fp16-in-the-forward-pass",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "450b64fe4447d044877a58958a6b08b9b82d21dc",
        "created_at": "2022-06-27 13:50:16 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-README-section-on-issues",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 10,
                "deletions": 0,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ea38d3d26140e261d7616a109c7f924fb5b18bc8",
        "created_at": "2022-06-25 18:02:30 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Fix-race-condition-in-backward-pass-smem_dq",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "eeca63a72a4b0f80e158488cd0ebb040f98ec4bf",
        "created_at": "2022-06-25 15:17:39 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Bug-fix-wrong-smem_o-write-pointer-for-d-16",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "765741c1eeb86c96ee71a3291ad6968cfbf4e4a1",
        "created_at": "2022-06-14 11:55:14 -0700",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "More-explanation",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2d5b2483b8487a8800fe4250d375951f181ab94d",
        "created_at": "2022-06-14 11:54:16 -0700",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "Speedup-graph-for-A100-d128",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 8,
                "deletions": 0,
                "changes": 8
            },
            {
                "filename": "assets/flashattn_speedup_a100_d128.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d3e64409588a243393fa9b7be2045d604efbdfe0",
        "created_at": "2022-06-11 17:51:16 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-bwd-for-head-dim-128",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 12,
                "deletions": 20,
                "changes": 32
            },
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "modified",
                "additions": 20,
                "deletions": 7,
                "changes": 27
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 16,
                "deletions": 2,
                "changes": 18
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 0,
                "deletions": 3,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5d07483bbcce7ee727952a8ea8425aaaecd5a451",
        "created_at": "2022-06-12 16:37:13 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Refactor-Gmem-code-to-store-q-k-v-pointers-separately",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 11,
                "deletions": 5,
                "changes": 16
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 12,
                "deletions": 9,
                "changes": 21
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 37,
                "deletions": 126,
                "changes": 163
            },
            {
                "filename": "csrc/flash_attn/src/fmha/kernel_traits.h",
                "status": "modified",
                "additions": 1,
                "deletions": 3,
                "changes": 4
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 10,
                "deletions": 19,
                "changes": 29
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 7,
                "deletions": 7,
                "changes": 14
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 10,
                "deletions": 19,
                "changes": 29
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0a398dfc37ac6493ee9224b1d974481aeff5bb17",
        "created_at": "2022-06-04 17:28:45 -0700",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "Broken-link",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "f2d8d4104e276f0a9ead015a8f6fdc615a71ad29",
        "created_at": "2022-06-04 16:06:48 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Edit-README-support-Turing-SM75",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "0d854692c60249ed82bcddd1859bd9326eb3eaf1",
        "created_at": "2022-06-05 22:30:09 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Implement-fwd-for-head-dim-128",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "modified",
                "additions": 60,
                "deletions": 5,
                "changes": 65
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 32,
                "deletions": 2,
                "changes": 34
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 11,
                "deletions": 2,
                "changes": 13
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "bd60750e0b0de04c256cdfcdd7b4825a77fe6457",
        "created_at": "2022-06-04 17:27:51 -0700",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "T4",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 20,
                "deletions": 0,
                "changes": 20
            },
            {
                "filename": "assets/flashattn_speedup.jpg",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/flashattn_speedup_3090.jpg",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/flashattn_speedup_t4.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/flashattn_speedup_t4_fwd.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d380e87fb6e784fa2e92a3f596581255450bfc45",
        "created_at": "2022-06-04 16:01:36 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Don-t-use-Smem_dp_sum-in-backward-pass",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 26,
                "deletions": 3,
                "changes": 29
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 30,
                "deletions": 55,
                "changes": 85
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 20,
                "deletions": 5,
                "changes": 25
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "321c57d07de9f525fad46f353ca121411ac22515",
        "created_at": "2022-06-04 16:51:28 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Set-block-size-of-SM75-fwd-to-256-if-there-s-no-dropout",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 14,
                "deletions": 4,
                "changes": 18
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "b17c6fe235b29c091f154c00c526dffa7ec4cce8",
        "created_at": "2022-06-03 16:59:11 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Reduce-smem-usage-for-Q-and-dO-in-the-backward-pass",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "modified",
                "additions": 13,
                "deletions": 3,
                "changes": 16
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "2712aa4c8d6a65b0646c33b088153dbb8a7f963c",
        "created_at": "2022-06-02 16:29:54 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-Turing-mma-instructions",
        "files": [
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 6,
                "deletions": 4,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gemm.h",
                "status": "modified",
                "additions": 61,
                "deletions": 7,
                "changes": 68
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 9,
                "deletions": 6,
                "changes": 15
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "050873327e83f0f84d4f5a37912ed5140d7e9d9f",
        "created_at": "2022-06-02 14:09:46 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Remove-softmax-fp16-max",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha/softmax.h",
                "status": "modified",
                "additions": 5,
                "deletions": 120,
                "changes": 125
            },
            {
                "filename": "csrc/flash_attn/src/fmha/utils.h",
                "status": "modified",
                "additions": 0,
                "deletions": 5,
                "changes": 5
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "14dc326e594d1cc970d5aa2ff93490db61f5e3a7",
        "created_at": "2022-06-02 10:33:32 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Use-Cutlass-gemm-as-WarpMma",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha/gemm.h",
                "status": "modified",
                "additions": 50,
                "deletions": 0,
                "changes": 50
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 12,
                "deletions": 12,
                "changes": 24
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 12,
                "deletions": 12,
                "changes": 24
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e78e7c9553e5008355898e08e0deb0dc855c339a",
        "created_at": "2022-06-02 10:13:44 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Remove-old-backward",
        "files": [
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_512_64_kernel.sm80.cu",
                "status": "removed",
                "additions": 0,
                "deletions": 83,
                "changes": 83
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_reload_recompute.h",
                "status": "removed",
                "additions": 0,
                "deletions": 855,
                "changes": 855
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "ad6c694bb3972ea033118cffdde3dd149d1e2673",
        "created_at": "2022-06-01 20:07:00 -0700",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "3090-speedup",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 15,
                "deletions": 3,
                "changes": 18
            },
            {
                "filename": "assets/flashattn_speedup_3090.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "512c98ee05c6077ba8717b8be4c4f9bde7aa6292",
        "created_at": "2022-06-02 09:50:11 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-Cutlass-as-submodule",
        "files": [
            {
                "filename": ".gitmodules",
                "status": "added",
                "additions": 3,
                "deletions": 0,
                "changes": 3
            },
            {
                "filename": "csrc/flash_attn/cutlass",
                "status": "added",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "5a61cb7729bc4fbc15abed5229c19165abc617be",
        "created_at": "2022-06-01 18:50:26 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Rename-src-flash_attn",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 0,
                "deletions": 1,
                "changes": 1
            },
            {
                "filename": "benchmarks/benchmark_flash_attention.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "benchmarks/utils.py",
                "status": "modified",
                "additions": 26,
                "deletions": 12,
                "changes": 38
            },
            {
                "filename": "flash_attn/bert_padding.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/flash_attention.py",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "flash_attn/flash_attn_interface.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/flash_blocksparse_attention.py",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "flash_attn/flash_blocksparse_attn_interface.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "flash_attn/rotary.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "setup.py",
                "status": "modified",
                "additions": 41,
                "deletions": 20,
                "changes": 61
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "c41479d66db18232768bca28bb68fc6c742685b5",
        "created_at": "2022-06-01 18:49:24 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Support-SM86-GPUs",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 12,
                "deletions": 7,
                "changes": 19
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4b7cfb5f4594135f66278411b038477f2447286b",
        "created_at": "2022-05-30 13:29:04 -0700",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "Citation",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "963173fcb5896e428f743504d95d53dcc2a454d0",
        "created_at": "2022-05-30 11:47:42 -0700",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "Jpg-resolution",
        "files": [
            {
                "filename": "assets/flashattn_banner.jpg",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "cd04d29883a3d3a96609f71cd3ad89a22a3a8ab8",
        "created_at": "2022-05-30 11:46:01 -0700",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "Fix-jpg",
        "files": [
            {
                "filename": "assets/flashattn_banner.jpg",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "a78745189aeb83f47952f16fefd2484a72f279aa",
        "created_at": "2022-05-29 18:15:43 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Add-paper-arXiv-link",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "d9fff84bd0596d1f51de05b5525048655bb86db6",
        "created_at": "2022-05-29 15:42:43 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Edit-roadmap",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 16,
                "deletions": 15,
                "changes": 31
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "e4ffe5d50e04ba2038bd447f7b97f939f66b3d27",
        "created_at": "2022-05-29 15:39:17 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Convert-banner-figure-from-pdf-to-jpg",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2
            },
            {
                "filename": "assets/flashattn_banner.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "4decc3c166df32d3c4b8e02c0d18c6c0786d42c2",
        "created_at": "2022-05-27 22:38:20 +0100",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "README-typo",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "67c3779598c4f32a0fec9c17484910118f2930b8",
        "created_at": "2022-05-29 15:34:22 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Reorganize-directories-add-banner-figure",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 11,
                "deletions": 3,
                "changes": 14
            },
            {
                "filename": "assets/flashattn_banner.pdf",
                "status": "added",
                "additions": 3356,
                "deletions": 0,
                "changes": 3356
            },
            {
                "filename": "assets/flashattn_memory.jpg",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "assets/flashattn_speedup.jpg",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "benchmarks/benchmark_flash_attention.py",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "benchmarks/utils.py",
                "status": "modified",
                "additions": 1,
                "deletions": 21,
                "changes": 22
            },
            {
                "filename": "src/bert_padding.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "src/flash_attention.py",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6
            },
            {
                "filename": "src/flash_attn_interface.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "src/flash_blocksparse_attention.py",
                "status": "modified",
                "additions": 4,
                "deletions": 3,
                "changes": 7
            },
            {
                "filename": "src/flash_blocksparse_attn_interface.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "src/rotary.py",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "7025a092d17b2155c4f2e5c02ed64675fb61dade",
        "created_at": "2022-05-28 22:46:49 +0100",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "Make-png-images-into-jpg-for-dark-mode",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4
            },
            {
                "filename": "images/flashattn_memory.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "images/flashattn_memory.png",
                "status": "removed",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "images/flashattn_speedup.jpg",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "images/flashattn_speedup.png",
                "status": "removed",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "dc6d1300880cbedaf19234fb3fe5b04372f9d0ff",
        "created_at": "2022-05-27 21:59:09 +0100",
        "author": "DanFu09",
        "committer": "DanFu09",
        "message": "Add-speedup-to-README",
        "files": [
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 24,
                "deletions": 0,
                "changes": 24
            },
            {
                "filename": "images/flashattn_memory.png",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "images/flashattn_speedup.png",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "9dbc491aa5063f8d67b5da8692fa0460d2b36229",
        "created_at": "2022-05-26 13:57:38 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "Rename-add-benchmarking-script",
        "files": [
            {
                "filename": "LICENSE",
                "status": "added",
                "additions": 201,
                "deletions": 0,
                "changes": 201
            },
            {
                "filename": "README.md",
                "status": "modified",
                "additions": 32,
                "deletions": 5,
                "changes": 37
            },
            {
                "filename": "benchmarks/benchmark_flash_attention.py",
                "status": "added",
                "additions": 68,
                "deletions": 0,
                "changes": 68
            },
            {
                "filename": "benchmarks/utils.py",
                "status": "added",
                "additions": 135,
                "deletions": 0,
                "changes": 135
            },
            {
                "filename": "csrc/flash_attn/fmha_api.cpp",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/setup.py",
                "status": "modified",
                "additions": 5,
                "deletions": 5,
                "changes": 10
            },
            {
                "filename": "csrc/flash_attn/src/.DS_Store",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gemm.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha/gmem_tile.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha/kernel_traits.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha/mask.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha/smem_tile.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha/softmax.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha/utils.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_blockmask.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_512_64_kernel.sm80.cu",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_dgrad_kernel_1xN_reload_recompute.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_kernel.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/fmha_utils.h",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/flash_attn/src/philox.cuh",
                "status": "modified",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/stream_attn/README.md",
                "status": "removed",
                "additions": 0,
                "deletions": 6,
                "changes": 6
            },
            {
                "filename": "flash_attention.py",
                "status": "modified",
                "additions": 7,
                "deletions": 7,
                "changes": 14
            },
            {
                "filename": "flash_attn_interface.py",
                "status": "modified",
                "additions": 13,
                "deletions": 13,
                "changes": 26
            },
            {
                "filename": "flash_blocksparse_attention.py",
                "status": "modified",
                "additions": 9,
                "deletions": 9,
                "changes": 18
            },
            {
                "filename": "flash_blocksparse_attn_interface.py",
                "status": "modified",
                "additions": 13,
                "deletions": 13,
                "changes": 26
            }
        ]
    },
    {
        "repo": "PaddlePaddle/flash-attention",
        "sha": "1fcbe6f0d088d807ba585ddb850eb3497cd7b65b",
        "created_at": "2022-05-20 14:21:58 -0700",
        "author": "tridao",
        "committer": "tridao",
        "message": "First-release",
        "files": [
            {
                "filename": "README.md",
                "status": "added",
                "additions": 11,
                "deletions": 0,
                "changes": 11
            },
            {
                "filename": "bert_padding.py",
                "status": "added",
                "additions": 95,
                "deletions": 0,
                "changes": 95
            },
            {
                "filename": "csrc/stream_attn/README.md",
                "status": "added",
                "additions": 6,
                "deletions": 0,
                "changes": 6
            },
            {
                "filename": "csrc/stream_attn/fmha_api.cpp",
                "status": "added",
                "additions": 567,
                "deletions": 0,
                "changes": 567
            },
            {
                "filename": "csrc/stream_attn/setup.py",
                "status": "added",
                "additions": 147,
                "deletions": 0,
                "changes": 147
            },
            {
                "filename": "csrc/stream_attn/src/.DS_Store",
                "status": "added",
                "additions": 0,
                "deletions": 0,
                "changes": 0
            },
            {
                "filename": "csrc/stream_attn/src/fmha.h",
                "status": "added",
                "additions": 174,
                "deletions": 0,
                "changes": 174
            },
            {
                "filename": "csrc/stream_attn/src/fmha/gemm.h",
                "status": "added",
                "additions": 329,
                "deletions": 0,
                "changes": 329
            },
            {
                "filename": "csrc/stream_attn/src/fmha/gmem_tile.h",
                "status": "added",
                "additions": 642,
                "deletions": 0,
                "changes": 642
            },
            {
                "filename": "csrc/stream_attn/src/fmha/kernel_traits.h",
                "status": "added",
                "additions": 108,
                "deletions": 0,
                "changes": 108
            },
            {
                "filename": "csrc/stream_attn/src/fmha/mask.h",
                "status": "added",
                "additions": 90,
                "deletions": 0,
                "changes": 90
            },
            {
                "filename": "csrc/stream_attn/src/fmha/smem_tile.h",
                "status": "added",
                "additions": 1610,
                "deletions": 0,
                "changes": 1610
            },
            {
                "filename": "csrc/stream_attn/src/fmha/softmax.h",
                "status": "added",
                "additions": 772,
                "deletions": 0,
                "changes": 772
            },
            {
                "filename": "csrc/stream_attn/src/fmha/utils.h",
                "status": "added",
                "additions": 1161,
                "deletions": 0,
                "changes": 1161
            },
            {
                "filename": "csrc/stream_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "added",
                "additions": 64,
                "deletions": 0,
                "changes": 64
            },
            {
                "filename": "csrc/stream_attn/src/fmha_block_dgrad_kernel_1xN_loop.h",
                "status": "added",
                "additions": 772,
                "deletions": 0,
                "changes": 772
            },
            {
                "filename": "csrc/stream_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu",
                "status": "added",
                "additions": 90,
                "deletions": 0,
                "changes": 90
            },
            {
                "filename": "csrc/stream_attn/src/fmha_block_fprop_kernel_1xN.h",
                "status": "added",
                "additions": 528,
                "deletions": 0,
                "changes": 528
            },
            {
                "filename": "csrc/stream_attn/src/fmha_blockmask.h",
                "status": "added",
                "additions": 57,
                "deletions": 0,
                "changes": 57
            },
            {
                "filename": "csrc/stream_attn/src/fmha_dgrad_fp16_512_64_kernel.sm80.cu",
                "status": "added",
                "additions": 83,
                "deletions": 0,
                "changes": 83
            },
            {
                "filename": "csrc/stream_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu",
                "status": "added",
                "additions": 92,
                "deletions": 0,
                "changes": 92
            },
            {
                "filename": "csrc/stream_attn/src/fmha_dgrad_kernel_1xN_loop.h",
                "status": "added",
                "additions": 734,
                "deletions": 0,
                "changes": 734
            },
            {
                "filename": "csrc/stream_attn/src/fmha_dgrad_kernel_1xN_reload_recompute.h",
                "status": "added",
                "additions": 855,
                "deletions": 0,
                "changes": 855
            },
            {
                "filename": "csrc/stream_attn/src/fmha_fprop_fp16_kernel.sm80.cu",
                "status": "added",
                "additions": 126,
                "deletions": 0,
                "changes": 126
            },
            {
                "filename": "csrc/stream_attn/src/fmha_fprop_kernel_1xN.h",
                "status": "added",
                "additions": 646,
                "deletions": 0,
                "changes": 646
            },
            {
                "filename": "csrc/stream_attn/src/fmha_kernel.h",
                "status": "added",
                "additions": 179,
                "deletions": 0,
                "changes": 179
            },
            {
                "filename": "csrc/stream_attn/src/fmha_utils.h",
                "status": "added",
                "additions": 92,
                "deletions": 0,
                "changes": 92
            },
            {
                "filename": "csrc/stream_attn/src/philox.cuh",
                "status": "added",
                "additions": 144,
                "deletions": 0,
                "changes": 144
            },
            {
                "filename": "rotary.py",
                "status": "added",
                "additions": 135,
                "deletions": 0,
                "changes": 135
            },
            {
                "filename": "stream_attn_interface.py",
                "status": "added",
                "additions": 100,
                "deletions": 0,
                "changes": 100
            },
            {
                "filename": "stream_blocksparse_attn_interface.py",
                "status": "added",
                "additions": 142,
                "deletions": 0,
                "changes": 142
            },
            {
                "filename": "streaming_attention.py",
                "status": "added",
                "additions": 114,
                "deletions": 0,
                "changes": 114
            },
            {
                "filename": "streaming_blocksparse_attention.py",
                "status": "added",
                "additions": 135,
                "deletions": 0,
                "changes": 135
            }
        ]
    }
]